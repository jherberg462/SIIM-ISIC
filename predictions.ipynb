{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:15.838633Z",
     "iopub.status.busy": "2020-08-07T06:41:15.837708Z",
     "iopub.status.idle": "2020-08-07T06:41:27.075697Z",
     "shell.execute_reply": "2020-08-07T06:41:27.074823Z"
    },
    "papermill": {
     "duration": 11.273571,
     "end_time": "2020-08-07T06:41:27.075865",
     "exception": false,
     "start_time": "2020-08-07T06:41:15.802294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got GCS path via KaggleDatasets .get_gcs_path method\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "try:\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "    dataset_gcs = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n",
    "    print('got GCS path via KaggleDatasets .get_gcs_path method')\n",
    "except ModuleNotFoundError:\n",
    "    #hardcode path while testing locally\n",
    "    dataset_gcs = 'gs://'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:27.132090Z",
     "iopub.status.busy": "2020-08-07T06:41:27.131051Z",
     "iopub.status.idle": "2020-08-07T06:41:27.136773Z",
     "shell.execute_reply": "2020-08-07T06:41:27.137393Z"
    },
    "papermill": {
     "duration": 0.037595,
     "end_time": "2020-08-07T06:41:27.137606",
     "exception": false,
     "start_time": "2020-08-07T06:41:27.100011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:27.186972Z",
     "iopub.status.busy": "2020-08-07T06:41:27.186120Z",
     "iopub.status.idle": "2020-08-07T06:41:27.189535Z",
     "shell.execute_reply": "2020-08-07T06:41:27.190190Z"
    },
    "papermill": {
     "duration": 0.032708,
     "end_time": "2020-08-07T06:41:27.190411",
     "exception": false,
     "start_time": "2020-08-07T06:41:27.157703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size' : 128,\n",
    "    'img_size' : [256, 256],\n",
    "    'epochs': 155\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:27.254443Z",
     "iopub.status.busy": "2020-08-07T06:41:27.243828Z",
     "iopub.status.idle": "2020-08-07T06:41:32.022740Z",
     "shell.execute_reply": "2020-08-07T06:41:32.021982Z"
    },
    "papermill": {
     "duration": 4.810568,
     "end_time": "2020-08-07T06:41:32.022925",
     "exception": false,
     "start_time": "2020-08-07T06:41:27.212357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:32.073575Z",
     "iopub.status.busy": "2020-08-07T06:41:32.072310Z",
     "iopub.status.idle": "2020-08-07T06:41:32.077251Z",
     "shell.execute_reply": "2020-08-07T06:41:32.076331Z"
    },
    "papermill": {
     "duration": 0.033057,
     "end_time": "2020-08-07T06:41:32.077414",
     "exception": false,
     "start_time": "2020-08-07T06:41:32.044357",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params['batch_size'] = params['batch_size'] * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:32.129589Z",
     "iopub.status.busy": "2020-08-07T06:41:32.128470Z",
     "iopub.status.idle": "2020-08-07T06:41:32.132401Z",
     "shell.execute_reply": "2020-08-07T06:41:32.131662Z"
    },
    "papermill": {
     "duration": 0.032132,
     "end_time": "2020-08-07T06:41:32.132564",
     "exception": false,
     "start_time": "2020-08-07T06:41:32.100432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub = pd.read_csv(dataset_gcs + '/sample_submission.csv')\n",
    "# sub.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:32.185376Z",
     "iopub.status.busy": "2020-08-07T06:41:32.184473Z",
     "iopub.status.idle": "2020-08-07T06:41:41.862872Z",
     "shell.execute_reply": "2020-08-07T06:41:41.863962Z"
    },
    "papermill": {
     "duration": 9.710107,
     "end_time": "2020-08-07T06:41:41.864279",
     "exception": false,
     "start_time": "2020-08-07T06:41:32.154172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32542</td>\n",
       "      <td>32542</td>\n",
       "      <td>32477</td>\n",
       "      <td>32474</td>\n",
       "      <td>32024</td>\n",
       "      <td>32542</td>\n",
       "      <td>32542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>575</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name  patient_id    sex  age_approx  \\\n",
       "target                                              \n",
       "0            32542       32542  32477       32474   \n",
       "1              584         584    584         584   \n",
       "\n",
       "        anatom_site_general_challenge  diagnosis  benign_malignant  \n",
       "target                                                              \n",
       "0                               32024      32542             32542  \n",
       "1                                 575        584               584  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(dataset_gcs + '/train.csv')\n",
    "train_df.groupby('target').count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:41.946551Z",
     "iopub.status.busy": "2020-08-07T06:41:41.945650Z",
     "iopub.status.idle": "2020-08-07T06:41:41.950049Z",
     "shell.execute_reply": "2020-08-07T06:41:41.948981Z"
    },
    "papermill": {
     "duration": 0.049705,
     "end_time": "2020-08-07T06:41:41.950263",
     "exception": false,
     "start_time": "2020-08-07T06:41:41.900558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image_label(tfrec):\n",
    "    '''\n",
    "    function to decode an image and target label from tfrecord\n",
    "    \n",
    "    args:\n",
    "        tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "    returns:\n",
    "        decoded_image: tensor, converted image from tfrecord\n",
    "        label: tensor, integer, either 1 or 0\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "    decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "    decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "    label = features['target']\n",
    "    \n",
    "    return decoded_image, label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:42.011883Z",
     "iopub.status.busy": "2020-08-07T06:41:42.010666Z",
     "iopub.status.idle": "2020-08-07T06:41:42.013715Z",
     "shell.execute_reply": "2020-08-07T06:41:42.014624Z"
    },
    "papermill": {
     "duration": 0.04148,
     "end_time": "2020-08-07T06:41:42.014884",
     "exception": false,
     "start_time": "2020-08-07T06:41:41.973404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(tfrec):\n",
    "    '''\n",
    "    function to decode an image from tfrecord\n",
    "    \n",
    "    args:\n",
    "        tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "    returns:\n",
    "        decoded_image: tensor, converted image from tfrecord\n",
    "        img_name: tensor, string, Id of the decoded image\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "    features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "    decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "    decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "    img_name = features['image_name']\n",
    "    \n",
    "    return decoded_image, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:42.077558Z",
     "iopub.status.busy": "2020-08-07T06:41:42.076300Z",
     "iopub.status.idle": "2020-08-07T06:41:42.080522Z",
     "shell.execute_reply": "2020-08-07T06:41:42.079515Z"
    },
    "papermill": {
     "duration": 0.03621,
     "end_time": "2020-08-07T06:41:42.080728",
     "exception": false,
     "start_time": "2020-08-07T06:41:42.044518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image_label(decoded_image, label):\n",
    "    '''\n",
    "    function to convert an image tensor values from 0 to 255 \n",
    "    -> -1 to 1\n",
    "    to be used when dealing with tfrecords containing labels\n",
    "    \n",
    "    args:\n",
    "        decoded_image: tensor that is an image with values from 0 to 255\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image_tensor: tensor that is an image with values from -1 to 1\n",
    "        label, same as input\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "    image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "    #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "    image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "    #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "    image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "    return image_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:42.153096Z",
     "iopub.status.busy": "2020-08-07T06:41:42.151669Z",
     "iopub.status.idle": "2020-08-07T06:41:42.156791Z",
     "shell.execute_reply": "2020-08-07T06:41:42.155909Z"
    },
    "papermill": {
     "duration": 0.04072,
     "end_time": "2020-08-07T06:41:42.156974",
     "exception": false,
     "start_time": "2020-08-07T06:41:42.116254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image(decoded_image):\n",
    "    '''\n",
    "    function to convert an image tensor values from 0 to 255 \n",
    "    -> -1 to 1\n",
    "    \n",
    "    args:\n",
    "        decoded_image: tensor that is an image with values from 0 to 255\n",
    "    \n",
    "    returns: \n",
    "        image_tensor: tensor that is an image with values from -1 to 1\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "    image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "    #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "    image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "    #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "    image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:42.213695Z",
     "iopub.status.busy": "2020-08-07T06:41:42.212720Z",
     "iopub.status.idle": "2020-08-07T06:41:42.217166Z",
     "shell.execute_reply": "2020-08-07T06:41:42.216329Z"
    },
    "papermill": {
     "duration": 0.0368,
     "end_time": "2020-08-07T06:41:42.217315",
     "exception": false,
     "start_time": "2020-08-07T06:41:42.180515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_flip(image, label):\n",
    "    '''\n",
    "    function to randomly flip images on the x and/or y axis\n",
    "    \n",
    "    args:\n",
    "        image: tensor, an image\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image: tensor, same as input, but possibly flipped on x and/or y axis\n",
    "        label, tensor, same as input\n",
    "    '''\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image, label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:42.277822Z",
     "iopub.status.busy": "2020-08-07T06:41:42.276603Z",
     "iopub.status.idle": "2020-08-07T06:41:42.280873Z",
     "shell.execute_reply": "2020-08-07T06:41:42.280104Z"
    },
    "papermill": {
     "duration": 0.040036,
     "end_time": "2020-08-07T06:41:42.281032",
     "exception": false,
     "start_time": "2020-08-07T06:41:42.240996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_ds(tfrecords, batch_size):\n",
    "    '''\n",
    "    function to create a ds pipeline from tfrecord files\n",
    "    \n",
    "    args:\n",
    "        tfrecords: list, tfrecord file paths\n",
    "        batch_size: int, batch size for number of records to pass into\n",
    "            model at a time\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images and labels\n",
    "    '''\n",
    "    ds = (tf.data.TFRecordDataset(filenames=[tfrecords],\n",
    "                                 num_parallel_reads=tf.data.experimental.AUTOTUNE).\n",
    "#           cache(). #need to remove cache while not usnig TPUs\n",
    "          map(decode_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(normalize_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(random_flip, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          repeat().\n",
    "          shuffle(512).\n",
    "          batch(batch_size,\n",
    "               drop_remainder=True).\n",
    "          prefetch(tf.data.experimental.AUTOTUNE)\n",
    "         )\n",
    "    \n",
    "\n",
    "    \n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:42.338994Z",
     "iopub.status.busy": "2020-08-07T06:41:42.337720Z",
     "iopub.status.idle": "2020-08-07T06:41:42.341831Z",
     "shell.execute_reply": "2020-08-07T06:41:42.342436Z"
    },
    "papermill": {
     "duration": 0.038239,
     "end_time": "2020-08-07T06:41:42.342758",
     "exception": false,
     "start_time": "2020-08-07T06:41:42.304519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_ds(tfrecords, batch_size):\n",
    "    '''\n",
    "    function to create a dataset for test data\n",
    "    args:\n",
    "        tfrecords: list, tfrecord file paths\n",
    "        batch_size: int, batch size for number of records to pass into\n",
    "            model at a time\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images and labels\n",
    "    \n",
    "    '''\n",
    "\n",
    "    ds = (tf.data.TFRecordDataset(filenames=[tfrecords],\n",
    "                                 num_parallel_reads=tf.data.experimental.AUTOTUNE).\n",
    "#           cache(). #there is no reason to cache this ds -- it is only being read 1x\n",
    "          map(decode_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(normalize_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "#           map(random_flip).\n",
    "          batch(batch_size).\n",
    "#                 drop_remainder=True).\n",
    "          prefetch(tf.data.experimental.AUTOTUNE)\n",
    "         )\n",
    "    \n",
    "    return ds\n",
    "    ###come back to this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.024317,
     "end_time": "2020-08-07T06:41:42.392592",
     "exception": false,
     "start_time": "2020-08-07T06:41:42.368275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:42.459695Z",
     "iopub.status.busy": "2020-08-07T06:41:42.458502Z",
     "iopub.status.idle": "2020-08-07T06:41:42.463012Z",
     "shell.execute_reply": "2020-08-07T06:41:42.462234Z"
    },
    "papermill": {
     "duration": 0.046243,
     "end_time": "2020-08-07T06:41:42.463162",
     "exception": false,
     "start_time": "2020-08-07T06:41:42.416919",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_of_layers(input_layer, \n",
    "                  filters_, \n",
    "                  kernal, \n",
    "                  strides_, \n",
    "                  dense=None, \n",
    "                  dense_activation=None,\n",
    "                  dropout=None,\n",
    "                  cnn_activation=None):\n",
    "    '''\n",
    "    function to add the following layers to a model:\n",
    "    Conv2D, MaxPooling2D, BatchNormalization, LeadyReLU, Dense,\n",
    "        Dropout\n",
    "\n",
    "    args:\n",
    "      input_layer : input layer to be fed into above layers\n",
    "      filters_: int, number of filters in Conv2D layer\n",
    "      kernal: int, kernal size in Conv2D layer\n",
    "      strides_: int, stride size in MaxPooling2D layer\n",
    "      dense: int, number of units in dense layer, default is None\n",
    "          Will only add layer if value is passed\n",
    "      dense_activation: str, activation function to pass into Dense layer\n",
    "          default is None\n",
    "      dropout: float, dropout percentage in Dropout layer, default is None\n",
    "        must be less than 1.0. Will only add layer if value is passed \n",
    "      cnn_activation: tensorflow activation layer, default is None\n",
    "          will only add layer is value is passed. Activation layer will be\n",
    "          added after the BatchNormalization layer\n",
    "\n",
    "    returns:\n",
    "      x: model that is the same as the input_layer input plus above \n",
    "        layers added\n",
    "    '''\n",
    "    x = layers.Conv2D(filters_, (kernal, kernal), padding='same')(input_layer)\n",
    "    x = layers.MaxPooling2D(strides_, strides_)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if cnn_activation:\n",
    "        x = cnn_activation(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    if dense:\n",
    "        x = layers.Dense(dense, activation=dense_activation)(x)\n",
    "    if dropout:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:42.522527Z",
     "iopub.status.busy": "2020-08-07T06:41:42.521264Z",
     "iopub.status.idle": "2020-08-07T06:41:42.525154Z",
     "shell.execute_reply": "2020-08-07T06:41:42.524442Z"
    },
    "papermill": {
     "duration": 0.039051,
     "end_time": "2020-08-07T06:41:42.525327",
     "exception": false,
     "start_time": "2020-08-07T06:41:42.486276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deconv_set_of_layers(input_layer, \n",
    "                         filters_, \n",
    "                         kernal_, \n",
    "                         stride, \n",
    "                         dense=None, \n",
    "                         dense_activation=None, \n",
    "                         dropout=None,\n",
    "                         cnn_activation=None):\n",
    "    '''\n",
    "    function to add the following layers to a model:\n",
    "    Conv2DTranspose, BatchNormalization, LeadyReLU, Dense\n",
    "\n",
    "    args:\n",
    "      input_layer : input layer to be fed into above layers\n",
    "      filters_: int, number of filters in Conv2DTranspose layer\n",
    "      kernal_: int, kernal size in Conv2DTranspose layer\n",
    "      strides_: int, stride size in Conv2DTranspose layer\n",
    "      dense: int, number of units in dense layer, default is None\n",
    "          Will only add layer if value is passed\n",
    "      dense_activation: str, activation function to pass into Dense layer\n",
    "          default is None\n",
    "      dropout: float, dropout percentage in Dropout layer, default is None\n",
    "        must be less than 1.0. Will only add layer if value is passed \n",
    "      cnn_activation: tensorflow activation layer, default is None\n",
    "          will only add layer is value is passed. Activation layer will be\n",
    "          added after the BatchNormalization layer\n",
    "\n",
    "\n",
    "    returns:\n",
    "      x: model that is the same as the input_layer input plus above \n",
    "        layers added\n",
    "    '''\n",
    "    \n",
    "    x = layers.Conv2DTranspose(filters_,\n",
    "                              kernal_,\n",
    "                              (stride, stride),\n",
    "                              padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    if cnn_activation:\n",
    "        x = cnn_activation(x)\n",
    "   \n",
    "    if dense:\n",
    "        x = layers.Dense(dense, activation=dense_activation)(x)\n",
    "    \n",
    "    if dropout:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:42.586837Z",
     "iopub.status.busy": "2020-08-07T06:41:42.582054Z",
     "iopub.status.idle": "2020-08-07T06:41:42.605979Z",
     "shell.execute_reply": "2020-08-07T06:41:42.605134Z"
    },
    "papermill": {
     "duration": 0.057249,
     "end_time": "2020-08-07T06:41:42.606127",
     "exception": false,
     "start_time": "2020-08-07T06:41:42.548878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape=[*params['img_size'], 3], bias_output=None):\n",
    "    '''\n",
    "    function to create a model that will be trained on train DS\n",
    "    \n",
    "    args:\n",
    "        input_shape: array, default: [1024, 1024, 3], shape\n",
    "            of input tensor that will be fed into model\n",
    "    \n",
    "    returns:\n",
    "        model: tf.sequential() model\n",
    "    '''\n",
    "\n",
    "    relu = layers.ReLU()\n",
    "    leakyrelu = layers.LeakyReLU()\n",
    "    input_tensor = layers.Input(shape=input_shape, name='images_input')\n",
    "    x = input_tensor\n",
    "    filters_list = [32, 128, 256, 512, 1024]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x1 = set_of_layers(x, filter_, 5, 2, 16, 'tanh', dropout=0.35, cnn_activation=relu)\n",
    "        x2 = set_of_layers(x, filter_, 5, 2, 16, 'tanh', dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "        x = layers.Concatenate()([x1, x2])\n",
    "        x = layers.Dense(filter_)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    \n",
    "    filters_list = [256, 128, 64]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x1 = deconv_set_of_layers(x, filter_, 4, 2, 16, 'tanh', dropout=0.35, cnn_activation=relu)\n",
    "        x2= deconv_set_of_layers(x, filter_, 4, 2, 16, 'tanh', dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = deconv_set_of_layers(x, filter_, 4, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = deconv_set_of_layers(x, filter_, 4, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "        x = layers.Concatenate()([x1, x2])\n",
    "        x = layers.Dense(filter_)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        \n",
    "    \n",
    "    filters_list = [64, 128, 256]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x1 = set_of_layers(x, filter_, 5, 2, 16, 'tanh', dropout=0.35, cnn_activation=relu)\n",
    "        x2 = set_of_layers(x, filter_, 5, 2, 16, 'tanh', dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "        x = layers.Concatenate()([x1, x2])\n",
    "        x = layers.Dense(filter_)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "    \n",
    "\n",
    "    #layers.Concatenate\n",
    "\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "#     model.add(layers.Dense(64))\n",
    "    \n",
    "    if bias_output is not None:\n",
    "        bias_output = tf.keras.initializers.Constant(bias_output)\n",
    "    output_layer = layers.Dense(1, activation='sigmoid', bias_initializer=bias_output)(x)\n",
    "    \n",
    "    model=keras.Model(inputs=[input_tensor],\n",
    "                     outputs=[output_layer])\n",
    "\n",
    " \n",
    "           \n",
    "    metrics = [\n",
    "          keras.metrics.TruePositives(name='tp'),\n",
    "#           keras.metrics.FalsePositives(name='fp'),\n",
    "#           keras.metrics.TrueNegatives(name='tn'),\n",
    "          keras.metrics.FalseNegatives(name='fn'), \n",
    "          keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#           keras.metrics.Precision(name='precision'),\n",
    "#           keras.metrics.Recall(name='recall'),\n",
    "          keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "    schedule = None\n",
    "    \n",
    "    model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.0004),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.01),\n",
    "    metrics=metrics\n",
    ")\n",
    "    \n",
    "\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:42.662720Z",
     "iopub.status.busy": "2020-08-07T06:41:42.661839Z",
     "iopub.status.idle": "2020-08-07T06:41:42.665347Z",
     "shell.execute_reply": "2020-08-07T06:41:42.664683Z"
    },
    "papermill": {
     "duration": 0.035829,
     "end_time": "2020-08-07T06:41:42.665492",
     "exception": false,
     "start_time": "2020-08-07T06:41:42.629663",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ds_size(files):\n",
    "    '''\n",
    "    function to get size of tfrecord Dataset, based on file name\n",
    "    \n",
    "    the file name has the number of records in the file, for example:\n",
    "    train09-2071.tfrec has 2017 records\n",
    "    \n",
    "    args:\n",
    "        files: list of str file names, each item should be the path to a tfrecord file\n",
    "    \n",
    "    returns:\n",
    "        size: int, size of dataset\n",
    "    '''\n",
    "    size = 0\n",
    "    for file in files:\n",
    "        file_size = int(file.split('.tfrec')[0].split('tfrecords/')[1].split('-')[1])\n",
    "        size += file_size\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:43.017444Z",
     "iopub.status.busy": "2020-08-07T06:41:43.016381Z",
     "iopub.status.idle": "2020-08-07T06:41:43.823594Z",
     "shell.execute_reply": "2020-08-07T06:41:43.822856Z"
    },
    "papermill": {
     "duration": 1.133988,
     "end_time": "2020-08-07T06:41:43.823865",
     "exception": false,
     "start_time": "2020-08-07T06:41:42.689877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get test file paths\n",
    "test_files = tf.io.gfile.glob(dataset_gcs + '/tfrecords/test*.tfrec')\n",
    "\n",
    "#get train and validation file paths\n",
    "train_files, valid_files = train_test_split(tf.io.gfile.glob(dataset_gcs + '/tfrecords/train*.tfrec'),\n",
    "                              test_size=.1, random_state=1)\n",
    "\n",
    "#create datasets\n",
    "train_ds = get_train_ds(train_files, params['batch_size'])\n",
    "valid_ds = get_train_ds(valid_files, params['batch_size'])\n",
    "test_ds = get_test_ds(test_files, params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:43.881270Z",
     "iopub.status.busy": "2020-08-07T06:41:43.880026Z",
     "iopub.status.idle": "2020-08-07T06:41:43.884990Z",
     "shell.execute_reply": "2020-08-07T06:41:43.884251Z"
    },
    "papermill": {
     "duration": 0.037445,
     "end_time": "2020-08-07T06:41:43.885137",
     "exception": false,
     "start_time": "2020-08-07T06:41:43.847692",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset consists of: 28984 training images, 4142 validation images, and 10982 test images\n"
     ]
    }
   ],
   "source": [
    "train_size, valid_size = get_ds_size(train_files), get_ds_size(valid_files)\n",
    "test_size = get_ds_size(test_files)\n",
    "print('the dataset consists of: {} training images, {} validation images, and {} test images'.\n",
    "     format(train_size, valid_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.027473,
     "end_time": "2020-08-07T06:41:43.937573",
     "exception": false,
     "start_time": "2020-08-07T06:41:43.910100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:43.995524Z",
     "iopub.status.busy": "2020-08-07T06:41:43.994347Z",
     "iopub.status.idle": "2020-08-07T06:41:43.998394Z",
     "shell.execute_reply": "2020-08-07T06:41:43.997619Z"
    },
    "papermill": {
     "duration": 0.035211,
     "end_time": "2020-08-07T06:41:43.998533",
     "exception": false,
     "start_time": "2020-08-07T06:41:43.963322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch_steps = train_size / params['batch_size'] \n",
    "valid_steps = valid_size / params['batch_size']\n",
    "test_steps = 1.0 * test_size / params['batch_size'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:44.058987Z",
     "iopub.status.busy": "2020-08-07T06:41:44.058153Z",
     "iopub.status.idle": "2020-08-07T06:41:44.091608Z",
     "shell.execute_reply": "2020-08-07T06:41:44.090871Z"
    },
    "papermill": {
     "duration": 0.069197,
     "end_time": "2020-08-07T06:41:44.091770",
     "exception": false,
     "start_time": "2020-08-07T06:41:44.022573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate class weights\n",
    "\n",
    "targets = train_df.groupby('target').count()['diagnosis'].to_list()\n",
    "target_0 = targets[0]\n",
    "target_1 = targets[1]\n",
    "total = target_0 + target_1\n",
    "\n",
    "class_weight_0 = (1 / target_0) * (total) / 2.0\n",
    "class_weight_1 = (1 / target_1) * (total) / 2.0\n",
    "\n",
    "class_weights = {0: class_weight_0, 1: class_weight_1}\n",
    "\n",
    "initial_bias = np.log([target_1 / target_0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.024706,
     "end_time": "2020-08-07T06:41:44.142688",
     "exception": false,
     "start_time": "2020-08-07T06:41:44.117982",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:44.202728Z",
     "iopub.status.busy": "2020-08-07T06:41:44.201080Z",
     "iopub.status.idle": "2020-08-07T06:41:56.179142Z",
     "shell.execute_reply": "2020-08-07T06:41:56.180273Z"
    },
    "papermill": {
     "duration": 12.011994,
     "end_time": "2020-08-07T06:41:56.180590",
     "exception": false,
     "start_time": "2020-08-07T06:41:44.168596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "images_input (InputLayer)       [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 32) 2432        images_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 2432        images_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 32) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 32) 128         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 32) 128         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "                                                                 batch_normalization_24[0][0]     \n",
      "                                                                 batch_normalization_27[0][0]     \n",
      "                                                                 batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         multiple             0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "                                                                 batch_normalization_22[0][0]     \n",
      "                                                                 batch_normalization_25[0][0]     \n",
      "                                                                 batch_normalization_28[0][0]     \n",
      "                                                                 batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 128, 128, 32) 0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 128, 128, 32) 0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128, 128, 16) 528         re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 128, 16) 528         re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128, 128, 16) 0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 128, 16) 0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, 128, 32) 0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128, 128, 32) 1056        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 128, 128, 32) 128         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 102528      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 102528      batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 64, 64, 128)  512         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 64, 64, 128)  0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 64, 64, 128)  0           leaky_re_lu[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64, 64, 16)   2064        re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 64, 64, 16)   2064        re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 64, 16)   0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64, 64, 16)   0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 32)   0           dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 64, 64, 128)  4224        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 64, 64, 128)  512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  819456      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  819456      batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 32, 32, 256)  1024        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 32, 32, 256)  0           re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 32, 32, 256)  0           leaky_re_lu[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32, 32, 16)   4112        re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 32, 32, 16)   4112        re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 16)   0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 16)   0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 32)   0           dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32, 32, 256)  8448        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 512)  3277312     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  3277312     batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 512)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 512)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 16, 16, 512)  2048        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 512)  2048        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 16, 16, 512)  0           re_lu[3][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 16, 16, 512)  0           leaky_re_lu[3][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16, 16, 16)   8208        re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16, 16, 16)   8208        re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 16, 16)   0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16, 16, 16)   0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 32)   0           dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16, 16, 512)  16896       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 512)  2048        dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 1024) 13108224    batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 13108224    batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 1024)   4096        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 1024)   4096        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 8, 8, 1024)   0           re_lu[4][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 8, 8, 1024)   0           leaky_re_lu[4][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 8, 8, 16)     16400       re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 8, 8, 16)     16400       re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 8, 8, 16)     0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 8, 8, 16)     0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 32)     0           dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 8, 8, 1024)   33792       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 8, 8, 1024)   4096        dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 16, 16, 256)  4194560     batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 256)  4194560     batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 16, 16, 256)  1024        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 256)  1024        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 16, 16, 16)   4112        re_lu[5][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 16, 16, 16)   4112        leaky_re_lu[5][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16, 16, 16)   0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16, 16, 16)   0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 32)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 16, 16, 256)  8448        concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 16, 16, 256)  1024        dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 128)  524416      batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 32, 32, 128)  524416      batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 128)  512         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 32, 32, 128)  512         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 32, 32, 16)   2064        re_lu[6][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 32, 32, 16)   2064        leaky_re_lu[6][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 16)   0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 32, 16)   0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 32)   0           dropout_12[0][0]                 \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 32, 32, 128)  4224        concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 32, 32, 128)  512         dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 64, 64, 64)   131136      batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 64)   131136      batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 64, 64, 64)   256         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 64, 64, 64)   256         conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64, 64, 16)   1040        re_lu[7][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 64, 64, 16)   1040        leaky_re_lu[7][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64, 64, 16)   0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 64, 64, 16)   0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 32)   0           dropout_14[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 64, 64, 64)   2112        concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 64, 64, 64)   256         dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 64)   102464      batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 64)   102464      batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 32, 32, 64)   256         max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 32, 32, 64)   256         max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 32, 32, 64)   0           re_lu[8][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 32, 32, 64)   0           leaky_re_lu[8][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 32, 32, 16)   1040        re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 32, 32, 16)   1040        re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 16)   0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 32, 32, 16)   0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 32)   0           dropout_16[0][0]                 \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 32, 32, 64)   2112        concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 32, 32, 64)   256         dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 128)  204928      batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 128)  204928      batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 16, 16, 128)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 16, 16, 128)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 16, 16, 128)  512         max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 16, 16, 128)  512         max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 16, 16, 128)  0           re_lu[9][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 16, 16, 128)  0           leaky_re_lu[9][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 16, 16, 16)   2064        re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 16, 16, 16)   2064        re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 16)   0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 16)   0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 32)   0           dropout_18[0][0]                 \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 16, 16, 128)  4224        concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 16, 16, 128)  512         dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 256)  819456      batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 256)  819456      batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 8, 8, 256)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 8, 8, 256)    0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 8, 8, 256)    1024        max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 8, 8, 256)    1024        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 8, 8, 256)    0           re_lu[10][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 8, 8, 256)    0           leaky_re_lu[10][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 8, 8, 16)     4112        re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 8, 8, 16)     4112        re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 8, 8, 16)     0           dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 8, 8, 16)     0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 8, 8, 32)     0           dropout_20[0][0]                 \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 8, 8, 256)    8448        concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 8, 8, 256)    1024        dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 16384)        0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 128)          2097280     flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 1)            129         dense_33[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 48,890,881\n",
      "Trainable params: 48,873,793\n",
      "Non-trainable params: 17,088\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model(bias_output=initial_bias)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034055,
     "end_time": "2020-08-07T06:41:56.250309",
     "exception": false,
     "start_time": "2020-08-07T06:41:56.216254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T06:41:56.317182Z",
     "iopub.status.busy": "2020-08-07T06:41:56.315701Z",
     "iopub.status.idle": "2020-08-07T08:00:23.487414Z",
     "shell.execute_reply": "2020-08-07T08:00:23.486644Z"
    },
    "papermill": {
     "duration": 4707.211152,
     "end_time": "2020-08-07T08:00:23.487593",
     "exception": false,
     "start_time": "2020-08-07T06:41:56.276441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/155\n",
      "29/28 [==============================] - 66s 2s/step - accuracy: 0.5355 - fn: 256.0000 - tp: 270.0000 - loss: 2.4417 - auc: 0.5370 - val_accuracy: 0.9834 - val_fn: 85.0000 - val_tp: 0.0000e+00 - val_loss: 0.1036 - val_auc: 0.5038\n",
      "Epoch 2/155\n",
      "29/28 [==============================] - 39s 1s/step - accuracy: 0.5815 - fn: 220.0000 - tp: 303.0000 - loss: 2.4459 - auc: 0.6004 - val_accuracy: 0.9836 - val_fn: 84.0000 - val_tp: 0.0000e+00 - val_loss: 0.1029 - val_auc: 0.5000\n",
      "Epoch 3/155\n",
      "29/28 [==============================] - 28s 980ms/step - accuracy: 0.6230 - fn: 217.0000 - tp: 313.0000 - loss: 1.8770 - auc: 0.6523 - val_accuracy: 0.9838 - val_fn: 83.0000 - val_tp: 0.0000e+00 - val_loss: 0.1054 - val_auc: 0.5000\n",
      "Epoch 4/155\n",
      "29/28 [==============================] - 28s 978ms/step - accuracy: 0.6025 - fn: 215.0000 - tp: 315.0000 - loss: 1.7592 - auc: 0.6438 - val_accuracy: 0.9832 - val_fn: 86.0000 - val_tp: 0.0000e+00 - val_loss: 0.1324 - val_auc: 0.5000\n",
      "Epoch 5/155\n",
      "29/28 [==============================] - 29s 987ms/step - accuracy: 0.5923 - fn: 205.0000 - tp: 321.0000 - loss: 1.5975 - auc: 0.6454 - val_accuracy: 0.9832 - val_fn: 86.0000 - val_tp: 0.0000e+00 - val_loss: 0.1334 - val_auc: 0.5000\n",
      "Epoch 6/155\n",
      "29/28 [==============================] - 28s 981ms/step - accuracy: 0.6117 - fn: 210.0000 - tp: 319.0000 - loss: 1.3178 - auc: 0.6553 - val_accuracy: 0.9836 - val_fn: 84.0000 - val_tp: 0.0000e+00 - val_loss: 0.1162 - val_auc: 0.4332\n",
      "Epoch 7/155\n",
      "29/28 [==============================] - 29s 983ms/step - accuracy: 0.6129 - fn: 196.0000 - tp: 336.0000 - loss: 1.2067 - auc: 0.6655 - val_accuracy: 0.9846 - val_fn: 79.0000 - val_tp: 0.0000e+00 - val_loss: 0.1075 - val_auc: 0.3280\n",
      "Epoch 8/155\n",
      "29/28 [==============================] - 29s 991ms/step - accuracy: 0.5963 - fn: 193.0000 - tp: 329.0000 - loss: 1.0692 - auc: 0.6553 - val_accuracy: 0.9828 - val_fn: 88.0000 - val_tp: 0.0000e+00 - val_loss: 0.1112 - val_auc: 0.3413\n",
      "Epoch 9/155\n",
      "29/28 [==============================] - 28s 962ms/step - accuracy: 0.6175 - fn: 196.0000 - tp: 336.0000 - loss: 0.9107 - auc: 0.6789 - val_accuracy: 0.9830 - val_fn: 87.0000 - val_tp: 0.0000e+00 - val_loss: 0.1895 - val_auc: 0.3185\n",
      "Epoch 10/155\n",
      "29/28 [==============================] - 28s 972ms/step - accuracy: 0.6244 - fn: 178.0000 - tp: 355.0000 - loss: 0.8207 - auc: 0.7038 - val_accuracy: 0.9836 - val_fn: 84.0000 - val_tp: 0.0000e+00 - val_loss: 0.1737 - val_auc: 0.3738\n",
      "Epoch 11/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.6230 - fn: 181.0000 - tp: 343.0000 - loss: 0.7601 - auc: 0.7105 - val_accuracy: 0.9828 - val_fn: 88.0000 - val_tp: 0.0000e+00 - val_loss: 0.2867 - val_auc: 0.3178\n",
      "Epoch 12/155\n",
      "29/28 [==============================] - 29s 988ms/step - accuracy: 0.6408 - fn: 172.0000 - tp: 361.0000 - loss: 0.7050 - auc: 0.7259 - val_accuracy: 0.9799 - val_fn: 86.0000 - val_tp: 0.0000e+00 - val_loss: 0.3316 - val_auc: 0.3161\n",
      "Epoch 13/155\n",
      "29/28 [==============================] - 29s 991ms/step - accuracy: 0.6341 - fn: 162.0000 - tp: 367.0000 - loss: 0.7200 - auc: 0.7157 - val_accuracy: 0.9838 - val_fn: 83.0000 - val_tp: 0.0000e+00 - val_loss: 0.2714 - val_auc: 0.4702\n",
      "Epoch 14/155\n",
      "29/28 [==============================] - 31s 1s/step - accuracy: 0.6439 - fn: 153.0000 - tp: 376.0000 - loss: 0.6544 - auc: 0.7418 - val_accuracy: 0.9824 - val_fn: 86.0000 - val_tp: 0.0000e+00 - val_loss: 0.2300 - val_auc: 0.5372\n",
      "Epoch 15/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.6287 - fn: 170.0000 - tp: 357.0000 - loss: 0.6980 - auc: 0.7185 - val_accuracy: 0.9744 - val_fn: 86.0000 - val_tp: 2.0000 - val_loss: 0.2502 - val_auc: 0.7344\n",
      "Epoch 16/155\n",
      "29/28 [==============================] - 29s 989ms/step - accuracy: 0.6366 - fn: 161.0000 - tp: 363.0000 - loss: 0.6666 - auc: 0.7363 - val_accuracy: 0.9824 - val_fn: 87.0000 - val_tp: 0.0000e+00 - val_loss: 0.1978 - val_auc: 0.5453\n",
      "Epoch 17/155\n",
      "29/28 [==============================] - 28s 973ms/step - accuracy: 0.6392 - fn: 131.0000 - tp: 397.0000 - loss: 0.6181 - auc: 0.7495 - val_accuracy: 0.9828 - val_fn: 87.0000 - val_tp: 0.0000e+00 - val_loss: 0.1838 - val_auc: 0.6114\n",
      "Epoch 18/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.6442 - fn: 160.0000 - tp: 363.0000 - loss: 0.6239 - auc: 0.7429 - val_accuracy: 0.9559 - val_fn: 85.0000 - val_tp: 0.0000e+00 - val_loss: 0.2602 - val_auc: 0.5448\n",
      "Epoch 19/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.6501 - fn: 139.0000 - tp: 394.0000 - loss: 0.5929 - auc: 0.7650 - val_accuracy: 0.9785 - val_fn: 86.0000 - val_tp: 0.0000e+00 - val_loss: 0.2229 - val_auc: 0.6297\n",
      "Epoch 20/155\n",
      "29/28 [==============================] - 28s 980ms/step - accuracy: 0.6529 - fn: 124.0000 - tp: 403.0000 - loss: 0.5837 - auc: 0.7696 - val_accuracy: 0.9729 - val_fn: 84.0000 - val_tp: 1.0000 - val_loss: 0.2673 - val_auc: 0.5609\n",
      "Epoch 21/155\n",
      "29/28 [==============================] - 28s 979ms/step - accuracy: 0.6678 - fn: 119.0000 - tp: 407.0000 - loss: 0.5646 - auc: 0.7841 - val_accuracy: 0.9791 - val_fn: 84.0000 - val_tp: 0.0000e+00 - val_loss: 0.2468 - val_auc: 0.5342\n",
      "Epoch 22/155\n",
      "29/28 [==============================] - 29s 985ms/step - accuracy: 0.6598 - fn: 109.0000 - tp: 409.0000 - loss: 0.5490 - auc: 0.7872 - val_accuracy: 0.9756 - val_fn: 81.0000 - val_tp: 1.0000 - val_loss: 0.2339 - val_auc: 0.5639\n",
      "Epoch 23/155\n",
      "29/28 [==============================] - 29s 984ms/step - accuracy: 0.6645 - fn: 121.0000 - tp: 421.0000 - loss: 0.5611 - auc: 0.7891 - val_accuracy: 0.9801 - val_fn: 86.0000 - val_tp: 1.0000 - val_loss: 0.2001 - val_auc: 0.5883\n",
      "Epoch 24/155\n",
      "29/28 [==============================] - 28s 970ms/step - accuracy: 0.6559 - fn: 117.0000 - tp: 406.0000 - loss: 0.5551 - auc: 0.7832 - val_accuracy: 0.9809 - val_fn: 82.0000 - val_tp: 1.0000 - val_loss: 0.2072 - val_auc: 0.6286\n",
      "Epoch 25/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.6606 - fn: 113.0000 - tp: 416.0000 - loss: 0.5534 - auc: 0.7888 - val_accuracy: 0.9643 - val_fn: 85.0000 - val_tp: 1.0000 - val_loss: 0.2115 - val_auc: 0.6306\n",
      "Epoch 26/155\n",
      "29/28 [==============================] - 28s 968ms/step - accuracy: 0.6658 - fn: 100.0000 - tp: 429.0000 - loss: 0.5326 - auc: 0.8005 - val_accuracy: 0.9697 - val_fn: 85.0000 - val_tp: 1.0000 - val_loss: 0.1939 - val_auc: 0.6229\n",
      "Epoch 27/155\n",
      "29/28 [==============================] - 28s 972ms/step - accuracy: 0.6778 - fn: 103.0000 - tp: 421.0000 - loss: 0.5290 - auc: 0.8078 - val_accuracy: 0.9805 - val_fn: 83.0000 - val_tp: 1.0000 - val_loss: 0.1717 - val_auc: 0.6557\n",
      "Epoch 28/155\n",
      "29/28 [==============================] - 28s 969ms/step - accuracy: 0.6808 - fn: 101.0000 - tp: 431.0000 - loss: 0.5286 - auc: 0.8083 - val_accuracy: 0.9754 - val_fn: 82.0000 - val_tp: 1.0000 - val_loss: 0.2036 - val_auc: 0.6265\n",
      "Epoch 29/155\n",
      "29/28 [==============================] - 28s 957ms/step - accuracy: 0.6880 - fn: 96.0000 - tp: 428.0000 - loss: 0.5081 - auc: 0.8173 - val_accuracy: 0.9799 - val_fn: 82.0000 - val_tp: 1.0000 - val_loss: 0.1712 - val_auc: 0.6490\n",
      "Epoch 30/155\n",
      "29/28 [==============================] - 28s 980ms/step - accuracy: 0.6940 - fn: 109.0000 - tp: 415.0000 - loss: 0.5207 - auc: 0.8126 - val_accuracy: 0.9801 - val_fn: 85.0000 - val_tp: 1.0000 - val_loss: 0.1740 - val_auc: 0.6463\n",
      "Epoch 31/155\n",
      "29/28 [==============================] - 29s 986ms/step - accuracy: 0.6928 - fn: 89.0000 - tp: 439.0000 - loss: 0.5133 - auc: 0.8183 - val_accuracy: 0.9775 - val_fn: 86.0000 - val_tp: 1.0000 - val_loss: 0.1932 - val_auc: 0.6359\n",
      "Epoch 32/155\n",
      "29/28 [==============================] - 28s 983ms/step - accuracy: 0.6861 - fn: 102.0000 - tp: 419.0000 - loss: 0.5150 - auc: 0.8153 - val_accuracy: 0.9803 - val_fn: 87.0000 - val_tp: 1.0000 - val_loss: 0.1766 - val_auc: 0.6269\n",
      "Epoch 33/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.6965 - fn: 96.0000 - tp: 444.0000 - loss: 0.5157 - auc: 0.8205 - val_accuracy: 0.9785 - val_fn: 86.0000 - val_tp: 2.0000 - val_loss: 0.1622 - val_auc: 0.6715\n",
      "Epoch 34/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.6893 - fn: 100.0000 - tp: 427.0000 - loss: 0.5105 - auc: 0.8203 - val_accuracy: 0.9797 - val_fn: 86.0000 - val_tp: 1.0000 - val_loss: 0.1535 - val_auc: 0.6731\n",
      "Epoch 35/155\n",
      "29/28 [==============================] - 29s 985ms/step - accuracy: 0.6899 - fn: 84.0000 - tp: 446.0000 - loss: 0.5037 - auc: 0.8233 - val_accuracy: 0.9771 - val_fn: 83.0000 - val_tp: 4.0000 - val_loss: 0.1878 - val_auc: 0.6523\n",
      "Epoch 36/155\n",
      "29/28 [==============================] - 29s 984ms/step - accuracy: 0.6933 - fn: 96.0000 - tp: 430.0000 - loss: 0.5051 - auc: 0.8213 - val_accuracy: 0.9760 - val_fn: 87.0000 - val_tp: 2.0000 - val_loss: 0.1682 - val_auc: 0.6844\n",
      "Epoch 37/155\n",
      "29/28 [==============================] - 29s 985ms/step - accuracy: 0.7065 - fn: 85.0000 - tp: 444.0000 - loss: 0.4887 - auc: 0.8373 - val_accuracy: 0.9795 - val_fn: 81.0000 - val_tp: 1.0000 - val_loss: 0.1596 - val_auc: 0.6764\n",
      "Epoch 38/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.6894 - fn: 84.0000 - tp: 442.0000 - loss: 0.4962 - auc: 0.8253 - val_accuracy: 0.9768 - val_fn: 82.0000 - val_tp: 2.0000 - val_loss: 0.1842 - val_auc: 0.7387\n",
      "Epoch 39/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.7001 - fn: 68.0000 - tp: 451.0000 - loss: 0.4755 - auc: 0.8400 - val_accuracy: 0.9738 - val_fn: 81.0000 - val_tp: 6.0000 - val_loss: 0.1891 - val_auc: 0.7397\n",
      "Epoch 40/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.6965 - fn: 82.0000 - tp: 450.0000 - loss: 0.4864 - auc: 0.8394 - val_accuracy: 0.9746 - val_fn: 82.0000 - val_tp: 7.0000 - val_loss: 0.1767 - val_auc: 0.7831\n",
      "Epoch 41/155\n",
      "29/28 [==============================] - 29s 999ms/step - accuracy: 0.7054 - fn: 69.0000 - tp: 455.0000 - loss: 0.4740 - auc: 0.8432 - val_accuracy: 0.9719 - val_fn: 83.0000 - val_tp: 2.0000 - val_loss: 0.1821 - val_auc: 0.7741\n",
      "Epoch 42/155\n",
      "29/28 [==============================] - 28s 959ms/step - accuracy: 0.7062 - fn: 71.0000 - tp: 453.0000 - loss: 0.4719 - auc: 0.8436 - val_accuracy: 0.9568 - val_fn: 75.0000 - val_tp: 9.0000 - val_loss: 0.1989 - val_auc: 0.7672\n",
      "Epoch 43/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.7030 - fn: 66.0000 - tp: 458.0000 - loss: 0.4735 - auc: 0.8433 - val_accuracy: 0.9693 - val_fn: 78.0000 - val_tp: 8.0000 - val_loss: 0.1803 - val_auc: 0.7950\n",
      "Epoch 44/155\n",
      "29/28 [==============================] - 28s 979ms/step - accuracy: 0.7008 - fn: 78.0000 - tp: 456.0000 - loss: 0.4764 - auc: 0.8449 - val_accuracy: 0.9781 - val_fn: 81.0000 - val_tp: 5.0000 - val_loss: 0.1619 - val_auc: 0.7872\n",
      "Epoch 45/155\n",
      "29/28 [==============================] - 31s 1s/step - accuracy: 0.7020 - fn: 85.0000 - tp: 440.0000 - loss: 0.4881 - auc: 0.8351 - val_accuracy: 0.9736 - val_fn: 80.0000 - val_tp: 6.0000 - val_loss: 0.1798 - val_auc: 0.7239\n",
      "Epoch 46/155\n",
      "29/28 [==============================] - 31s 1s/step - accuracy: 0.7028 - fn: 79.0000 - tp: 448.0000 - loss: 0.4703 - auc: 0.8457 - val_accuracy: 0.9797 - val_fn: 86.0000 - val_tp: 2.0000 - val_loss: 0.1315 - val_auc: 0.7920\n",
      "Epoch 47/155\n",
      "29/28 [==============================] - 31s 1s/step - accuracy: 0.6978 - fn: 77.0000 - tp: 456.0000 - loss: 0.4764 - auc: 0.8446 - val_accuracy: 0.9760 - val_fn: 80.0000 - val_tp: 8.0000 - val_loss: 0.1571 - val_auc: 0.7953\n",
      "Epoch 48/155\n",
      "29/28 [==============================] - 33s 1s/step - accuracy: 0.7034 - fn: 82.0000 - tp: 447.0000 - loss: 0.4734 - auc: 0.8449 - val_accuracy: 0.9768 - val_fn: 78.0000 - val_tp: 6.0000 - val_loss: 0.1519 - val_auc: 0.8197\n",
      "Epoch 49/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.7015 - fn: 76.0000 - tp: 451.0000 - loss: 0.4642 - auc: 0.8508 - val_accuracy: 0.9742 - val_fn: 77.0000 - val_tp: 10.0000 - val_loss: 0.1786 - val_auc: 0.8074\n",
      "Epoch 50/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.7011 - fn: 76.0000 - tp: 451.0000 - loss: 0.4734 - auc: 0.8444 - val_accuracy: 0.9633 - val_fn: 77.0000 - val_tp: 10.0000 - val_loss: 0.1958 - val_auc: 0.7803\n",
      "Epoch 51/155\n",
      "29/28 [==============================] - 28s 965ms/step - accuracy: 0.7095 - fn: 69.0000 - tp: 465.0000 - loss: 0.4630 - auc: 0.8527 - val_accuracy: 0.9699 - val_fn: 83.0000 - val_tp: 6.0000 - val_loss: 0.1761 - val_auc: 0.7595\n",
      "Epoch 52/155\n",
      "29/28 [==============================] - 28s 978ms/step - accuracy: 0.7161 - fn: 76.0000 - tp: 452.0000 - loss: 0.4637 - auc: 0.8541 - val_accuracy: 0.9711 - val_fn: 77.0000 - val_tp: 6.0000 - val_loss: 0.1724 - val_auc: 0.7927\n",
      "Epoch 53/155\n",
      "29/28 [==============================] - 29s 987ms/step - accuracy: 0.7183 - fn: 72.0000 - tp: 458.0000 - loss: 0.4480 - auc: 0.8632 - val_accuracy: 0.9730 - val_fn: 76.0000 - val_tp: 8.0000 - val_loss: 0.1812 - val_auc: 0.7533\n",
      "Epoch 54/155\n",
      "29/28 [==============================] - 28s 963ms/step - accuracy: 0.7027 - fn: 70.0000 - tp: 457.0000 - loss: 0.4601 - auc: 0.8515 - val_accuracy: 0.9336 - val_fn: 72.0000 - val_tp: 18.0000 - val_loss: 0.2074 - val_auc: 0.7874\n",
      "Epoch 55/155\n",
      "29/28 [==============================] - 28s 978ms/step - accuracy: 0.7099 - fn: 60.0000 - tp: 467.0000 - loss: 0.4504 - auc: 0.8612 - val_accuracy: 0.9129 - val_fn: 64.0000 - val_tp: 22.0000 - val_loss: 0.2321 - val_auc: 0.8029\n",
      "Epoch 56/155\n",
      "29/28 [==============================] - 28s 959ms/step - accuracy: 0.7174 - fn: 75.0000 - tp: 452.0000 - loss: 0.4568 - auc: 0.8567 - val_accuracy: 0.9271 - val_fn: 68.0000 - val_tp: 21.0000 - val_loss: 0.2136 - val_auc: 0.7965\n",
      "Epoch 57/155\n",
      "29/28 [==============================] - 29s 995ms/step - accuracy: 0.7287 - fn: 65.0000 - tp: 462.0000 - loss: 0.4442 - auc: 0.8657 - val_accuracy: 0.9283 - val_fn: 70.0000 - val_tp: 19.0000 - val_loss: 0.2047 - val_auc: 0.8074\n",
      "Epoch 58/155\n",
      "29/28 [==============================] - 29s 984ms/step - accuracy: 0.7131 - fn: 68.0000 - tp: 457.0000 - loss: 0.4540 - auc: 0.8586 - val_accuracy: 0.9484 - val_fn: 69.0000 - val_tp: 17.0000 - val_loss: 0.1950 - val_auc: 0.7968\n",
      "Epoch 59/155\n",
      "29/28 [==============================] - 29s 986ms/step - accuracy: 0.7190 - fn: 69.0000 - tp: 461.0000 - loss: 0.4471 - auc: 0.8659 - val_accuracy: 0.9400 - val_fn: 70.0000 - val_tp: 17.0000 - val_loss: 0.1906 - val_auc: 0.7938\n",
      "Epoch 60/155\n",
      "29/28 [==============================] - 28s 968ms/step - accuracy: 0.7221 - fn: 71.0000 - tp: 458.0000 - loss: 0.4608 - auc: 0.8575 - val_accuracy: 0.9434 - val_fn: 71.0000 - val_tp: 18.0000 - val_loss: 0.1802 - val_auc: 0.8191\n",
      "Epoch 61/155\n",
      "29/28 [==============================] - 28s 974ms/step - accuracy: 0.7192 - fn: 67.0000 - tp: 458.0000 - loss: 0.4542 - auc: 0.8581 - val_accuracy: 0.9482 - val_fn: 74.0000 - val_tp: 10.0000 - val_loss: 0.1724 - val_auc: 0.8040\n",
      "Epoch 62/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.7210 - fn: 70.0000 - tp: 457.0000 - loss: 0.4426 - auc: 0.8664 - val_accuracy: 0.9543 - val_fn: 65.0000 - val_tp: 22.0000 - val_loss: 0.1600 - val_auc: 0.8267\n",
      "Epoch 63/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.7324 - fn: 66.0000 - tp: 460.0000 - loss: 0.4373 - auc: 0.8728 - val_accuracy: 0.9576 - val_fn: 69.0000 - val_tp: 17.0000 - val_loss: 0.1530 - val_auc: 0.8311\n",
      "Epoch 64/155\n",
      "29/28 [==============================] - 29s 995ms/step - accuracy: 0.7213 - fn: 70.0000 - tp: 465.0000 - loss: 0.4469 - auc: 0.8644 - val_accuracy: 0.9178 - val_fn: 60.0000 - val_tp: 27.0000 - val_loss: 0.2160 - val_auc: 0.8084\n",
      "Epoch 65/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.7301 - fn: 72.0000 - tp: 448.0000 - loss: 0.4401 - auc: 0.8683 - val_accuracy: 0.9191 - val_fn: 61.0000 - val_tp: 25.0000 - val_loss: 0.2043 - val_auc: 0.8175\n",
      "Epoch 66/155\n",
      "29/28 [==============================] - 29s 989ms/step - accuracy: 0.7280 - fn: 65.0000 - tp: 464.0000 - loss: 0.4369 - auc: 0.8679 - val_accuracy: 0.9303 - val_fn: 73.0000 - val_tp: 17.0000 - val_loss: 0.1805 - val_auc: 0.8281\n",
      "Epoch 67/155\n",
      "29/28 [==============================] - 29s 997ms/step - accuracy: 0.7298 - fn: 72.0000 - tp: 461.0000 - loss: 0.4446 - auc: 0.8704 - val_accuracy: 0.9473 - val_fn: 68.0000 - val_tp: 16.0000 - val_loss: 0.1537 - val_auc: 0.8218\n",
      "Epoch 68/155\n",
      "29/28 [==============================] - 29s 996ms/step - accuracy: 0.7364 - fn: 63.0000 - tp: 461.0000 - loss: 0.4224 - auc: 0.8761 - val_accuracy: 0.9406 - val_fn: 68.0000 - val_tp: 19.0000 - val_loss: 0.1648 - val_auc: 0.8116\n",
      "Epoch 69/155\n",
      "29/28 [==============================] - 29s 995ms/step - accuracy: 0.7443 - fn: 67.0000 - tp: 458.0000 - loss: 0.4212 - auc: 0.8794 - val_accuracy: 0.9393 - val_fn: 60.0000 - val_tp: 20.0000 - val_loss: 0.1607 - val_auc: 0.8209\n",
      "Epoch 70/155\n",
      "29/28 [==============================] - 29s 997ms/step - accuracy: 0.7331 - fn: 77.0000 - tp: 448.0000 - loss: 0.4327 - auc: 0.8725 - val_accuracy: 0.9352 - val_fn: 65.0000 - val_tp: 21.0000 - val_loss: 0.1741 - val_auc: 0.8079\n",
      "Epoch 71/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.7279 - fn: 71.0000 - tp: 457.0000 - loss: 0.4540 - auc: 0.8609 - val_accuracy: 0.9420 - val_fn: 69.0000 - val_tp: 19.0000 - val_loss: 0.1622 - val_auc: 0.8343\n",
      "Epoch 72/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.7345 - fn: 67.0000 - tp: 460.0000 - loss: 0.4319 - auc: 0.8756 - val_accuracy: 0.9633 - val_fn: 72.0000 - val_tp: 12.0000 - val_loss: 0.1445 - val_auc: 0.8072\n",
      "Epoch 73/155\n",
      "29/28 [==============================] - 28s 966ms/step - accuracy: 0.7243 - fn: 68.0000 - tp: 461.0000 - loss: 0.4414 - auc: 0.8688 - val_accuracy: 0.9467 - val_fn: 61.0000 - val_tp: 25.0000 - val_loss: 0.1649 - val_auc: 0.8300\n",
      "Epoch 74/155\n",
      "29/28 [==============================] - 29s 997ms/step - accuracy: 0.7302 - fn: 66.0000 - tp: 470.0000 - loss: 0.4566 - auc: 0.8624 - val_accuracy: 0.9508 - val_fn: 69.0000 - val_tp: 15.0000 - val_loss: 0.1512 - val_auc: 0.8040\n",
      "Epoch 75/155\n",
      "29/28 [==============================] - 29s 989ms/step - accuracy: 0.7338 - fn: 60.0000 - tp: 465.0000 - loss: 0.4288 - auc: 0.8763 - val_accuracy: 0.9400 - val_fn: 65.0000 - val_tp: 22.0000 - val_loss: 0.1709 - val_auc: 0.8262\n",
      "Epoch 76/155\n",
      "29/28 [==============================] - 29s 986ms/step - accuracy: 0.7367 - fn: 60.0000 - tp: 471.0000 - loss: 0.4313 - auc: 0.8739 - val_accuracy: 0.9322 - val_fn: 63.0000 - val_tp: 22.0000 - val_loss: 0.1808 - val_auc: 0.8011\n",
      "Epoch 77/155\n",
      "29/28 [==============================] - 28s 968ms/step - accuracy: 0.7335 - fn: 65.0000 - tp: 460.0000 - loss: 0.4422 - auc: 0.8675 - val_accuracy: 0.9146 - val_fn: 63.0000 - val_tp: 22.0000 - val_loss: 0.2170 - val_auc: 0.7846\n",
      "Epoch 78/155\n",
      "29/28 [==============================] - 28s 970ms/step - accuracy: 0.7240 - fn: 69.0000 - tp: 456.0000 - loss: 0.4487 - auc: 0.8651 - val_accuracy: 0.9510 - val_fn: 63.0000 - val_tp: 20.0000 - val_loss: 0.1578 - val_auc: 0.8179\n",
      "Epoch 79/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.7362 - fn: 59.0000 - tp: 466.0000 - loss: 0.4261 - auc: 0.8782 - val_accuracy: 0.9207 - val_fn: 63.0000 - val_tp: 23.0000 - val_loss: 0.2132 - val_auc: 0.7841\n",
      "Epoch 80/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.7360 - fn: 62.0000 - tp: 461.0000 - loss: 0.4289 - auc: 0.8735 - val_accuracy: 0.9090 - val_fn: 54.0000 - val_tp: 27.0000 - val_loss: 0.2144 - val_auc: 0.8297\n",
      "Epoch 81/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.7325 - fn: 64.0000 - tp: 470.0000 - loss: 0.4335 - auc: 0.8744 - val_accuracy: 0.9369 - val_fn: 64.0000 - val_tp: 23.0000 - val_loss: 0.1775 - val_auc: 0.8055\n",
      "Epoch 82/155\n",
      "29/28 [==============================] - 28s 979ms/step - accuracy: 0.7281 - fn: 72.0000 - tp: 450.0000 - loss: 0.4386 - auc: 0.8675 - val_accuracy: 0.9566 - val_fn: 70.0000 - val_tp: 13.0000 - val_loss: 0.1691 - val_auc: 0.8171\n",
      "Epoch 83/155\n",
      "29/28 [==============================] - 28s 967ms/step - accuracy: 0.7322 - fn: 64.0000 - tp: 462.0000 - loss: 0.4315 - auc: 0.8753 - val_accuracy: 0.9086 - val_fn: 61.0000 - val_tp: 29.0000 - val_loss: 0.2188 - val_auc: 0.8254\n",
      "Epoch 84/155\n",
      "29/28 [==============================] - 28s 973ms/step - accuracy: 0.7389 - fn: 60.0000 - tp: 470.0000 - loss: 0.4186 - auc: 0.8806 - val_accuracy: 0.9145 - val_fn: 52.0000 - val_tp: 30.0000 - val_loss: 0.2021 - val_auc: 0.8272\n",
      "Epoch 85/155\n",
      "29/28 [==============================] - 29s 995ms/step - accuracy: 0.7411 - fn: 69.0000 - tp: 458.0000 - loss: 0.4315 - auc: 0.8760 - val_accuracy: 0.9332 - val_fn: 53.0000 - val_tp: 31.0000 - val_loss: 0.1942 - val_auc: 0.8326\n",
      "Epoch 86/155\n",
      "29/28 [==============================] - 29s 985ms/step - accuracy: 0.7489 - fn: 59.0000 - tp: 465.0000 - loss: 0.4209 - auc: 0.8805 - val_accuracy: 0.9305 - val_fn: 60.0000 - val_tp: 25.0000 - val_loss: 0.1954 - val_auc: 0.8333\n",
      "Epoch 87/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.7371 - fn: 69.0000 - tp: 462.0000 - loss: 0.4327 - auc: 0.8754 - val_accuracy: 0.9455 - val_fn: 68.0000 - val_tp: 16.0000 - val_loss: 0.1597 - val_auc: 0.8457\n",
      "Epoch 88/155\n",
      "29/28 [==============================] - 28s 969ms/step - accuracy: 0.7333 - fn: 58.0000 - tp: 471.0000 - loss: 0.4211 - auc: 0.8801 - val_accuracy: 0.8920 - val_fn: 54.0000 - val_tp: 35.0000 - val_loss: 0.2421 - val_auc: 0.8247\n",
      "Epoch 89/155\n",
      "29/28 [==============================] - 29s 996ms/step - accuracy: 0.7493 - fn: 71.0000 - tp: 460.0000 - loss: 0.4260 - auc: 0.8802 - val_accuracy: 0.8945 - val_fn: 55.0000 - val_tp: 32.0000 - val_loss: 0.2324 - val_auc: 0.8445\n",
      "Epoch 90/155\n",
      "29/28 [==============================] - 29s 986ms/step - accuracy: 0.7290 - fn: 56.0000 - tp: 468.0000 - loss: 0.4259 - auc: 0.8749 - val_accuracy: 0.9027 - val_fn: 51.0000 - val_tp: 33.0000 - val_loss: 0.2227 - val_auc: 0.8183\n",
      "Epoch 91/155\n",
      "29/28 [==============================] - 28s 979ms/step - accuracy: 0.7398 - fn: 69.0000 - tp: 462.0000 - loss: 0.4376 - auc: 0.8693 - val_accuracy: 0.9309 - val_fn: 67.0000 - val_tp: 20.0000 - val_loss: 0.1926 - val_auc: 0.8097\n",
      "Epoch 92/155\n",
      "29/28 [==============================] - 29s 991ms/step - accuracy: 0.7338 - fn: 63.0000 - tp: 464.0000 - loss: 0.4322 - auc: 0.8744 - val_accuracy: 0.9215 - val_fn: 65.0000 - val_tp: 24.0000 - val_loss: 0.2018 - val_auc: 0.7916\n",
      "Epoch 93/155\n",
      "29/28 [==============================] - 29s 995ms/step - accuracy: 0.7362 - fn: 55.0000 - tp: 472.0000 - loss: 0.4228 - auc: 0.8768 - val_accuracy: 0.9107 - val_fn: 55.0000 - val_tp: 29.0000 - val_loss: 0.2194 - val_auc: 0.8206\n",
      "Epoch 94/155\n",
      "29/28 [==============================] - 28s 979ms/step - accuracy: 0.7310 - fn: 65.0000 - tp: 474.0000 - loss: 0.4297 - auc: 0.8743 - val_accuracy: 0.9189 - val_fn: 60.0000 - val_tp: 29.0000 - val_loss: 0.2081 - val_auc: 0.8301\n",
      "Epoch 95/155\n",
      "29/28 [==============================] - 29s 989ms/step - accuracy: 0.7304 - fn: 60.0000 - tp: 468.0000 - loss: 0.4188 - auc: 0.8804 - val_accuracy: 0.9096 - val_fn: 49.0000 - val_tp: 31.0000 - val_loss: 0.2308 - val_auc: 0.8154\n",
      "Epoch 96/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.7334 - fn: 63.0000 - tp: 463.0000 - loss: 0.4184 - auc: 0.8796 - val_accuracy: 0.9098 - val_fn: 55.0000 - val_tp: 30.0000 - val_loss: 0.2160 - val_auc: 0.8110\n",
      "Epoch 97/155\n",
      "29/28 [==============================] - 31s 1s/step - accuracy: 0.7450 - fn: 64.0000 - tp: 459.0000 - loss: 0.4083 - auc: 0.8853 - val_accuracy: 0.8404 - val_fn: 40.0000 - val_tp: 41.0000 - val_loss: 0.3181 - val_auc: 0.8135\n",
      "Epoch 98/155\n",
      "29/28 [==============================] - 28s 980ms/step - accuracy: 0.7434 - fn: 69.0000 - tp: 461.0000 - loss: 0.4180 - auc: 0.8831 - val_accuracy: 0.9037 - val_fn: 53.0000 - val_tp: 30.0000 - val_loss: 0.2296 - val_auc: 0.8296\n",
      "Epoch 99/155\n",
      "29/28 [==============================] - 29s 987ms/step - accuracy: 0.7379 - fn: 65.0000 - tp: 459.0000 - loss: 0.4299 - auc: 0.8739 - val_accuracy: 0.8836 - val_fn: 49.0000 - val_tp: 37.0000 - val_loss: 0.2709 - val_auc: 0.8214\n",
      "Epoch 100/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.7416 - fn: 53.0000 - tp: 474.0000 - loss: 0.4086 - auc: 0.8863 - val_accuracy: 0.9389 - val_fn: 56.0000 - val_tp: 29.0000 - val_loss: 0.1834 - val_auc: 0.8322\n",
      "Epoch 101/155\n",
      "29/28 [==============================] - 28s 963ms/step - accuracy: 0.7505 - fn: 43.0000 - tp: 485.0000 - loss: 0.3985 - auc: 0.8925 - val_accuracy: 0.9229 - val_fn: 57.0000 - val_tp: 31.0000 - val_loss: 0.2138 - val_auc: 0.8152\n",
      "Epoch 102/155\n",
      "29/28 [==============================] - 29s 984ms/step - accuracy: 0.7489 - fn: 57.0000 - tp: 466.0000 - loss: 0.4092 - auc: 0.8867 - val_accuracy: 0.8445 - val_fn: 47.0000 - val_tp: 38.0000 - val_loss: 0.3127 - val_auc: 0.8137\n",
      "Epoch 103/155\n",
      "29/28 [==============================] - 29s 998ms/step - accuracy: 0.7417 - fn: 61.0000 - tp: 470.0000 - loss: 0.4253 - auc: 0.8812 - val_accuracy: 0.8859 - val_fn: 51.0000 - val_tp: 38.0000 - val_loss: 0.2507 - val_auc: 0.8093\n",
      "Epoch 104/155\n",
      "29/28 [==============================] - 28s 981ms/step - accuracy: 0.7442 - fn: 62.0000 - tp: 468.0000 - loss: 0.4156 - auc: 0.8828 - val_accuracy: 0.9281 - val_fn: 59.0000 - val_tp: 27.0000 - val_loss: 0.1937 - val_auc: 0.8047\n",
      "Epoch 105/155\n",
      "29/28 [==============================] - 29s 983ms/step - accuracy: 0.7400 - fn: 63.0000 - tp: 466.0000 - loss: 0.4158 - auc: 0.8817 - val_accuracy: 0.8998 - val_fn: 54.0000 - val_tp: 31.0000 - val_loss: 0.2334 - val_auc: 0.8221\n",
      "Epoch 106/155\n",
      "29/28 [==============================] - 29s 990ms/step - accuracy: 0.7421 - fn: 51.0000 - tp: 475.0000 - loss: 0.4123 - auc: 0.8813 - val_accuracy: 0.8914 - val_fn: 47.0000 - val_tp: 38.0000 - val_loss: 0.2462 - val_auc: 0.8069\n",
      "Epoch 107/155\n",
      "29/28 [==============================] - 29s 994ms/step - accuracy: 0.7426 - fn: 59.0000 - tp: 465.0000 - loss: 0.4077 - auc: 0.8877 - val_accuracy: 0.8768 - val_fn: 49.0000 - val_tp: 33.0000 - val_loss: 0.2606 - val_auc: 0.8005\n",
      "Epoch 108/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.7579 - fn: 64.0000 - tp: 463.0000 - loss: 0.4023 - auc: 0.8910 - val_accuracy: 0.8826 - val_fn: 42.0000 - val_tp: 44.0000 - val_loss: 0.2672 - val_auc: 0.8041\n",
      "Epoch 109/155\n",
      "29/28 [==============================] - 29s 986ms/step - accuracy: 0.7392 - fn: 66.0000 - tp: 468.0000 - loss: 0.4315 - auc: 0.8779 - val_accuracy: 0.8902 - val_fn: 50.0000 - val_tp: 37.0000 - val_loss: 0.2553 - val_auc: 0.8317\n",
      "Epoch 110/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.7434 - fn: 51.0000 - tp: 474.0000 - loss: 0.4043 - auc: 0.8875 - val_accuracy: 0.8846 - val_fn: 49.0000 - val_tp: 31.0000 - val_loss: 0.2486 - val_auc: 0.8172\n",
      "Epoch 111/155\n",
      "29/28 [==============================] - 28s 977ms/step - accuracy: 0.7517 - fn: 50.0000 - tp: 476.0000 - loss: 0.3968 - auc: 0.8930 - val_accuracy: 0.8627 - val_fn: 48.0000 - val_tp: 38.0000 - val_loss: 0.2702 - val_auc: 0.8018\n",
      "Epoch 112/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.7524 - fn: 55.0000 - tp: 469.0000 - loss: 0.4051 - auc: 0.8876 - val_accuracy: 0.8732 - val_fn: 49.0000 - val_tp: 33.0000 - val_loss: 0.2724 - val_auc: 0.7918\n",
      "Epoch 113/155\n",
      "29/28 [==============================] - 28s 961ms/step - accuracy: 0.7508 - fn: 51.0000 - tp: 477.0000 - loss: 0.4054 - auc: 0.8890 - val_accuracy: 0.8871 - val_fn: 44.0000 - val_tp: 42.0000 - val_loss: 0.2354 - val_auc: 0.8267\n",
      "Epoch 114/155\n",
      "29/28 [==============================] - 29s 983ms/step - accuracy: 0.7423 - fn: 57.0000 - tp: 472.0000 - loss: 0.4140 - auc: 0.8852 - val_accuracy: 0.9018 - val_fn: 54.0000 - val_tp: 29.0000 - val_loss: 0.2218 - val_auc: 0.8273\n",
      "Epoch 115/155\n",
      "29/28 [==============================] - 29s 994ms/step - accuracy: 0.7438 - fn: 68.0000 - tp: 464.0000 - loss: 0.4140 - auc: 0.8846 - val_accuracy: 0.8637 - val_fn: 43.0000 - val_tp: 44.0000 - val_loss: 0.2715 - val_auc: 0.8206\n",
      "Epoch 116/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.7492 - fn: 65.0000 - tp: 470.0000 - loss: 0.4124 - auc: 0.8861 - val_accuracy: 0.8615 - val_fn: 48.0000 - val_tp: 38.0000 - val_loss: 0.2981 - val_auc: 0.8225\n",
      "Epoch 117/155\n",
      "29/28 [==============================] - 29s 984ms/step - accuracy: 0.7523 - fn: 61.0000 - tp: 462.0000 - loss: 0.4046 - auc: 0.8868 - val_accuracy: 0.8031 - val_fn: 35.0000 - val_tp: 49.0000 - val_loss: 0.3722 - val_auc: 0.8125\n",
      "Epoch 118/155\n",
      "29/28 [==============================] - 29s 984ms/step - accuracy: 0.7400 - fn: 65.0000 - tp: 460.0000 - loss: 0.4172 - auc: 0.8812 - val_accuracy: 0.8424 - val_fn: 40.0000 - val_tp: 48.0000 - val_loss: 0.3154 - val_auc: 0.8229\n",
      "Epoch 119/155\n",
      "29/28 [==============================] - 28s 976ms/step - accuracy: 0.7530 - fn: 57.0000 - tp: 471.0000 - loss: 0.4117 - auc: 0.8871 - val_accuracy: 0.8309 - val_fn: 41.0000 - val_tp: 45.0000 - val_loss: 0.3384 - val_auc: 0.8254\n",
      "Epoch 120/155\n",
      "29/28 [==============================] - 28s 968ms/step - accuracy: 0.7455 - fn: 65.0000 - tp: 457.0000 - loss: 0.4221 - auc: 0.8813 - val_accuracy: 0.8182 - val_fn: 37.0000 - val_tp: 50.0000 - val_loss: 0.3632 - val_auc: 0.7980\n",
      "Epoch 121/155\n",
      "29/28 [==============================] - 29s 997ms/step - accuracy: 0.7528 - fn: 59.0000 - tp: 469.0000 - loss: 0.4144 - auc: 0.8854 - val_accuracy: 0.8096 - val_fn: 38.0000 - val_tp: 49.0000 - val_loss: 0.3690 - val_auc: 0.8169\n",
      "Epoch 122/155\n",
      "29/28 [==============================] - 29s 988ms/step - accuracy: 0.7529 - fn: 69.0000 - tp: 461.0000 - loss: 0.4148 - auc: 0.8857 - val_accuracy: 0.8170 - val_fn: 29.0000 - val_tp: 55.0000 - val_loss: 0.3785 - val_auc: 0.8324\n",
      "Epoch 123/155\n",
      "29/28 [==============================] - 30s 1s/step - accuracy: 0.7570 - fn: 53.0000 - tp: 467.0000 - loss: 0.3912 - auc: 0.8950 - val_accuracy: 0.8453 - val_fn: 35.0000 - val_tp: 49.0000 - val_loss: 0.3127 - val_auc: 0.8518\n",
      "Epoch 124/155\n",
      "29/28 [==============================] - 28s 972ms/step - accuracy: 0.7509 - fn: 59.0000 - tp: 464.0000 - loss: 0.4051 - auc: 0.8877 - val_accuracy: 0.8121 - val_fn: 31.0000 - val_tp: 51.0000 - val_loss: 0.3534 - val_auc: 0.8124\n",
      "Epoch 125/155\n",
      "29/28 [==============================] - 29s 989ms/step - accuracy: 0.7551 - fn: 56.0000 - tp: 476.0000 - loss: 0.4025 - auc: 0.8912 - val_accuracy: 0.8699 - val_fn: 38.0000 - val_tp: 44.0000 - val_loss: 0.2554 - val_auc: 0.8397\n",
      "Epoch 126/155\n",
      "29/28 [==============================] - 29s 988ms/step - accuracy: 0.7563 - fn: 59.0000 - tp: 471.0000 - loss: 0.3995 - auc: 0.8921 - val_accuracy: 0.8760 - val_fn: 51.0000 - val_tp: 36.0000 - val_loss: 0.2380 - val_auc: 0.8318\n",
      "Epoch 127/155\n",
      "29/28 [==============================] - 27s 930ms/step - accuracy: 0.7626 - fn: 49.0000 - tp: 474.0000 - loss: 0.3863 - auc: 0.8961 - val_accuracy: 0.8795 - val_fn: 49.0000 - val_tp: 34.0000 - val_loss: 0.2490 - val_auc: 0.8302\n",
      "Epoch 128/155\n",
      "29/28 [==============================] - 28s 967ms/step - accuracy: 0.7645 - fn: 64.0000 - tp: 467.0000 - loss: 0.3926 - auc: 0.8962 - val_accuracy: 0.8635 - val_fn: 40.0000 - val_tp: 47.0000 - val_loss: 0.2798 - val_auc: 0.8201\n",
      "Epoch 129/155\n",
      "29/28 [==============================] - 28s 969ms/step - accuracy: 0.7531 - fn: 55.0000 - tp: 472.0000 - loss: 0.3915 - auc: 0.8982 - val_accuracy: 0.8703 - val_fn: 38.0000 - val_tp: 47.0000 - val_loss: 0.2610 - val_auc: 0.8264\n",
      "Epoch 130/155\n",
      "29/28 [==============================] - 28s 972ms/step - accuracy: 0.7624 - fn: 56.0000 - tp: 475.0000 - loss: 0.4101 - auc: 0.8907 - val_accuracy: 0.8768 - val_fn: 50.0000 - val_tp: 36.0000 - val_loss: 0.2437 - val_auc: 0.8277\n",
      "Epoch 131/155\n",
      "29/28 [==============================] - 29s 1s/step - accuracy: 0.7534 - fn: 54.0000 - tp: 472.0000 - loss: 0.4044 - auc: 0.8899 - val_accuracy: 0.8527 - val_fn: 42.0000 - val_tp: 45.0000 - val_loss: 0.2821 - val_auc: 0.8169\n",
      "Epoch 132/155\n",
      "29/28 [==============================] - 28s 966ms/step - accuracy: 0.7568 - fn: 56.0000 - tp: 478.0000 - loss: 0.3989 - auc: 0.8934 - val_accuracy: 0.8605 - val_fn: 39.0000 - val_tp: 46.0000 - val_loss: 0.2906 - val_auc: 0.8461\n",
      "Epoch 133/155\n",
      "29/28 [==============================] - 28s 959ms/step - accuracy: 0.7599 - fn: 51.0000 - tp: 475.0000 - loss: 0.3952 - auc: 0.8961 - val_accuracy: 0.8529 - val_fn: 45.0000 - val_tp: 41.0000 - val_loss: 0.3066 - val_auc: 0.8125\n",
      "Epoch 134/155\n",
      "29/28 [==============================] - 28s 970ms/step - accuracy: 0.7624 - fn: 71.0000 - tp: 465.0000 - loss: 0.3980 - auc: 0.8954 - val_accuracy: 0.8875 - val_fn: 45.0000 - val_tp: 41.0000 - val_loss: 0.2520 - val_auc: 0.8253\n",
      "Epoch 135/155\n",
      "29/28 [==============================] - 28s 956ms/step - accuracy: 0.7580 - fn: 58.0000 - tp: 472.0000 - loss: 0.3958 - auc: 0.8943 - val_accuracy: 0.8516 - val_fn: 37.0000 - val_tp: 49.0000 - val_loss: 0.3051 - val_auc: 0.8349\n",
      "Epoch 136/155\n",
      "29/28 [==============================] - 29s 993ms/step - accuracy: 0.7477 - fn: 60.0000 - tp: 468.0000 - loss: 0.4110 - auc: 0.8857 - val_accuracy: 0.8000 - val_fn: 31.0000 - val_tp: 53.0000 - val_loss: 0.3736 - val_auc: 0.8146\n",
      "Epoch 137/155\n",
      "29/28 [==============================] - 28s 976ms/step - accuracy: 0.7350 - fn: 63.0000 - tp: 460.0000 - loss: 0.4211 - auc: 0.8814 - val_accuracy: 0.8488 - val_fn: 39.0000 - val_tp: 47.0000 - val_loss: 0.3058 - val_auc: 0.8247\n",
      "Epoch 138/155\n",
      "29/28 [==============================] - 28s 971ms/step - accuracy: 0.7526 - fn: 61.0000 - tp: 467.0000 - loss: 0.4018 - auc: 0.8914 - val_accuracy: 0.8301 - val_fn: 41.0000 - val_tp: 48.0000 - val_loss: 0.3634 - val_auc: 0.8095\n",
      "Epoch 139/155\n",
      "29/28 [==============================] - 29s 984ms/step - accuracy: 0.7607 - fn: 57.0000 - tp: 469.0000 - loss: 0.3954 - auc: 0.8953 - val_accuracy: 0.8289 - val_fn: 36.0000 - val_tp: 51.0000 - val_loss: 0.3406 - val_auc: 0.8211\n",
      "Epoch 140/155\n",
      "29/28 [==============================] - 28s 983ms/step - accuracy: 0.7608 - fn: 53.0000 - tp: 475.0000 - loss: 0.3911 - auc: 0.8941 - val_accuracy: 0.7951 - val_fn: 34.0000 - val_tp: 52.0000 - val_loss: 0.4176 - val_auc: 0.8284\n",
      "Epoch 141/155\n",
      "29/28 [==============================] - 28s 955ms/step - accuracy: 0.7545 - fn: 51.0000 - tp: 474.0000 - loss: 0.3962 - auc: 0.8931 - val_accuracy: 0.8439 - val_fn: 33.0000 - val_tp: 50.0000 - val_loss: 0.3244 - val_auc: 0.8351\n",
      "Epoch 142/155\n",
      "29/28 [==============================] - 28s 966ms/step - accuracy: 0.7434 - fn: 54.0000 - tp: 477.0000 - loss: 0.3985 - auc: 0.8929 - val_accuracy: 0.8242 - val_fn: 36.0000 - val_tp: 52.0000 - val_loss: 0.3244 - val_auc: 0.8333\n",
      "Epoch 143/155\n",
      "29/28 [==============================] - 29s 999ms/step - accuracy: 0.7540 - fn: 60.0000 - tp: 461.0000 - loss: 0.3998 - auc: 0.8951 - val_accuracy: 0.8703 - val_fn: 46.0000 - val_tp: 40.0000 - val_loss: 0.2691 - val_auc: 0.8110\n",
      "Epoch 144/155\n",
      "29/28 [==============================] - 28s 968ms/step - accuracy: 0.7534 - fn: 65.0000 - tp: 462.0000 - loss: 0.4016 - auc: 0.8906 - val_accuracy: 0.8871 - val_fn: 41.0000 - val_tp: 47.0000 - val_loss: 0.2458 - val_auc: 0.8387\n",
      "Epoch 145/155\n",
      "29/28 [==============================] - 28s 979ms/step - accuracy: 0.7671 - fn: 46.0000 - tp: 489.0000 - loss: 0.3837 - auc: 0.9034 - val_accuracy: 0.8537 - val_fn: 45.0000 - val_tp: 43.0000 - val_loss: 0.2643 - val_auc: 0.8237\n",
      "Epoch 146/155\n",
      "29/28 [==============================] - 28s 974ms/step - accuracy: 0.7613 - fn: 52.0000 - tp: 475.0000 - loss: 0.3901 - auc: 0.8983 - val_accuracy: 0.8203 - val_fn: 39.0000 - val_tp: 47.0000 - val_loss: 0.3186 - val_auc: 0.8349\n",
      "Epoch 147/155\n",
      "29/28 [==============================] - 28s 976ms/step - accuracy: 0.7604 - fn: 54.0000 - tp: 469.0000 - loss: 0.3860 - auc: 0.9003 - val_accuracy: 0.8842 - val_fn: 46.0000 - val_tp: 37.0000 - val_loss: 0.2442 - val_auc: 0.8284\n",
      "Epoch 148/155\n",
      "29/28 [==============================] - 28s 956ms/step - accuracy: 0.7567 - fn: 54.0000 - tp: 469.0000 - loss: 0.3909 - auc: 0.8970 - val_accuracy: 0.8615 - val_fn: 38.0000 - val_tp: 48.0000 - val_loss: 0.2630 - val_auc: 0.8440\n",
      "Epoch 149/155\n",
      "29/28 [==============================] - 29s 990ms/step - accuracy: 0.7672 - fn: 54.0000 - tp: 480.0000 - loss: 0.3900 - auc: 0.8996 - val_accuracy: 0.8529 - val_fn: 45.0000 - val_tp: 41.0000 - val_loss: 0.2929 - val_auc: 0.8040\n",
      "Epoch 150/155\n",
      "29/28 [==============================] - 29s 991ms/step - accuracy: 0.7555 - fn: 54.0000 - tp: 472.0000 - loss: 0.3904 - auc: 0.8953 - val_accuracy: 0.8525 - val_fn: 52.0000 - val_tp: 34.0000 - val_loss: 0.2935 - val_auc: 0.8025\n",
      "Epoch 151/155\n",
      "29/28 [==============================] - 28s 965ms/step - accuracy: 0.7692 - fn: 59.0000 - tp: 470.0000 - loss: 0.4003 - auc: 0.8948 - val_accuracy: 0.8662 - val_fn: 48.0000 - val_tp: 40.0000 - val_loss: 0.2771 - val_auc: 0.7959\n",
      "Epoch 152/155\n",
      "29/28 [==============================] - 29s 996ms/step - accuracy: 0.7540 - fn: 60.0000 - tp: 465.0000 - loss: 0.4072 - auc: 0.8884 - val_accuracy: 0.8070 - val_fn: 32.0000 - val_tp: 55.0000 - val_loss: 0.3660 - val_auc: 0.8255\n",
      "Epoch 153/155\n",
      "29/28 [==============================] - 28s 976ms/step - accuracy: 0.7554 - fn: 48.0000 - tp: 479.0000 - loss: 0.3866 - auc: 0.8990 - val_accuracy: 0.8342 - val_fn: 31.0000 - val_tp: 55.0000 - val_loss: 0.3090 - val_auc: 0.8209\n",
      "Epoch 154/155\n",
      "29/28 [==============================] - 28s 970ms/step - accuracy: 0.7686 - fn: 46.0000 - tp: 479.0000 - loss: 0.3662 - auc: 0.9101 - val_accuracy: 0.8305 - val_fn: 34.0000 - val_tp: 51.0000 - val_loss: 0.3125 - val_auc: 0.8371\n",
      "Epoch 155/155\n",
      "29/28 [==============================] - 28s 957ms/step - accuracy: 0.7659 - fn: 57.0000 - tp: 475.0000 - loss: 0.3864 - auc: 0.9018 - val_accuracy: 0.7777 - val_fn: 36.0000 - val_tp: 53.0000 - val_loss: 0.3815 - val_auc: 0.8166\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', #val_auc\n",
    "                                patience=50,\n",
    "                                mode='max',\n",
    "                                restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "#     batch_size=params['batch_size'],\n",
    "    epochs= params['epochs'], \n",
    "    steps_per_epoch=epoch_steps,\n",
    "    validation_data=valid_ds,\n",
    "    validation_steps=valid_steps,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T08:00:24.253033Z",
     "iopub.status.busy": "2020-08-07T08:00:24.251944Z",
     "iopub.status.idle": "2020-08-07T08:01:30.232970Z",
     "shell.execute_reply": "2020-08-07T08:01:30.232000Z"
    },
    "papermill": {
     "duration": 66.367924,
     "end_time": "2020-08-07T08:01:30.233146",
     "exception": false,
     "start_time": "2020-08-07T08:00:23.865222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_ds.map(lambda img, igs: img), steps=test_steps)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T08:01:31.052725Z",
     "iopub.status.busy": "2020-08-07T08:01:31.051805Z",
     "iopub.status.idle": "2020-08-07T08:01:35.365425Z",
     "shell.execute_reply": "2020-08-07T08:01:35.364546Z"
    },
    "papermill": {
     "duration": 4.726255,
     "end_time": "2020-08-07T08:01:35.365613",
     "exception": false,
     "start_time": "2020-08-07T08:01:30.639358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7f775fd564d0> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "                          map(lambda img, ids:ids).\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction_ids = next(iter(test_ds.\n",
    "                          map(lambda img, ids:ids).\n",
    "                          unbatch().\n",
    "                          batch(test_size))).numpy().astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T08:01:36.156003Z",
     "iopub.status.busy": "2020-08-07T08:01:36.154810Z",
     "iopub.status.idle": "2020-08-07T08:01:36.175270Z",
     "shell.execute_reply": "2020-08-07T08:01:36.174356Z"
    },
    "papermill": {
     "duration": 0.415944,
     "end_time": "2020-08-07T08:01:36.175432",
     "exception": false,
     "start_time": "2020-08-07T08:01:35.759488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_dict = {\n",
    "    'image_name': prediction_ids,\n",
    "    'target': np.concatenate(predictions)\n",
    "}\n",
    "submission_ds = pd.DataFrame(prediction_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T08:01:37.047818Z",
     "iopub.status.busy": "2020-08-07T08:01:37.045994Z",
     "iopub.status.idle": "2020-08-07T08:01:37.054093Z",
     "shell.execute_reply": "2020-08-07T08:01:37.052961Z"
    },
    "papermill": {
     "duration": 0.406786,
     "end_time": "2020-08-07T08:01:37.054378",
     "exception": false,
     "start_time": "2020-08-07T08:01:36.647592",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6381819</td>\n",
       "      <td>0.083794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_5583376</td>\n",
       "      <td>0.001164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_6408546</td>\n",
       "      <td>0.001886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_6932354</td>\n",
       "      <td>0.103722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_8191278</td>\n",
       "      <td>0.002033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name    target\n",
       "0  ISIC_6381819  0.083794\n",
       "1  ISIC_5583376  0.001164\n",
       "2  ISIC_6408546  0.001886\n",
       "3  ISIC_6932354  0.103722\n",
       "4  ISIC_8191278  0.002033"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T08:01:37.856749Z",
     "iopub.status.busy": "2020-08-07T08:01:37.855764Z",
     "iopub.status.idle": "2020-08-07T08:01:37.937656Z",
     "shell.execute_reply": "2020-08-07T08:01:37.936560Z"
    },
    "papermill": {
     "duration": 0.483644,
     "end_time": "2020-08-07T08:01:37.937833",
     "exception": false,
     "start_time": "2020-08-07T08:01:37.454189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_ds.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.48915,
     "end_time": "2020-08-07T08:01:38.819847",
     "exception": false,
     "start_time": "2020-08-07T08:01:38.330697",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T08:01:39.606576Z",
     "iopub.status.busy": "2020-08-07T08:01:39.605631Z",
     "iopub.status.idle": "2020-08-07T08:01:39.610582Z",
     "shell.execute_reply": "2020-08-07T08:01:39.609673Z"
    },
    "papermill": {
     "duration": 0.399081,
     "end_time": "2020-08-07T08:01:39.610736",
     "exception": false,
     "start_time": "2020-08-07T08:01:39.211655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_metric(metric1, metric2, ylabel):\n",
    "    plt.plot(history.history[metric1], label=metric1)\n",
    "    plt.plot(history.history[metric2], label=metric2)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T08:01:40.357272Z",
     "iopub.status.busy": "2020-08-07T08:01:40.356437Z",
     "iopub.status.idle": "2020-08-07T08:01:41.255541Z",
     "shell.execute_reply": "2020-08-07T08:01:41.256352Z"
    },
    "papermill": {
     "duration": 1.274204,
     "end_time": "2020-08-07T08:01:41.256601",
     "exception": false,
     "start_time": "2020-08-07T08:01:39.982397",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('auc', 'val_auc', 'auc')\n",
    "plot_metric('loss', 'val_loss', 'loss')\n",
    "plot_metric('accuracy', 'val_accuracy', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-07T08:01:42.175705Z",
     "iopub.status.busy": "2020-08-07T08:01:42.170533Z",
     "iopub.status.idle": "2020-08-07T08:01:42.209078Z",
     "shell.execute_reply": "2020-08-07T08:01:42.210435Z"
    },
    "papermill": {
     "duration": 0.566314,
     "end_time": "2020-08-07T08:01:42.210756",
     "exception": false,
     "start_time": "2020-08-07T08:01:41.644442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.535526692867279,\n",
       "  0.5814924836158752,\n",
       "  0.6230131983757019,\n",
       "  0.6024717092514038,\n",
       "  0.5923019647598267,\n",
       "  0.611698567867279,\n",
       "  0.612944483757019,\n",
       "  0.5962755680084229,\n",
       "  0.6174569129943848,\n",
       "  0.624360203742981,\n",
       "  0.6230131983757019,\n",
       "  0.6407933831214905,\n",
       "  0.6340921521186829,\n",
       "  0.643891453742981,\n",
       "  0.6286705136299133,\n",
       "  0.6366177201271057,\n",
       "  0.6392443180084229,\n",
       "  0.644160807132721,\n",
       "  0.6501212120056152,\n",
       "  0.652949869632721,\n",
       "  0.6677666902542114,\n",
       "  0.659785807132721,\n",
       "  0.6644666194915771,\n",
       "  0.655913233757019,\n",
       "  0.6605603694915771,\n",
       "  0.6658472418785095,\n",
       "  0.6778354048728943,\n",
       "  0.6807650923728943,\n",
       "  0.6880050897598267,\n",
       "  0.6940328478813171,\n",
       "  0.6927869319915771,\n",
       "  0.6861193180084229,\n",
       "  0.6964574456214905,\n",
       "  0.6892510652542114,\n",
       "  0.6898909211158752,\n",
       "  0.6933256983757019,\n",
       "  0.7065261006355286,\n",
       "  0.6893520951271057,\n",
       "  0.7000942826271057,\n",
       "  0.6964574456214905,\n",
       "  0.705448567867279,\n",
       "  0.7061893939971924,\n",
       "  0.7030239701271057,\n",
       "  0.7007677555084229,\n",
       "  0.7020137310028076,\n",
       "  0.702788233757019,\n",
       "  0.6978380680084229,\n",
       "  0.7033944129943848,\n",
       "  0.7014749646186829,\n",
       "  0.7010708451271057,\n",
       "  0.7094894647598267,\n",
       "  0.7160560488700867,\n",
       "  0.7183458805084229,\n",
       "  0.7026535272598267,\n",
       "  0.7098935842514038,\n",
       "  0.7173693180084229,\n",
       "  0.7286503314971924,\n",
       "  0.7131263613700867,\n",
       "  0.7189520597457886,\n",
       "  0.7220838069915771,\n",
       "  0.7191541194915771,\n",
       "  0.7209725379943848,\n",
       "  0.732421875,\n",
       "  0.7212755680084229,\n",
       "  0.7300646305084229,\n",
       "  0.7280441522598267,\n",
       "  0.729828953742981,\n",
       "  0.7364291548728943,\n",
       "  0.7442753314971924,\n",
       "  0.733061671257019,\n",
       "  0.7279431819915771,\n",
       "  0.7344760298728943,\n",
       "  0.724272608757019,\n",
       "  0.7301993370056152,\n",
       "  0.733768880367279,\n",
       "  0.736698567867279,\n",
       "  0.7334994673728943,\n",
       "  0.724003255367279,\n",
       "  0.7362270951271057,\n",
       "  0.735957682132721,\n",
       "  0.7325229048728943,\n",
       "  0.7280778288841248,\n",
       "  0.7321524620056152,\n",
       "  0.7388536930084229,\n",
       "  0.7411435842514038,\n",
       "  0.7488887310028076,\n",
       "  0.7371026277542114,\n",
       "  0.7332974076271057,\n",
       "  0.7493265271186829,\n",
       "  0.7289534211158752,\n",
       "  0.7397629022598267,\n",
       "  0.7338025569915771,\n",
       "  0.7362270951271057,\n",
       "  0.7309738397598267,\n",
       "  0.7304350733757019,\n",
       "  0.7334321141242981,\n",
       "  0.7449824810028076,\n",
       "  0.7434334754943848,\n",
       "  0.737910807132721,\n",
       "  0.741581380367279,\n",
       "  0.7505387663841248,\n",
       "  0.7488887310028076,\n",
       "  0.7416823506355286,\n",
       "  0.7442079782485962,\n",
       "  0.7399986386299133,\n",
       "  0.7421201467514038,\n",
       "  0.742557942867279,\n",
       "  0.7578798532485962,\n",
       "  0.7391567826271057,\n",
       "  0.7433661222457886,\n",
       "  0.7516500353813171,\n",
       "  0.7523909211158752,\n",
       "  0.7508081793785095,\n",
       "  0.7422548532485962,\n",
       "  0.7438375353813171,\n",
       "  0.7491918206214905,\n",
       "  0.7522562146186829,\n",
       "  0.7400323152542114,\n",
       "  0.7529970407485962,\n",
       "  0.7455213069915771,\n",
       "  0.7527949810028076,\n",
       "  0.7528960108757019,\n",
       "  0.7570043206214905,\n",
       "  0.7508755326271057,\n",
       "  0.7551185488700867,\n",
       "  0.7562971711158752,\n",
       "  0.7626279592514038,\n",
       "  0.7645137310028076,\n",
       "  0.7531317472457886,\n",
       "  0.762358546257019,\n",
       "  0.7533674836158752,\n",
       "  0.7568022608757019,\n",
       "  0.7598666548728943,\n",
       "  0.7623922228813171,\n",
       "  0.7579808831214905,\n",
       "  0.747710108757019,\n",
       "  0.734981119632721,\n",
       "  0.7526265978813171,\n",
       "  0.7607085108757019,\n",
       "  0.7608095407485962,\n",
       "  0.754512369632721,\n",
       "  0.7433661222457886,\n",
       "  0.7539736032485962,\n",
       "  0.7534347772598267,\n",
       "  0.7670729756355286,\n",
       "  0.7612809538841248,\n",
       "  0.7604390978813171,\n",
       "  0.7566675543785095,\n",
       "  0.767207682132721,\n",
       "  0.755522608757019,\n",
       "  0.769194483757019,\n",
       "  0.7539736032485962,\n",
       "  0.7554215788841248,\n",
       "  0.7686220407485962,\n",
       "  0.7658944129943848],\n",
       " 'fn': [256.0,\n",
       "  220.0,\n",
       "  217.0,\n",
       "  215.0,\n",
       "  205.0,\n",
       "  210.0,\n",
       "  196.0,\n",
       "  193.0,\n",
       "  196.0,\n",
       "  178.0,\n",
       "  181.0,\n",
       "  172.0,\n",
       "  162.0,\n",
       "  153.0,\n",
       "  170.0,\n",
       "  161.0,\n",
       "  131.0,\n",
       "  160.0,\n",
       "  139.0,\n",
       "  124.0,\n",
       "  119.0,\n",
       "  109.0,\n",
       "  121.0,\n",
       "  117.0,\n",
       "  113.0,\n",
       "  100.0,\n",
       "  103.0,\n",
       "  101.0,\n",
       "  96.0,\n",
       "  109.0,\n",
       "  89.0,\n",
       "  102.0,\n",
       "  96.0,\n",
       "  100.0,\n",
       "  84.0,\n",
       "  96.0,\n",
       "  85.0,\n",
       "  84.0,\n",
       "  68.0,\n",
       "  82.0,\n",
       "  69.0,\n",
       "  71.0,\n",
       "  66.0,\n",
       "  78.0,\n",
       "  85.0,\n",
       "  79.0,\n",
       "  77.0,\n",
       "  82.0,\n",
       "  76.0,\n",
       "  76.0,\n",
       "  69.0,\n",
       "  76.0,\n",
       "  72.0,\n",
       "  70.0,\n",
       "  60.0,\n",
       "  75.0,\n",
       "  65.0,\n",
       "  68.0,\n",
       "  69.0,\n",
       "  71.0,\n",
       "  67.0,\n",
       "  70.0,\n",
       "  66.0,\n",
       "  70.0,\n",
       "  72.0,\n",
       "  65.0,\n",
       "  72.0,\n",
       "  63.0,\n",
       "  67.0,\n",
       "  77.0,\n",
       "  71.0,\n",
       "  67.0,\n",
       "  68.0,\n",
       "  66.0,\n",
       "  60.0,\n",
       "  60.0,\n",
       "  65.0,\n",
       "  69.0,\n",
       "  59.0,\n",
       "  62.0,\n",
       "  64.0,\n",
       "  72.0,\n",
       "  64.0,\n",
       "  60.0,\n",
       "  69.0,\n",
       "  59.0,\n",
       "  69.0,\n",
       "  58.0,\n",
       "  71.0,\n",
       "  56.0,\n",
       "  69.0,\n",
       "  63.0,\n",
       "  55.0,\n",
       "  65.0,\n",
       "  60.0,\n",
       "  63.0,\n",
       "  64.0,\n",
       "  69.0,\n",
       "  65.0,\n",
       "  53.0,\n",
       "  43.0,\n",
       "  57.0,\n",
       "  61.0,\n",
       "  62.0,\n",
       "  63.0,\n",
       "  51.0,\n",
       "  59.0,\n",
       "  64.0,\n",
       "  66.0,\n",
       "  51.0,\n",
       "  50.0,\n",
       "  55.0,\n",
       "  51.0,\n",
       "  57.0,\n",
       "  68.0,\n",
       "  65.0,\n",
       "  61.0,\n",
       "  65.0,\n",
       "  57.0,\n",
       "  65.0,\n",
       "  59.0,\n",
       "  69.0,\n",
       "  53.0,\n",
       "  59.0,\n",
       "  56.0,\n",
       "  59.0,\n",
       "  49.0,\n",
       "  64.0,\n",
       "  55.0,\n",
       "  56.0,\n",
       "  54.0,\n",
       "  56.0,\n",
       "  51.0,\n",
       "  71.0,\n",
       "  58.0,\n",
       "  60.0,\n",
       "  63.0,\n",
       "  61.0,\n",
       "  57.0,\n",
       "  53.0,\n",
       "  51.0,\n",
       "  54.0,\n",
       "  60.0,\n",
       "  65.0,\n",
       "  46.0,\n",
       "  52.0,\n",
       "  54.0,\n",
       "  54.0,\n",
       "  54.0,\n",
       "  54.0,\n",
       "  59.0,\n",
       "  60.0,\n",
       "  48.0,\n",
       "  46.0,\n",
       "  57.0],\n",
       " 'tp': [270.0,\n",
       "  303.0,\n",
       "  313.0,\n",
       "  315.0,\n",
       "  321.0,\n",
       "  319.0,\n",
       "  336.0,\n",
       "  329.0,\n",
       "  336.0,\n",
       "  355.0,\n",
       "  343.0,\n",
       "  361.0,\n",
       "  367.0,\n",
       "  376.0,\n",
       "  357.0,\n",
       "  363.0,\n",
       "  397.0,\n",
       "  363.0,\n",
       "  394.0,\n",
       "  403.0,\n",
       "  407.0,\n",
       "  409.0,\n",
       "  421.0,\n",
       "  406.0,\n",
       "  416.0,\n",
       "  429.0,\n",
       "  421.0,\n",
       "  431.0,\n",
       "  428.0,\n",
       "  415.0,\n",
       "  439.0,\n",
       "  419.0,\n",
       "  444.0,\n",
       "  427.0,\n",
       "  446.0,\n",
       "  430.0,\n",
       "  444.0,\n",
       "  442.0,\n",
       "  451.0,\n",
       "  450.0,\n",
       "  455.0,\n",
       "  453.0,\n",
       "  458.0,\n",
       "  456.0,\n",
       "  440.0,\n",
       "  448.0,\n",
       "  456.0,\n",
       "  447.0,\n",
       "  451.0,\n",
       "  451.0,\n",
       "  465.0,\n",
       "  452.0,\n",
       "  458.0,\n",
       "  457.0,\n",
       "  467.0,\n",
       "  452.0,\n",
       "  462.0,\n",
       "  457.0,\n",
       "  461.0,\n",
       "  458.0,\n",
       "  458.0,\n",
       "  457.0,\n",
       "  460.0,\n",
       "  465.0,\n",
       "  448.0,\n",
       "  464.0,\n",
       "  461.0,\n",
       "  461.0,\n",
       "  458.0,\n",
       "  448.0,\n",
       "  457.0,\n",
       "  460.0,\n",
       "  461.0,\n",
       "  470.0,\n",
       "  465.0,\n",
       "  471.0,\n",
       "  460.0,\n",
       "  456.0,\n",
       "  466.0,\n",
       "  461.0,\n",
       "  470.0,\n",
       "  450.0,\n",
       "  462.0,\n",
       "  470.0,\n",
       "  458.0,\n",
       "  465.0,\n",
       "  462.0,\n",
       "  471.0,\n",
       "  460.0,\n",
       "  468.0,\n",
       "  462.0,\n",
       "  464.0,\n",
       "  472.0,\n",
       "  474.0,\n",
       "  468.0,\n",
       "  463.0,\n",
       "  459.0,\n",
       "  461.0,\n",
       "  459.0,\n",
       "  474.0,\n",
       "  485.0,\n",
       "  466.0,\n",
       "  470.0,\n",
       "  468.0,\n",
       "  466.0,\n",
       "  475.0,\n",
       "  465.0,\n",
       "  463.0,\n",
       "  468.0,\n",
       "  474.0,\n",
       "  476.0,\n",
       "  469.0,\n",
       "  477.0,\n",
       "  472.0,\n",
       "  464.0,\n",
       "  470.0,\n",
       "  462.0,\n",
       "  460.0,\n",
       "  471.0,\n",
       "  457.0,\n",
       "  469.0,\n",
       "  461.0,\n",
       "  467.0,\n",
       "  464.0,\n",
       "  476.0,\n",
       "  471.0,\n",
       "  474.0,\n",
       "  467.0,\n",
       "  472.0,\n",
       "  475.0,\n",
       "  472.0,\n",
       "  478.0,\n",
       "  475.0,\n",
       "  465.0,\n",
       "  472.0,\n",
       "  468.0,\n",
       "  460.0,\n",
       "  467.0,\n",
       "  469.0,\n",
       "  475.0,\n",
       "  474.0,\n",
       "  477.0,\n",
       "  461.0,\n",
       "  462.0,\n",
       "  489.0,\n",
       "  475.0,\n",
       "  469.0,\n",
       "  469.0,\n",
       "  480.0,\n",
       "  472.0,\n",
       "  470.0,\n",
       "  465.0,\n",
       "  479.0,\n",
       "  479.0,\n",
       "  475.0],\n",
       " 'loss': [2.441716432571411,\n",
       "  2.445889949798584,\n",
       "  1.8770277500152588,\n",
       "  1.7591843605041504,\n",
       "  1.5975100994110107,\n",
       "  1.3178409337997437,\n",
       "  1.206684947013855,\n",
       "  1.0691660642623901,\n",
       "  0.9106631278991699,\n",
       "  0.8206840753555298,\n",
       "  0.7600905895233154,\n",
       "  0.7050211429595947,\n",
       "  0.7199740409851074,\n",
       "  0.6543513536453247,\n",
       "  0.6980474591255188,\n",
       "  0.6665531396865845,\n",
       "  0.618137538433075,\n",
       "  0.6239429712295532,\n",
       "  0.5928523540496826,\n",
       "  0.5836978554725647,\n",
       "  0.5645628571510315,\n",
       "  0.5490072965621948,\n",
       "  0.5610848665237427,\n",
       "  0.5550617575645447,\n",
       "  0.5534390211105347,\n",
       "  0.5326462388038635,\n",
       "  0.5290252566337585,\n",
       "  0.528629720211029,\n",
       "  0.5081328749656677,\n",
       "  0.520747184753418,\n",
       "  0.5133114457130432,\n",
       "  0.5150338411331177,\n",
       "  0.5157240629196167,\n",
       "  0.5105252861976624,\n",
       "  0.5036937594413757,\n",
       "  0.5050703287124634,\n",
       "  0.48870640993118286,\n",
       "  0.4962427616119385,\n",
       "  0.47554486989974976,\n",
       "  0.48638468980789185,\n",
       "  0.47396498918533325,\n",
       "  0.471859872341156,\n",
       "  0.4734611213207245,\n",
       "  0.4764202833175659,\n",
       "  0.48813286423683167,\n",
       "  0.4703303277492523,\n",
       "  0.47635456919670105,\n",
       "  0.4733632206916809,\n",
       "  0.4641793668270111,\n",
       "  0.47337570786476135,\n",
       "  0.4629654288291931,\n",
       "  0.46368876099586487,\n",
       "  0.4479523003101349,\n",
       "  0.46010613441467285,\n",
       "  0.4503873288631439,\n",
       "  0.4567742943763733,\n",
       "  0.4441705644130707,\n",
       "  0.45399951934814453,\n",
       "  0.44710850715637207,\n",
       "  0.46084585785865784,\n",
       "  0.4542197287082672,\n",
       "  0.44264769554138184,\n",
       "  0.4372873604297638,\n",
       "  0.4469496011734009,\n",
       "  0.44009146094322205,\n",
       "  0.43689027428627014,\n",
       "  0.4446456730365753,\n",
       "  0.42239484190940857,\n",
       "  0.4212228059768677,\n",
       "  0.4326865077018738,\n",
       "  0.45397505164146423,\n",
       "  0.4318831264972687,\n",
       "  0.4414319694042206,\n",
       "  0.456621378660202,\n",
       "  0.4287598729133606,\n",
       "  0.4312880039215088,\n",
       "  0.44222378730773926,\n",
       "  0.44873467087745667,\n",
       "  0.42611661553382874,\n",
       "  0.42885085940361023,\n",
       "  0.4335038661956787,\n",
       "  0.438597708940506,\n",
       "  0.43153828382492065,\n",
       "  0.41858136653900146,\n",
       "  0.43150779604911804,\n",
       "  0.4209461808204651,\n",
       "  0.4327319860458374,\n",
       "  0.421101450920105,\n",
       "  0.4260029196739197,\n",
       "  0.4259152412414551,\n",
       "  0.4376046061515808,\n",
       "  0.4322042465209961,\n",
       "  0.42284849286079407,\n",
       "  0.4296753704547882,\n",
       "  0.4187609851360321,\n",
       "  0.4184296131134033,\n",
       "  0.40825632214546204,\n",
       "  0.4179694354534149,\n",
       "  0.42991164326667786,\n",
       "  0.4086005985736847,\n",
       "  0.3985433876514435,\n",
       "  0.4091505706310272,\n",
       "  0.42533111572265625,\n",
       "  0.41562944650650024,\n",
       "  0.41576310992240906,\n",
       "  0.4123382270336151,\n",
       "  0.4076542556285858,\n",
       "  0.402261346578598,\n",
       "  0.43151578307151794,\n",
       "  0.4043404757976532,\n",
       "  0.39679381251335144,\n",
       "  0.4051320552825928,\n",
       "  0.40537047386169434,\n",
       "  0.4139740765094757,\n",
       "  0.41396188735961914,\n",
       "  0.4124198853969574,\n",
       "  0.40461719036102295,\n",
       "  0.41724157333374023,\n",
       "  0.4117358326911926,\n",
       "  0.4221280813217163,\n",
       "  0.4143811762332916,\n",
       "  0.41482415795326233,\n",
       "  0.39119279384613037,\n",
       "  0.4051476716995239,\n",
       "  0.4025256633758545,\n",
       "  0.39953166246414185,\n",
       "  0.38631871342658997,\n",
       "  0.3925866484642029,\n",
       "  0.3914653956890106,\n",
       "  0.410052627325058,\n",
       "  0.40443331003189087,\n",
       "  0.398908406496048,\n",
       "  0.39518195390701294,\n",
       "  0.39804428815841675,\n",
       "  0.39576202630996704,\n",
       "  0.4109961688518524,\n",
       "  0.42105987668037415,\n",
       "  0.4018154442310333,\n",
       "  0.39537233114242554,\n",
       "  0.39110031723976135,\n",
       "  0.3962305784225464,\n",
       "  0.39850661158561707,\n",
       "  0.399774968624115,\n",
       "  0.4016471803188324,\n",
       "  0.38370177149772644,\n",
       "  0.39007022976875305,\n",
       "  0.3860231637954712,\n",
       "  0.39092034101486206,\n",
       "  0.39002567529678345,\n",
       "  0.39040085673332214,\n",
       "  0.40028977394104004,\n",
       "  0.40718844532966614,\n",
       "  0.3866056501865387,\n",
       "  0.36616361141204834,\n",
       "  0.3864430785179138],\n",
       " 'auc': [0.5369746685028076,\n",
       "  0.600359320640564,\n",
       "  0.6522718071937561,\n",
       "  0.6438357830047607,\n",
       "  0.6454098224639893,\n",
       "  0.6552883386611938,\n",
       "  0.6654574275016785,\n",
       "  0.655342161655426,\n",
       "  0.6789326071739197,\n",
       "  0.7038145065307617,\n",
       "  0.7105384469032288,\n",
       "  0.7259399890899658,\n",
       "  0.7156615853309631,\n",
       "  0.7417964935302734,\n",
       "  0.7184518575668335,\n",
       "  0.7363088726997375,\n",
       "  0.7494745254516602,\n",
       "  0.7428656220436096,\n",
       "  0.7650218605995178,\n",
       "  0.7696437835693359,\n",
       "  0.7840729355812073,\n",
       "  0.7872024774551392,\n",
       "  0.7890849113464355,\n",
       "  0.7832028865814209,\n",
       "  0.7887638807296753,\n",
       "  0.800540030002594,\n",
       "  0.8077971339225769,\n",
       "  0.8083037734031677,\n",
       "  0.8173121213912964,\n",
       "  0.8125576972961426,\n",
       "  0.8183135390281677,\n",
       "  0.8153194785118103,\n",
       "  0.8204593658447266,\n",
       "  0.8203036785125732,\n",
       "  0.823279619216919,\n",
       "  0.821303129196167,\n",
       "  0.8373134732246399,\n",
       "  0.8253350853919983,\n",
       "  0.8400022983551025,\n",
       "  0.8393993973731995,\n",
       "  0.8431728482246399,\n",
       "  0.8435691595077515,\n",
       "  0.8433220982551575,\n",
       "  0.8449307084083557,\n",
       "  0.8350602984428406,\n",
       "  0.845694899559021,\n",
       "  0.8445578813552856,\n",
       "  0.8449137210845947,\n",
       "  0.8508204817771912,\n",
       "  0.8444438576698303,\n",
       "  0.8526603579521179,\n",
       "  0.8541203737258911,\n",
       "  0.863239049911499,\n",
       "  0.8515021204948425,\n",
       "  0.8611770272254944,\n",
       "  0.8567463159561157,\n",
       "  0.8657314777374268,\n",
       "  0.8585545420646667,\n",
       "  0.8658615350723267,\n",
       "  0.8574622273445129,\n",
       "  0.8580895066261292,\n",
       "  0.8663673996925354,\n",
       "  0.8727821111679077,\n",
       "  0.8644423484802246,\n",
       "  0.8683153390884399,\n",
       "  0.8678553104400635,\n",
       "  0.8703577518463135,\n",
       "  0.8760558366775513,\n",
       "  0.8794440627098083,\n",
       "  0.8724921345710754,\n",
       "  0.8608728647232056,\n",
       "  0.8755567073822021,\n",
       "  0.8688486218452454,\n",
       "  0.8624190092086792,\n",
       "  0.8762533068656921,\n",
       "  0.8739327788352966,\n",
       "  0.8674553036689758,\n",
       "  0.8650853037834167,\n",
       "  0.8781975507736206,\n",
       "  0.873505711555481,\n",
       "  0.8743665814399719,\n",
       "  0.8675323724746704,\n",
       "  0.8752752542495728,\n",
       "  0.8805618286132812,\n",
       "  0.8760189414024353,\n",
       "  0.8804705142974854,\n",
       "  0.8753640055656433,\n",
       "  0.8800689578056335,\n",
       "  0.880187451839447,\n",
       "  0.8749445676803589,\n",
       "  0.869276762008667,\n",
       "  0.8744114637374878,\n",
       "  0.8767886757850647,\n",
       "  0.8743112087249756,\n",
       "  0.8803979158401489,\n",
       "  0.8795846700668335,\n",
       "  0.885252058506012,\n",
       "  0.8830678462982178,\n",
       "  0.873937726020813,\n",
       "  0.8863387107849121,\n",
       "  0.8924887776374817,\n",
       "  0.8867248296737671,\n",
       "  0.88116055727005,\n",
       "  0.8828116655349731,\n",
       "  0.8817058205604553,\n",
       "  0.8813475966453552,\n",
       "  0.8876796960830688,\n",
       "  0.8909893035888672,\n",
       "  0.877852201461792,\n",
       "  0.8874605894088745,\n",
       "  0.8930386304855347,\n",
       "  0.8875514268875122,\n",
       "  0.8890345096588135,\n",
       "  0.8851926922798157,\n",
       "  0.8846427202224731,\n",
       "  0.8860752582550049,\n",
       "  0.8868187069892883,\n",
       "  0.8812094330787659,\n",
       "  0.8870524168014526,\n",
       "  0.8812623023986816,\n",
       "  0.8853824734687805,\n",
       "  0.8856844305992126,\n",
       "  0.8949520587921143,\n",
       "  0.8876636028289795,\n",
       "  0.8912444710731506,\n",
       "  0.8920738697052002,\n",
       "  0.8960513472557068,\n",
       "  0.8961928486824036,\n",
       "  0.8982030749320984,\n",
       "  0.890744149684906,\n",
       "  0.8899231553077698,\n",
       "  0.8933825492858887,\n",
       "  0.8961341381072998,\n",
       "  0.8953795433044434,\n",
       "  0.8943026065826416,\n",
       "  0.8856623768806458,\n",
       "  0.8813852667808533,\n",
       "  0.8914382457733154,\n",
       "  0.8952745199203491,\n",
       "  0.8940892815589905,\n",
       "  0.8930639624595642,\n",
       "  0.8928767442703247,\n",
       "  0.8951088786125183,\n",
       "  0.8906465768814087,\n",
       "  0.9033734798431396,\n",
       "  0.8982821702957153,\n",
       "  0.9002672433853149,\n",
       "  0.8970494270324707,\n",
       "  0.899566113948822,\n",
       "  0.8952746391296387,\n",
       "  0.8948014974594116,\n",
       "  0.8883898854255676,\n",
       "  0.8989845514297485,\n",
       "  0.9100891351699829,\n",
       "  0.9018070101737976],\n",
       " 'val_accuracy': [0.9833984375,\n",
       "  0.983593761920929,\n",
       "  0.9837890863418579,\n",
       "  0.983203113079071,\n",
       "  0.983203113079071,\n",
       "  0.983593761920929,\n",
       "  0.984570324420929,\n",
       "  0.9828125238418579,\n",
       "  0.9830078482627869,\n",
       "  0.983593761920929,\n",
       "  0.9828125238418579,\n",
       "  0.9798828363418579,\n",
       "  0.9837890863418579,\n",
       "  0.982421875,\n",
       "  0.974414050579071,\n",
       "  0.982421875,\n",
       "  0.9828125238418579,\n",
       "  0.955859363079071,\n",
       "  0.978515625,\n",
       "  0.972851574420929,\n",
       "  0.9791015982627869,\n",
       "  0.9755859375,\n",
       "  0.9800781607627869,\n",
       "  0.9808593988418579,\n",
       "  0.9642578363418579,\n",
       "  0.9697265625,\n",
       "  0.98046875,\n",
       "  0.975390613079071,\n",
       "  0.9798828363418579,\n",
       "  0.9800781607627869,\n",
       "  0.9775390625,\n",
       "  0.980273425579071,\n",
       "  0.978515625,\n",
       "  0.979687511920929,\n",
       "  0.9771484732627869,\n",
       "  0.9759765863418579,\n",
       "  0.9794921875,\n",
       "  0.976757824420929,\n",
       "  0.973828136920929,\n",
       "  0.974609375,\n",
       "  0.971875011920929,\n",
       "  0.956835925579071,\n",
       "  0.9693359732627869,\n",
       "  0.9781250357627869,\n",
       "  0.9736328125,\n",
       "  0.979687511920929,\n",
       "  0.9759765863418579,\n",
       "  0.976757824420929,\n",
       "  0.9742187857627869,\n",
       "  0.9632812738418579,\n",
       "  0.969921886920929,\n",
       "  0.9710937738418579,\n",
       "  0.9730468988418579,\n",
       "  0.93359375,\n",
       "  0.912890613079071,\n",
       "  0.9271484613418579,\n",
       "  0.9283203482627869,\n",
       "  0.948437511920929,\n",
       "  0.9400390982627869,\n",
       "  0.943359375,\n",
       "  0.9482421875,\n",
       "  0.954296886920929,\n",
       "  0.9576172232627869,\n",
       "  0.917773425579071,\n",
       "  0.919140636920929,\n",
       "  0.9302734732627869,\n",
       "  0.947265625,\n",
       "  0.940625011920929,\n",
       "  0.939257800579071,\n",
       "  0.9351562857627869,\n",
       "  0.9419922232627869,\n",
       "  0.9632812738418579,\n",
       "  0.9466797113418579,\n",
       "  0.9507812857627869,\n",
       "  0.9400390982627869,\n",
       "  0.9322265982627869,\n",
       "  0.9146484732627869,\n",
       "  0.950976550579071,\n",
       "  0.920703113079071,\n",
       "  0.908984363079071,\n",
       "  0.9369140863418579,\n",
       "  0.9566406607627869,\n",
       "  0.9085937738418579,\n",
       "  0.9144531488418579,\n",
       "  0.9332031607627869,\n",
       "  0.930468738079071,\n",
       "  0.945507824420929,\n",
       "  0.8919922113418579,\n",
       "  0.89453125,\n",
       "  0.9027343988418579,\n",
       "  0.930859386920929,\n",
       "  0.9214844107627869,\n",
       "  0.9107422232627869,\n",
       "  0.9189453125,\n",
       "  0.9095703363418579,\n",
       "  0.9097656607627869,\n",
       "  0.8404297232627869,\n",
       "  0.9037109613418579,\n",
       "  0.883593738079071,\n",
       "  0.9388672113418579,\n",
       "  0.9228515625,\n",
       "  0.844531238079071,\n",
       "  0.885937511920929,\n",
       "  0.9281250238418579,\n",
       "  0.8998047113418579,\n",
       "  0.891406238079071,\n",
       "  0.876757800579071,\n",
       "  0.882617175579071,\n",
       "  0.8902344107627869,\n",
       "  0.884570300579071,\n",
       "  0.8626953363418579,\n",
       "  0.873242199420929,\n",
       "  0.8871093988418579,\n",
       "  0.9017578363418579,\n",
       "  0.8636718988418579,\n",
       "  0.861523449420929,\n",
       "  0.8031250238418579,\n",
       "  0.8423828482627869,\n",
       "  0.830859363079071,\n",
       "  0.818164050579071,\n",
       "  0.8095703125,\n",
       "  0.8169922232627869,\n",
       "  0.8453125357627869,\n",
       "  0.8121094107627869,\n",
       "  0.869921863079071,\n",
       "  0.8759765625,\n",
       "  0.8794922232627869,\n",
       "  0.863476574420929,\n",
       "  0.870312511920929,\n",
       "  0.876757800579071,\n",
       "  0.852734386920929,\n",
       "  0.860546886920929,\n",
       "  0.8529297113418579,\n",
       "  0.887499988079071,\n",
       "  0.8515625,\n",
       "  0.800000011920929,\n",
       "  0.848828136920929,\n",
       "  0.830078125,\n",
       "  0.828906238079071,\n",
       "  0.795117199420929,\n",
       "  0.843945324420929,\n",
       "  0.82421875,\n",
       "  0.870312511920929,\n",
       "  0.8871093988418579,\n",
       "  0.853710949420929,\n",
       "  0.8203125,\n",
       "  0.8841797113418579,\n",
       "  0.861523449420929,\n",
       "  0.8529297113418579,\n",
       "  0.8525390625,\n",
       "  0.8662109375,\n",
       "  0.8070312738418579,\n",
       "  0.834179699420929,\n",
       "  0.8304687738418579,\n",
       "  0.7777343988418579],\n",
       " 'val_fn': [85.0,\n",
       "  84.0,\n",
       "  83.0,\n",
       "  86.0,\n",
       "  86.0,\n",
       "  84.0,\n",
       "  79.0,\n",
       "  88.0,\n",
       "  87.0,\n",
       "  84.0,\n",
       "  88.0,\n",
       "  86.0,\n",
       "  83.0,\n",
       "  86.0,\n",
       "  86.0,\n",
       "  87.0,\n",
       "  87.0,\n",
       "  85.0,\n",
       "  86.0,\n",
       "  84.0,\n",
       "  84.0,\n",
       "  81.0,\n",
       "  86.0,\n",
       "  82.0,\n",
       "  85.0,\n",
       "  85.0,\n",
       "  83.0,\n",
       "  82.0,\n",
       "  82.0,\n",
       "  85.0,\n",
       "  86.0,\n",
       "  87.0,\n",
       "  86.0,\n",
       "  86.0,\n",
       "  83.0,\n",
       "  87.0,\n",
       "  81.0,\n",
       "  82.0,\n",
       "  81.0,\n",
       "  82.0,\n",
       "  83.0,\n",
       "  75.0,\n",
       "  78.0,\n",
       "  81.0,\n",
       "  80.0,\n",
       "  86.0,\n",
       "  80.0,\n",
       "  78.0,\n",
       "  77.0,\n",
       "  77.0,\n",
       "  83.0,\n",
       "  77.0,\n",
       "  76.0,\n",
       "  72.0,\n",
       "  64.0,\n",
       "  68.0,\n",
       "  70.0,\n",
       "  69.0,\n",
       "  70.0,\n",
       "  71.0,\n",
       "  74.0,\n",
       "  65.0,\n",
       "  69.0,\n",
       "  60.0,\n",
       "  61.0,\n",
       "  73.0,\n",
       "  68.0,\n",
       "  68.0,\n",
       "  60.0,\n",
       "  65.0,\n",
       "  69.0,\n",
       "  72.0,\n",
       "  61.0,\n",
       "  69.0,\n",
       "  65.0,\n",
       "  63.0,\n",
       "  63.0,\n",
       "  63.0,\n",
       "  63.0,\n",
       "  54.0,\n",
       "  64.0,\n",
       "  70.0,\n",
       "  61.0,\n",
       "  52.0,\n",
       "  53.0,\n",
       "  60.0,\n",
       "  68.0,\n",
       "  54.0,\n",
       "  55.0,\n",
       "  51.0,\n",
       "  67.0,\n",
       "  65.0,\n",
       "  55.0,\n",
       "  60.0,\n",
       "  49.0,\n",
       "  55.0,\n",
       "  40.0,\n",
       "  53.0,\n",
       "  49.0,\n",
       "  56.0,\n",
       "  57.0,\n",
       "  47.0,\n",
       "  51.0,\n",
       "  59.0,\n",
       "  54.0,\n",
       "  47.0,\n",
       "  49.0,\n",
       "  42.0,\n",
       "  50.0,\n",
       "  49.0,\n",
       "  48.0,\n",
       "  49.0,\n",
       "  44.0,\n",
       "  54.0,\n",
       "  43.0,\n",
       "  48.0,\n",
       "  35.0,\n",
       "  40.0,\n",
       "  41.0,\n",
       "  37.0,\n",
       "  38.0,\n",
       "  29.0,\n",
       "  35.0,\n",
       "  31.0,\n",
       "  38.0,\n",
       "  51.0,\n",
       "  49.0,\n",
       "  40.0,\n",
       "  38.0,\n",
       "  50.0,\n",
       "  42.0,\n",
       "  39.0,\n",
       "  45.0,\n",
       "  45.0,\n",
       "  37.0,\n",
       "  31.0,\n",
       "  39.0,\n",
       "  41.0,\n",
       "  36.0,\n",
       "  34.0,\n",
       "  33.0,\n",
       "  36.0,\n",
       "  46.0,\n",
       "  41.0,\n",
       "  45.0,\n",
       "  39.0,\n",
       "  46.0,\n",
       "  38.0,\n",
       "  45.0,\n",
       "  52.0,\n",
       "  48.0,\n",
       "  32.0,\n",
       "  31.0,\n",
       "  34.0,\n",
       "  36.0],\n",
       " 'val_tp': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  4.0,\n",
       "  2.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  6.0,\n",
       "  7.0,\n",
       "  2.0,\n",
       "  9.0,\n",
       "  8.0,\n",
       "  5.0,\n",
       "  6.0,\n",
       "  2.0,\n",
       "  8.0,\n",
       "  6.0,\n",
       "  10.0,\n",
       "  10.0,\n",
       "  6.0,\n",
       "  6.0,\n",
       "  8.0,\n",
       "  18.0,\n",
       "  22.0,\n",
       "  21.0,\n",
       "  19.0,\n",
       "  17.0,\n",
       "  17.0,\n",
       "  18.0,\n",
       "  10.0,\n",
       "  22.0,\n",
       "  17.0,\n",
       "  27.0,\n",
       "  25.0,\n",
       "  17.0,\n",
       "  16.0,\n",
       "  19.0,\n",
       "  20.0,\n",
       "  21.0,\n",
       "  19.0,\n",
       "  12.0,\n",
       "  25.0,\n",
       "  15.0,\n",
       "  22.0,\n",
       "  22.0,\n",
       "  22.0,\n",
       "  20.0,\n",
       "  23.0,\n",
       "  27.0,\n",
       "  23.0,\n",
       "  13.0,\n",
       "  29.0,\n",
       "  30.0,\n",
       "  31.0,\n",
       "  25.0,\n",
       "  16.0,\n",
       "  35.0,\n",
       "  32.0,\n",
       "  33.0,\n",
       "  20.0,\n",
       "  24.0,\n",
       "  29.0,\n",
       "  29.0,\n",
       "  31.0,\n",
       "  30.0,\n",
       "  41.0,\n",
       "  30.0,\n",
       "  37.0,\n",
       "  29.0,\n",
       "  31.0,\n",
       "  38.0,\n",
       "  38.0,\n",
       "  27.0,\n",
       "  31.0,\n",
       "  38.0,\n",
       "  33.0,\n",
       "  44.0,\n",
       "  37.0,\n",
       "  31.0,\n",
       "  38.0,\n",
       "  33.0,\n",
       "  42.0,\n",
       "  29.0,\n",
       "  44.0,\n",
       "  38.0,\n",
       "  49.0,\n",
       "  48.0,\n",
       "  45.0,\n",
       "  50.0,\n",
       "  49.0,\n",
       "  55.0,\n",
       "  49.0,\n",
       "  51.0,\n",
       "  44.0,\n",
       "  36.0,\n",
       "  34.0,\n",
       "  47.0,\n",
       "  47.0,\n",
       "  36.0,\n",
       "  45.0,\n",
       "  46.0,\n",
       "  41.0,\n",
       "  41.0,\n",
       "  49.0,\n",
       "  53.0,\n",
       "  47.0,\n",
       "  48.0,\n",
       "  51.0,\n",
       "  52.0,\n",
       "  50.0,\n",
       "  52.0,\n",
       "  40.0,\n",
       "  47.0,\n",
       "  43.0,\n",
       "  47.0,\n",
       "  37.0,\n",
       "  48.0,\n",
       "  41.0,\n",
       "  34.0,\n",
       "  40.0,\n",
       "  55.0,\n",
       "  55.0,\n",
       "  51.0,\n",
       "  53.0],\n",
       " 'val_loss': [0.10361137241125107,\n",
       "  0.10288675129413605,\n",
       "  0.10540187358856201,\n",
       "  0.13236473500728607,\n",
       "  0.13339585065841675,\n",
       "  0.11620255559682846,\n",
       "  0.10745463520288467,\n",
       "  0.11121080070734024,\n",
       "  0.1894952654838562,\n",
       "  0.17374025285243988,\n",
       "  0.28666988015174866,\n",
       "  0.33162328600883484,\n",
       "  0.27139782905578613,\n",
       "  0.22997832298278809,\n",
       "  0.25019916892051697,\n",
       "  0.19779472053050995,\n",
       "  0.18382088840007782,\n",
       "  0.2601521611213684,\n",
       "  0.22291569411754608,\n",
       "  0.267345666885376,\n",
       "  0.24678686261177063,\n",
       "  0.23391468822956085,\n",
       "  0.20009922981262207,\n",
       "  0.20718896389007568,\n",
       "  0.2115272581577301,\n",
       "  0.1939375251531601,\n",
       "  0.17169320583343506,\n",
       "  0.20359830558300018,\n",
       "  0.17117026448249817,\n",
       "  0.1739993840456009,\n",
       "  0.1932176798582077,\n",
       "  0.17663314938545227,\n",
       "  0.16224397718906403,\n",
       "  0.1535102128982544,\n",
       "  0.187758207321167,\n",
       "  0.16821850836277008,\n",
       "  0.1595672070980072,\n",
       "  0.1841513216495514,\n",
       "  0.18905292451381683,\n",
       "  0.17669616639614105,\n",
       "  0.18206565082073212,\n",
       "  0.19890658557415009,\n",
       "  0.18034933507442474,\n",
       "  0.16191820800304413,\n",
       "  0.1797504872083664,\n",
       "  0.1314820647239685,\n",
       "  0.15708903968334198,\n",
       "  0.15192681550979614,\n",
       "  0.17863838374614716,\n",
       "  0.19577720761299133,\n",
       "  0.1761188507080078,\n",
       "  0.17243821918964386,\n",
       "  0.181234672665596,\n",
       "  0.20735536515712738,\n",
       "  0.23214469850063324,\n",
       "  0.21361921727657318,\n",
       "  0.20473110675811768,\n",
       "  0.19501833617687225,\n",
       "  0.19058798253536224,\n",
       "  0.18017692863941193,\n",
       "  0.17237702012062073,\n",
       "  0.15995243191719055,\n",
       "  0.15302057564258575,\n",
       "  0.21597416698932648,\n",
       "  0.20434752106666565,\n",
       "  0.18052074313163757,\n",
       "  0.15370480716228485,\n",
       "  0.16483592987060547,\n",
       "  0.1606699675321579,\n",
       "  0.1741061508655548,\n",
       "  0.16222093999385834,\n",
       "  0.1445033997297287,\n",
       "  0.16494619846343994,\n",
       "  0.15121141076087952,\n",
       "  0.17092248797416687,\n",
       "  0.18078134953975677,\n",
       "  0.21700899302959442,\n",
       "  0.1578477919101715,\n",
       "  0.21315407752990723,\n",
       "  0.21439070999622345,\n",
       "  0.17754463851451874,\n",
       "  0.1690824329853058,\n",
       "  0.21878819167613983,\n",
       "  0.20205210149288177,\n",
       "  0.19419801235198975,\n",
       "  0.1954190582036972,\n",
       "  0.1597476303577423,\n",
       "  0.24211733043193817,\n",
       "  0.23235563933849335,\n",
       "  0.22273121774196625,\n",
       "  0.19257178902626038,\n",
       "  0.20181997120380402,\n",
       "  0.21943990886211395,\n",
       "  0.2080649882555008,\n",
       "  0.23077653348445892,\n",
       "  0.2159625142812729,\n",
       "  0.3181489408016205,\n",
       "  0.22963538765907288,\n",
       "  0.2708801329135895,\n",
       "  0.18342356383800507,\n",
       "  0.21376805007457733,\n",
       "  0.31272411346435547,\n",
       "  0.25074025988578796,\n",
       "  0.1936720609664917,\n",
       "  0.23342740535736084,\n",
       "  0.2462252676486969,\n",
       "  0.26058319211006165,\n",
       "  0.2672104239463806,\n",
       "  0.25525611639022827,\n",
       "  0.2486077845096588,\n",
       "  0.27017006278038025,\n",
       "  0.2724171280860901,\n",
       "  0.23544590175151825,\n",
       "  0.22178366780281067,\n",
       "  0.2714539170265198,\n",
       "  0.29805588722229004,\n",
       "  0.37215709686279297,\n",
       "  0.31544122099876404,\n",
       "  0.3384349048137665,\n",
       "  0.36324238777160645,\n",
       "  0.3689543902873993,\n",
       "  0.3784548342227936,\n",
       "  0.31274691224098206,\n",
       "  0.353404700756073,\n",
       "  0.2554358243942261,\n",
       "  0.23803992569446564,\n",
       "  0.2490425854921341,\n",
       "  0.27983519434928894,\n",
       "  0.2609977424144745,\n",
       "  0.2436549961566925,\n",
       "  0.2821357548236847,\n",
       "  0.2906486690044403,\n",
       "  0.30661457777023315,\n",
       "  0.25199076533317566,\n",
       "  0.3050954043865204,\n",
       "  0.3736239969730377,\n",
       "  0.30579400062561035,\n",
       "  0.3633982241153717,\n",
       "  0.3405703902244568,\n",
       "  0.4175797402858734,\n",
       "  0.32438984513282776,\n",
       "  0.3244304358959198,\n",
       "  0.26911649107933044,\n",
       "  0.24584417045116425,\n",
       "  0.2642960250377655,\n",
       "  0.31856462359428406,\n",
       "  0.24421894550323486,\n",
       "  0.26298436522483826,\n",
       "  0.29286566376686096,\n",
       "  0.2934635579586029,\n",
       "  0.2771175801753998,\n",
       "  0.3659505546092987,\n",
       "  0.30904483795166016,\n",
       "  0.3124711513519287,\n",
       "  0.38151612877845764],\n",
       " 'val_auc': [0.5038495063781738,\n",
       "  0.5,\n",
       "  0.4999999701976776,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.4331597685813904,\n",
       "  0.3279525339603424,\n",
       "  0.341277152299881,\n",
       "  0.3184579014778137,\n",
       "  0.3737541735172272,\n",
       "  0.317787766456604,\n",
       "  0.31613171100616455,\n",
       "  0.47016772627830505,\n",
       "  0.5372190475463867,\n",
       "  0.7344022393226624,\n",
       "  0.5453341007232666,\n",
       "  0.6113901138305664,\n",
       "  0.5448272824287415,\n",
       "  0.6297214031219482,\n",
       "  0.5608749985694885,\n",
       "  0.5342322587966919,\n",
       "  0.5638633966445923,\n",
       "  0.5883009433746338,\n",
       "  0.6285678148269653,\n",
       "  0.6306328177452087,\n",
       "  0.6229187250137329,\n",
       "  0.6557255387306213,\n",
       "  0.6264808177947998,\n",
       "  0.6489506363868713,\n",
       "  0.6462647914886475,\n",
       "  0.6359176635742188,\n",
       "  0.6268609166145325,\n",
       "  0.671474277973175,\n",
       "  0.6730612516403198,\n",
       "  0.6522617340087891,\n",
       "  0.68435138463974,\n",
       "  0.6764262914657593,\n",
       "  0.7387228012084961,\n",
       "  0.7397431135177612,\n",
       "  0.7831376791000366,\n",
       "  0.7741456627845764,\n",
       "  0.7672154307365417,\n",
       "  0.7950366139411926,\n",
       "  0.7872411012649536,\n",
       "  0.7238630056381226,\n",
       "  0.7919747829437256,\n",
       "  0.7953371405601501,\n",
       "  0.8196924328804016,\n",
       "  0.8074411749839783,\n",
       "  0.7802696824073792,\n",
       "  0.7594531178474426,\n",
       "  0.7926813364028931,\n",
       "  0.7533330917358398,\n",
       "  0.7873833775520325,\n",
       "  0.8029352426528931,\n",
       "  0.7964699268341064,\n",
       "  0.80739426612854,\n",
       "  0.7968120574951172,\n",
       "  0.7938272356987,\n",
       "  0.8190677762031555,\n",
       "  0.8039877414703369,\n",
       "  0.8266852498054504,\n",
       "  0.8310511708259583,\n",
       "  0.8084141612052917,\n",
       "  0.8175476789474487,\n",
       "  0.828115701675415,\n",
       "  0.8217820525169373,\n",
       "  0.8116487860679626,\n",
       "  0.82085782289505,\n",
       "  0.8079352378845215,\n",
       "  0.8342956900596619,\n",
       "  0.8072237968444824,\n",
       "  0.8299828767776489,\n",
       "  0.8040382862091064,\n",
       "  0.8262133598327637,\n",
       "  0.8010538220405579,\n",
       "  0.784614622592926,\n",
       "  0.8178514242172241,\n",
       "  0.7840984463691711,\n",
       "  0.8297391533851624,\n",
       "  0.8054723143577576,\n",
       "  0.817103922367096,\n",
       "  0.825406551361084,\n",
       "  0.8272407054901123,\n",
       "  0.8325921893119812,\n",
       "  0.8332636952400208,\n",
       "  0.8456705212593079,\n",
       "  0.8246869444847107,\n",
       "  0.8444659113883972,\n",
       "  0.8182809352874756,\n",
       "  0.8096638917922974,\n",
       "  0.7915710210800171,\n",
       "  0.8206358551979065,\n",
       "  0.8301307559013367,\n",
       "  0.8153917789459229,\n",
       "  0.8109925985336304,\n",
       "  0.813480794429779,\n",
       "  0.8295549750328064,\n",
       "  0.8213854432106018,\n",
       "  0.832150399684906,\n",
       "  0.8152336478233337,\n",
       "  0.8136967420578003,\n",
       "  0.809299111366272,\n",
       "  0.8046678304672241,\n",
       "  0.8220902681350708,\n",
       "  0.806873083114624,\n",
       "  0.8005160689353943,\n",
       "  0.8040739297866821,\n",
       "  0.8316844701766968,\n",
       "  0.8171811103820801,\n",
       "  0.8018413186073303,\n",
       "  0.7917665243148804,\n",
       "  0.8266867399215698,\n",
       "  0.8272802829742432,\n",
       "  0.8205909729003906,\n",
       "  0.8224989175796509,\n",
       "  0.8125426173210144,\n",
       "  0.8228620290756226,\n",
       "  0.8253563046455383,\n",
       "  0.7980408668518066,\n",
       "  0.8168706297874451,\n",
       "  0.8324040174484253,\n",
       "  0.8517898321151733,\n",
       "  0.812351644039154,\n",
       "  0.8397305607795715,\n",
       "  0.8318420052528381,\n",
       "  0.8302009701728821,\n",
       "  0.8200622797012329,\n",
       "  0.8263591527938843,\n",
       "  0.8277249336242676,\n",
       "  0.8169233202934265,\n",
       "  0.8461159467697144,\n",
       "  0.8125014901161194,\n",
       "  0.8253412842750549,\n",
       "  0.8349445462226868,\n",
       "  0.8145599961280823,\n",
       "  0.8246884942054749,\n",
       "  0.8094611167907715,\n",
       "  0.8210625648498535,\n",
       "  0.8283692598342896,\n",
       "  0.8351008892059326,\n",
       "  0.8333370685577393,\n",
       "  0.8109632730484009,\n",
       "  0.8387162685394287,\n",
       "  0.8237462043762207,\n",
       "  0.834904134273529,\n",
       "  0.8284478783607483,\n",
       "  0.8439876437187195,\n",
       "  0.804039716720581,\n",
       "  0.8024871945381165,\n",
       "  0.7959005832672119,\n",
       "  0.8255102634429932,\n",
       "  0.820858895778656,\n",
       "  0.8371226191520691,\n",
       "  0.8165684938430786]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.371002,
     "end_time": "2020-08-07T08:01:42.967987",
     "exception": false,
     "start_time": "2020-08-07T08:01:42.596985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "duration": 4834.552758,
   "end_time": "2020-08-07T08:01:43.451753",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-07T06:41:08.898995",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
