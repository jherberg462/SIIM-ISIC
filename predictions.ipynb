{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:14.354956Z",
     "iopub.status.busy": "2020-08-11T07:51:14.354229Z",
     "iopub.status.idle": "2020-08-11T07:51:21.842777Z",
     "shell.execute_reply": "2020-08-11T07:51:21.842115Z"
    },
    "papermill": {
     "duration": 7.515897,
     "end_time": "2020-08-11T07:51:21.842898",
     "exception": false,
     "start_time": "2020-08-11T07:51:14.327001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got GCS path via KaggleDatasets .get_gcs_path method\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "try:\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "    dataset_gcs = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n",
    "    print('got GCS path via KaggleDatasets .get_gcs_path method')\n",
    "except ModuleNotFoundError:\n",
    "    #hardcode path while testing locally\n",
    "    dataset_gcs = 'gs://'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:21.889176Z",
     "iopub.status.busy": "2020-08-11T07:51:21.888199Z",
     "iopub.status.idle": "2020-08-11T07:51:21.892966Z",
     "shell.execute_reply": "2020-08-11T07:51:21.892259Z"
    },
    "papermill": {
     "duration": 0.029505,
     "end_time": "2020-08-11T07:51:21.893088",
     "exception": false,
     "start_time": "2020-08-11T07:51:21.863583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:21.936489Z",
     "iopub.status.busy": "2020-08-11T07:51:21.935498Z",
     "iopub.status.idle": "2020-08-11T07:51:21.938858Z",
     "shell.execute_reply": "2020-08-11T07:51:21.938146Z"
    },
    "papermill": {
     "duration": 0.02685,
     "end_time": "2020-08-11T07:51:21.938981",
     "exception": false,
     "start_time": "2020-08-11T07:51:21.912131",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size' : 128,\n",
    "    'img_size' : [256, 256],\n",
    "    'epochs': 350\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:22.023583Z",
     "iopub.status.busy": "2020-08-11T07:51:21.992184Z",
     "iopub.status.idle": "2020-08-11T07:51:26.444457Z",
     "shell.execute_reply": "2020-08-11T07:51:26.445246Z"
    },
    "papermill": {
     "duration": 4.487553,
     "end_time": "2020-08-11T07:51:26.445595",
     "exception": false,
     "start_time": "2020-08-11T07:51:21.958042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:26.494434Z",
     "iopub.status.busy": "2020-08-11T07:51:26.493571Z",
     "iopub.status.idle": "2020-08-11T07:51:26.496374Z",
     "shell.execute_reply": "2020-08-11T07:51:26.496984Z"
    },
    "papermill": {
     "duration": 0.03009,
     "end_time": "2020-08-11T07:51:26.497141",
     "exception": false,
     "start_time": "2020-08-11T07:51:26.467051",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params['batch_size'] = params['batch_size'] * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:26.542724Z",
     "iopub.status.busy": "2020-08-11T07:51:26.542013Z",
     "iopub.status.idle": "2020-08-11T07:51:26.545164Z",
     "shell.execute_reply": "2020-08-11T07:51:26.544576Z"
    },
    "papermill": {
     "duration": 0.02737,
     "end_time": "2020-08-11T07:51:26.545280",
     "exception": false,
     "start_time": "2020-08-11T07:51:26.517910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub = pd.read_csv(dataset_gcs + '/sample_submission.csv')\n",
    "# sub.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:26.591542Z",
     "iopub.status.busy": "2020-08-11T07:51:26.590868Z",
     "iopub.status.idle": "2020-08-11T07:51:36.275081Z",
     "shell.execute_reply": "2020-08-11T07:51:36.274443Z"
    },
    "papermill": {
     "duration": 9.709283,
     "end_time": "2020-08-11T07:51:36.275228",
     "exception": false,
     "start_time": "2020-08-11T07:51:26.565945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32542</td>\n",
       "      <td>32542</td>\n",
       "      <td>32477</td>\n",
       "      <td>32474</td>\n",
       "      <td>32024</td>\n",
       "      <td>32542</td>\n",
       "      <td>32542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>575</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name  patient_id    sex  age_approx  \\\n",
       "target                                              \n",
       "0            32542       32542  32477       32474   \n",
       "1              584         584    584         584   \n",
       "\n",
       "        anatom_site_general_challenge  diagnosis  benign_malignant  \n",
       "target                                                              \n",
       "0                               32024      32542             32542  \n",
       "1                                 575        584               584  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(dataset_gcs + '/train.csv')\n",
    "train_df.groupby('target').count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:36.327758Z",
     "iopub.status.busy": "2020-08-11T07:51:36.327039Z",
     "iopub.status.idle": "2020-08-11T07:51:36.329676Z",
     "shell.execute_reply": "2020-08-11T07:51:36.330230Z"
    },
    "papermill": {
     "duration": 0.033618,
     "end_time": "2020-08-11T07:51:36.330381",
     "exception": false,
     "start_time": "2020-08-11T07:51:36.296763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image_label(tfrec):\n",
    "    '''\n",
    "    function to decode an image and target label from tfrecord\n",
    "    \n",
    "    args:\n",
    "        tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "    returns:\n",
    "        decoded_image: tensor, converted image from tfrecord\n",
    "        label: tensor, integer, either 1 or 0\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "    decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "    decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "    label = features['target']\n",
    "    \n",
    "    return decoded_image, label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:36.382988Z",
     "iopub.status.busy": "2020-08-11T07:51:36.381935Z",
     "iopub.status.idle": "2020-08-11T07:51:36.384751Z",
     "shell.execute_reply": "2020-08-11T07:51:36.385272Z"
    },
    "papermill": {
     "duration": 0.03366,
     "end_time": "2020-08-11T07:51:36.385426",
     "exception": false,
     "start_time": "2020-08-11T07:51:36.351766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(tfrec):\n",
    "    '''\n",
    "    function to decode an image from tfrecord\n",
    "    \n",
    "    args:\n",
    "        tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "    returns:\n",
    "        decoded_image: tensor, converted image from tfrecord\n",
    "        img_name: tensor, string, Id of the decoded image\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "    features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "    decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "    decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "    img_name = features['image_name']\n",
    "    \n",
    "    return decoded_image, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:36.436529Z",
     "iopub.status.busy": "2020-08-11T07:51:36.435516Z",
     "iopub.status.idle": "2020-08-11T07:51:36.438907Z",
     "shell.execute_reply": "2020-08-11T07:51:36.438173Z"
    },
    "papermill": {
     "duration": 0.031919,
     "end_time": "2020-08-11T07:51:36.439021",
     "exception": false,
     "start_time": "2020-08-11T07:51:36.407102",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image_label(decoded_image, label):\n",
    "    '''\n",
    "    function to convert an image tensor values from 0 to 255 \n",
    "    -> -1 to 1\n",
    "    to be used when dealing with tfrecords containing labels\n",
    "    \n",
    "    args:\n",
    "        decoded_image: tensor that is an image with values from 0 to 255\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image_tensor: tensor that is an image with values from -1 to 1\n",
    "        label, same as input\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "    image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "    #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "    image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "    #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "    image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "    return image_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:36.491608Z",
     "iopub.status.busy": "2020-08-11T07:51:36.490602Z",
     "iopub.status.idle": "2020-08-11T07:51:36.494955Z",
     "shell.execute_reply": "2020-08-11T07:51:36.494302Z"
    },
    "papermill": {
     "duration": 0.034375,
     "end_time": "2020-08-11T07:51:36.495077",
     "exception": false,
     "start_time": "2020-08-11T07:51:36.460702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image(decoded_image):\n",
    "    '''\n",
    "    function to convert an image tensor values from 0 to 255 \n",
    "    -> -1 to 1\n",
    "    \n",
    "    args:\n",
    "        decoded_image: tensor that is an image with values from 0 to 255\n",
    "    \n",
    "    returns: \n",
    "        image_tensor: tensor that is an image with values from -1 to 1\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "    image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "    #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "    image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "    #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "    image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:36.547596Z",
     "iopub.status.busy": "2020-08-11T07:51:36.546506Z",
     "iopub.status.idle": "2020-08-11T07:51:36.549882Z",
     "shell.execute_reply": "2020-08-11T07:51:36.549151Z"
    },
    "papermill": {
     "duration": 0.031212,
     "end_time": "2020-08-11T07:51:36.549998",
     "exception": false,
     "start_time": "2020-08-11T07:51:36.518786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_flip(image, label):\n",
    "    '''\n",
    "    function to randomly flip images on the x and/or y axis\n",
    "    \n",
    "    args:\n",
    "        image: tensor, an image\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image: tensor, same as input, but possibly flipped on x and/or y axis\n",
    "        label, tensor, same as input\n",
    "    '''\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image, label #, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:36.604272Z",
     "iopub.status.busy": "2020-08-11T07:51:36.603483Z",
     "iopub.status.idle": "2020-08-11T07:51:36.606723Z",
     "shell.execute_reply": "2020-08-11T07:51:36.606109Z"
    },
    "papermill": {
     "duration": 0.034651,
     "end_time": "2020-08-11T07:51:36.606841",
     "exception": false,
     "start_time": "2020-08-11T07:51:36.572190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_ds(tfrecords, batch_size):\n",
    "    '''\n",
    "    function to create a ds pipeline from tfrecord files\n",
    "    \n",
    "    args:\n",
    "        tfrecords: list, tfrecord file paths\n",
    "        batch_size: int, batch size for number of records to pass into\n",
    "            model at a time\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images and labels\n",
    "    '''\n",
    "    ds = (tf.data.TFRecordDataset(filenames=[tfrecords],\n",
    "                                 num_parallel_reads=tf.data.experimental.AUTOTUNE).\n",
    "          cache(). #need to remove cache while not usnig TPUs\n",
    "          map(decode_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(normalize_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(random_flip, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          repeat().\n",
    "          shuffle(512).\n",
    "          batch(batch_size,\n",
    "               drop_remainder=True).\n",
    "          prefetch(tf.data.experimental.AUTOTUNE)\n",
    "         )\n",
    "    \n",
    "\n",
    "    \n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:36.660423Z",
     "iopub.status.busy": "2020-08-11T07:51:36.659321Z",
     "iopub.status.idle": "2020-08-11T07:51:36.662607Z",
     "shell.execute_reply": "2020-08-11T07:51:36.661904Z"
    },
    "papermill": {
     "duration": 0.033672,
     "end_time": "2020-08-11T07:51:36.662746",
     "exception": false,
     "start_time": "2020-08-11T07:51:36.629074",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_ds(tfrecords, batch_size):\n",
    "    '''\n",
    "    function to create a dataset for test data\n",
    "    args:\n",
    "        tfrecords: list, tfrecord file paths\n",
    "        batch_size: int, batch size for number of records to pass into\n",
    "            model at a time\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images and labels\n",
    "    \n",
    "    '''\n",
    "\n",
    "    ds = (tf.data.TFRecordDataset(filenames=[tfrecords],\n",
    "                                 num_parallel_reads=tf.data.experimental.AUTOTUNE).\n",
    "#           cache(). #there is no reason to cache this ds -- it is only being read 1x\n",
    "          map(decode_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(normalize_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "#           map(random_flip).\n",
    "          batch(batch_size).\n",
    "#                 drop_remainder=True).\n",
    "          prefetch(tf.data.experimental.AUTOTUNE)\n",
    "         )\n",
    "    \n",
    "    return ds\n",
    "    ###come back to this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022118,
     "end_time": "2020-08-11T07:51:36.707405",
     "exception": false,
     "start_time": "2020-08-11T07:51:36.685287",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:36.769843Z",
     "iopub.status.busy": "2020-08-11T07:51:36.768710Z",
     "iopub.status.idle": "2020-08-11T07:51:36.772098Z",
     "shell.execute_reply": "2020-08-11T07:51:36.771369Z"
    },
    "papermill": {
     "duration": 0.042157,
     "end_time": "2020-08-11T07:51:36.772217",
     "exception": false,
     "start_time": "2020-08-11T07:51:36.730060",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_of_layers(input_layer, \n",
    "                  filters_, \n",
    "                  kernal, \n",
    "                  strides_, \n",
    "                  dense=None, \n",
    "                  dense_activation=None,\n",
    "                  dropout=None,\n",
    "                  cnn_activation=None):\n",
    "    '''\n",
    "    function to add the following layers to a model:\n",
    "    Conv2D, MaxPooling2D, BatchNormalization, LeadyReLU, Dense,\n",
    "        Dropout\n",
    "\n",
    "    args:\n",
    "      input_layer : input layer to be fed into above layers\n",
    "      filters_: int, number of filters in Conv2D layer\n",
    "      kernal: int, kernal size in Conv2D layer\n",
    "      strides_: int, stride size in MaxPooling2D layer\n",
    "      dense: int, number of units in dense layer, default is None\n",
    "          Will only add layer if value is passed\n",
    "      dense_activation: str, activation function to pass into Dense layer\n",
    "          default is None\n",
    "      dropout: float, dropout percentage in Dropout layer, default is None\n",
    "        must be less than 1.0. Will only add layer if value is passed \n",
    "      cnn_activation: tensorflow activation layer, default is None\n",
    "          will only add layer is value is passed. Activation layer will be\n",
    "          added after the BatchNormalization layer\n",
    "\n",
    "    returns:\n",
    "      x: model that is the same as the input_layer input plus above \n",
    "        layers added\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    x_dict = {}\n",
    "    for xx in range(len(kernal)):\n",
    "        x_dict[xx] = layers.Conv2D(filters_, (kernal[xx], kernal[xx]),\n",
    "                                   padding='same', activation=cnn_activation)(input_layer)\n",
    "        for _ in range(1):\n",
    "            x_dict[xx] = layers.Conv2D(filters_, (kernal[xx], kernal[xx]),\n",
    "                                       padding='same', activation=cnn_activation)(x_dict[xx])\n",
    "    x_list = [x_dict[xx] for xx in x_dict]\n",
    "    if len(x_list) > 1:\n",
    "        x = layers.Concatenate()(x_list)\n",
    "    else:\n",
    "        x = x_list[0]\n",
    "    x = layers.MaxPooling2D(strides_, strides_)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "\n",
    "    \n",
    "    if cnn_activation:\n",
    "        x = cnn_activation(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    if dense:\n",
    "        x = layers.Dense(dense, activation=dense_activation)(x)\n",
    "    if dropout:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:36.832825Z",
     "iopub.status.busy": "2020-08-11T07:51:36.831675Z",
     "iopub.status.idle": "2020-08-11T07:51:36.835140Z",
     "shell.execute_reply": "2020-08-11T07:51:36.834527Z"
    },
    "papermill": {
     "duration": 0.040402,
     "end_time": "2020-08-11T07:51:36.835254",
     "exception": false,
     "start_time": "2020-08-11T07:51:36.794852",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deconv_set_of_layers(input_layer, \n",
    "                         filters_, \n",
    "                         kernal_, \n",
    "                         stride, \n",
    "                         dense=None, \n",
    "                         dense_activation=None, \n",
    "                         dropout=None,\n",
    "                         cnn_activation=None):\n",
    "    '''\n",
    "    function to add the following layers to a model:\n",
    "    Conv2DTranspose, BatchNormalization, LeadyReLU, Dense\n",
    "\n",
    "    args:\n",
    "      input_layer : input layer to be fed into above layers\n",
    "      filters_: int, number of filters in Conv2DTranspose layer\n",
    "      kernal_: int, kernal size in Conv2DTranspose layer\n",
    "      strides_: int, stride size in Conv2DTranspose layer\n",
    "      dense: int, number of units in dense layer, default is None\n",
    "          Will only add layer if value is passed\n",
    "      dense_activation: str, activation function to pass into Dense layer\n",
    "          default is None\n",
    "      dropout: float, dropout percentage in Dropout layer, default is None\n",
    "        must be less than 1.0. Will only add layer if value is passed \n",
    "      cnn_activation: tensorflow activation layer, default is None\n",
    "          will only add layer is value is passed. Activation layer will be\n",
    "          added after the BatchNormalization layer\n",
    "\n",
    "\n",
    "    returns:\n",
    "      x: model that is the same as the input_layer input plus above \n",
    "        layers added\n",
    "    '''\n",
    "\n",
    "        \n",
    "    x_dict = {}\n",
    "    for xx in range(len(kernal_)):\n",
    "        x_dict[xx] = layers.Conv2DTranspose(filters_,\n",
    "                                           kernal_[xx],\n",
    "                                           (stride, stride),\n",
    "                                           padding='same')(input_layer)\n",
    "        x_dict[xx] = layers.BatchNormalization()(x_dict[xx])\n",
    "    x_list = [x_dict[xx] for xx in x_dict]\n",
    "    if len(x_list) > 1:\n",
    "        x = layers.Concatenate()(x_list)\n",
    "    else:\n",
    "        x = x_list[0]\n",
    "    \n",
    "    if cnn_activation:\n",
    "        x = cnn_activation(x)\n",
    "   \n",
    "    if dense:\n",
    "        x = layers.Dense(dense, activation=dense_activation)(x)\n",
    "    \n",
    "    if dropout:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:36.902667Z",
     "iopub.status.busy": "2020-08-11T07:51:36.901638Z",
     "iopub.status.idle": "2020-08-11T07:51:36.905193Z",
     "shell.execute_reply": "2020-08-11T07:51:36.904509Z"
    },
    "papermill": {
     "duration": 0.047504,
     "end_time": "2020-08-11T07:51:36.905313",
     "exception": false,
     "start_time": "2020-08-11T07:51:36.857809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape=[*params['img_size'], 3], bias_output=None):\n",
    "    '''\n",
    "    function to create a model that will be trained on train DS\n",
    "    \n",
    "    args:\n",
    "        input_shape: array, default: [1024, 1024, 3], shape\n",
    "            of input tensor that will be fed into model\n",
    "    \n",
    "    returns:\n",
    "        model: tf.sequential() model\n",
    "    '''\n",
    "\n",
    "    relu = layers.ReLU()\n",
    "    leakyrelu = layers.LeakyReLU()\n",
    "    input_tensor = layers.Input(shape=input_shape, name='images_input')\n",
    "    x = input_tensor\n",
    "#     filters_list = [64, 128, 256, 512, 1024]\n",
    "    filters_list = [32, 64, 128, 256, 512]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x = set_of_layers(x, filter_, [3, 5], 2, 16,  dropout=0.35, dense_activation='tanh', \n",
    "                           cnn_activation=relu)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "#         x2 = set_of_layers(x, filter_, 5, 2, 16,  dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "#         x = layers.Concatenate()([x1, x2])\n",
    "#         x = layers.Dense(filter_, activation='elu')(x) #consider adding dropout\n",
    "#         x = layers.Dropout(0.35)(x)\n",
    "    \n",
    "    \n",
    "#     filters_list = [1024, 512, 256]\n",
    "    filters_list = [512, 256, 128]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x = deconv_set_of_layers(x, filter_, [2, 4], 2, 16,  dense_activation='tanh', cnn_activation=relu,\n",
    "                                 dropout=0.35)\n",
    "#         x2= deconv_set_of_layers(x, filter_, 4, 2, 16,  dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = deconv_set_of_layers(x, filter_, 4, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = deconv_set_of_layers(x, filter_, 4, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "#         x = layers.Concatenate()([x1, x2])\n",
    "#         x = layers.Dense(filter_, activation='elu')(x)\n",
    "#         x = layers.Dropout(0.35)(x)        \n",
    "    \n",
    "#     filters_list = [256, 512, 1024]\n",
    "    filters_list = [128, 256, 512]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x = set_of_layers(x, filter_, [3, 5], 2, 16,  dropout=0.35, dense_activation='tanh',\n",
    "                           cnn_activation=relu)\n",
    "#         x2 = set_of_layers(x, filter_, 5, 2, 16,  dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "#         x = layers.Concatenate()([x1, x2])\n",
    "#         x = layers.Dense(filter_, activation='elu')(x)\n",
    "#         x = layers.Dropout(0.35)(x)\n",
    "    \n",
    "\n",
    "    #layers.Concatenate\n",
    "\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "#     model.add(layers.Dense(64))\n",
    "    \n",
    "    if bias_output is not None:\n",
    "        bias_output = tf.keras.initializers.Constant(bias_output)\n",
    "    output_layer = layers.Dense(1, activation='sigmoid', bias_initializer=bias_output)(x)\n",
    "    \n",
    "    model=keras.Model(inputs=[input_tensor],\n",
    "                     outputs=[output_layer])\n",
    "\n",
    " \n",
    "           \n",
    "    metrics = [\n",
    "          keras.metrics.TruePositives(name='tp'),\n",
    "#           keras.metrics.FalsePositives(name='fp'),\n",
    "#           keras.metrics.TrueNegatives(name='tn'),\n",
    "          keras.metrics.FalseNegatives(name='fn'), \n",
    "          keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#           keras.metrics.Precision(name='precision'),\n",
    "#           keras.metrics.Recall(name='recall'),\n",
    "          keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "    schedule = None\n",
    "    \n",
    "    model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.00033),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.01),\n",
    "    metrics=metrics\n",
    ")\n",
    "    \n",
    "\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:36.958954Z",
     "iopub.status.busy": "2020-08-11T07:51:36.957855Z",
     "iopub.status.idle": "2020-08-11T07:51:36.961152Z",
     "shell.execute_reply": "2020-08-11T07:51:36.960435Z"
    },
    "papermill": {
     "duration": 0.033013,
     "end_time": "2020-08-11T07:51:36.961267",
     "exception": false,
     "start_time": "2020-08-11T07:51:36.928254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ds_size(files):\n",
    "    '''\n",
    "    function to get size of tfrecord Dataset, based on file name\n",
    "    \n",
    "    the file name has the number of records in the file, for example:\n",
    "    train09-2071.tfrec has 2017 records\n",
    "    \n",
    "    args:\n",
    "        files: list of str file names, each item should be the path to a tfrecord file\n",
    "    \n",
    "    returns:\n",
    "        size: int, size of dataset\n",
    "    '''\n",
    "    size = 0\n",
    "    for file in files:\n",
    "        file_size = int(file.split('.tfrec')[0].split('tfrecords/')[1].split('-')[1])\n",
    "        size += file_size\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:37.303458Z",
     "iopub.status.busy": "2020-08-11T07:51:37.302472Z",
     "iopub.status.idle": "2020-08-11T07:51:38.002333Z",
     "shell.execute_reply": "2020-08-11T07:51:38.001535Z"
    },
    "papermill": {
     "duration": 1.018394,
     "end_time": "2020-08-11T07:51:38.002455",
     "exception": false,
     "start_time": "2020-08-11T07:51:36.984061",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get test file paths\n",
    "test_files = tf.io.gfile.glob(dataset_gcs + '/tfrecords/test*.tfrec')\n",
    "\n",
    "#get train and validation file paths\n",
    "train_files, valid_files = train_test_split(tf.io.gfile.glob(dataset_gcs + '/tfrecords/train*.tfrec'),\n",
    "                              test_size=.1, random_state=1)\n",
    "\n",
    "#create datasets\n",
    "train_ds = get_train_ds(train_files, params['batch_size'])\n",
    "valid_ds = get_train_ds(valid_files, params['batch_size'])\n",
    "test_ds = get_test_ds(test_files, params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:38.055054Z",
     "iopub.status.busy": "2020-08-11T07:51:38.054297Z",
     "iopub.status.idle": "2020-08-11T07:51:38.057774Z",
     "shell.execute_reply": "2020-08-11T07:51:38.057205Z"
    },
    "papermill": {
     "duration": 0.032421,
     "end_time": "2020-08-11T07:51:38.057897",
     "exception": false,
     "start_time": "2020-08-11T07:51:38.025476",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset consists of: 28984 training images, 4142 validation images, and 10982 test images\n"
     ]
    }
   ],
   "source": [
    "train_size, valid_size = get_ds_size(train_files), get_ds_size(valid_files)\n",
    "test_size = get_ds_size(test_files)\n",
    "print('the dataset consists of: {} training images, {} validation images, and {} test images'.\n",
    "     format(train_size, valid_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.022682,
     "end_time": "2020-08-11T07:51:38.103702",
     "exception": false,
     "start_time": "2020-08-11T07:51:38.081020",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:38.156025Z",
     "iopub.status.busy": "2020-08-11T07:51:38.155264Z",
     "iopub.status.idle": "2020-08-11T07:51:38.158565Z",
     "shell.execute_reply": "2020-08-11T07:51:38.157847Z"
    },
    "papermill": {
     "duration": 0.031755,
     "end_time": "2020-08-11T07:51:38.158708",
     "exception": false,
     "start_time": "2020-08-11T07:51:38.126953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch_steps = train_size / params['batch_size'] \n",
    "valid_steps = valid_size / params['batch_size']\n",
    "test_steps = 1.0 * test_size / params['batch_size'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:38.215974Z",
     "iopub.status.busy": "2020-08-11T07:51:38.215264Z",
     "iopub.status.idle": "2020-08-11T07:51:38.244028Z",
     "shell.execute_reply": "2020-08-11T07:51:38.243376Z"
    },
    "papermill": {
     "duration": 0.062582,
     "end_time": "2020-08-11T07:51:38.244159",
     "exception": false,
     "start_time": "2020-08-11T07:51:38.181577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate class weights\n",
    "\n",
    "targets = train_df.groupby('target').count()['diagnosis'].to_list()\n",
    "target_0 = targets[0]\n",
    "target_1 = targets[1]\n",
    "total = target_0 + target_1\n",
    "\n",
    "class_weight_0 = (1 / target_0) * (total) / 2.0\n",
    "class_weight_1 = (1 / target_1) * (total) / 2.0\n",
    "\n",
    "class_weights = {0: class_weight_0, 1: class_weight_1}\n",
    "\n",
    "initial_bias = np.log([target_1 / target_0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.023132,
     "end_time": "2020-08-11T07:51:38.290590",
     "exception": false,
     "start_time": "2020-08-11T07:51:38.267458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:38.343439Z",
     "iopub.status.busy": "2020-08-11T07:51:38.342546Z",
     "iopub.status.idle": "2020-08-11T07:51:45.674050Z",
     "shell.execute_reply": "2020-08-11T07:51:45.673127Z"
    },
    "papermill": {
     "duration": 7.360288,
     "end_time": "2020-08-11T07:51:45.674233",
     "exception": false,
     "start_time": "2020-08-11T07:51:38.313945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "images_input (InputLayer)       [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 32) 896         images_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 32) 2432        images_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 9248        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 32) 25632       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256, 256, 64) 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 64) 256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 128, 128, 64) 0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128, 128, 16) 1040        re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128, 128, 16) 0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 64) 9280        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 64) 25664       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 64) 36928       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 64) 102464      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 128 0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 128)  512         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 64, 64, 128)  0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64, 64, 16)   2064        re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 64, 16)   0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 128)  18560       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  51328       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 128)  147584      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  409728      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 256)  0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 256)  1024        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 32, 32, 256)  0           re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32, 32, 16)   4112        re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 16)   0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 256)  37120       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 256)  102656      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 256)  1638656     conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 512)  0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 512)  2048        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 16, 16, 512)  0           re_lu[3][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16, 16, 16)   8208        re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 16, 16)   0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 512)  74240       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 512)  205312      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 512)  6554112     conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 1024) 0           conv2d_17[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 1024)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 8, 1024)   4096        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 8, 8, 1024)   0           re_lu[4][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 8, 8, 16)     16400       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 8, 8, 16)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 16, 16, 512)  33280       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 512)  131584      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 512)  2048        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 512)  2048        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 1024) 0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16, 16, 16)   16400       re_lu[5][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 16)   0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 256)  16640       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 32, 32, 256)  65792       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 512)  0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32, 32, 16)   8208        re_lu[6][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 16)   0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 64, 64, 128)  8320        dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 128)  32896       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 128)  512         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 128)  512         conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 256)  0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64, 64, 16)   4112        re_lu[7][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 16)   0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 64, 64, 128)  18560       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 64, 64, 128)  51328       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 64, 64, 128)  147584      conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 64, 64, 128)  409728      conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 64, 64, 256)  0           conv2d_21[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 256)  0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 256)  1024        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 32, 32, 256)  0           re_lu[8][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32, 32, 16)   4112        re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 16)   0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 32, 32, 256)  37120       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 32, 32, 256)  102656      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 32, 32, 256)  1638656     conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 512)  0           conv2d_25[0][0]                  \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 512)  0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 512)  2048        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 16, 16, 512)  0           re_lu[9][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16, 16, 16)   8208        re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 16, 16)   0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 16, 16, 512)  74240       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 16, 16, 512)  205312      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 16, 16, 512)  6554112     conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 16, 16, 1024) 0           conv2d_29[0][0]                  \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 1024)   0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 1024)   4096        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 8, 8, 1024)   0           re_lu[10][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 8, 8, 16)     16400       re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 8, 8, 16)     0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 128)          131200      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            129         dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 25,122,289\n",
      "Trainable params: 25,111,153\n",
      "Non-trainable params: 11,136\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model(bias_output=initial_bias)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023262,
     "end_time": "2020-08-11T07:51:45.722960",
     "exception": false,
     "start_time": "2020-08-11T07:51:45.699698",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:51:45.781660Z",
     "iopub.status.busy": "2020-08-11T07:51:45.780887Z",
     "iopub.status.idle": "2020-08-11T09:55:36.243493Z",
     "shell.execute_reply": "2020-08-11T09:55:36.244252Z"
    },
    "papermill": {
     "duration": 7430.497981,
     "end_time": "2020-08-11T09:55:36.244513",
     "exception": false,
     "start_time": "2020-08-11T07:51:45.746532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "29/28 [==============================] - 39s 1s/step - loss: 0.9394 - auc: 0.5252 - accuracy: 0.5228 - tp: 268.0000 - fn: 258.0000 - val_loss: 0.1055 - val_auc: 0.5000 - val_accuracy: 0.9830 - val_tp: 0.0000e+00 - val_fn: 87.0000\n",
      "Epoch 2/350\n",
      "29/28 [==============================] - 28s 970ms/step - loss: 0.7237 - auc: 0.6707 - accuracy: 0.6038 - tp: 334.0000 - fn: 191.0000 - val_loss: 0.1039 - val_auc: 0.5000 - val_accuracy: 0.9834 - val_tp: 0.0000e+00 - val_fn: 85.0000\n",
      "Epoch 3/350\n",
      "29/28 [==============================] - 28s 973ms/step - loss: 0.6786 - auc: 0.6988 - accuracy: 0.6187 - tp: 357.0000 - fn: 171.0000 - val_loss: 0.1062 - val_auc: 0.5000 - val_accuracy: 0.9828 - val_tp: 0.0000e+00 - val_fn: 88.0000\n",
      "Epoch 4/350\n",
      "29/28 [==============================] - 31s 1s/step - loss: 0.6435 - auc: 0.7155 - accuracy: 0.6069 - tp: 382.0000 - fn: 142.0000 - val_loss: 0.1031 - val_auc: 0.5000 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_fn: 84.0000\n",
      "Epoch 5/350\n",
      "29/28 [==============================] - 29s 999ms/step - loss: 0.6291 - auc: 0.7264 - accuracy: 0.6142 - tp: 372.0000 - fn: 157.0000 - val_loss: 0.1054 - val_auc: 0.5000 - val_accuracy: 0.9830 - val_tp: 0.0000e+00 - val_fn: 87.0000\n",
      "Epoch 6/350\n",
      "29/28 [==============================] - 27s 926ms/step - loss: 0.5939 - auc: 0.7403 - accuracy: 0.6021 - tp: 418.0000 - fn: 111.0000 - val_loss: 0.1046 - val_auc: 0.5000 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_fn: 86.0000\n",
      "Epoch 7/350\n",
      "29/28 [==============================] - 27s 933ms/step - loss: 0.5919 - auc: 0.7415 - accuracy: 0.5999 - tp: 414.0000 - fn: 117.0000 - val_loss: 0.1069 - val_auc: 0.5000 - val_accuracy: 0.9826 - val_tp: 0.0000e+00 - val_fn: 89.0000\n",
      "Epoch 8/350\n",
      "29/28 [==============================] - 28s 983ms/step - loss: 0.5962 - auc: 0.7316 - accuracy: 0.5704 - tp: 419.0000 - fn: 112.0000 - val_loss: 0.1030 - val_auc: 0.5000 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_fn: 84.0000\n",
      "Epoch 9/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.5709 - auc: 0.7487 - accuracy: 0.5841 - tp: 416.0000 - fn: 110.0000 - val_loss: 0.1030 - val_auc: 0.5000 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_fn: 84.0000\n",
      "Epoch 10/350\n",
      "29/28 [==============================] - 29s 990ms/step - loss: 0.5763 - auc: 0.7445 - accuracy: 0.5851 - tp: 415.0000 - fn: 114.0000 - val_loss: 0.1046 - val_auc: 0.5000 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_fn: 86.0000\n",
      "Epoch 11/350\n",
      "29/28 [==============================] - 28s 973ms/step - loss: 0.5700 - auc: 0.7576 - accuracy: 0.6013 - tp: 433.0000 - fn: 99.0000 - val_loss: 0.1030 - val_auc: 0.5000 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_fn: 84.0000\n",
      "Epoch 12/350\n",
      "29/28 [==============================] - 28s 969ms/step - loss: 0.5641 - auc: 0.7624 - accuracy: 0.6032 - tp: 437.0000 - fn: 90.0000 - val_loss: 0.1060 - val_auc: 0.5000 - val_accuracy: 0.9828 - val_tp: 0.0000e+00 - val_fn: 88.0000\n",
      "Epoch 13/350\n",
      "29/28 [==============================] - 29s 990ms/step - loss: 0.5592 - auc: 0.7687 - accuracy: 0.5966 - tp: 448.0000 - fn: 90.0000 - val_loss: 0.1045 - val_auc: 0.5000 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_fn: 86.0000\n",
      "Epoch 14/350\n",
      "29/28 [==============================] - 29s 984ms/step - loss: 0.5353 - auc: 0.7833 - accuracy: 0.6223 - tp: 433.0000 - fn: 87.0000 - val_loss: 0.1052 - val_auc: 0.5000 - val_accuracy: 0.9830 - val_tp: 0.0000e+00 - val_fn: 87.0000\n",
      "Epoch 15/350\n",
      "29/28 [==============================] - 28s 965ms/step - loss: 0.5304 - auc: 0.7818 - accuracy: 0.6107 - tp: 453.0000 - fn: 78.0000 - val_loss: 0.1042 - val_auc: 0.5904 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_fn: 86.0000\n",
      "Epoch 16/350\n",
      "29/28 [==============================] - 28s 981ms/step - loss: 0.5186 - auc: 0.7940 - accuracy: 0.6319 - tp: 457.0000 - fn: 67.0000 - val_loss: 0.1041 - val_auc: 0.6020 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_fn: 86.0000\n",
      "Epoch 17/350\n",
      "29/28 [==============================] - 29s 997ms/step - loss: 0.5181 - auc: 0.7958 - accuracy: 0.6380 - tp: 441.0000 - fn: 85.0000 - val_loss: 0.1027 - val_auc: 0.6084 - val_accuracy: 0.9834 - val_tp: 0.0000e+00 - val_fn: 85.0000\n",
      "Epoch 18/350\n",
      "29/28 [==============================] - 29s 994ms/step - loss: 0.5172 - auc: 0.8010 - accuracy: 0.6389 - tp: 440.0000 - fn: 85.0000 - val_loss: 0.1026 - val_auc: 0.6364 - val_accuracy: 0.9834 - val_tp: 0.0000e+00 - val_fn: 85.0000\n",
      "Epoch 19/350\n",
      "29/28 [==============================] - 29s 991ms/step - loss: 0.5313 - auc: 0.7937 - accuracy: 0.6309 - tp: 440.0000 - fn: 92.0000 - val_loss: 0.1013 - val_auc: 0.7040 - val_accuracy: 0.9834 - val_tp: 0.0000e+00 - val_fn: 85.0000\n",
      "Epoch 20/350\n",
      "29/28 [==============================] - 29s 1000ms/step - loss: 0.5231 - auc: 0.7901 - accuracy: 0.6465 - tp: 440.0000 - fn: 86.0000 - val_loss: 0.1381 - val_auc: 0.7225 - val_accuracy: 0.9803 - val_tp: 2.0000 - val_fn: 79.0000\n",
      "Epoch 21/350\n",
      "29/28 [==============================] - 29s 991ms/step - loss: 0.5149 - auc: 0.7960 - accuracy: 0.6378 - tp: 452.0000 - fn: 71.0000 - val_loss: 0.2373 - val_auc: 0.7380 - val_accuracy: 0.8676 - val_tp: 29.0000 - val_fn: 58.0000\n",
      "Epoch 22/350\n",
      "29/28 [==============================] - 28s 971ms/step - loss: 0.5159 - auc: 0.8017 - accuracy: 0.6457 - tp: 456.0000 - fn: 70.0000 - val_loss: 0.1895 - val_auc: 0.7586 - val_accuracy: 0.9320 - val_tp: 13.0000 - val_fn: 72.0000\n",
      "Epoch 23/350\n",
      "29/28 [==============================] - 29s 1s/step - loss: 0.5125 - auc: 0.8064 - accuracy: 0.6627 - tp: 455.0000 - fn: 78.0000 - val_loss: 0.1554 - val_auc: 0.7710 - val_accuracy: 0.9818 - val_tp: 0.0000e+00 - val_fn: 86.0000\n",
      "Epoch 24/350\n",
      "29/28 [==============================] - 28s 970ms/step - loss: 0.5117 - auc: 0.8119 - accuracy: 0.6615 - tp: 448.0000 - fn: 81.0000 - val_loss: 0.1088 - val_auc: 0.7705 - val_accuracy: 0.9834 - val_tp: 0.0000e+00 - val_fn: 85.0000\n",
      "Epoch 25/350\n",
      "29/28 [==============================] - 29s 993ms/step - loss: 0.5028 - auc: 0.8162 - accuracy: 0.6719 - tp: 448.0000 - fn: 81.0000 - val_loss: 0.1060 - val_auc: 0.7511 - val_accuracy: 0.9828 - val_tp: 0.0000e+00 - val_fn: 88.0000\n",
      "Epoch 26/350\n",
      "29/28 [==============================] - 28s 977ms/step - loss: 0.4918 - auc: 0.8215 - accuracy: 0.6627 - tp: 461.0000 - fn: 64.0000 - val_loss: 0.0997 - val_auc: 0.8001 - val_accuracy: 0.9828 - val_tp: 0.0000e+00 - val_fn: 88.0000\n",
      "Epoch 27/350\n",
      "29/28 [==============================] - 29s 985ms/step - loss: 0.5096 - auc: 0.8104 - accuracy: 0.6629 - tp: 447.0000 - fn: 85.0000 - val_loss: 0.1005 - val_auc: 0.7854 - val_accuracy: 0.9828 - val_tp: 0.0000e+00 - val_fn: 88.0000\n",
      "Epoch 28/350\n",
      "29/28 [==============================] - 28s 955ms/step - loss: 0.4850 - auc: 0.8295 - accuracy: 0.6830 - tp: 459.0000 - fn: 61.0000 - val_loss: 0.1010 - val_auc: 0.7737 - val_accuracy: 0.9830 - val_tp: 0.0000e+00 - val_fn: 87.0000\n",
      "Epoch 29/350\n",
      "29/28 [==============================] - 27s 937ms/step - loss: 0.4860 - auc: 0.8231 - accuracy: 0.6682 - tp: 455.0000 - fn: 73.0000 - val_loss: 0.1023 - val_auc: 0.7408 - val_accuracy: 0.9828 - val_tp: 0.0000e+00 - val_fn: 88.0000\n",
      "Epoch 30/350\n",
      "29/28 [==============================] - 29s 1s/step - loss: 0.4906 - auc: 0.8267 - accuracy: 0.6800 - tp: 447.0000 - fn: 82.0000 - val_loss: 0.1016 - val_auc: 0.7554 - val_accuracy: 0.9828 - val_tp: 0.0000e+00 - val_fn: 88.0000\n",
      "Epoch 31/350\n",
      "29/28 [==============================] - 29s 999ms/step - loss: 0.4860 - auc: 0.8277 - accuracy: 0.6737 - tp: 455.0000 - fn: 69.0000 - val_loss: 0.1074 - val_auc: 0.7576 - val_accuracy: 0.9834 - val_tp: 0.0000e+00 - val_fn: 85.0000\n",
      "Epoch 32/350\n",
      "29/28 [==============================] - 28s 972ms/step - loss: 0.4789 - auc: 0.8297 - accuracy: 0.6801 - tp: 461.0000 - fn: 69.0000 - val_loss: 0.1099 - val_auc: 0.7748 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_fn: 84.0000\n",
      "Epoch 33/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.4879 - auc: 0.8258 - accuracy: 0.6826 - tp: 453.0000 - fn: 79.0000 - val_loss: 0.1072 - val_auc: 0.6592 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_fn: 84.0000\n",
      "Epoch 34/350\n",
      "29/28 [==============================] - 28s 975ms/step - loss: 0.4775 - auc: 0.8292 - accuracy: 0.6771 - tp: 464.0000 - fn: 67.0000 - val_loss: 0.1039 - val_auc: 0.7426 - val_accuracy: 0.9838 - val_tp: 0.0000e+00 - val_fn: 83.0000\n",
      "Epoch 35/350\n",
      "29/28 [==============================] - 28s 977ms/step - loss: 0.4883 - auc: 0.8208 - accuracy: 0.6725 - tp: 457.0000 - fn: 64.0000 - val_loss: 0.1033 - val_auc: 0.7831 - val_accuracy: 0.9844 - val_tp: 0.0000e+00 - val_fn: 80.0000\n",
      "Epoch 36/350\n",
      "29/28 [==============================] - 28s 975ms/step - loss: 0.4815 - auc: 0.8297 - accuracy: 0.6800 - tp: 466.0000 - fn: 69.0000 - val_loss: 0.1183 - val_auc: 0.7988 - val_accuracy: 0.9807 - val_tp: 1.0000 - val_fn: 85.0000\n",
      "Epoch 37/350\n",
      "29/28 [==============================] - 28s 956ms/step - loss: 0.4705 - auc: 0.8401 - accuracy: 0.6987 - tp: 451.0000 - fn: 73.0000 - val_loss: 0.1085 - val_auc: 0.7456 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_fn: 86.0000\n",
      "Epoch 38/350\n",
      "29/28 [==============================] - 29s 986ms/step - loss: 0.5002 - auc: 0.8154 - accuracy: 0.6634 - tp: 450.0000 - fn: 77.0000 - val_loss: 0.1069 - val_auc: 0.7732 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_fn: 86.0000\n",
      "Epoch 39/350\n",
      "29/28 [==============================] - 27s 933ms/step - loss: 0.4708 - auc: 0.8400 - accuracy: 0.6930 - tp: 455.0000 - fn: 67.0000 - val_loss: 0.1452 - val_auc: 0.7989 - val_accuracy: 0.9627 - val_tp: 7.0000 - val_fn: 78.0000\n",
      "Epoch 40/350\n",
      "29/28 [==============================] - 29s 992ms/step - loss: 0.4637 - auc: 0.8387 - accuracy: 0.6907 - tp: 467.0000 - fn: 59.0000 - val_loss: 0.1147 - val_auc: 0.8080 - val_accuracy: 0.9807 - val_tp: 0.0000e+00 - val_fn: 86.0000\n",
      "Epoch 41/350\n",
      "29/28 [==============================] - 28s 971ms/step - loss: 0.4663 - auc: 0.8434 - accuracy: 0.7015 - tp: 466.0000 - fn: 63.0000 - val_loss: 0.1011 - val_auc: 0.8080 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_fn: 84.0000\n",
      "Epoch 42/350\n",
      "29/28 [==============================] - 29s 987ms/step - loss: 0.4610 - auc: 0.8404 - accuracy: 0.6948 - tp: 454.0000 - fn: 70.0000 - val_loss: 0.1128 - val_auc: 0.7083 - val_accuracy: 0.9830 - val_tp: 0.0000e+00 - val_fn: 87.0000\n",
      "Epoch 43/350\n",
      "29/28 [==============================] - 27s 930ms/step - loss: 0.4655 - auc: 0.8448 - accuracy: 0.6946 - tp: 460.0000 - fn: 70.0000 - val_loss: 0.1046 - val_auc: 0.7310 - val_accuracy: 0.9830 - val_tp: 0.0000e+00 - val_fn: 87.0000\n",
      "Epoch 44/350\n",
      "29/28 [==============================] - 29s 999ms/step - loss: 0.4654 - auc: 0.8427 - accuracy: 0.6932 - tp: 471.0000 - fn: 56.0000 - val_loss: 0.1426 - val_auc: 0.6918 - val_accuracy: 0.9814 - val_tp: 2.0000 - val_fn: 83.0000\n",
      "Epoch 45/350\n",
      "29/28 [==============================] - 29s 989ms/step - loss: 0.4709 - auc: 0.8365 - accuracy: 0.6948 - tp: 460.0000 - fn: 66.0000 - val_loss: 0.1016 - val_auc: 0.7945 - val_accuracy: 0.9828 - val_tp: 0.0000e+00 - val_fn: 88.0000\n",
      "Epoch 46/350\n",
      "29/28 [==============================] - 29s 1s/step - loss: 0.4640 - auc: 0.8431 - accuracy: 0.6891 - tp: 466.0000 - fn: 61.0000 - val_loss: 0.1134 - val_auc: 0.6808 - val_accuracy: 0.9828 - val_tp: 1.0000 - val_fn: 88.0000\n",
      "Epoch 47/350\n",
      "29/28 [==============================] - 28s 980ms/step - loss: 0.4737 - auc: 0.8449 - accuracy: 0.7072 - tp: 456.0000 - fn: 73.0000 - val_loss: 0.1214 - val_auc: 0.6815 - val_accuracy: 0.9801 - val_tp: 3.0000 - val_fn: 82.0000\n",
      "Epoch 48/350\n",
      "29/28 [==============================] - 28s 977ms/step - loss: 0.4547 - auc: 0.8500 - accuracy: 0.7093 - tp: 465.0000 - fn: 63.0000 - val_loss: 0.1160 - val_auc: 0.7275 - val_accuracy: 0.9812 - val_tp: 4.0000 - val_fn: 83.0000\n",
      "Epoch 49/350\n",
      "29/28 [==============================] - 28s 960ms/step - loss: 0.4664 - auc: 0.8457 - accuracy: 0.6999 - tp: 468.0000 - fn: 60.0000 - val_loss: 0.1291 - val_auc: 0.8012 - val_accuracy: 0.9686 - val_tp: 7.0000 - val_fn: 80.0000\n",
      "Epoch 50/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.4663 - auc: 0.8512 - accuracy: 0.7100 - tp: 460.0000 - fn: 70.0000 - val_loss: 0.1445 - val_auc: 0.7839 - val_accuracy: 0.9635 - val_tp: 8.0000 - val_fn: 78.0000\n",
      "Epoch 51/350\n",
      "29/28 [==============================] - 30s 1s/step - loss: 0.4525 - auc: 0.8514 - accuracy: 0.7019 - tp: 462.0000 - fn: 67.0000 - val_loss: 0.2105 - val_auc: 0.7289 - val_accuracy: 0.9174 - val_tp: 17.0000 - val_fn: 70.0000\n",
      "Epoch 52/350\n",
      "29/28 [==============================] - 29s 990ms/step - loss: 0.4608 - auc: 0.8474 - accuracy: 0.6997 - tp: 467.0000 - fn: 68.0000 - val_loss: 0.1251 - val_auc: 0.8195 - val_accuracy: 0.9684 - val_tp: 7.0000 - val_fn: 77.0000\n",
      "Epoch 53/350\n",
      "29/28 [==============================] - 28s 967ms/step - loss: 0.4567 - auc: 0.8526 - accuracy: 0.7019 - tp: 461.0000 - fn: 70.0000 - val_loss: 0.1754 - val_auc: 0.7594 - val_accuracy: 0.9389 - val_tp: 16.0000 - val_fn: 68.0000\n",
      "Epoch 54/350\n",
      "29/28 [==============================] - 28s 971ms/step - loss: 0.4595 - auc: 0.8498 - accuracy: 0.7086 - tp: 463.0000 - fn: 64.0000 - val_loss: 0.3093 - val_auc: 0.7677 - val_accuracy: 0.8434 - val_tp: 41.0000 - val_fn: 44.0000\n",
      "Epoch 55/350\n",
      "29/28 [==============================] - 29s 993ms/step - loss: 0.4505 - auc: 0.8530 - accuracy: 0.7075 - tp: 469.0000 - fn: 58.0000 - val_loss: 0.1706 - val_auc: 0.7334 - val_accuracy: 0.9484 - val_tp: 9.0000 - val_fn: 77.0000\n",
      "Epoch 56/350\n",
      "29/28 [==============================] - 28s 978ms/step - loss: 0.4600 - auc: 0.8509 - accuracy: 0.7000 - tp: 460.0000 - fn: 68.0000 - val_loss: 0.1823 - val_auc: 0.6488 - val_accuracy: 0.9523 - val_tp: 7.0000 - val_fn: 79.0000\n",
      "Epoch 57/350\n",
      "29/28 [==============================] - 27s 945ms/step - loss: 0.4477 - auc: 0.8592 - accuracy: 0.7183 - tp: 453.0000 - fn: 71.0000 - val_loss: 0.1615 - val_auc: 0.6874 - val_accuracy: 0.9688 - val_tp: 6.0000 - val_fn: 81.0000\n",
      "Epoch 58/350\n",
      "29/28 [==============================] - 29s 998ms/step - loss: 0.4406 - auc: 0.8638 - accuracy: 0.7215 - tp: 460.0000 - fn: 66.0000 - val_loss: 0.1113 - val_auc: 0.6999 - val_accuracy: 0.9824 - val_tp: 1.0000 - val_fn: 85.0000\n",
      "Epoch 59/350\n",
      "29/28 [==============================] - 28s 976ms/step - loss: 0.4402 - auc: 0.8670 - accuracy: 0.7269 - tp: 454.0000 - fn: 73.0000 - val_loss: 0.1185 - val_auc: 0.7505 - val_accuracy: 0.9803 - val_tp: 0.0000e+00 - val_fn: 82.0000\n",
      "Epoch 60/350\n",
      "29/28 [==============================] - 28s 970ms/step - loss: 0.4472 - auc: 0.8636 - accuracy: 0.7220 - tp: 465.0000 - fn: 65.0000 - val_loss: 0.1430 - val_auc: 0.6940 - val_accuracy: 0.9707 - val_tp: 5.0000 - val_fn: 82.0000\n",
      "Epoch 61/350\n",
      "29/28 [==============================] - 28s 958ms/step - loss: 0.4490 - auc: 0.8628 - accuracy: 0.7302 - tp: 445.0000 - fn: 77.0000 - val_loss: 0.1363 - val_auc: 0.7596 - val_accuracy: 0.9709 - val_tp: 7.0000 - val_fn: 78.0000\n",
      "Epoch 62/350\n",
      "29/28 [==============================] - 28s 972ms/step - loss: 0.4482 - auc: 0.8572 - accuracy: 0.7082 - tp: 459.0000 - fn: 66.0000 - val_loss: 0.1373 - val_auc: 0.7443 - val_accuracy: 0.9680 - val_tp: 3.0000 - val_fn: 81.0000\n",
      "Epoch 63/350\n",
      "29/28 [==============================] - 28s 963ms/step - loss: 0.4361 - auc: 0.8656 - accuracy: 0.7235 - tp: 458.0000 - fn: 72.0000 - val_loss: 0.1667 - val_auc: 0.7849 - val_accuracy: 0.9445 - val_tp: 18.0000 - val_fn: 66.0000\n",
      "Epoch 64/350\n",
      "29/28 [==============================] - 28s 973ms/step - loss: 0.4458 - auc: 0.8631 - accuracy: 0.7193 - tp: 463.0000 - fn: 69.0000 - val_loss: 0.1278 - val_auc: 0.7486 - val_accuracy: 0.9715 - val_tp: 2.0000 - val_fn: 86.0000\n",
      "Epoch 65/350\n",
      "29/28 [==============================] - 28s 957ms/step - loss: 0.4629 - auc: 0.8495 - accuracy: 0.7064 - tp: 452.0000 - fn: 74.0000 - val_loss: 0.2107 - val_auc: 0.7750 - val_accuracy: 0.9082 - val_tp: 16.0000 - val_fn: 68.0000\n",
      "Epoch 66/350\n",
      "29/28 [==============================] - 29s 998ms/step - loss: 0.4373 - auc: 0.8665 - accuracy: 0.7284 - tp: 460.0000 - fn: 65.0000 - val_loss: 0.1876 - val_auc: 0.8022 - val_accuracy: 0.9273 - val_tp: 19.0000 - val_fn: 67.0000\n",
      "Epoch 67/350\n",
      "29/28 [==============================] - 27s 932ms/step - loss: 0.4374 - auc: 0.8690 - accuracy: 0.7281 - tp: 459.0000 - fn: 74.0000 - val_loss: 0.1689 - val_auc: 0.8091 - val_accuracy: 0.9383 - val_tp: 28.0000 - val_fn: 58.0000\n",
      "Epoch 68/350\n",
      "29/28 [==============================] - 29s 988ms/step - loss: 0.4343 - auc: 0.8661 - accuracy: 0.7153 - tp: 480.0000 - fn: 48.0000 - val_loss: 0.1662 - val_auc: 0.8110 - val_accuracy: 0.9414 - val_tp: 14.0000 - val_fn: 75.0000\n",
      "Epoch 69/350\n",
      "29/28 [==============================] - 28s 971ms/step - loss: 0.4258 - auc: 0.8755 - accuracy: 0.7361 - tp: 450.0000 - fn: 74.0000 - val_loss: 0.2443 - val_auc: 0.8188 - val_accuracy: 0.8904 - val_tp: 36.0000 - val_fn: 51.0000\n",
      "Epoch 70/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.4284 - auc: 0.8733 - accuracy: 0.7315 - tp: 468.0000 - fn: 59.0000 - val_loss: 0.2794 - val_auc: 0.8061 - val_accuracy: 0.8715 - val_tp: 36.0000 - val_fn: 51.0000\n",
      "Epoch 71/350\n",
      "29/28 [==============================] - 29s 986ms/step - loss: 0.4204 - auc: 0.8772 - accuracy: 0.7366 - tp: 460.0000 - fn: 65.0000 - val_loss: 0.2253 - val_auc: 0.6586 - val_accuracy: 0.9166 - val_tp: 10.0000 - val_fn: 75.0000\n",
      "Epoch 72/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.4607 - auc: 0.8550 - accuracy: 0.7221 - tp: 446.0000 - fn: 82.0000 - val_loss: 0.1162 - val_auc: 0.8057 - val_accuracy: 0.9746 - val_tp: 6.0000 - val_fn: 83.0000\n",
      "Epoch 73/350\n",
      "29/28 [==============================] - 28s 975ms/step - loss: 0.4423 - auc: 0.8655 - accuracy: 0.7314 - tp: 453.0000 - fn: 75.0000 - val_loss: 0.2143 - val_auc: 0.8120 - val_accuracy: 0.9119 - val_tp: 27.0000 - val_fn: 61.0000\n",
      "Epoch 74/350\n",
      "29/28 [==============================] - 29s 998ms/step - loss: 0.4280 - auc: 0.8750 - accuracy: 0.7357 - tp: 472.0000 - fn: 60.0000 - val_loss: 0.2259 - val_auc: 0.8222 - val_accuracy: 0.8951 - val_tp: 37.0000 - val_fn: 50.0000\n",
      "Epoch 75/350\n",
      "29/28 [==============================] - 29s 988ms/step - loss: 0.4096 - auc: 0.8842 - accuracy: 0.7520 - tp: 468.0000 - fn: 62.0000 - val_loss: 0.2749 - val_auc: 0.7968 - val_accuracy: 0.8816 - val_tp: 33.0000 - val_fn: 48.0000\n",
      "Epoch 76/350\n",
      "29/28 [==============================] - 28s 958ms/step - loss: 0.4336 - auc: 0.8688 - accuracy: 0.7363 - tp: 465.0000 - fn: 62.0000 - val_loss: 0.2344 - val_auc: 0.8038 - val_accuracy: 0.8992 - val_tp: 35.0000 - val_fn: 50.0000\n",
      "Epoch 77/350\n",
      "29/28 [==============================] - 28s 975ms/step - loss: 0.4230 - auc: 0.8781 - accuracy: 0.7450 - tp: 465.0000 - fn: 63.0000 - val_loss: 0.2369 - val_auc: 0.8219 - val_accuracy: 0.9006 - val_tp: 32.0000 - val_fn: 54.0000\n",
      "Epoch 78/350\n",
      "29/28 [==============================] - 27s 937ms/step - loss: 0.4266 - auc: 0.8749 - accuracy: 0.7417 - tp: 450.0000 - fn: 71.0000 - val_loss: 0.2569 - val_auc: 0.7825 - val_accuracy: 0.8895 - val_tp: 35.0000 - val_fn: 52.0000\n",
      "Epoch 79/350\n",
      "29/28 [==============================] - 28s 954ms/step - loss: 0.4294 - auc: 0.8745 - accuracy: 0.7361 - tp: 467.0000 - fn: 61.0000 - val_loss: 0.2162 - val_auc: 0.8077 - val_accuracy: 0.9109 - val_tp: 31.0000 - val_fn: 53.0000\n",
      "Epoch 80/350\n",
      "29/28 [==============================] - 27s 945ms/step - loss: 0.4215 - auc: 0.8807 - accuracy: 0.7467 - tp: 458.0000 - fn: 68.0000 - val_loss: 0.2353 - val_auc: 0.8067 - val_accuracy: 0.8973 - val_tp: 33.0000 - val_fn: 48.0000\n",
      "Epoch 81/350\n",
      "29/28 [==============================] - 29s 998ms/step - loss: 0.4161 - auc: 0.8815 - accuracy: 0.7505 - tp: 473.0000 - fn: 56.0000 - val_loss: 0.2307 - val_auc: 0.8116 - val_accuracy: 0.8994 - val_tp: 30.0000 - val_fn: 59.0000\n",
      "Epoch 82/350\n",
      "29/28 [==============================] - 27s 926ms/step - loss: 0.4318 - auc: 0.8734 - accuracy: 0.7490 - tp: 456.0000 - fn: 67.0000 - val_loss: 0.2966 - val_auc: 0.8100 - val_accuracy: 0.8627 - val_tp: 39.0000 - val_fn: 44.0000\n",
      "Epoch 83/350\n",
      "29/28 [==============================] - 28s 975ms/step - loss: 0.4199 - auc: 0.8787 - accuracy: 0.7493 - tp: 457.0000 - fn: 68.0000 - val_loss: 0.2664 - val_auc: 0.7830 - val_accuracy: 0.8814 - val_tp: 29.0000 - val_fn: 59.0000\n",
      "Epoch 84/350\n",
      "29/28 [==============================] - 28s 967ms/step - loss: 0.4282 - auc: 0.8753 - accuracy: 0.7445 - tp: 460.0000 - fn: 72.0000 - val_loss: 0.1245 - val_auc: 0.7466 - val_accuracy: 0.9828 - val_tp: 0.0000e+00 - val_fn: 87.0000\n",
      "Epoch 85/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.4251 - auc: 0.8776 - accuracy: 0.7467 - tp: 459.0000 - fn: 69.0000 - val_loss: 0.2192 - val_auc: 0.8153 - val_accuracy: 0.9002 - val_tp: 33.0000 - val_fn: 51.0000\n",
      "Epoch 86/350\n",
      "29/28 [==============================] - 29s 990ms/step - loss: 0.4177 - auc: 0.8835 - accuracy: 0.7556 - tp: 460.0000 - fn: 62.0000 - val_loss: 0.1859 - val_auc: 0.8181 - val_accuracy: 0.9281 - val_tp: 20.0000 - val_fn: 66.0000\n",
      "Epoch 87/350\n",
      "29/28 [==============================] - 28s 973ms/step - loss: 0.4299 - auc: 0.8770 - accuracy: 0.7524 - tp: 461.0000 - fn: 70.0000 - val_loss: 0.1799 - val_auc: 0.7575 - val_accuracy: 0.9377 - val_tp: 10.0000 - val_fn: 76.0000\n",
      "Epoch 88/350\n",
      "29/28 [==============================] - 28s 970ms/step - loss: 0.4263 - auc: 0.8751 - accuracy: 0.7420 - tp: 462.0000 - fn: 64.0000 - val_loss: 0.2688 - val_auc: 0.7998 - val_accuracy: 0.8709 - val_tp: 40.0000 - val_fn: 49.0000\n",
      "Epoch 89/350\n",
      "29/28 [==============================] - 29s 985ms/step - loss: 0.4489 - auc: 0.8633 - accuracy: 0.7293 - tp: 458.0000 - fn: 74.0000 - val_loss: 0.2400 - val_auc: 0.7857 - val_accuracy: 0.8982 - val_tp: 36.0000 - val_fn: 52.0000\n",
      "Epoch 90/350\n",
      "29/28 [==============================] - 28s 951ms/step - loss: 0.4470 - auc: 0.8655 - accuracy: 0.7336 - tp: 454.0000 - fn: 76.0000 - val_loss: 0.1677 - val_auc: 0.8053 - val_accuracy: 0.9414 - val_tp: 17.0000 - val_fn: 69.0000\n",
      "Epoch 91/350\n",
      "29/28 [==============================] - 29s 990ms/step - loss: 0.4251 - auc: 0.8797 - accuracy: 0.7441 - tp: 457.0000 - fn: 68.0000 - val_loss: 0.2751 - val_auc: 0.7615 - val_accuracy: 0.8793 - val_tp: 40.0000 - val_fn: 46.0000\n",
      "Epoch 92/350\n",
      "29/28 [==============================] - 28s 964ms/step - loss: 0.4329 - auc: 0.8762 - accuracy: 0.7525 - tp: 461.0000 - fn: 72.0000 - val_loss: 0.2067 - val_auc: 0.8147 - val_accuracy: 0.9203 - val_tp: 29.0000 - val_fn: 55.0000\n",
      "Epoch 93/350\n",
      "29/28 [==============================] - 29s 1s/step - loss: 0.4199 - auc: 0.8832 - accuracy: 0.7519 - tp: 461.0000 - fn: 68.0000 - val_loss: 0.1908 - val_auc: 0.8497 - val_accuracy: 0.9262 - val_tp: 23.0000 - val_fn: 66.0000\n",
      "Epoch 94/350\n",
      "29/28 [==============================] - 28s 965ms/step - loss: 0.4197 - auc: 0.8800 - accuracy: 0.7492 - tp: 456.0000 - fn: 74.0000 - val_loss: 0.3875 - val_auc: 0.8305 - val_accuracy: 0.8225 - val_tp: 49.0000 - val_fn: 34.0000\n",
      "Epoch 95/350\n",
      "29/28 [==============================] - 28s 972ms/step - loss: 0.4112 - auc: 0.8854 - accuracy: 0.7629 - tp: 465.0000 - fn: 66.0000 - val_loss: 0.5141 - val_auc: 0.8145 - val_accuracy: 0.7789 - val_tp: 64.0000 - val_fn: 27.0000\n",
      "Epoch 96/350\n",
      "29/28 [==============================] - 27s 941ms/step - loss: 0.4235 - auc: 0.8773 - accuracy: 0.7507 - tp: 457.0000 - fn: 69.0000 - val_loss: 0.2992 - val_auc: 0.8055 - val_accuracy: 0.8619 - val_tp: 45.0000 - val_fn: 42.0000\n",
      "Epoch 97/350\n",
      "29/28 [==============================] - 29s 985ms/step - loss: 0.4338 - auc: 0.8736 - accuracy: 0.7380 - tp: 466.0000 - fn: 59.0000 - val_loss: 0.4855 - val_auc: 0.8409 - val_accuracy: 0.7602 - val_tp: 60.0000 - val_fn: 25.0000\n",
      "Epoch 98/350\n",
      "29/28 [==============================] - 27s 929ms/step - loss: 0.4211 - auc: 0.8826 - accuracy: 0.7545 - tp: 463.0000 - fn: 67.0000 - val_loss: 0.3989 - val_auc: 0.8252 - val_accuracy: 0.8023 - val_tp: 59.0000 - val_fn: 27.0000\n",
      "Epoch 99/350\n",
      "29/28 [==============================] - 28s 970ms/step - loss: 0.4051 - auc: 0.8882 - accuracy: 0.7554 - tp: 469.0000 - fn: 56.0000 - val_loss: 0.3277 - val_auc: 0.8462 - val_accuracy: 0.8473 - val_tp: 54.0000 - val_fn: 32.0000\n",
      "Epoch 100/350\n",
      "29/28 [==============================] - 28s 973ms/step - loss: 0.4049 - auc: 0.8887 - accuracy: 0.7538 - tp: 468.0000 - fn: 59.0000 - val_loss: 0.2548 - val_auc: 0.8256 - val_accuracy: 0.8805 - val_tp: 41.0000 - val_fn: 42.0000\n",
      "Epoch 101/350\n",
      "29/28 [==============================] - 28s 973ms/step - loss: 0.4010 - auc: 0.8898 - accuracy: 0.7592 - tp: 472.0000 - fn: 54.0000 - val_loss: 0.1790 - val_auc: 0.8184 - val_accuracy: 0.9348 - val_tp: 25.0000 - val_fn: 60.0000\n",
      "Epoch 102/350\n",
      "29/28 [==============================] - 29s 999ms/step - loss: 0.4004 - auc: 0.8922 - accuracy: 0.7629 - tp: 460.0000 - fn: 67.0000 - val_loss: 0.2201 - val_auc: 0.8074 - val_accuracy: 0.9045 - val_tp: 33.0000 - val_fn: 53.0000\n",
      "Epoch 103/350\n",
      "29/28 [==============================] - 28s 970ms/step - loss: 0.4026 - auc: 0.8893 - accuracy: 0.7609 - tp: 461.0000 - fn: 63.0000 - val_loss: 0.2730 - val_auc: 0.8025 - val_accuracy: 0.8760 - val_tp: 42.0000 - val_fn: 44.0000\n",
      "Epoch 104/350\n",
      "29/28 [==============================] - 27s 936ms/step - loss: 0.3999 - auc: 0.8924 - accuracy: 0.7659 - tp: 475.0000 - fn: 57.0000 - val_loss: 0.2564 - val_auc: 0.8159 - val_accuracy: 0.8783 - val_tp: 33.0000 - val_fn: 53.0000\n",
      "Epoch 105/350\n",
      "29/28 [==============================] - 29s 997ms/step - loss: 0.4195 - auc: 0.8849 - accuracy: 0.7646 - tp: 464.0000 - fn: 68.0000 - val_loss: 0.1878 - val_auc: 0.8153 - val_accuracy: 0.9174 - val_tp: 30.0000 - val_fn: 59.0000\n",
      "Epoch 106/350\n",
      "29/28 [==============================] - 27s 938ms/step - loss: 0.4190 - auc: 0.8815 - accuracy: 0.7487 - tp: 457.0000 - fn: 65.0000 - val_loss: 0.2182 - val_auc: 0.8038 - val_accuracy: 0.8986 - val_tp: 23.0000 - val_fn: 59.0000\n",
      "Epoch 107/350\n",
      "29/28 [==============================] - 29s 983ms/step - loss: 0.4155 - auc: 0.8869 - accuracy: 0.7604 - tp: 469.0000 - fn: 60.0000 - val_loss: 0.2695 - val_auc: 0.8179 - val_accuracy: 0.8725 - val_tp: 38.0000 - val_fn: 46.0000\n",
      "Epoch 108/350\n",
      "29/28 [==============================] - 28s 978ms/step - loss: 0.4038 - auc: 0.8912 - accuracy: 0.7612 - tp: 456.0000 - fn: 69.0000 - val_loss: 0.2601 - val_auc: 0.8404 - val_accuracy: 0.8813 - val_tp: 39.0000 - val_fn: 46.0000\n",
      "Epoch 109/350\n",
      "29/28 [==============================] - 29s 999ms/step - loss: 0.4077 - auc: 0.8890 - accuracy: 0.7640 - tp: 472.0000 - fn: 62.0000 - val_loss: 0.5131 - val_auc: 0.8369 - val_accuracy: 0.7135 - val_tp: 74.0000 - val_fn: 11.0000\n",
      "Epoch 110/350\n",
      "29/28 [==============================] - 28s 977ms/step - loss: 0.4050 - auc: 0.8909 - accuracy: 0.7545 - tp: 469.0000 - fn: 54.0000 - val_loss: 0.4293 - val_auc: 0.8325 - val_accuracy: 0.7910 - val_tp: 65.0000 - val_fn: 25.0000\n",
      "Epoch 111/350\n",
      "29/28 [==============================] - 31s 1s/step - loss: 0.4124 - auc: 0.8859 - accuracy: 0.7506 - tp: 477.0000 - fn: 53.0000 - val_loss: 0.3740 - val_auc: 0.8443 - val_accuracy: 0.8189 - val_tp: 61.0000 - val_fn: 26.0000\n",
      "Epoch 112/350\n",
      "29/28 [==============================] - 28s 975ms/step - loss: 0.3950 - auc: 0.8966 - accuracy: 0.7734 - tp: 460.0000 - fn: 58.0000 - val_loss: 0.2673 - val_auc: 0.8483 - val_accuracy: 0.8662 - val_tp: 49.0000 - val_fn: 36.0000\n",
      "Epoch 113/350\n",
      "29/28 [==============================] - 28s 973ms/step - loss: 0.4145 - auc: 0.8838 - accuracy: 0.7522 - tp: 462.0000 - fn: 69.0000 - val_loss: 0.3221 - val_auc: 0.8490 - val_accuracy: 0.8383 - val_tp: 57.0000 - val_fn: 31.0000\n",
      "Epoch 114/350\n",
      "29/28 [==============================] - 29s 992ms/step - loss: 0.3931 - auc: 0.9012 - accuracy: 0.7851 - tp: 471.0000 - fn: 62.0000 - val_loss: 0.2839 - val_auc: 0.8209 - val_accuracy: 0.8758 - val_tp: 41.0000 - val_fn: 45.0000\n",
      "Epoch 115/350\n",
      "29/28 [==============================] - 28s 950ms/step - loss: 0.4108 - auc: 0.8870 - accuracy: 0.7533 - tp: 473.0000 - fn: 54.0000 - val_loss: 0.3884 - val_auc: 0.8082 - val_accuracy: 0.8010 - val_tp: 55.0000 - val_fn: 31.0000\n",
      "Epoch 116/350\n",
      "29/28 [==============================] - 29s 983ms/step - loss: 0.4037 - auc: 0.8931 - accuracy: 0.7671 - tp: 475.0000 - fn: 59.0000 - val_loss: 0.3192 - val_auc: 0.8425 - val_accuracy: 0.8576 - val_tp: 48.0000 - val_fn: 39.0000\n",
      "Epoch 117/350\n",
      "29/28 [==============================] - 27s 922ms/step - loss: 0.3825 - auc: 0.8993 - accuracy: 0.7767 - tp: 470.0000 - fn: 56.0000 - val_loss: 0.2754 - val_auc: 0.8311 - val_accuracy: 0.8818 - val_tp: 50.0000 - val_fn: 34.0000\n",
      "Epoch 118/350\n",
      "29/28 [==============================] - 29s 989ms/step - loss: 0.3769 - auc: 0.9057 - accuracy: 0.7783 - tp: 470.0000 - fn: 60.0000 - val_loss: 0.4070 - val_auc: 0.8308 - val_accuracy: 0.8400 - val_tp: 54.0000 - val_fn: 33.0000\n",
      "Epoch 119/350\n",
      "29/28 [==============================] - 28s 978ms/step - loss: 0.4254 - auc: 0.8769 - accuracy: 0.7499 - tp: 455.0000 - fn: 68.0000 - val_loss: 0.3742 - val_auc: 0.8412 - val_accuracy: 0.8205 - val_tp: 51.0000 - val_fn: 35.0000\n",
      "Epoch 120/350\n",
      "29/28 [==============================] - 28s 978ms/step - loss: 0.4157 - auc: 0.8824 - accuracy: 0.7504 - tp: 471.0000 - fn: 49.0000 - val_loss: 0.4021 - val_auc: 0.8433 - val_accuracy: 0.8145 - val_tp: 60.0000 - val_fn: 23.0000\n",
      "Epoch 121/350\n",
      "29/28 [==============================] - 29s 986ms/step - loss: 0.4035 - auc: 0.8911 - accuracy: 0.7617 - tp: 470.0000 - fn: 62.0000 - val_loss: 0.3688 - val_auc: 0.8576 - val_accuracy: 0.8264 - val_tp: 55.0000 - val_fn: 30.0000\n",
      "Epoch 122/350\n",
      "29/28 [==============================] - 27s 918ms/step - loss: 0.3835 - auc: 0.8996 - accuracy: 0.7735 - tp: 482.0000 - fn: 47.0000 - val_loss: 0.3635 - val_auc: 0.8443 - val_accuracy: 0.8250 - val_tp: 59.0000 - val_fn: 29.0000\n",
      "Epoch 123/350\n",
      "29/28 [==============================] - 29s 986ms/step - loss: 0.4117 - auc: 0.8865 - accuracy: 0.7586 - tp: 458.0000 - fn: 63.0000 - val_loss: 0.3207 - val_auc: 0.8390 - val_accuracy: 0.8479 - val_tp: 54.0000 - val_fn: 33.0000\n",
      "Epoch 124/350\n",
      "29/28 [==============================] - 28s 981ms/step - loss: 0.3997 - auc: 0.8925 - accuracy: 0.7740 - tp: 459.0000 - fn: 67.0000 - val_loss: 0.3585 - val_auc: 0.8256 - val_accuracy: 0.8326 - val_tp: 48.0000 - val_fn: 36.0000\n",
      "Epoch 125/350\n",
      "29/28 [==============================] - 27s 932ms/step - loss: 0.4082 - auc: 0.8907 - accuracy: 0.7650 - tp: 465.0000 - fn: 64.0000 - val_loss: 0.2542 - val_auc: 0.8276 - val_accuracy: 0.8697 - val_tp: 38.0000 - val_fn: 45.0000\n",
      "Epoch 126/350\n",
      "29/28 [==============================] - 28s 962ms/step - loss: 0.3815 - auc: 0.9040 - accuracy: 0.7804 - tp: 473.0000 - fn: 55.0000 - val_loss: 0.2439 - val_auc: 0.8301 - val_accuracy: 0.8953 - val_tp: 38.0000 - val_fn: 49.0000\n",
      "Epoch 127/350\n",
      "29/28 [==============================] - 27s 944ms/step - loss: 0.3859 - auc: 0.9003 - accuracy: 0.7823 - tp: 463.0000 - fn: 63.0000 - val_loss: 0.2682 - val_auc: 0.8398 - val_accuracy: 0.8785 - val_tp: 43.0000 - val_fn: 43.0000\n",
      "Epoch 128/350\n",
      "29/28 [==============================] - 28s 967ms/step - loss: 0.3820 - auc: 0.9012 - accuracy: 0.7773 - tp: 471.0000 - fn: 58.0000 - val_loss: 0.4107 - val_auc: 0.8365 - val_accuracy: 0.8146 - val_tp: 58.0000 - val_fn: 28.0000\n",
      "Epoch 129/350\n",
      "29/28 [==============================] - 27s 943ms/step - loss: 0.4008 - auc: 0.8931 - accuracy: 0.7690 - tp: 470.0000 - fn: 61.0000 - val_loss: 0.3539 - val_auc: 0.8571 - val_accuracy: 0.8250 - val_tp: 55.0000 - val_fn: 32.0000\n",
      "Epoch 130/350\n",
      "29/28 [==============================] - 29s 992ms/step - loss: 0.3715 - auc: 0.9073 - accuracy: 0.7862 - tp: 473.0000 - fn: 51.0000 - val_loss: 0.2241 - val_auc: 0.7869 - val_accuracy: 0.9088 - val_tp: 33.0000 - val_fn: 51.0000\n",
      "Epoch 131/350\n",
      "29/28 [==============================] - 29s 993ms/step - loss: 0.4064 - auc: 0.8925 - accuracy: 0.7722 - tp: 466.0000 - fn: 63.0000 - val_loss: 0.1992 - val_auc: 0.8254 - val_accuracy: 0.9082 - val_tp: 27.0000 - val_fn: 61.0000\n",
      "Epoch 132/350\n",
      "29/28 [==============================] - 29s 995ms/step - loss: 0.4015 - auc: 0.8952 - accuracy: 0.7742 - tp: 465.0000 - fn: 67.0000 - val_loss: 0.2820 - val_auc: 0.7656 - val_accuracy: 0.8604 - val_tp: 33.0000 - val_fn: 50.0000\n",
      "Epoch 133/350\n",
      "29/28 [==============================] - 29s 1s/step - loss: 0.4000 - auc: 0.8935 - accuracy: 0.7683 - tp: 472.0000 - fn: 60.0000 - val_loss: 0.3699 - val_auc: 0.8187 - val_accuracy: 0.8322 - val_tp: 48.0000 - val_fn: 38.0000\n",
      "Epoch 134/350\n",
      "29/28 [==============================] - 28s 969ms/step - loss: 0.3852 - auc: 0.9016 - accuracy: 0.7805 - tp: 475.0000 - fn: 56.0000 - val_loss: 0.2620 - val_auc: 0.7797 - val_accuracy: 0.8967 - val_tp: 30.0000 - val_fn: 55.0000\n",
      "Epoch 135/350\n",
      "29/28 [==============================] - 29s 988ms/step - loss: 0.3946 - auc: 0.8952 - accuracy: 0.7659 - tp: 487.0000 - fn: 46.0000 - val_loss: 0.3618 - val_auc: 0.7976 - val_accuracy: 0.8354 - val_tp: 45.0000 - val_fn: 42.0000\n",
      "Epoch 136/350\n",
      "29/28 [==============================] - 29s 987ms/step - loss: 0.3726 - auc: 0.9079 - accuracy: 0.7877 - tp: 468.0000 - fn: 52.0000 - val_loss: 0.3374 - val_auc: 0.8210 - val_accuracy: 0.8631 - val_tp: 42.0000 - val_fn: 45.0000\n",
      "Epoch 137/350\n",
      "29/28 [==============================] - 29s 988ms/step - loss: 0.3790 - auc: 0.9056 - accuracy: 0.7816 - tp: 479.0000 - fn: 52.0000 - val_loss: 0.4648 - val_auc: 0.8253 - val_accuracy: 0.7822 - val_tp: 57.0000 - val_fn: 31.0000\n",
      "Epoch 138/350\n",
      "29/28 [==============================] - 29s 994ms/step - loss: 0.3689 - auc: 0.9087 - accuracy: 0.7864 - tp: 467.0000 - fn: 57.0000 - val_loss: 0.3995 - val_auc: 0.8101 - val_accuracy: 0.8328 - val_tp: 44.0000 - val_fn: 40.0000\n",
      "Epoch 139/350\n",
      "29/28 [==============================] - 28s 975ms/step - loss: 0.3795 - auc: 0.9056 - accuracy: 0.7862 - tp: 466.0000 - fn: 62.0000 - val_loss: 0.3599 - val_auc: 0.8111 - val_accuracy: 0.8439 - val_tp: 42.0000 - val_fn: 41.0000\n",
      "Epoch 140/350\n",
      "29/28 [==============================] - 28s 968ms/step - loss: 0.3783 - auc: 0.9062 - accuracy: 0.7834 - tp: 473.0000 - fn: 53.0000 - val_loss: 0.2168 - val_auc: 0.7946 - val_accuracy: 0.9141 - val_tp: 30.0000 - val_fn: 54.0000\n",
      "Epoch 141/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.3774 - auc: 0.9065 - accuracy: 0.7869 - tp: 464.0000 - fn: 61.0000 - val_loss: 0.2696 - val_auc: 0.7799 - val_accuracy: 0.8965 - val_tp: 33.0000 - val_fn: 55.0000\n",
      "Epoch 142/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.3960 - auc: 0.8969 - accuracy: 0.7689 - tp: 463.0000 - fn: 66.0000 - val_loss: 0.1612 - val_auc: 0.8211 - val_accuracy: 0.9465 - val_tp: 24.0000 - val_fn: 60.0000\n",
      "Epoch 143/350\n",
      "29/28 [==============================] - 28s 980ms/step - loss: 0.4033 - auc: 0.8951 - accuracy: 0.7703 - tp: 467.0000 - fn: 58.0000 - val_loss: 0.2354 - val_auc: 0.8375 - val_accuracy: 0.8900 - val_tp: 37.0000 - val_fn: 50.0000\n",
      "Epoch 144/350\n",
      "29/28 [==============================] - 28s 973ms/step - loss: 0.3804 - auc: 0.9040 - accuracy: 0.7804 - tp: 465.0000 - fn: 61.0000 - val_loss: 0.3245 - val_auc: 0.8488 - val_accuracy: 0.8568 - val_tp: 50.0000 - val_fn: 36.0000\n",
      "Epoch 145/350\n",
      "29/28 [==============================] - 28s 976ms/step - loss: 0.3926 - auc: 0.8985 - accuracy: 0.7723 - tp: 479.0000 - fn: 54.0000 - val_loss: 0.2466 - val_auc: 0.8311 - val_accuracy: 0.8797 - val_tp: 43.0000 - val_fn: 42.0000\n",
      "Epoch 146/350\n",
      "29/28 [==============================] - 28s 957ms/step - loss: 0.3964 - auc: 0.8965 - accuracy: 0.7709 - tp: 473.0000 - fn: 53.0000 - val_loss: 0.2619 - val_auc: 0.8335 - val_accuracy: 0.8727 - val_tp: 48.0000 - val_fn: 38.0000\n",
      "Epoch 147/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.3932 - auc: 0.8972 - accuracy: 0.7666 - tp: 476.0000 - fn: 54.0000 - val_loss: 0.3444 - val_auc: 0.8472 - val_accuracy: 0.8281 - val_tp: 52.0000 - val_fn: 34.0000\n",
      "Epoch 148/350\n",
      "29/28 [==============================] - 28s 977ms/step - loss: 0.3788 - auc: 0.9050 - accuracy: 0.7894 - tp: 464.0000 - fn: 63.0000 - val_loss: 0.3616 - val_auc: 0.8596 - val_accuracy: 0.8154 - val_tp: 57.0000 - val_fn: 32.0000\n",
      "Epoch 149/350\n",
      "29/28 [==============================] - 29s 1s/step - loss: 0.3802 - auc: 0.9041 - accuracy: 0.7828 - tp: 471.0000 - fn: 54.0000 - val_loss: 0.3603 - val_auc: 0.8204 - val_accuracy: 0.8227 - val_tp: 50.0000 - val_fn: 34.0000\n",
      "Epoch 150/350\n",
      "29/28 [==============================] - 28s 962ms/step - loss: 0.3843 - auc: 0.9034 - accuracy: 0.7848 - tp: 466.0000 - fn: 61.0000 - val_loss: 0.3925 - val_auc: 0.8335 - val_accuracy: 0.8078 - val_tp: 57.0000 - val_fn: 28.0000\n",
      "Epoch 151/350\n",
      "29/28 [==============================] - 28s 973ms/step - loss: 0.3896 - auc: 0.9012 - accuracy: 0.7808 - tp: 469.0000 - fn: 63.0000 - val_loss: 0.3144 - val_auc: 0.8244 - val_accuracy: 0.8393 - val_tp: 48.0000 - val_fn: 37.0000\n",
      "Epoch 152/350\n",
      "29/28 [==============================] - 27s 944ms/step - loss: 0.3801 - auc: 0.9004 - accuracy: 0.7717 - tp: 465.0000 - fn: 56.0000 - val_loss: 0.3383 - val_auc: 0.8499 - val_accuracy: 0.8258 - val_tp: 58.0000 - val_fn: 30.0000\n",
      "Epoch 153/350\n",
      "29/28 [==============================] - 29s 1s/step - loss: 0.3862 - auc: 0.9005 - accuracy: 0.7847 - tp: 469.0000 - fn: 62.0000 - val_loss: 0.2526 - val_auc: 0.8704 - val_accuracy: 0.8785 - val_tp: 49.0000 - val_fn: 36.0000\n",
      "Epoch 154/350\n",
      "29/28 [==============================] - 27s 926ms/step - loss: 0.3786 - auc: 0.9049 - accuracy: 0.7875 - tp: 464.0000 - fn: 58.0000 - val_loss: 0.2963 - val_auc: 0.8272 - val_accuracy: 0.8564 - val_tp: 43.0000 - val_fn: 41.0000\n",
      "Epoch 155/350\n",
      "29/28 [==============================] - 29s 992ms/step - loss: 0.3908 - auc: 0.9030 - accuracy: 0.7866 - tp: 477.0000 - fn: 59.0000 - val_loss: 0.4486 - val_auc: 0.8553 - val_accuracy: 0.7943 - val_tp: 63.0000 - val_fn: 23.0000\n",
      "Epoch 156/350\n",
      "29/28 [==============================] - 28s 969ms/step - loss: 0.3777 - auc: 0.9091 - accuracy: 0.7936 - tp: 462.0000 - fn: 67.0000 - val_loss: 0.2528 - val_auc: 0.8115 - val_accuracy: 0.8932 - val_tp: 38.0000 - val_fn: 47.0000\n",
      "Epoch 157/350\n",
      "29/28 [==============================] - 28s 955ms/step - loss: 0.3502 - auc: 0.9195 - accuracy: 0.8006 - tp: 482.0000 - fn: 46.0000 - val_loss: 0.3137 - val_auc: 0.8300 - val_accuracy: 0.8713 - val_tp: 44.0000 - val_fn: 41.0000\n",
      "Epoch 158/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.3749 - auc: 0.9071 - accuracy: 0.7899 - tp: 465.0000 - fn: 59.0000 - val_loss: 0.5036 - val_auc: 0.8148 - val_accuracy: 0.7787 - val_tp: 58.0000 - val_fn: 30.0000\n",
      "Epoch 159/350\n",
      "29/28 [==============================] - 29s 997ms/step - loss: 0.3814 - auc: 0.9026 - accuracy: 0.7820 - tp: 472.0000 - fn: 54.0000 - val_loss: 0.5709 - val_auc: 0.8467 - val_accuracy: 0.7447 - val_tp: 70.0000 - val_fn: 16.0000\n",
      "Epoch 160/350\n",
      "29/28 [==============================] - 27s 928ms/step - loss: 0.3724 - auc: 0.9098 - accuracy: 0.7846 - tp: 475.0000 - fn: 56.0000 - val_loss: 0.4466 - val_auc: 0.8520 - val_accuracy: 0.8117 - val_tp: 56.0000 - val_fn: 27.0000\n",
      "Epoch 161/350\n",
      "29/28 [==============================] - 27s 945ms/step - loss: 0.3763 - auc: 0.9028 - accuracy: 0.7762 - tp: 472.0000 - fn: 47.0000 - val_loss: 0.2694 - val_auc: 0.8334 - val_accuracy: 0.8762 - val_tp: 43.0000 - val_fn: 44.0000\n",
      "Epoch 162/350\n",
      "29/28 [==============================] - 28s 971ms/step - loss: 0.3756 - auc: 0.9071 - accuracy: 0.7809 - tp: 458.0000 - fn: 68.0000 - val_loss: 0.3504 - val_auc: 0.8326 - val_accuracy: 0.8365 - val_tp: 56.0000 - val_fn: 26.0000\n",
      "Epoch 163/350\n",
      "29/28 [==============================] - 27s 941ms/step - loss: 0.3881 - auc: 0.9032 - accuracy: 0.7808 - tp: 468.0000 - fn: 63.0000 - val_loss: 0.3312 - val_auc: 0.8388 - val_accuracy: 0.8492 - val_tp: 51.0000 - val_fn: 35.0000\n",
      "Epoch 164/350\n",
      "29/28 [==============================] - 29s 993ms/step - loss: 0.3759 - auc: 0.9066 - accuracy: 0.7794 - tp: 469.0000 - fn: 56.0000 - val_loss: 0.2926 - val_auc: 0.8341 - val_accuracy: 0.8717 - val_tp: 48.0000 - val_fn: 37.0000\n",
      "Epoch 165/350\n",
      "29/28 [==============================] - 28s 972ms/step - loss: 0.3693 - auc: 0.9112 - accuracy: 0.7996 - tp: 465.0000 - fn: 59.0000 - val_loss: 0.3290 - val_auc: 0.8385 - val_accuracy: 0.8508 - val_tp: 52.0000 - val_fn: 37.0000\n",
      "Epoch 166/350\n",
      "29/28 [==============================] - 28s 976ms/step - loss: 0.3724 - auc: 0.9098 - accuracy: 0.7905 - tp: 468.0000 - fn: 62.0000 - val_loss: 0.2896 - val_auc: 0.8450 - val_accuracy: 0.8686 - val_tp: 48.0000 - val_fn: 40.0000\n",
      "Epoch 167/350\n",
      "29/28 [==============================] - 28s 964ms/step - loss: 0.3693 - auc: 0.9088 - accuracy: 0.7915 - tp: 479.0000 - fn: 48.0000 - val_loss: 0.2822 - val_auc: 0.8528 - val_accuracy: 0.8789 - val_tp: 44.0000 - val_fn: 44.0000\n",
      "Epoch 168/350\n",
      "29/28 [==============================] - 30s 1s/step - loss: 0.3510 - auc: 0.9186 - accuracy: 0.7973 - tp: 478.0000 - fn: 52.0000 - val_loss: 0.2468 - val_auc: 0.8490 - val_accuracy: 0.8975 - val_tp: 42.0000 - val_fn: 45.0000\n",
      "Epoch 169/350\n",
      "29/28 [==============================] - 28s 982ms/step - loss: 0.3552 - auc: 0.9182 - accuracy: 0.8035 - tp: 480.0000 - fn: 48.0000 - val_loss: 0.3289 - val_auc: 0.8229 - val_accuracy: 0.8477 - val_tp: 48.0000 - val_fn: 43.0000\n",
      "Epoch 170/350\n",
      "29/28 [==============================] - 29s 997ms/step - loss: 0.3616 - auc: 0.9151 - accuracy: 0.8028 - tp: 473.0000 - fn: 59.0000 - val_loss: 0.3323 - val_auc: 0.7709 - val_accuracy: 0.8514 - val_tp: 44.0000 - val_fn: 40.0000\n",
      "Epoch 171/350\n",
      "29/28 [==============================] - 28s 963ms/step - loss: 0.3612 - auc: 0.9148 - accuracy: 0.7927 - tp: 480.0000 - fn: 43.0000 - val_loss: 0.3409 - val_auc: 0.8340 - val_accuracy: 0.8502 - val_tp: 48.0000 - val_fn: 40.0000\n",
      "Epoch 172/350\n",
      "29/28 [==============================] - 28s 975ms/step - loss: 0.3621 - auc: 0.9138 - accuracy: 0.7950 - tp: 485.0000 - fn: 46.0000 - val_loss: 0.3061 - val_auc: 0.8343 - val_accuracy: 0.8709 - val_tp: 41.0000 - val_fn: 48.0000\n",
      "Epoch 173/350\n",
      "29/28 [==============================] - 28s 968ms/step - loss: 0.3697 - auc: 0.9133 - accuracy: 0.7988 - tp: 473.0000 - fn: 57.0000 - val_loss: 0.2508 - val_auc: 0.8410 - val_accuracy: 0.8885 - val_tp: 42.0000 - val_fn: 47.0000\n",
      "Epoch 174/350\n",
      "29/28 [==============================] - 28s 976ms/step - loss: 0.3616 - auc: 0.9122 - accuracy: 0.7837 - tp: 481.0000 - fn: 47.0000 - val_loss: 0.3220 - val_auc: 0.8384 - val_accuracy: 0.8557 - val_tp: 48.0000 - val_fn: 39.0000\n",
      "Epoch 175/350\n",
      "29/28 [==============================] - 27s 927ms/step - loss: 0.3628 - auc: 0.9165 - accuracy: 0.8005 - tp: 482.0000 - fn: 54.0000 - val_loss: 0.3121 - val_auc: 0.8150 - val_accuracy: 0.8615 - val_tp: 46.0000 - val_fn: 44.0000\n",
      "Epoch 176/350\n",
      "29/28 [==============================] - 28s 977ms/step - loss: 0.3753 - auc: 0.9078 - accuracy: 0.7825 - tp: 472.0000 - fn: 55.0000 - val_loss: 0.3792 - val_auc: 0.8206 - val_accuracy: 0.8121 - val_tp: 50.0000 - val_fn: 36.0000\n",
      "Epoch 177/350\n",
      "29/28 [==============================] - 29s 989ms/step - loss: 0.3822 - auc: 0.9042 - accuracy: 0.7874 - tp: 472.0000 - fn: 57.0000 - val_loss: 0.3627 - val_auc: 0.7848 - val_accuracy: 0.8303 - val_tp: 46.0000 - val_fn: 42.0000\n",
      "Epoch 178/350\n",
      "29/28 [==============================] - 28s 972ms/step - loss: 0.3915 - auc: 0.8997 - accuracy: 0.7720 - tp: 466.0000 - fn: 59.0000 - val_loss: 0.4669 - val_auc: 0.7912 - val_accuracy: 0.7629 - val_tp: 62.0000 - val_fn: 25.0000\n",
      "Epoch 179/350\n",
      "29/28 [==============================] - 28s 955ms/step - loss: 0.3733 - auc: 0.9058 - accuracy: 0.7763 - tp: 478.0000 - fn: 45.0000 - val_loss: 0.6010 - val_auc: 0.8473 - val_accuracy: 0.7541 - val_tp: 67.0000 - val_fn: 20.0000\n",
      "Epoch 180/350\n",
      "29/28 [==============================] - 28s 969ms/step - loss: 0.3693 - auc: 0.9094 - accuracy: 0.7887 - tp: 471.0000 - fn: 53.0000 - val_loss: 0.4058 - val_auc: 0.8081 - val_accuracy: 0.8012 - val_tp: 48.0000 - val_fn: 35.0000\n",
      "Epoch 181/350\n",
      "29/28 [==============================] - 28s 971ms/step - loss: 0.3712 - auc: 0.9082 - accuracy: 0.7787 - tp: 485.0000 - fn: 44.0000 - val_loss: 0.5182 - val_auc: 0.8459 - val_accuracy: 0.7682 - val_tp: 67.0000 - val_fn: 22.0000\n",
      "Epoch 182/350\n",
      "29/28 [==============================] - 28s 973ms/step - loss: 0.3474 - auc: 0.9206 - accuracy: 0.8065 - tp: 479.0000 - fn: 53.0000 - val_loss: 0.4364 - val_auc: 0.8596 - val_accuracy: 0.8000 - val_tp: 62.0000 - val_fn: 21.0000\n",
      "Epoch 183/350\n",
      "29/28 [==============================] - 28s 949ms/step - loss: 0.3636 - auc: 0.9116 - accuracy: 0.7920 - tp: 470.0000 - fn: 52.0000 - val_loss: 0.3990 - val_auc: 0.8182 - val_accuracy: 0.8291 - val_tp: 52.0000 - val_fn: 34.0000\n",
      "Epoch 184/350\n",
      "29/28 [==============================] - 28s 956ms/step - loss: 0.3563 - auc: 0.9178 - accuracy: 0.8098 - tp: 475.0000 - fn: 55.0000 - val_loss: 0.3137 - val_auc: 0.8649 - val_accuracy: 0.8619 - val_tp: 59.0000 - val_fn: 27.0000\n",
      "Epoch 185/350\n",
      "29/28 [==============================] - 27s 947ms/step - loss: 0.3540 - auc: 0.9186 - accuracy: 0.8055 - tp: 471.0000 - fn: 54.0000 - val_loss: 0.3655 - val_auc: 0.8406 - val_accuracy: 0.8273 - val_tp: 58.0000 - val_fn: 29.0000\n",
      "Epoch 186/350\n",
      "29/28 [==============================] - 28s 972ms/step - loss: 0.3606 - auc: 0.9134 - accuracy: 0.7902 - tp: 486.0000 - fn: 41.0000 - val_loss: 0.4452 - val_auc: 0.8581 - val_accuracy: 0.7955 - val_tp: 66.0000 - val_fn: 22.0000\n",
      "Epoch 187/350\n",
      "29/28 [==============================] - 28s 979ms/step - loss: 0.3435 - auc: 0.9243 - accuracy: 0.8095 - tp: 486.0000 - fn: 50.0000 - val_loss: 0.3883 - val_auc: 0.8407 - val_accuracy: 0.8119 - val_tp: 61.0000 - val_fn: 27.0000\n",
      "Epoch 188/350\n",
      "29/28 [==============================] - 30s 1s/step - loss: 0.3656 - auc: 0.9122 - accuracy: 0.7961 - tp: 463.0000 - fn: 59.0000 - val_loss: 0.4180 - val_auc: 0.8285 - val_accuracy: 0.8006 - val_tp: 51.0000 - val_fn: 33.0000\n",
      "Epoch 189/350\n",
      "29/28 [==============================] - 28s 979ms/step - loss: 0.3500 - auc: 0.9204 - accuracy: 0.7996 - tp: 476.0000 - fn: 50.0000 - val_loss: 0.2849 - val_auc: 0.8440 - val_accuracy: 0.8641 - val_tp: 50.0000 - val_fn: 39.0000\n",
      "Epoch 190/350\n",
      "29/28 [==============================] - 28s 958ms/step - loss: 0.3426 - auc: 0.9249 - accuracy: 0.8145 - tp: 487.0000 - fn: 46.0000 - val_loss: 0.2784 - val_auc: 0.8535 - val_accuracy: 0.8727 - val_tp: 53.0000 - val_fn: 35.0000\n",
      "Epoch 191/350\n",
      "29/28 [==============================] - 27s 935ms/step - loss: 0.3581 - auc: 0.9171 - accuracy: 0.8025 - tp: 466.0000 - fn: 59.0000 - val_loss: 0.2587 - val_auc: 0.8477 - val_accuracy: 0.8781 - val_tp: 41.0000 - val_fn: 42.0000\n",
      "Epoch 192/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.3467 - auc: 0.9214 - accuracy: 0.8091 - tp: 479.0000 - fn: 48.0000 - val_loss: 0.2390 - val_auc: 0.8539 - val_accuracy: 0.8881 - val_tp: 40.0000 - val_fn: 43.0000\n",
      "Epoch 193/350\n",
      "29/28 [==============================] - 29s 995ms/step - loss: 0.3543 - auc: 0.9168 - accuracy: 0.8011 - tp: 473.0000 - fn: 53.0000 - val_loss: 0.3845 - val_auc: 0.8732 - val_accuracy: 0.8121 - val_tp: 61.0000 - val_fn: 24.0000\n",
      "Epoch 194/350\n",
      "29/28 [==============================] - 28s 970ms/step - loss: 0.3467 - auc: 0.9209 - accuracy: 0.8035 - tp: 477.0000 - fn: 47.0000 - val_loss: 0.3372 - val_auc: 0.8337 - val_accuracy: 0.8498 - val_tp: 46.0000 - val_fn: 35.0000\n",
      "Epoch 195/350\n",
      "29/28 [==============================] - 28s 975ms/step - loss: 0.3498 - auc: 0.9197 - accuracy: 0.8022 - tp: 474.0000 - fn: 55.0000 - val_loss: 0.1918 - val_auc: 0.8123 - val_accuracy: 0.9271 - val_tp: 32.0000 - val_fn: 54.0000\n",
      "Epoch 196/350\n",
      "29/28 [==============================] - 30s 1s/step - loss: 0.3644 - auc: 0.9144 - accuracy: 0.7983 - tp: 479.0000 - fn: 54.0000 - val_loss: 0.3672 - val_auc: 0.8142 - val_accuracy: 0.8125 - val_tp: 52.0000 - val_fn: 33.0000\n",
      "Epoch 197/350\n",
      "29/28 [==============================] - 28s 978ms/step - loss: 0.3472 - auc: 0.9207 - accuracy: 0.7993 - tp: 474.0000 - fn: 56.0000 - val_loss: 0.4079 - val_auc: 0.8661 - val_accuracy: 0.8121 - val_tp: 62.0000 - val_fn: 22.0000\n",
      "Epoch 198/350\n",
      "29/28 [==============================] - 28s 955ms/step - loss: 0.3639 - auc: 0.9153 - accuracy: 0.7967 - tp: 479.0000 - fn: 53.0000 - val_loss: 0.3858 - val_auc: 0.8152 - val_accuracy: 0.8160 - val_tp: 49.0000 - val_fn: 35.0000\n",
      "Epoch 199/350\n",
      "29/28 [==============================] - 28s 976ms/step - loss: 0.3700 - auc: 0.9120 - accuracy: 0.7948 - tp: 465.0000 - fn: 60.0000 - val_loss: 0.6985 - val_auc: 0.8451 - val_accuracy: 0.6820 - val_tp: 80.0000 - val_fn: 6.0000\n",
      "Epoch 200/350\n",
      "29/28 [==============================] - 29s 995ms/step - loss: 0.3547 - auc: 0.9182 - accuracy: 0.8056 - tp: 483.0000 - fn: 43.0000 - val_loss: 0.4458 - val_auc: 0.8630 - val_accuracy: 0.7939 - val_tp: 66.0000 - val_fn: 24.0000\n",
      "Epoch 201/350\n",
      "29/28 [==============================] - 29s 1s/step - loss: 0.3328 - auc: 0.9272 - accuracy: 0.8158 - tp: 477.0000 - fn: 48.0000 - val_loss: 0.4169 - val_auc: 0.8476 - val_accuracy: 0.8254 - val_tp: 52.0000 - val_fn: 35.0000\n",
      "Epoch 202/350\n",
      "29/28 [==============================] - 27s 942ms/step - loss: 0.3304 - auc: 0.9287 - accuracy: 0.8146 - tp: 474.0000 - fn: 47.0000 - val_loss: 0.3607 - val_auc: 0.8467 - val_accuracy: 0.8305 - val_tp: 54.0000 - val_fn: 34.0000\n",
      "Epoch 203/350\n",
      "29/28 [==============================] - 29s 988ms/step - loss: 0.3393 - auc: 0.9251 - accuracy: 0.8105 - tp: 482.0000 - fn: 47.0000 - val_loss: 0.3549 - val_auc: 0.8527 - val_accuracy: 0.8541 - val_tp: 51.0000 - val_fn: 35.0000\n",
      "Epoch 204/350\n",
      "29/28 [==============================] - 27s 924ms/step - loss: 0.3372 - auc: 0.9257 - accuracy: 0.8133 - tp: 477.0000 - fn: 49.0000 - val_loss: 0.3074 - val_auc: 0.7873 - val_accuracy: 0.8809 - val_tp: 45.0000 - val_fn: 42.0000\n",
      "Epoch 205/350\n",
      "29/28 [==============================] - 28s 975ms/step - loss: 0.3281 - auc: 0.9293 - accuracy: 0.8159 - tp: 488.0000 - fn: 37.0000 - val_loss: 0.3371 - val_auc: 0.7669 - val_accuracy: 0.8559 - val_tp: 44.0000 - val_fn: 44.0000\n",
      "Epoch 206/350\n",
      "29/28 [==============================] - 28s 963ms/step - loss: 0.3605 - auc: 0.9174 - accuracy: 0.8014 - tp: 467.0000 - fn: 57.0000 - val_loss: 0.3484 - val_auc: 0.8574 - val_accuracy: 0.8443 - val_tp: 55.0000 - val_fn: 28.0000\n",
      "Epoch 207/350\n",
      "29/28 [==============================] - 28s 972ms/step - loss: 0.3366 - auc: 0.9285 - accuracy: 0.8204 - tp: 476.0000 - fn: 54.0000 - val_loss: 0.3436 - val_auc: 0.8617 - val_accuracy: 0.8516 - val_tp: 53.0000 - val_fn: 31.0000\n",
      "Epoch 208/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.3299 - auc: 0.9296 - accuracy: 0.8187 - tp: 481.0000 - fn: 47.0000 - val_loss: 0.2599 - val_auc: 0.8459 - val_accuracy: 0.8928 - val_tp: 39.0000 - val_fn: 48.0000\n",
      "Epoch 209/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.3531 - auc: 0.9196 - accuracy: 0.8139 - tp: 473.0000 - fn: 53.0000 - val_loss: 0.2132 - val_auc: 0.8232 - val_accuracy: 0.9174 - val_tp: 42.0000 - val_fn: 43.0000\n",
      "Epoch 210/350\n",
      "29/28 [==============================] - 29s 998ms/step - loss: 0.3539 - auc: 0.9193 - accuracy: 0.8018 - tp: 480.0000 - fn: 49.0000 - val_loss: 0.2070 - val_auc: 0.8523 - val_accuracy: 0.9201 - val_tp: 39.0000 - val_fn: 48.0000\n",
      "Epoch 211/350\n",
      "29/28 [==============================] - 28s 977ms/step - loss: 0.3540 - auc: 0.9200 - accuracy: 0.8122 - tp: 476.0000 - fn: 59.0000 - val_loss: 0.2796 - val_auc: 0.8572 - val_accuracy: 0.8785 - val_tp: 47.0000 - val_fn: 37.0000\n",
      "Epoch 212/350\n",
      "29/28 [==============================] - 28s 978ms/step - loss: 0.3731 - auc: 0.9108 - accuracy: 0.7960 - tp: 464.0000 - fn: 60.0000 - val_loss: 0.4461 - val_auc: 0.8478 - val_accuracy: 0.8018 - val_tp: 60.0000 - val_fn: 26.0000\n",
      "Epoch 213/350\n",
      "29/28 [==============================] - 28s 980ms/step - loss: 0.3652 - auc: 0.9143 - accuracy: 0.8011 - tp: 482.0000 - fn: 52.0000 - val_loss: 0.2987 - val_auc: 0.7975 - val_accuracy: 0.8729 - val_tp: 45.0000 - val_fn: 41.0000\n",
      "Epoch 214/350\n",
      "29/28 [==============================] - 28s 961ms/step - loss: 0.3914 - auc: 0.9019 - accuracy: 0.7835 - tp: 465.0000 - fn: 65.0000 - val_loss: 0.4529 - val_auc: 0.8405 - val_accuracy: 0.7934 - val_tp: 56.0000 - val_fn: 29.0000\n",
      "Epoch 215/350\n",
      "29/28 [==============================] - 28s 968ms/step - loss: 0.3744 - auc: 0.9105 - accuracy: 0.7939 - tp: 476.0000 - fn: 54.0000 - val_loss: 0.4668 - val_auc: 0.8397 - val_accuracy: 0.7654 - val_tp: 55.0000 - val_fn: 27.0000\n",
      "Epoch 216/350\n",
      "29/28 [==============================] - 27s 942ms/step - loss: 0.3437 - auc: 0.9233 - accuracy: 0.8052 - tp: 483.0000 - fn: 50.0000 - val_loss: 0.6392 - val_auc: 0.8369 - val_accuracy: 0.7387 - val_tp: 68.0000 - val_fn: 17.0000\n",
      "Epoch 217/350\n",
      "29/28 [==============================] - 28s 966ms/step - loss: 0.3312 - auc: 0.9284 - accuracy: 0.8106 - tp: 487.0000 - fn: 41.0000 - val_loss: 0.3857 - val_auc: 0.8228 - val_accuracy: 0.8203 - val_tp: 56.0000 - val_fn: 32.0000\n",
      "Epoch 218/350\n",
      "29/28 [==============================] - 27s 928ms/step - loss: 0.3363 - auc: 0.9268 - accuracy: 0.8125 - tp: 473.0000 - fn: 52.0000 - val_loss: 0.2958 - val_auc: 0.8429 - val_accuracy: 0.8697 - val_tp: 44.0000 - val_fn: 39.0000\n",
      "Epoch 219/350\n",
      "29/28 [==============================] - 29s 1s/step - loss: 0.3483 - auc: 0.9214 - accuracy: 0.8104 - tp: 473.0000 - fn: 52.0000 - val_loss: 0.4273 - val_auc: 0.8309 - val_accuracy: 0.8107 - val_tp: 57.0000 - val_fn: 26.0000\n",
      "Epoch 220/350\n",
      "29/28 [==============================] - 27s 930ms/step - loss: 0.3457 - auc: 0.9210 - accuracy: 0.8073 - tp: 471.0000 - fn: 52.0000 - val_loss: 0.6617 - val_auc: 0.8330 - val_accuracy: 0.7488 - val_tp: 67.0000 - val_fn: 20.0000\n",
      "Epoch 221/350\n",
      "29/28 [==============================] - 29s 984ms/step - loss: 0.3488 - auc: 0.9224 - accuracy: 0.8088 - tp: 482.0000 - fn: 44.0000 - val_loss: 0.4154 - val_auc: 0.8537 - val_accuracy: 0.8268 - val_tp: 58.0000 - val_fn: 27.0000\n",
      "Epoch 222/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.3431 - auc: 0.9250 - accuracy: 0.8168 - tp: 474.0000 - fn: 59.0000 - val_loss: 0.3274 - val_auc: 0.8296 - val_accuracy: 0.8721 - val_tp: 49.0000 - val_fn: 33.0000\n",
      "Epoch 223/350\n",
      "29/28 [==============================] - 28s 969ms/step - loss: 0.3332 - auc: 0.9285 - accuracy: 0.8158 - tp: 471.0000 - fn: 55.0000 - val_loss: 0.4039 - val_auc: 0.8545 - val_accuracy: 0.8172 - val_tp: 58.0000 - val_fn: 27.0000\n",
      "Epoch 224/350\n",
      "29/28 [==============================] - 29s 995ms/step - loss: 0.3217 - auc: 0.9330 - accuracy: 0.8230 - tp: 481.0000 - fn: 45.0000 - val_loss: 0.5285 - val_auc: 0.8387 - val_accuracy: 0.7736 - val_tp: 58.0000 - val_fn: 29.0000\n",
      "Epoch 225/350\n",
      "29/28 [==============================] - 28s 972ms/step - loss: 0.3185 - auc: 0.9346 - accuracy: 0.8310 - tp: 480.0000 - fn: 46.0000 - val_loss: 0.5075 - val_auc: 0.8358 - val_accuracy: 0.7783 - val_tp: 64.0000 - val_fn: 23.0000\n",
      "Epoch 226/350\n",
      "29/28 [==============================] - 29s 994ms/step - loss: 0.3275 - auc: 0.9314 - accuracy: 0.8223 - tp: 481.0000 - fn: 47.0000 - val_loss: 0.2580 - val_auc: 0.8482 - val_accuracy: 0.8893 - val_tp: 42.0000 - val_fn: 45.0000\n",
      "Epoch 227/350\n",
      "29/28 [==============================] - 28s 975ms/step - loss: 0.3369 - auc: 0.9279 - accuracy: 0.8217 - tp: 481.0000 - fn: 47.0000 - val_loss: 0.3449 - val_auc: 0.8569 - val_accuracy: 0.8406 - val_tp: 52.0000 - val_fn: 35.0000\n",
      "Epoch 228/350\n",
      "29/28 [==============================] - 29s 1s/step - loss: 0.3312 - auc: 0.9311 - accuracy: 0.8237 - tp: 489.0000 - fn: 41.0000 - val_loss: 0.3752 - val_auc: 0.8535 - val_accuracy: 0.8250 - val_tp: 58.0000 - val_fn: 30.0000\n",
      "Epoch 229/350\n",
      "29/28 [==============================] - 27s 943ms/step - loss: 0.3104 - auc: 0.9377 - accuracy: 0.8354 - tp: 479.0000 - fn: 45.0000 - val_loss: 0.3105 - val_auc: 0.8490 - val_accuracy: 0.8732 - val_tp: 45.0000 - val_fn: 41.0000\n",
      "Epoch 230/350\n",
      "29/28 [==============================] - 28s 975ms/step - loss: 0.3453 - auc: 0.9231 - accuracy: 0.8140 - tp: 481.0000 - fn: 49.0000 - val_loss: 0.3000 - val_auc: 0.8277 - val_accuracy: 0.8498 - val_tp: 43.0000 - val_fn: 41.0000\n",
      "Epoch 231/350\n",
      "29/28 [==============================] - 29s 994ms/step - loss: 0.3514 - auc: 0.9210 - accuracy: 0.8110 - tp: 480.0000 - fn: 47.0000 - val_loss: 0.2993 - val_auc: 0.8521 - val_accuracy: 0.8557 - val_tp: 49.0000 - val_fn: 37.0000\n",
      "Epoch 232/350\n",
      "29/28 [==============================] - 28s 976ms/step - loss: 0.3500 - auc: 0.9204 - accuracy: 0.7974 - tp: 493.0000 - fn: 36.0000 - val_loss: 0.3415 - val_auc: 0.8384 - val_accuracy: 0.8223 - val_tp: 47.0000 - val_fn: 39.0000\n",
      "Epoch 233/350\n",
      "29/28 [==============================] - 28s 949ms/step - loss: 0.3400 - auc: 0.9270 - accuracy: 0.8085 - tp: 478.0000 - fn: 48.0000 - val_loss: 0.2107 - val_auc: 0.8140 - val_accuracy: 0.9068 - val_tp: 36.0000 - val_fn: 50.0000\n",
      "Epoch 234/350\n",
      "29/28 [==============================] - 28s 975ms/step - loss: 0.3268 - auc: 0.9316 - accuracy: 0.8330 - tp: 480.0000 - fn: 46.0000 - val_loss: 0.2300 - val_auc: 0.8338 - val_accuracy: 0.9047 - val_tp: 38.0000 - val_fn: 46.0000\n",
      "Epoch 235/350\n",
      "29/28 [==============================] - 28s 966ms/step - loss: 0.3433 - auc: 0.9261 - accuracy: 0.8131 - tp: 481.0000 - fn: 47.0000 - val_loss: 0.2185 - val_auc: 0.8313 - val_accuracy: 0.9061 - val_tp: 33.0000 - val_fn: 53.0000\n",
      "Epoch 236/350\n",
      "29/28 [==============================] - 27s 935ms/step - loss: 0.3375 - auc: 0.9273 - accuracy: 0.8162 - tp: 480.0000 - fn: 47.0000 - val_loss: 0.2299 - val_auc: 0.8638 - val_accuracy: 0.8988 - val_tp: 38.0000 - val_fn: 50.0000\n",
      "Epoch 237/350\n",
      "29/28 [==============================] - 27s 942ms/step - loss: 0.3145 - auc: 0.9368 - accuracy: 0.8315 - tp: 488.0000 - fn: 47.0000 - val_loss: 0.3502 - val_auc: 0.8429 - val_accuracy: 0.8408 - val_tp: 45.0000 - val_fn: 42.0000\n",
      "Epoch 238/350\n",
      "29/28 [==============================] - 28s 977ms/step - loss: 0.3272 - auc: 0.9314 - accuracy: 0.8241 - tp: 474.0000 - fn: 49.0000 - val_loss: 0.2947 - val_auc: 0.8218 - val_accuracy: 0.8555 - val_tp: 45.0000 - val_fn: 39.0000\n",
      "Epoch 239/350\n",
      "29/28 [==============================] - 28s 966ms/step - loss: 0.3167 - auc: 0.9348 - accuracy: 0.8299 - tp: 489.0000 - fn: 40.0000 - val_loss: 0.2035 - val_auc: 0.8165 - val_accuracy: 0.9125 - val_tp: 26.0000 - val_fn: 61.0000\n",
      "Epoch 240/350\n",
      "29/28 [==============================] - 28s 974ms/step - loss: 0.3100 - auc: 0.9385 - accuracy: 0.8297 - tp: 487.0000 - fn: 39.0000 - val_loss: 0.2925 - val_auc: 0.8383 - val_accuracy: 0.8764 - val_tp: 42.0000 - val_fn: 45.0000\n",
      "Epoch 241/350\n",
      "29/28 [==============================] - 27s 933ms/step - loss: 0.3047 - auc: 0.9413 - accuracy: 0.8416 - tp: 489.0000 - fn: 42.0000 - val_loss: 0.2595 - val_auc: 0.8427 - val_accuracy: 0.9041 - val_tp: 45.0000 - val_fn: 42.0000\n",
      "Epoch 242/350\n",
      "29/28 [==============================] - 27s 935ms/step - loss: 0.3151 - auc: 0.9376 - accuracy: 0.8361 - tp: 472.0000 - fn: 52.0000 - val_loss: 0.3854 - val_auc: 0.8598 - val_accuracy: 0.8297 - val_tp: 60.0000 - val_fn: 26.0000\n",
      "Epoch 243/350\n",
      "29/28 [==============================] - 27s 940ms/step - loss: 0.3171 - auc: 0.9368 - accuracy: 0.8322 - tp: 480.0000 - fn: 44.0000 - val_loss: 0.3947 - val_auc: 0.8668 - val_accuracy: 0.8391 - val_tp: 61.0000 - val_fn: 24.0000\n",
      "Epoch 244/350\n",
      "29/28 [==============================] - 28s 969ms/step - loss: 0.3158 - auc: 0.9378 - accuracy: 0.8353 - tp: 484.0000 - fn: 50.0000 - val_loss: 0.4105 - val_auc: 0.8465 - val_accuracy: 0.8354 - val_tp: 52.0000 - val_fn: 35.0000\n",
      "Epoch 245/350\n",
      "29/28 [==============================] - 27s 933ms/step - loss: 0.3131 - auc: 0.9370 - accuracy: 0.8367 - tp: 481.0000 - fn: 39.0000 - val_loss: 0.3394 - val_auc: 0.8315 - val_accuracy: 0.8639 - val_tp: 49.0000 - val_fn: 35.0000\n",
      "Epoch 246/350\n",
      "29/28 [==============================] - 28s 967ms/step - loss: 0.3001 - auc: 0.9425 - accuracy: 0.8401 - tp: 483.0000 - fn: 42.0000 - val_loss: 0.3021 - val_auc: 0.8622 - val_accuracy: 0.8785 - val_tp: 43.0000 - val_fn: 40.0000\n",
      "Epoch 247/350\n",
      "29/28 [==============================] - 29s 998ms/step - loss: 0.3214 - auc: 0.9341 - accuracy: 0.8308 - tp: 474.0000 - fn: 51.0000 - val_loss: 0.2486 - val_auc: 0.8372 - val_accuracy: 0.8965 - val_tp: 40.0000 - val_fn: 43.0000\n",
      "Epoch 248/350\n",
      "29/28 [==============================] - 28s 971ms/step - loss: 0.3160 - auc: 0.9371 - accuracy: 0.8296 - tp: 481.0000 - fn: 47.0000 - val_loss: 0.2019 - val_auc: 0.8138 - val_accuracy: 0.9252 - val_tp: 32.0000 - val_fn: 53.0000\n",
      "Epoch 249/350\n",
      "29/28 [==============================] - 28s 972ms/step - loss: 0.3133 - auc: 0.9387 - accuracy: 0.8417 - tp: 483.0000 - fn: 47.0000 - val_loss: 0.2575 - val_auc: 0.8101 - val_accuracy: 0.8947 - val_tp: 41.0000 - val_fn: 45.0000\n",
      "Epoch 250/350\n",
      "29/28 [==============================] - 28s 962ms/step - loss: 0.3041 - auc: 0.9399 - accuracy: 0.8421 - tp: 486.0000 - fn: 43.0000 - val_loss: 0.3155 - val_auc: 0.8414 - val_accuracy: 0.8779 - val_tp: 49.0000 - val_fn: 37.0000\n",
      "Epoch 251/350\n",
      "29/28 [==============================] - 29s 1s/step - loss: 0.3268 - auc: 0.9329 - accuracy: 0.8260 - tp: 481.0000 - fn: 46.0000 - val_loss: 0.2226 - val_auc: 0.8056 - val_accuracy: 0.9051 - val_tp: 34.0000 - val_fn: 52.0000\n",
      "Epoch 252/350\n",
      "29/28 [==============================] - 29s 984ms/step - loss: 0.3074 - auc: 0.9383 - accuracy: 0.8294 - tp: 497.0000 - fn: 33.0000 - val_loss: 0.3057 - val_auc: 0.8107 - val_accuracy: 0.8738 - val_tp: 42.0000 - val_fn: 44.0000\n",
      "Epoch 253/350\n",
      "29/28 [==============================] - 30s 1s/step - loss: 0.3148 - auc: 0.9365 - accuracy: 0.8286 - tp: 483.0000 - fn: 46.0000 - val_loss: 0.2956 - val_auc: 0.8462 - val_accuracy: 0.8783 - val_tp: 44.0000 - val_fn: 41.0000\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', #val_auc\n",
    "                                patience=60,\n",
    "                                mode='max',\n",
    "                                restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "#     batch_size=params['batch_size'],\n",
    "    epochs= params['epochs'], \n",
    "    steps_per_epoch=epoch_steps,\n",
    "    validation_data=valid_ds,\n",
    "    validation_steps=valid_steps,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T09:55:37.227340Z",
     "iopub.status.busy": "2020-08-11T09:55:37.226687Z",
     "iopub.status.idle": "2020-08-11T09:56:27.399548Z",
     "shell.execute_reply": "2020-08-11T09:56:27.398533Z"
    },
    "papermill": {
     "duration": 50.648088,
     "end_time": "2020-08-11T09:56:27.399693",
     "exception": false,
     "start_time": "2020-08-11T09:55:36.751605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_ds.map(lambda img, igs: img), steps=test_steps)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T09:56:28.367550Z",
     "iopub.status.busy": "2020-08-11T09:56:28.366695Z",
     "iopub.status.idle": "2020-08-11T09:56:32.730901Z",
     "shell.execute_reply": "2020-08-11T09:56:32.730136Z"
    },
    "papermill": {
     "duration": 4.830235,
     "end_time": "2020-08-11T09:56:32.731036",
     "exception": false,
     "start_time": "2020-08-11T09:56:27.900801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7ff544c38830> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "                          map(lambda img, ids:ids).\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction_ids = next(iter(test_ds.\n",
    "                          map(lambda img, ids:ids).\n",
    "                          unbatch().\n",
    "                          batch(test_size))).numpy().astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T09:56:33.662526Z",
     "iopub.status.busy": "2020-08-11T09:56:33.661883Z",
     "iopub.status.idle": "2020-08-11T09:56:33.674197Z",
     "shell.execute_reply": "2020-08-11T09:56:33.673715Z"
    },
    "papermill": {
     "duration": 0.483503,
     "end_time": "2020-08-11T09:56:33.674304",
     "exception": false,
     "start_time": "2020-08-11T09:56:33.190801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_dict = {\n",
    "    'image_name': prediction_ids,\n",
    "    'target': np.concatenate(predictions)\n",
    "}\n",
    "submission_ds = pd.DataFrame(prediction_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T09:56:34.653989Z",
     "iopub.status.busy": "2020-08-11T09:56:34.653033Z",
     "iopub.status.idle": "2020-08-11T09:56:34.657092Z",
     "shell.execute_reply": "2020-08-11T09:56:34.656418Z"
    },
    "papermill": {
     "duration": 0.47506,
     "end_time": "2020-08-11T09:56:34.657220",
     "exception": false,
     "start_time": "2020-08-11T09:56:34.182160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6381819</td>\n",
       "      <td>0.315045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_5583376</td>\n",
       "      <td>0.604079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_6408546</td>\n",
       "      <td>0.006234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_6932354</td>\n",
       "      <td>0.002046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_8191278</td>\n",
       "      <td>0.076233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name    target\n",
       "0  ISIC_6381819  0.315045\n",
       "1  ISIC_5583376  0.604079\n",
       "2  ISIC_6408546  0.006234\n",
       "3  ISIC_6932354  0.002046\n",
       "4  ISIC_8191278  0.076233"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T09:56:35.693531Z",
     "iopub.status.busy": "2020-08-11T09:56:35.692833Z",
     "iopub.status.idle": "2020-08-11T09:56:35.751577Z",
     "shell.execute_reply": "2020-08-11T09:56:35.750845Z"
    },
    "papermill": {
     "duration": 0.602341,
     "end_time": "2020-08-11T09:56:35.751726",
     "exception": false,
     "start_time": "2020-08-11T09:56:35.149385",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_ds.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.463194,
     "end_time": "2020-08-11T09:56:36.680672",
     "exception": false,
     "start_time": "2020-08-11T09:56:36.217478",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T09:56:37.657469Z",
     "iopub.status.busy": "2020-08-11T09:56:37.656570Z",
     "iopub.status.idle": "2020-08-11T09:56:37.659523Z",
     "shell.execute_reply": "2020-08-11T09:56:37.658938Z"
    },
    "papermill": {
     "duration": 0.516281,
     "end_time": "2020-08-11T09:56:37.659618",
     "exception": false,
     "start_time": "2020-08-11T09:56:37.143337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_metric(metric1, metric2, ylabel):\n",
    "    plt.plot(history.history[metric1], label=metric1)\n",
    "    plt.plot(history.history[metric2], label=metric2)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T09:56:38.604495Z",
     "iopub.status.busy": "2020-08-11T09:56:38.603765Z",
     "iopub.status.idle": "2020-08-11T09:56:39.160485Z",
     "shell.execute_reply": "2020-08-11T09:56:39.159891Z"
    },
    "papermill": {
     "duration": 1.035239,
     "end_time": "2020-08-11T09:56:39.160588",
     "exception": false,
     "start_time": "2020-08-11T09:56:38.125349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('auc', 'val_auc', 'auc')\n",
    "plot_metric('loss', 'val_loss', 'loss')\n",
    "plot_metric('accuracy', 'val_accuracy', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T09:56:40.160416Z",
     "iopub.status.busy": "2020-08-11T09:56:40.155378Z",
     "iopub.status.idle": "2020-08-11T09:56:40.185614Z",
     "shell.execute_reply": "2020-08-11T09:56:40.186097Z"
    },
    "papermill": {
     "duration": 0.550174,
     "end_time": "2020-08-11T09:56:40.186228",
     "exception": false,
     "start_time": "2020-08-11T09:56:39.636054",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.9393677711486816,\n",
       "  0.7236790060997009,\n",
       "  0.6785851120948792,\n",
       "  0.6435030102729797,\n",
       "  0.6290987133979797,\n",
       "  0.5938875675201416,\n",
       "  0.591886579990387,\n",
       "  0.5961906909942627,\n",
       "  0.5709428191184998,\n",
       "  0.5762805342674255,\n",
       "  0.5700060725212097,\n",
       "  0.5640883445739746,\n",
       "  0.559181272983551,\n",
       "  0.5352975726127625,\n",
       "  0.5304234027862549,\n",
       "  0.5185737013816833,\n",
       "  0.5181434750556946,\n",
       "  0.5172249674797058,\n",
       "  0.5312722325325012,\n",
       "  0.5230799913406372,\n",
       "  0.5148994326591492,\n",
       "  0.5159243941307068,\n",
       "  0.5124918818473816,\n",
       "  0.5117032527923584,\n",
       "  0.5028495192527771,\n",
       "  0.4917711317539215,\n",
       "  0.5095529556274414,\n",
       "  0.484973281621933,\n",
       "  0.4859904646873474,\n",
       "  0.49062034487724304,\n",
       "  0.48597201704978943,\n",
       "  0.4789247214794159,\n",
       "  0.4879489839076996,\n",
       "  0.47752225399017334,\n",
       "  0.4882640838623047,\n",
       "  0.48148658871650696,\n",
       "  0.47048163414001465,\n",
       "  0.5002372860908508,\n",
       "  0.4708181917667389,\n",
       "  0.4636821746826172,\n",
       "  0.4663366675376892,\n",
       "  0.46095672249794006,\n",
       "  0.4654691517353058,\n",
       "  0.4653775691986084,\n",
       "  0.47088077664375305,\n",
       "  0.4639565050601959,\n",
       "  0.4737108051776886,\n",
       "  0.4546992778778076,\n",
       "  0.4663664996623993,\n",
       "  0.4663456678390503,\n",
       "  0.4525453746318817,\n",
       "  0.4608420133590698,\n",
       "  0.4567374289035797,\n",
       "  0.4595131576061249,\n",
       "  0.45050281286239624,\n",
       "  0.45995837450027466,\n",
       "  0.44774556159973145,\n",
       "  0.4405565857887268,\n",
       "  0.4402272403240204,\n",
       "  0.44721829891204834,\n",
       "  0.4490271210670471,\n",
       "  0.4481545388698578,\n",
       "  0.4360882043838501,\n",
       "  0.4458073675632477,\n",
       "  0.46289753913879395,\n",
       "  0.4373207092285156,\n",
       "  0.43736788630485535,\n",
       "  0.4343261122703552,\n",
       "  0.42581331729888916,\n",
       "  0.4284399151802063,\n",
       "  0.4203909635543823,\n",
       "  0.46070095896720886,\n",
       "  0.4423334300518036,\n",
       "  0.42799603939056396,\n",
       "  0.40961623191833496,\n",
       "  0.4336426556110382,\n",
       "  0.4230120778083801,\n",
       "  0.42661359906196594,\n",
       "  0.4294285476207733,\n",
       "  0.4215284287929535,\n",
       "  0.4161286950111389,\n",
       "  0.4318074882030487,\n",
       "  0.41987916827201843,\n",
       "  0.4281655550003052,\n",
       "  0.4250546991825104,\n",
       "  0.41767820715904236,\n",
       "  0.4298504590988159,\n",
       "  0.4263436496257782,\n",
       "  0.4489322602748871,\n",
       "  0.4469897747039795,\n",
       "  0.4251250922679901,\n",
       "  0.432885080575943,\n",
       "  0.4198548495769501,\n",
       "  0.4197128415107727,\n",
       "  0.41116711497306824,\n",
       "  0.4234773814678192,\n",
       "  0.4338340759277344,\n",
       "  0.4211180806159973,\n",
       "  0.40506717562675476,\n",
       "  0.4049362242221832,\n",
       "  0.400966078042984,\n",
       "  0.4003749191761017,\n",
       "  0.4026051163673401,\n",
       "  0.39986464381217957,\n",
       "  0.4195078909397125,\n",
       "  0.4190097749233246,\n",
       "  0.41546863317489624,\n",
       "  0.40378886461257935,\n",
       "  0.40772566199302673,\n",
       "  0.40498673915863037,\n",
       "  0.41236642003059387,\n",
       "  0.39500972628593445,\n",
       "  0.4145411550998688,\n",
       "  0.3931383788585663,\n",
       "  0.41082262992858887,\n",
       "  0.40370437502861023,\n",
       "  0.38245144486427307,\n",
       "  0.376860111951828,\n",
       "  0.4253979027271271,\n",
       "  0.4157068729400635,\n",
       "  0.4034617245197296,\n",
       "  0.38347265124320984,\n",
       "  0.41174930334091187,\n",
       "  0.3996598720550537,\n",
       "  0.40824374556541443,\n",
       "  0.38145211338996887,\n",
       "  0.3859335482120514,\n",
       "  0.3820093274116516,\n",
       "  0.4007664620876312,\n",
       "  0.37149766087532043,\n",
       "  0.40635883808135986,\n",
       "  0.40149062871932983,\n",
       "  0.40000808238983154,\n",
       "  0.3851943612098694,\n",
       "  0.3946281969547272,\n",
       "  0.37255150079727173,\n",
       "  0.37903258204460144,\n",
       "  0.36888059973716736,\n",
       "  0.3795335292816162,\n",
       "  0.3783024847507477,\n",
       "  0.3774188160896301,\n",
       "  0.396027535200119,\n",
       "  0.40329501032829285,\n",
       "  0.3804076015949249,\n",
       "  0.3926025927066803,\n",
       "  0.3963560163974762,\n",
       "  0.3932139575481415,\n",
       "  0.37882110476493835,\n",
       "  0.380154013633728,\n",
       "  0.38433921337127686,\n",
       "  0.3895650804042816,\n",
       "  0.3800916373729706,\n",
       "  0.3862404525279999,\n",
       "  0.37862154841423035,\n",
       "  0.390796035528183,\n",
       "  0.377707302570343,\n",
       "  0.3501545786857605,\n",
       "  0.37485864758491516,\n",
       "  0.38140714168548584,\n",
       "  0.37244391441345215,\n",
       "  0.37625038623809814,\n",
       "  0.37563249468803406,\n",
       "  0.3880729079246521,\n",
       "  0.37590086460113525,\n",
       "  0.3692861795425415,\n",
       "  0.3723730742931366,\n",
       "  0.36928969621658325,\n",
       "  0.35095879435539246,\n",
       "  0.35524746775627136,\n",
       "  0.3616260290145874,\n",
       "  0.36119621992111206,\n",
       "  0.3620525896549225,\n",
       "  0.36969229578971863,\n",
       "  0.3615623712539673,\n",
       "  0.3628149628639221,\n",
       "  0.3752829432487488,\n",
       "  0.3821961283683777,\n",
       "  0.3915402591228485,\n",
       "  0.3732844293117523,\n",
       "  0.369268536567688,\n",
       "  0.37117666006088257,\n",
       "  0.3473624289035797,\n",
       "  0.36358240246772766,\n",
       "  0.3562535047531128,\n",
       "  0.35402944684028625,\n",
       "  0.36064353585243225,\n",
       "  0.34353482723236084,\n",
       "  0.36557090282440186,\n",
       "  0.34995344281196594,\n",
       "  0.3426021635532379,\n",
       "  0.3581302762031555,\n",
       "  0.34667959809303284,\n",
       "  0.3543291687965393,\n",
       "  0.34673890471458435,\n",
       "  0.3498353064060211,\n",
       "  0.36438223719596863,\n",
       "  0.3471960723400116,\n",
       "  0.3639165461063385,\n",
       "  0.37004798650741577,\n",
       "  0.3547484576702118,\n",
       "  0.33284980058670044,\n",
       "  0.3304451107978821,\n",
       "  0.33929094672203064,\n",
       "  0.3372161090373993,\n",
       "  0.3281116783618927,\n",
       "  0.3605417013168335,\n",
       "  0.3366027772426605,\n",
       "  0.32993483543395996,\n",
       "  0.35310932993888855,\n",
       "  0.35386723279953003,\n",
       "  0.3540131151676178,\n",
       "  0.37314164638519287,\n",
       "  0.3652436137199402,\n",
       "  0.39139705896377563,\n",
       "  0.37436485290527344,\n",
       "  0.343732088804245,\n",
       "  0.33121782541275024,\n",
       "  0.3362819254398346,\n",
       "  0.3482949733734131,\n",
       "  0.34566789865493774,\n",
       "  0.3488312065601349,\n",
       "  0.3430618345737457,\n",
       "  0.3331816792488098,\n",
       "  0.3217020630836487,\n",
       "  0.31854748725891113,\n",
       "  0.3274914622306824,\n",
       "  0.3368723690509796,\n",
       "  0.33119308948516846,\n",
       "  0.3104238510131836,\n",
       "  0.3452920913696289,\n",
       "  0.35140731930732727,\n",
       "  0.35003286600112915,\n",
       "  0.3399604558944702,\n",
       "  0.3268214762210846,\n",
       "  0.3432832658290863,\n",
       "  0.33747318387031555,\n",
       "  0.3144884705543518,\n",
       "  0.3271837532520294,\n",
       "  0.31671079993247986,\n",
       "  0.3099660277366638,\n",
       "  0.3046989142894745,\n",
       "  0.3151458203792572,\n",
       "  0.3171265721321106,\n",
       "  0.31580662727355957,\n",
       "  0.31305792927742004,\n",
       "  0.30009016394615173,\n",
       "  0.32138803601264954,\n",
       "  0.3160161077976227,\n",
       "  0.31325972080230713,\n",
       "  0.3041333258152008,\n",
       "  0.32678523659706116,\n",
       "  0.30736881494522095,\n",
       "  0.3147783577442169],\n",
       " 'auc': [0.5251554250717163,\n",
       "  0.6707174181938171,\n",
       "  0.6988208889961243,\n",
       "  0.7155293226242065,\n",
       "  0.7264121770858765,\n",
       "  0.7403258085250854,\n",
       "  0.7415011525154114,\n",
       "  0.7315953373908997,\n",
       "  0.7487382292747498,\n",
       "  0.744512677192688,\n",
       "  0.7575856447219849,\n",
       "  0.7623783349990845,\n",
       "  0.7686980962753296,\n",
       "  0.7832809686660767,\n",
       "  0.7818460464477539,\n",
       "  0.7940437197685242,\n",
       "  0.7957964539527893,\n",
       "  0.8009610176086426,\n",
       "  0.7936816811561584,\n",
       "  0.7900807857513428,\n",
       "  0.7959796190261841,\n",
       "  0.8016837239265442,\n",
       "  0.8064262866973877,\n",
       "  0.8119198679924011,\n",
       "  0.8162460923194885,\n",
       "  0.8215263485908508,\n",
       "  0.8104425072669983,\n",
       "  0.8294587135314941,\n",
       "  0.8231140375137329,\n",
       "  0.8267101645469666,\n",
       "  0.82765132188797,\n",
       "  0.8296811580657959,\n",
       "  0.825806736946106,\n",
       "  0.829237699508667,\n",
       "  0.8208431601524353,\n",
       "  0.8297125697135925,\n",
       "  0.840100109577179,\n",
       "  0.8153788447380066,\n",
       "  0.8400372862815857,\n",
       "  0.8387269973754883,\n",
       "  0.843410849571228,\n",
       "  0.8403509855270386,\n",
       "  0.844829797744751,\n",
       "  0.8427110314369202,\n",
       "  0.8364681601524353,\n",
       "  0.8430688977241516,\n",
       "  0.8449409008026123,\n",
       "  0.8499921560287476,\n",
       "  0.8456650972366333,\n",
       "  0.8511946797370911,\n",
       "  0.8513503670692444,\n",
       "  0.8474355340003967,\n",
       "  0.8525842428207397,\n",
       "  0.8498204946517944,\n",
       "  0.8529771566390991,\n",
       "  0.8509182929992676,\n",
       "  0.8592157959938049,\n",
       "  0.8638292551040649,\n",
       "  0.8669942021369934,\n",
       "  0.8636125922203064,\n",
       "  0.8628410696983337,\n",
       "  0.8572453856468201,\n",
       "  0.8655789494514465,\n",
       "  0.8631458282470703,\n",
       "  0.849487841129303,\n",
       "  0.8665488362312317,\n",
       "  0.8689901232719421,\n",
       "  0.8661080002784729,\n",
       "  0.8754966259002686,\n",
       "  0.873339831829071,\n",
       "  0.8771848678588867,\n",
       "  0.8549891114234924,\n",
       "  0.8654612302780151,\n",
       "  0.8749963045120239,\n",
       "  0.8841791152954102,\n",
       "  0.8688256144523621,\n",
       "  0.8781331181526184,\n",
       "  0.8749441504478455,\n",
       "  0.8744925856590271,\n",
       "  0.8807053565979004,\n",
       "  0.8814787268638611,\n",
       "  0.8734015226364136,\n",
       "  0.878656268119812,\n",
       "  0.8752949237823486,\n",
       "  0.8775765299797058,\n",
       "  0.883491575717926,\n",
       "  0.8770267963409424,\n",
       "  0.8750887513160706,\n",
       "  0.8633497357368469,\n",
       "  0.865540087223053,\n",
       "  0.8796699643135071,\n",
       "  0.876201331615448,\n",
       "  0.8831838369369507,\n",
       "  0.8800269365310669,\n",
       "  0.8853755593299866,\n",
       "  0.8773193955421448,\n",
       "  0.8736274838447571,\n",
       "  0.8825626373291016,\n",
       "  0.8882171511650085,\n",
       "  0.8886814117431641,\n",
       "  0.8897609114646912,\n",
       "  0.8922371864318848,\n",
       "  0.8893492817878723,\n",
       "  0.8924068808555603,\n",
       "  0.8849189877510071,\n",
       "  0.8815253376960754,\n",
       "  0.8869090676307678,\n",
       "  0.891152560710907,\n",
       "  0.8889957666397095,\n",
       "  0.8908705115318298,\n",
       "  0.8859071135520935,\n",
       "  0.8966423869132996,\n",
       "  0.8838157057762146,\n",
       "  0.9012022614479065,\n",
       "  0.887000322341919,\n",
       "  0.8930626511573792,\n",
       "  0.8993450999259949,\n",
       "  0.9056916832923889,\n",
       "  0.8768582344055176,\n",
       "  0.8823732733726501,\n",
       "  0.8911476731300354,\n",
       "  0.8996438980102539,\n",
       "  0.8865159749984741,\n",
       "  0.8924503922462463,\n",
       "  0.8906791806221008,\n",
       "  0.9040499925613403,\n",
       "  0.9003267884254456,\n",
       "  0.9012295007705688,\n",
       "  0.8930651545524597,\n",
       "  0.9073019623756409,\n",
       "  0.8925490975379944,\n",
       "  0.8952420949935913,\n",
       "  0.8934648633003235,\n",
       "  0.9016305208206177,\n",
       "  0.895175039768219,\n",
       "  0.9078900218009949,\n",
       "  0.9056124687194824,\n",
       "  0.9086649417877197,\n",
       "  0.9056496620178223,\n",
       "  0.9061813950538635,\n",
       "  0.9065448641777039,\n",
       "  0.8968807458877563,\n",
       "  0.8950564861297607,\n",
       "  0.9040391445159912,\n",
       "  0.8985135555267334,\n",
       "  0.8965132832527161,\n",
       "  0.897180438041687,\n",
       "  0.9049883484840393,\n",
       "  0.9041418433189392,\n",
       "  0.903403103351593,\n",
       "  0.90119469165802,\n",
       "  0.9004045128822327,\n",
       "  0.9004826545715332,\n",
       "  0.9048817157745361,\n",
       "  0.9030296206474304,\n",
       "  0.9091498255729675,\n",
       "  0.9194697737693787,\n",
       "  0.9071424007415771,\n",
       "  0.9025591611862183,\n",
       "  0.9098208546638489,\n",
       "  0.902776837348938,\n",
       "  0.9070882797241211,\n",
       "  0.9032276272773743,\n",
       "  0.9066349267959595,\n",
       "  0.9111734628677368,\n",
       "  0.9097881317138672,\n",
       "  0.9088431000709534,\n",
       "  0.9186367988586426,\n",
       "  0.9182421565055847,\n",
       "  0.9151228666305542,\n",
       "  0.9148092865943909,\n",
       "  0.9137817621231079,\n",
       "  0.9132526516914368,\n",
       "  0.9122149348258972,\n",
       "  0.9164834022521973,\n",
       "  0.9077556729316711,\n",
       "  0.9042143821716309,\n",
       "  0.8996751308441162,\n",
       "  0.9057621359825134,\n",
       "  0.9094324707984924,\n",
       "  0.908218502998352,\n",
       "  0.9205818176269531,\n",
       "  0.9116255640983582,\n",
       "  0.9178445339202881,\n",
       "  0.9186077117919922,\n",
       "  0.9133630990982056,\n",
       "  0.9242886900901794,\n",
       "  0.9121565818786621,\n",
       "  0.9204009771347046,\n",
       "  0.9249253869056702,\n",
       "  0.9170926213264465,\n",
       "  0.921353816986084,\n",
       "  0.9168057441711426,\n",
       "  0.9208804965019226,\n",
       "  0.9196825623512268,\n",
       "  0.9144163131713867,\n",
       "  0.9207229614257812,\n",
       "  0.9153406620025635,\n",
       "  0.9119581580162048,\n",
       "  0.9181967377662659,\n",
       "  0.9272028207778931,\n",
       "  0.9286866784095764,\n",
       "  0.92509526014328,\n",
       "  0.9257024526596069,\n",
       "  0.9293155670166016,\n",
       "  0.9174442291259766,\n",
       "  0.9284787178039551,\n",
       "  0.9295750260353088,\n",
       "  0.9195957183837891,\n",
       "  0.9192720651626587,\n",
       "  0.9200040698051453,\n",
       "  0.9107860922813416,\n",
       "  0.9143451452255249,\n",
       "  0.9019178152084351,\n",
       "  0.9105172157287598,\n",
       "  0.9232525825500488,\n",
       "  0.9283599853515625,\n",
       "  0.9268230199813843,\n",
       "  0.921363353729248,\n",
       "  0.9209978580474854,\n",
       "  0.9224136471748352,\n",
       "  0.9250261783599854,\n",
       "  0.9285413026809692,\n",
       "  0.9330039024353027,\n",
       "  0.9345630407333374,\n",
       "  0.9314358234405518,\n",
       "  0.9278801679611206,\n",
       "  0.9311131238937378,\n",
       "  0.9376797676086426,\n",
       "  0.9230793118476868,\n",
       "  0.9209896326065063,\n",
       "  0.9204062223434448,\n",
       "  0.9270358681678772,\n",
       "  0.9315940737724304,\n",
       "  0.9261114597320557,\n",
       "  0.9272776246070862,\n",
       "  0.9368491172790527,\n",
       "  0.9313768148422241,\n",
       "  0.9347653985023499,\n",
       "  0.938472330570221,\n",
       "  0.9412535429000854,\n",
       "  0.9376261830329895,\n",
       "  0.9368258118629456,\n",
       "  0.9377508759498596,\n",
       "  0.9369738101959229,\n",
       "  0.9424628019332886,\n",
       "  0.934072732925415,\n",
       "  0.9370955228805542,\n",
       "  0.9387407898902893,\n",
       "  0.9399337768554688,\n",
       "  0.9328722357749939,\n",
       "  0.9382687211036682,\n",
       "  0.9365200400352478],\n",
       " 'accuracy': [0.522831380367279,\n",
       "  0.6037850379943848,\n",
       "  0.6187365055084229,\n",
       "  0.6068831086158752,\n",
       "  0.6141904592514038,\n",
       "  0.6021349430084229,\n",
       "  0.5999124646186829,\n",
       "  0.5704135298728943,\n",
       "  0.5840854048728943,\n",
       "  0.5851293206214905,\n",
       "  0.6012594103813171,\n",
       "  0.603178858757019,\n",
       "  0.5965786576271057,\n",
       "  0.6222723722457886,\n",
       "  0.6106546521186829,\n",
       "  0.6318696141242981,\n",
       "  0.638032078742981,\n",
       "  0.6389076113700867,\n",
       "  0.630859375,\n",
       "  0.646484375,\n",
       "  0.6378300189971924,\n",
       "  0.6457098722457886,\n",
       "  0.662715494632721,\n",
       "  0.6615369319915771,\n",
       "  0.6719423532485962,\n",
       "  0.662715494632721,\n",
       "  0.6628838777542114,\n",
       "  0.682953953742981,\n",
       "  0.6682381629943848,\n",
       "  0.6799905896186829,\n",
       "  0.6737270951271057,\n",
       "  0.6801252961158752,\n",
       "  0.6825835108757019,\n",
       "  0.677094578742981,\n",
       "  0.672514796257019,\n",
       "  0.680024266242981,\n",
       "  0.6987136006355286,\n",
       "  0.6633553504943848,\n",
       "  0.6929552555084229,\n",
       "  0.6906991004943848,\n",
       "  0.701508641242981,\n",
       "  0.6948073506355286,\n",
       "  0.6946390271186829,\n",
       "  0.6931573152542114,\n",
       "  0.6948073506355286,\n",
       "  0.689116358757019,\n",
       "  0.7071659564971924,\n",
       "  0.7092537879943848,\n",
       "  0.6998922228813171,\n",
       "  0.7100282907485962,\n",
       "  0.7019463777542114,\n",
       "  0.6996565461158752,\n",
       "  0.7018790245056152,\n",
       "  0.7085802555084229,\n",
       "  0.7074690461158752,\n",
       "  0.6999595761299133,\n",
       "  0.7182785272598267,\n",
       "  0.7215113043785095,\n",
       "  0.726932942867279,\n",
       "  0.722016453742981,\n",
       "  0.7301993370056152,\n",
       "  0.7082098722457886,\n",
       "  0.7234644293785095,\n",
       "  0.7193224430084229,\n",
       "  0.7063577771186829,\n",
       "  0.7283809185028076,\n",
       "  0.7281115055084229,\n",
       "  0.7153151631355286,\n",
       "  0.7360923886299133,\n",
       "  0.7314789891242981,\n",
       "  0.7365975379943848,\n",
       "  0.7221174836158752,\n",
       "  0.7314116358757019,\n",
       "  0.735722005367279,\n",
       "  0.7519868016242981,\n",
       "  0.7362944483757019,\n",
       "  0.7449824810028076,\n",
       "  0.7417497038841248,\n",
       "  0.7360923886299133,\n",
       "  0.746733546257019,\n",
       "  0.7504714131355286,\n",
       "  0.7489897608757019,\n",
       "  0.7492591738700867,\n",
       "  0.7445447444915771,\n",
       "  0.7466661930084229,\n",
       "  0.7555899620056152,\n",
       "  0.7524245381355286,\n",
       "  0.7420191168785095,\n",
       "  0.7292901277542114,\n",
       "  0.7336341738700867,\n",
       "  0.7440732717514038,\n",
       "  0.7525255680084229,\n",
       "  0.7519194483757019,\n",
       "  0.7491918206214905,\n",
       "  0.7629310488700867,\n",
       "  0.7506734728813171,\n",
       "  0.7379781603813171,\n",
       "  0.754546046257019,\n",
       "  0.7553879022598267,\n",
       "  0.7537715435028076,\n",
       "  0.7592268586158752,\n",
       "  0.7629310488700867,\n",
       "  0.7608768939971924,\n",
       "  0.7658607363700867,\n",
       "  0.7646147608757019,\n",
       "  0.748686671257019,\n",
       "  0.760405421257019,\n",
       "  0.7611799836158752,\n",
       "  0.764042317867279,\n",
       "  0.754512369632721,\n",
       "  0.7505724430084229,\n",
       "  0.7734038233757019,\n",
       "  0.7521888613700867,\n",
       "  0.7851225733757019,\n",
       "  0.753300130367279,\n",
       "  0.7671403288841248,\n",
       "  0.776703953742981,\n",
       "  0.7783203125,\n",
       "  0.7498989701271057,\n",
       "  0.750370442867279,\n",
       "  0.7616513967514038,\n",
       "  0.7735385298728943,\n",
       "  0.7585533261299133,\n",
       "  0.7740099430084229,\n",
       "  0.764985203742981,\n",
       "  0.7804418206214905,\n",
       "  0.7822939157485962,\n",
       "  0.77734375,\n",
       "  0.7690261006355286,\n",
       "  0.7862338423728943,\n",
       "  0.7721915245056152,\n",
       "  0.7742456793785095,\n",
       "  0.7682852745056152,\n",
       "  0.7805428504943848,\n",
       "  0.7659280896186829,\n",
       "  0.7876818180084229,\n",
       "  0.7815530896186829,\n",
       "  0.7864022254943848,\n",
       "  0.7862338423728943,\n",
       "  0.7834388613700867,\n",
       "  0.7869073152542114,\n",
       "  0.768925130367279,\n",
       "  0.7702720761299133,\n",
       "  0.7803744673728943,\n",
       "  0.7722925543785095,\n",
       "  0.7709456086158752,\n",
       "  0.7666352391242981,\n",
       "  0.7893655896186829,\n",
       "  0.7827653288841248,\n",
       "  0.784785807132721,\n",
       "  0.7807785272598267,\n",
       "  0.7717201113700867,\n",
       "  0.7846511006355286,\n",
       "  0.7875134944915771,\n",
       "  0.7866379022598267,\n",
       "  0.7936422228813171,\n",
       "  0.8005791902542114,\n",
       "  0.7899380326271057,\n",
       "  0.7819571495056152,\n",
       "  0.7846174836158752,\n",
       "  0.7762324810028076,\n",
       "  0.780913233757019,\n",
       "  0.7807785272598267,\n",
       "  0.7794315814971924,\n",
       "  0.7996363043785095,\n",
       "  0.7904768586158752,\n",
       "  0.7914534211158752,\n",
       "  0.7972791194915771,\n",
       "  0.8034752011299133,\n",
       "  0.8027680516242981,\n",
       "  0.7926656603813171,\n",
       "  0.7949892282485962,\n",
       "  0.7987944483757019,\n",
       "  0.7837082147598267,\n",
       "  0.8004781603813171,\n",
       "  0.7824959754943848,\n",
       "  0.787446141242981,\n",
       "  0.7720231413841248,\n",
       "  0.7762998342514038,\n",
       "  0.7886583805084229,\n",
       "  0.778690755367279,\n",
       "  0.8065059185028076,\n",
       "  0.7919921875,\n",
       "  0.8098397254943848,\n",
       "  0.8054956793785095,\n",
       "  0.7902411222457886,\n",
       "  0.8094692826271057,\n",
       "  0.7961004972457886,\n",
       "  0.7996026277542114,\n",
       "  0.814453125,\n",
       "  0.8024649620056152,\n",
       "  0.8091325163841248,\n",
       "  0.801118016242981,\n",
       "  0.8034752011299133,\n",
       "  0.8022292256355286,\n",
       "  0.7982893586158752,\n",
       "  0.7992995381355286,\n",
       "  0.7966729402542114,\n",
       "  0.7947534918785095,\n",
       "  0.8056303858757019,\n",
       "  0.815800130367279,\n",
       "  0.8145878314971924,\n",
       "  0.8104795217514038,\n",
       "  0.8132745027542114,\n",
       "  0.8159011006355286,\n",
       "  0.801421046257019,\n",
       "  0.8203798532485962,\n",
       "  0.8186624646186829,\n",
       "  0.8138806819915771,\n",
       "  0.8017578125,\n",
       "  0.8122305870056152,\n",
       "  0.7960331439971924,\n",
       "  0.8010843396186829,\n",
       "  0.783539891242981,\n",
       "  0.7939116358757019,\n",
       "  0.8051589131355286,\n",
       "  0.8106479048728943,\n",
       "  0.8125336766242981,\n",
       "  0.8104458451271057,\n",
       "  0.8073477745056152,\n",
       "  0.8088294863700867,\n",
       "  0.8168103694915771,\n",
       "  0.815766453742981,\n",
       "  0.8230064511299133,\n",
       "  0.8309873342514038,\n",
       "  0.8222993016242981,\n",
       "  0.8217268586158752,\n",
       "  0.8237136006355286,\n",
       "  0.8353650569915771,\n",
       "  0.8139816522598267,\n",
       "  0.8109846711158752,\n",
       "  0.7973800897598267,\n",
       "  0.8084927201271057,\n",
       "  0.8330414891242981,\n",
       "  0.813106119632721,\n",
       "  0.8161705136299133,\n",
       "  0.8315261006355286,\n",
       "  0.8241177201271057,\n",
       "  0.8299097418785095,\n",
       "  0.8296740055084229,\n",
       "  0.8415611386299133,\n",
       "  0.8360722064971924,\n",
       "  0.8321996331214905,\n",
       "  0.835331380367279,\n",
       "  0.8367120027542114,\n",
       "  0.8401468396186829,\n",
       "  0.8307852745056152,\n",
       "  0.8295729756355286,\n",
       "  0.8416621685028076,\n",
       "  0.8420662879943848,\n",
       "  0.8259698152542114,\n",
       "  0.829438328742981,\n",
       "  0.8285964131355286],\n",
       " 'tp': [268.0,\n",
       "  334.0,\n",
       "  357.0,\n",
       "  382.0,\n",
       "  372.0,\n",
       "  418.0,\n",
       "  414.0,\n",
       "  419.0,\n",
       "  416.0,\n",
       "  415.0,\n",
       "  433.0,\n",
       "  437.0,\n",
       "  448.0,\n",
       "  433.0,\n",
       "  453.0,\n",
       "  457.0,\n",
       "  441.0,\n",
       "  440.0,\n",
       "  440.0,\n",
       "  440.0,\n",
       "  452.0,\n",
       "  456.0,\n",
       "  455.0,\n",
       "  448.0,\n",
       "  448.0,\n",
       "  461.0,\n",
       "  447.0,\n",
       "  459.0,\n",
       "  455.0,\n",
       "  447.0,\n",
       "  455.0,\n",
       "  461.0,\n",
       "  453.0,\n",
       "  464.0,\n",
       "  457.0,\n",
       "  466.0,\n",
       "  451.0,\n",
       "  450.0,\n",
       "  455.0,\n",
       "  467.0,\n",
       "  466.0,\n",
       "  454.0,\n",
       "  460.0,\n",
       "  471.0,\n",
       "  460.0,\n",
       "  466.0,\n",
       "  456.0,\n",
       "  465.0,\n",
       "  468.0,\n",
       "  460.0,\n",
       "  462.0,\n",
       "  467.0,\n",
       "  461.0,\n",
       "  463.0,\n",
       "  469.0,\n",
       "  460.0,\n",
       "  453.0,\n",
       "  460.0,\n",
       "  454.0,\n",
       "  465.0,\n",
       "  445.0,\n",
       "  459.0,\n",
       "  458.0,\n",
       "  463.0,\n",
       "  452.0,\n",
       "  460.0,\n",
       "  459.0,\n",
       "  480.0,\n",
       "  450.0,\n",
       "  468.0,\n",
       "  460.0,\n",
       "  446.0,\n",
       "  453.0,\n",
       "  472.0,\n",
       "  468.0,\n",
       "  465.0,\n",
       "  465.0,\n",
       "  450.0,\n",
       "  467.0,\n",
       "  458.0,\n",
       "  473.0,\n",
       "  456.0,\n",
       "  457.0,\n",
       "  460.0,\n",
       "  459.0,\n",
       "  460.0,\n",
       "  461.0,\n",
       "  462.0,\n",
       "  458.0,\n",
       "  454.0,\n",
       "  457.0,\n",
       "  461.0,\n",
       "  461.0,\n",
       "  456.0,\n",
       "  465.0,\n",
       "  457.0,\n",
       "  466.0,\n",
       "  463.0,\n",
       "  469.0,\n",
       "  468.0,\n",
       "  472.0,\n",
       "  460.0,\n",
       "  461.0,\n",
       "  475.0,\n",
       "  464.0,\n",
       "  457.0,\n",
       "  469.0,\n",
       "  456.0,\n",
       "  472.0,\n",
       "  469.0,\n",
       "  477.0,\n",
       "  460.0,\n",
       "  462.0,\n",
       "  471.0,\n",
       "  473.0,\n",
       "  475.0,\n",
       "  470.0,\n",
       "  470.0,\n",
       "  455.0,\n",
       "  471.0,\n",
       "  470.0,\n",
       "  482.0,\n",
       "  458.0,\n",
       "  459.0,\n",
       "  465.0,\n",
       "  473.0,\n",
       "  463.0,\n",
       "  471.0,\n",
       "  470.0,\n",
       "  473.0,\n",
       "  466.0,\n",
       "  465.0,\n",
       "  472.0,\n",
       "  475.0,\n",
       "  487.0,\n",
       "  468.0,\n",
       "  479.0,\n",
       "  467.0,\n",
       "  466.0,\n",
       "  473.0,\n",
       "  464.0,\n",
       "  463.0,\n",
       "  467.0,\n",
       "  465.0,\n",
       "  479.0,\n",
       "  473.0,\n",
       "  476.0,\n",
       "  464.0,\n",
       "  471.0,\n",
       "  466.0,\n",
       "  469.0,\n",
       "  465.0,\n",
       "  469.0,\n",
       "  464.0,\n",
       "  477.0,\n",
       "  462.0,\n",
       "  482.0,\n",
       "  465.0,\n",
       "  472.0,\n",
       "  475.0,\n",
       "  472.0,\n",
       "  458.0,\n",
       "  468.0,\n",
       "  469.0,\n",
       "  465.0,\n",
       "  468.0,\n",
       "  479.0,\n",
       "  478.0,\n",
       "  480.0,\n",
       "  473.0,\n",
       "  480.0,\n",
       "  485.0,\n",
       "  473.0,\n",
       "  481.0,\n",
       "  482.0,\n",
       "  472.0,\n",
       "  472.0,\n",
       "  466.0,\n",
       "  478.0,\n",
       "  471.0,\n",
       "  485.0,\n",
       "  479.0,\n",
       "  470.0,\n",
       "  475.0,\n",
       "  471.0,\n",
       "  486.0,\n",
       "  486.0,\n",
       "  463.0,\n",
       "  476.0,\n",
       "  487.0,\n",
       "  466.0,\n",
       "  479.0,\n",
       "  473.0,\n",
       "  477.0,\n",
       "  474.0,\n",
       "  479.0,\n",
       "  474.0,\n",
       "  479.0,\n",
       "  465.0,\n",
       "  483.0,\n",
       "  477.0,\n",
       "  474.0,\n",
       "  482.0,\n",
       "  477.0,\n",
       "  488.0,\n",
       "  467.0,\n",
       "  476.0,\n",
       "  481.0,\n",
       "  473.0,\n",
       "  480.0,\n",
       "  476.0,\n",
       "  464.0,\n",
       "  482.0,\n",
       "  465.0,\n",
       "  476.0,\n",
       "  483.0,\n",
       "  487.0,\n",
       "  473.0,\n",
       "  473.0,\n",
       "  471.0,\n",
       "  482.0,\n",
       "  474.0,\n",
       "  471.0,\n",
       "  481.0,\n",
       "  480.0,\n",
       "  481.0,\n",
       "  481.0,\n",
       "  489.0,\n",
       "  479.0,\n",
       "  481.0,\n",
       "  480.0,\n",
       "  493.0,\n",
       "  478.0,\n",
       "  480.0,\n",
       "  481.0,\n",
       "  480.0,\n",
       "  488.0,\n",
       "  474.0,\n",
       "  489.0,\n",
       "  487.0,\n",
       "  489.0,\n",
       "  472.0,\n",
       "  480.0,\n",
       "  484.0,\n",
       "  481.0,\n",
       "  483.0,\n",
       "  474.0,\n",
       "  481.0,\n",
       "  483.0,\n",
       "  486.0,\n",
       "  481.0,\n",
       "  497.0,\n",
       "  483.0],\n",
       " 'fn': [258.0,\n",
       "  191.0,\n",
       "  171.0,\n",
       "  142.0,\n",
       "  157.0,\n",
       "  111.0,\n",
       "  117.0,\n",
       "  112.0,\n",
       "  110.0,\n",
       "  114.0,\n",
       "  99.0,\n",
       "  90.0,\n",
       "  90.0,\n",
       "  87.0,\n",
       "  78.0,\n",
       "  67.0,\n",
       "  85.0,\n",
       "  85.0,\n",
       "  92.0,\n",
       "  86.0,\n",
       "  71.0,\n",
       "  70.0,\n",
       "  78.0,\n",
       "  81.0,\n",
       "  81.0,\n",
       "  64.0,\n",
       "  85.0,\n",
       "  61.0,\n",
       "  73.0,\n",
       "  82.0,\n",
       "  69.0,\n",
       "  69.0,\n",
       "  79.0,\n",
       "  67.0,\n",
       "  64.0,\n",
       "  69.0,\n",
       "  73.0,\n",
       "  77.0,\n",
       "  67.0,\n",
       "  59.0,\n",
       "  63.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  56.0,\n",
       "  66.0,\n",
       "  61.0,\n",
       "  73.0,\n",
       "  63.0,\n",
       "  60.0,\n",
       "  70.0,\n",
       "  67.0,\n",
       "  68.0,\n",
       "  70.0,\n",
       "  64.0,\n",
       "  58.0,\n",
       "  68.0,\n",
       "  71.0,\n",
       "  66.0,\n",
       "  73.0,\n",
       "  65.0,\n",
       "  77.0,\n",
       "  66.0,\n",
       "  72.0,\n",
       "  69.0,\n",
       "  74.0,\n",
       "  65.0,\n",
       "  74.0,\n",
       "  48.0,\n",
       "  74.0,\n",
       "  59.0,\n",
       "  65.0,\n",
       "  82.0,\n",
       "  75.0,\n",
       "  60.0,\n",
       "  62.0,\n",
       "  62.0,\n",
       "  63.0,\n",
       "  71.0,\n",
       "  61.0,\n",
       "  68.0,\n",
       "  56.0,\n",
       "  67.0,\n",
       "  68.0,\n",
       "  72.0,\n",
       "  69.0,\n",
       "  62.0,\n",
       "  70.0,\n",
       "  64.0,\n",
       "  74.0,\n",
       "  76.0,\n",
       "  68.0,\n",
       "  72.0,\n",
       "  68.0,\n",
       "  74.0,\n",
       "  66.0,\n",
       "  69.0,\n",
       "  59.0,\n",
       "  67.0,\n",
       "  56.0,\n",
       "  59.0,\n",
       "  54.0,\n",
       "  67.0,\n",
       "  63.0,\n",
       "  57.0,\n",
       "  68.0,\n",
       "  65.0,\n",
       "  60.0,\n",
       "  69.0,\n",
       "  62.0,\n",
       "  54.0,\n",
       "  53.0,\n",
       "  58.0,\n",
       "  69.0,\n",
       "  62.0,\n",
       "  54.0,\n",
       "  59.0,\n",
       "  56.0,\n",
       "  60.0,\n",
       "  68.0,\n",
       "  49.0,\n",
       "  62.0,\n",
       "  47.0,\n",
       "  63.0,\n",
       "  67.0,\n",
       "  64.0,\n",
       "  55.0,\n",
       "  63.0,\n",
       "  58.0,\n",
       "  61.0,\n",
       "  51.0,\n",
       "  63.0,\n",
       "  67.0,\n",
       "  60.0,\n",
       "  56.0,\n",
       "  46.0,\n",
       "  52.0,\n",
       "  52.0,\n",
       "  57.0,\n",
       "  62.0,\n",
       "  53.0,\n",
       "  61.0,\n",
       "  66.0,\n",
       "  58.0,\n",
       "  61.0,\n",
       "  54.0,\n",
       "  53.0,\n",
       "  54.0,\n",
       "  63.0,\n",
       "  54.0,\n",
       "  61.0,\n",
       "  63.0,\n",
       "  56.0,\n",
       "  62.0,\n",
       "  58.0,\n",
       "  59.0,\n",
       "  67.0,\n",
       "  46.0,\n",
       "  59.0,\n",
       "  54.0,\n",
       "  56.0,\n",
       "  47.0,\n",
       "  68.0,\n",
       "  63.0,\n",
       "  56.0,\n",
       "  59.0,\n",
       "  62.0,\n",
       "  48.0,\n",
       "  52.0,\n",
       "  48.0,\n",
       "  59.0,\n",
       "  43.0,\n",
       "  46.0,\n",
       "  57.0,\n",
       "  47.0,\n",
       "  54.0,\n",
       "  55.0,\n",
       "  57.0,\n",
       "  59.0,\n",
       "  45.0,\n",
       "  53.0,\n",
       "  44.0,\n",
       "  53.0,\n",
       "  52.0,\n",
       "  55.0,\n",
       "  54.0,\n",
       "  41.0,\n",
       "  50.0,\n",
       "  59.0,\n",
       "  50.0,\n",
       "  46.0,\n",
       "  59.0,\n",
       "  48.0,\n",
       "  53.0,\n",
       "  47.0,\n",
       "  55.0,\n",
       "  54.0,\n",
       "  56.0,\n",
       "  53.0,\n",
       "  60.0,\n",
       "  43.0,\n",
       "  48.0,\n",
       "  47.0,\n",
       "  47.0,\n",
       "  49.0,\n",
       "  37.0,\n",
       "  57.0,\n",
       "  54.0,\n",
       "  47.0,\n",
       "  53.0,\n",
       "  49.0,\n",
       "  59.0,\n",
       "  60.0,\n",
       "  52.0,\n",
       "  65.0,\n",
       "  54.0,\n",
       "  50.0,\n",
       "  41.0,\n",
       "  52.0,\n",
       "  52.0,\n",
       "  52.0,\n",
       "  44.0,\n",
       "  59.0,\n",
       "  55.0,\n",
       "  45.0,\n",
       "  46.0,\n",
       "  47.0,\n",
       "  47.0,\n",
       "  41.0,\n",
       "  45.0,\n",
       "  49.0,\n",
       "  47.0,\n",
       "  36.0,\n",
       "  48.0,\n",
       "  46.0,\n",
       "  47.0,\n",
       "  47.0,\n",
       "  47.0,\n",
       "  49.0,\n",
       "  40.0,\n",
       "  39.0,\n",
       "  42.0,\n",
       "  52.0,\n",
       "  44.0,\n",
       "  50.0,\n",
       "  39.0,\n",
       "  42.0,\n",
       "  51.0,\n",
       "  47.0,\n",
       "  47.0,\n",
       "  43.0,\n",
       "  46.0,\n",
       "  33.0,\n",
       "  46.0],\n",
       " 'val_loss': [0.10545466095209122,\n",
       "  0.10390090197324753,\n",
       "  0.10620849579572678,\n",
       "  0.10309696197509766,\n",
       "  0.10539080202579498,\n",
       "  0.10461118072271347,\n",
       "  0.1069059893488884,\n",
       "  0.1030445471405983,\n",
       "  0.10302760452032089,\n",
       "  0.10455461591482162,\n",
       "  0.10300996154546738,\n",
       "  0.10604651272296906,\n",
       "  0.10448875278234482,\n",
       "  0.10523386299610138,\n",
       "  0.1042010560631752,\n",
       "  0.10405553877353668,\n",
       "  0.10273394733667374,\n",
       "  0.10255730152130127,\n",
       "  0.10132475197315216,\n",
       "  0.13811711966991425,\n",
       "  0.2373085469007492,\n",
       "  0.18950222432613373,\n",
       "  0.15540750324726105,\n",
       "  0.1088072806596756,\n",
       "  0.10595337301492691,\n",
       "  0.09968005865812302,\n",
       "  0.10050401836633682,\n",
       "  0.1009988784790039,\n",
       "  0.10227587074041367,\n",
       "  0.10160919278860092,\n",
       "  0.10741015523672104,\n",
       "  0.1099279448390007,\n",
       "  0.10715272277593613,\n",
       "  0.10391715914011002,\n",
       "  0.10325954109430313,\n",
       "  0.11829590052366257,\n",
       "  0.1084754690527916,\n",
       "  0.10689821094274521,\n",
       "  0.14522294700145721,\n",
       "  0.11465330421924591,\n",
       "  0.10111618041992188,\n",
       "  0.11278297752141953,\n",
       "  0.10455679893493652,\n",
       "  0.14258402585983276,\n",
       "  0.10156358778476715,\n",
       "  0.11340492218732834,\n",
       "  0.12143038958311081,\n",
       "  0.11598926037549973,\n",
       "  0.1290595531463623,\n",
       "  0.14447645843029022,\n",
       "  0.21046863496303558,\n",
       "  0.12505312263965607,\n",
       "  0.1753961145877838,\n",
       "  0.3093108832836151,\n",
       "  0.1706029176712036,\n",
       "  0.182265043258667,\n",
       "  0.1615159511566162,\n",
       "  0.11125089973211288,\n",
       "  0.11850793659687042,\n",
       "  0.1430310755968094,\n",
       "  0.1362951099872589,\n",
       "  0.13733236491680145,\n",
       "  0.1666935384273529,\n",
       "  0.12782590091228485,\n",
       "  0.21072924137115479,\n",
       "  0.1875850260257721,\n",
       "  0.16891151666641235,\n",
       "  0.16619887948036194,\n",
       "  0.24430029094219208,\n",
       "  0.279378741979599,\n",
       "  0.22533825039863586,\n",
       "  0.11617393791675568,\n",
       "  0.2142992466688156,\n",
       "  0.2259352058172226,\n",
       "  0.27490589022636414,\n",
       "  0.23435132205486298,\n",
       "  0.23687811195850372,\n",
       "  0.25687143206596375,\n",
       "  0.21618317067623138,\n",
       "  0.23532798886299133,\n",
       "  0.23070941865444183,\n",
       "  0.2965782582759857,\n",
       "  0.266388475894928,\n",
       "  0.12449336051940918,\n",
       "  0.21920828521251678,\n",
       "  0.18585947155952454,\n",
       "  0.1799362599849701,\n",
       "  0.2687889039516449,\n",
       "  0.23995327949523926,\n",
       "  0.16769400238990784,\n",
       "  0.2751263380050659,\n",
       "  0.20665064454078674,\n",
       "  0.190781831741333,\n",
       "  0.38753506541252136,\n",
       "  0.5141351222991943,\n",
       "  0.2992304265499115,\n",
       "  0.48552560806274414,\n",
       "  0.39886870980262756,\n",
       "  0.32765641808509827,\n",
       "  0.2547994554042816,\n",
       "  0.179025799036026,\n",
       "  0.22009539604187012,\n",
       "  0.272964209318161,\n",
       "  0.2563680410385132,\n",
       "  0.18783216178417206,\n",
       "  0.21816614270210266,\n",
       "  0.2694948613643646,\n",
       "  0.26009401679039,\n",
       "  0.5130829811096191,\n",
       "  0.42926549911499023,\n",
       "  0.3739786148071289,\n",
       "  0.2672947347164154,\n",
       "  0.32206329703330994,\n",
       "  0.28388142585754395,\n",
       "  0.38836294412612915,\n",
       "  0.319167822599411,\n",
       "  0.27542921900749207,\n",
       "  0.40696701407432556,\n",
       "  0.37420979142189026,\n",
       "  0.40208640694618225,\n",
       "  0.36883875727653503,\n",
       "  0.3635324239730835,\n",
       "  0.3206874430179596,\n",
       "  0.3584546744823456,\n",
       "  0.2542480230331421,\n",
       "  0.24386368691921234,\n",
       "  0.26824644207954407,\n",
       "  0.41070786118507385,\n",
       "  0.353887140750885,\n",
       "  0.2240532487630844,\n",
       "  0.19921806454658508,\n",
       "  0.28198978304862976,\n",
       "  0.3698689043521881,\n",
       "  0.2620169222354889,\n",
       "  0.36176201701164246,\n",
       "  0.33741024136543274,\n",
       "  0.4647981822490692,\n",
       "  0.39949458837509155,\n",
       "  0.35989126563072205,\n",
       "  0.2168399542570114,\n",
       "  0.2695755660533905,\n",
       "  0.1611626148223877,\n",
       "  0.23540984094142914,\n",
       "  0.3245350420475006,\n",
       "  0.24658837914466858,\n",
       "  0.26194068789482117,\n",
       "  0.34438422322273254,\n",
       "  0.3615585267543793,\n",
       "  0.3603009283542633,\n",
       "  0.39252111315727234,\n",
       "  0.31444787979125977,\n",
       "  0.338301420211792,\n",
       "  0.2525857090950012,\n",
       "  0.2963416576385498,\n",
       "  0.44857388734817505,\n",
       "  0.25276660919189453,\n",
       "  0.31369519233703613,\n",
       "  0.5036157965660095,\n",
       "  0.5708620548248291,\n",
       "  0.44662532210350037,\n",
       "  0.26942044496536255,\n",
       "  0.3504312336444855,\n",
       "  0.3311931788921356,\n",
       "  0.2925984561443329,\n",
       "  0.32895681262016296,\n",
       "  0.28962406516075134,\n",
       "  0.2822260558605194,\n",
       "  0.24683323502540588,\n",
       "  0.3289380967617035,\n",
       "  0.33233442902565,\n",
       "  0.34092119336128235,\n",
       "  0.3061193823814392,\n",
       "  0.2508489191532135,\n",
       "  0.32195767760276794,\n",
       "  0.31207868456840515,\n",
       "  0.37922629714012146,\n",
       "  0.3626690208911896,\n",
       "  0.4668582081794739,\n",
       "  0.6009898781776428,\n",
       "  0.40575313568115234,\n",
       "  0.5182121396064758,\n",
       "  0.43644094467163086,\n",
       "  0.39896875619888306,\n",
       "  0.31367620825767517,\n",
       "  0.3654998242855072,\n",
       "  0.44523724913597107,\n",
       "  0.3883346617221832,\n",
       "  0.41800791025161743,\n",
       "  0.28490743041038513,\n",
       "  0.27836647629737854,\n",
       "  0.258668452501297,\n",
       "  0.23901763558387756,\n",
       "  0.3844522535800934,\n",
       "  0.3372128903865814,\n",
       "  0.19182385504245758,\n",
       "  0.36723262071609497,\n",
       "  0.4079137444496155,\n",
       "  0.3858340382575989,\n",
       "  0.6984729170799255,\n",
       "  0.44584259390830994,\n",
       "  0.4169081747531891,\n",
       "  0.3606518805027008,\n",
       "  0.35494253039360046,\n",
       "  0.3073963224887848,\n",
       "  0.3370570242404938,\n",
       "  0.34837737679481506,\n",
       "  0.34360477328300476,\n",
       "  0.2598819434642792,\n",
       "  0.21324920654296875,\n",
       "  0.20698228478431702,\n",
       "  0.2796366810798645,\n",
       "  0.4461497962474823,\n",
       "  0.29866930842399597,\n",
       "  0.45290037989616394,\n",
       "  0.4668303430080414,\n",
       "  0.63918536901474,\n",
       "  0.3856971859931946,\n",
       "  0.2958357334136963,\n",
       "  0.42731618881225586,\n",
       "  0.6617001295089722,\n",
       "  0.41535648703575134,\n",
       "  0.32740288972854614,\n",
       "  0.4038933217525482,\n",
       "  0.5285071730613708,\n",
       "  0.5075262188911438,\n",
       "  0.25801825523376465,\n",
       "  0.34489673376083374,\n",
       "  0.3751565217971802,\n",
       "  0.3104958236217499,\n",
       "  0.299955815076828,\n",
       "  0.29927772283554077,\n",
       "  0.34150660037994385,\n",
       "  0.21069137752056122,\n",
       "  0.22996683418750763,\n",
       "  0.21848678588867188,\n",
       "  0.22989149391651154,\n",
       "  0.3502165973186493,\n",
       "  0.29469034075737,\n",
       "  0.2035326510667801,\n",
       "  0.29254913330078125,\n",
       "  0.2594636082649231,\n",
       "  0.3853500187397003,\n",
       "  0.39469677209854126,\n",
       "  0.4105103611946106,\n",
       "  0.3394105136394501,\n",
       "  0.3021312952041626,\n",
       "  0.24856209754943848,\n",
       "  0.20189516246318817,\n",
       "  0.2575213611125946,\n",
       "  0.31546375155448914,\n",
       "  0.22260747849941254,\n",
       "  0.3056676983833313,\n",
       "  0.29560670256614685],\n",
       " 'val_auc': [0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.590408444404602,\n",
       "  0.6019740104675293,\n",
       "  0.6084291934967041,\n",
       "  0.6364156603813171,\n",
       "  0.7039943933486938,\n",
       "  0.7224846482276917,\n",
       "  0.7379525303840637,\n",
       "  0.7586038112640381,\n",
       "  0.7710336446762085,\n",
       "  0.770542562007904,\n",
       "  0.7510872483253479,\n",
       "  0.800081729888916,\n",
       "  0.7853927612304688,\n",
       "  0.7737107872962952,\n",
       "  0.7407806515693665,\n",
       "  0.7554040551185608,\n",
       "  0.7576318383216858,\n",
       "  0.7748236656188965,\n",
       "  0.6591694355010986,\n",
       "  0.7426178455352783,\n",
       "  0.783095121383667,\n",
       "  0.7988227605819702,\n",
       "  0.7456241846084595,\n",
       "  0.7731750011444092,\n",
       "  0.7989193797111511,\n",
       "  0.808040201663971,\n",
       "  0.8079587817192078,\n",
       "  0.7083010673522949,\n",
       "  0.7309516668319702,\n",
       "  0.6918323636054993,\n",
       "  0.7944802045822144,\n",
       "  0.6808473467826843,\n",
       "  0.6814661026000977,\n",
       "  0.727495014667511,\n",
       "  0.8011665344238281,\n",
       "  0.7838813066482544,\n",
       "  0.728883683681488,\n",
       "  0.8194736838340759,\n",
       "  0.75936359167099,\n",
       "  0.7676522135734558,\n",
       "  0.7334046363830566,\n",
       "  0.6488242149353027,\n",
       "  0.6874148845672607,\n",
       "  0.6998643279075623,\n",
       "  0.7505202889442444,\n",
       "  0.6940491199493408,\n",
       "  0.7596387267112732,\n",
       "  0.7442543506622314,\n",
       "  0.7848857641220093,\n",
       "  0.7486349940299988,\n",
       "  0.7749691605567932,\n",
       "  0.8022183775901794,\n",
       "  0.8090577125549316,\n",
       "  0.8110131621360779,\n",
       "  0.8187822103500366,\n",
       "  0.8061072826385498,\n",
       "  0.6585862636566162,\n",
       "  0.8056767582893372,\n",
       "  0.8119544982910156,\n",
       "  0.8221531510353088,\n",
       "  0.7967530488967896,\n",
       "  0.8038203120231628,\n",
       "  0.821906328201294,\n",
       "  0.7824528813362122,\n",
       "  0.8076777458190918,\n",
       "  0.8067235350608826,\n",
       "  0.811631977558136,\n",
       "  0.8099855780601501,\n",
       "  0.783018171787262,\n",
       "  0.7466000914573669,\n",
       "  0.8153094053268433,\n",
       "  0.8181041479110718,\n",
       "  0.7575013637542725,\n",
       "  0.7997607588768005,\n",
       "  0.7856549024581909,\n",
       "  0.8053295612335205,\n",
       "  0.7615149021148682,\n",
       "  0.8147076964378357,\n",
       "  0.8496566414833069,\n",
       "  0.8304519653320312,\n",
       "  0.8144879937171936,\n",
       "  0.8055490851402283,\n",
       "  0.8408507108688354,\n",
       "  0.8251816630363464,\n",
       "  0.8461785316467285,\n",
       "  0.8255714178085327,\n",
       "  0.8184486031532288,\n",
       "  0.8074197173118591,\n",
       "  0.8025012612342834,\n",
       "  0.8158614635467529,\n",
       "  0.8153191804885864,\n",
       "  0.8037923574447632,\n",
       "  0.8179193139076233,\n",
       "  0.840424120426178,\n",
       "  0.836852490901947,\n",
       "  0.8325369358062744,\n",
       "  0.8442633152008057,\n",
       "  0.8483241200447083,\n",
       "  0.8490368127822876,\n",
       "  0.8208645582199097,\n",
       "  0.8081601858139038,\n",
       "  0.8424925208091736,\n",
       "  0.831069827079773,\n",
       "  0.8307903409004211,\n",
       "  0.8412320017814636,\n",
       "  0.8432728052139282,\n",
       "  0.8576096296310425,\n",
       "  0.8443406820297241,\n",
       "  0.8390210866928101,\n",
       "  0.8256118297576904,\n",
       "  0.8276024460792542,\n",
       "  0.8301473259925842,\n",
       "  0.8398308753967285,\n",
       "  0.8364964723587036,\n",
       "  0.8570903539657593,\n",
       "  0.78691166639328,\n",
       "  0.8254490494728088,\n",
       "  0.76558518409729,\n",
       "  0.8187417387962341,\n",
       "  0.7797324061393738,\n",
       "  0.7975613474845886,\n",
       "  0.8210408091545105,\n",
       "  0.8252625465393066,\n",
       "  0.8101125359535217,\n",
       "  0.8111287951469421,\n",
       "  0.7945837378501892,\n",
       "  0.7798953056335449,\n",
       "  0.8211283087730408,\n",
       "  0.8374861478805542,\n",
       "  0.848793625831604,\n",
       "  0.8311304450035095,\n",
       "  0.8334532976150513,\n",
       "  0.8471683859825134,\n",
       "  0.8595662117004395,\n",
       "  0.8204416036605835,\n",
       "  0.8335090279579163,\n",
       "  0.8244314193725586,\n",
       "  0.8498607277870178,\n",
       "  0.8704442381858826,\n",
       "  0.8271589279174805,\n",
       "  0.855286180973053,\n",
       "  0.8114505410194397,\n",
       "  0.8299738764762878,\n",
       "  0.8148497343063354,\n",
       "  0.8466787338256836,\n",
       "  0.851990282535553,\n",
       "  0.8334247469902039,\n",
       "  0.8325663208961487,\n",
       "  0.8388031721115112,\n",
       "  0.8341116905212402,\n",
       "  0.8384755849838257,\n",
       "  0.8450227975845337,\n",
       "  0.8527807593345642,\n",
       "  0.8490242958068848,\n",
       "  0.8228691220283508,\n",
       "  0.7709302306175232,\n",
       "  0.834003210067749,\n",
       "  0.8342522978782654,\n",
       "  0.8410393595695496,\n",
       "  0.8383645415306091,\n",
       "  0.8150463104248047,\n",
       "  0.8205977082252502,\n",
       "  0.7847512364387512,\n",
       "  0.7912341952323914,\n",
       "  0.8473443388938904,\n",
       "  0.8080947399139404,\n",
       "  0.8458781242370605,\n",
       "  0.8595656752586365,\n",
       "  0.8182185888290405,\n",
       "  0.8648999333381653,\n",
       "  0.8405912518501282,\n",
       "  0.858101487159729,\n",
       "  0.8406956791877747,\n",
       "  0.8284803628921509,\n",
       "  0.8440157771110535,\n",
       "  0.853522777557373,\n",
       "  0.8477184176445007,\n",
       "  0.8538681268692017,\n",
       "  0.8731936812400818,\n",
       "  0.8337375521659851,\n",
       "  0.8123308420181274,\n",
       "  0.814172625541687,\n",
       "  0.8661172986030579,\n",
       "  0.8152253031730652,\n",
       "  0.8450651168823242,\n",
       "  0.8629940748214722,\n",
       "  0.8476310968399048,\n",
       "  0.8466924428939819,\n",
       "  0.8527234196662903,\n",
       "  0.7873184084892273,\n",
       "  0.7668533325195312,\n",
       "  0.8574198484420776,\n",
       "  0.8617489337921143,\n",
       "  0.845921516418457,\n",
       "  0.823228120803833,\n",
       "  0.8523320555686951,\n",
       "  0.8572244644165039,\n",
       "  0.847787618637085,\n",
       "  0.7975233793258667,\n",
       "  0.840454638004303,\n",
       "  0.8396683931350708,\n",
       "  0.836897075176239,\n",
       "  0.8227841258049011,\n",
       "  0.8429127931594849,\n",
       "  0.8309209942817688,\n",
       "  0.8330146670341492,\n",
       "  0.8537113666534424,\n",
       "  0.8295674324035645,\n",
       "  0.8544983863830566,\n",
       "  0.838654637336731,\n",
       "  0.8357712626457214,\n",
       "  0.8482099175453186,\n",
       "  0.8568742871284485,\n",
       "  0.8534560203552246,\n",
       "  0.8489965200424194,\n",
       "  0.8276622891426086,\n",
       "  0.8521309494972229,\n",
       "  0.8384231328964233,\n",
       "  0.8140121698379517,\n",
       "  0.8338035345077515,\n",
       "  0.8313329219818115,\n",
       "  0.8638316988945007,\n",
       "  0.8429080247879028,\n",
       "  0.8217829465866089,\n",
       "  0.8164631724357605,\n",
       "  0.8382856249809265,\n",
       "  0.8426924347877502,\n",
       "  0.8598424196243286,\n",
       "  0.8668344020843506,\n",
       "  0.8464925289154053,\n",
       "  0.8315426111221313,\n",
       "  0.862219512462616,\n",
       "  0.8371723890304565,\n",
       "  0.8138278722763062,\n",
       "  0.8101455569267273,\n",
       "  0.8414373397827148,\n",
       "  0.8056345582008362,\n",
       "  0.8106907606124878,\n",
       "  0.8461897969245911],\n",
       " 'val_accuracy': [0.9830078482627869,\n",
       "  0.9833984375,\n",
       "  0.9828125238418579,\n",
       "  0.983593761920929,\n",
       "  0.9830078482627869,\n",
       "  0.983203113079071,\n",
       "  0.982617199420929,\n",
       "  0.983593761920929,\n",
       "  0.983593761920929,\n",
       "  0.983203113079071,\n",
       "  0.983593761920929,\n",
       "  0.9828125238418579,\n",
       "  0.983203113079071,\n",
       "  0.9830078482627869,\n",
       "  0.983203113079071,\n",
       "  0.983203113079071,\n",
       "  0.9833984375,\n",
       "  0.9833984375,\n",
       "  0.9833984375,\n",
       "  0.980273425579071,\n",
       "  0.8675781488418579,\n",
       "  0.9320312738418579,\n",
       "  0.9818359613418579,\n",
       "  0.9833984375,\n",
       "  0.9828125238418579,\n",
       "  0.9828125238418579,\n",
       "  0.9828125238418579,\n",
       "  0.9830078482627869,\n",
       "  0.9828125238418579,\n",
       "  0.9828125238418579,\n",
       "  0.9833984375,\n",
       "  0.983593761920929,\n",
       "  0.983593761920929,\n",
       "  0.9837890863418579,\n",
       "  0.984375,\n",
       "  0.980664074420929,\n",
       "  0.983203113079071,\n",
       "  0.983203113079071,\n",
       "  0.962695300579071,\n",
       "  0.980664074420929,\n",
       "  0.983593761920929,\n",
       "  0.9830078482627869,\n",
       "  0.9830078482627869,\n",
       "  0.9814453125,\n",
       "  0.9828125238418579,\n",
       "  0.9828125238418579,\n",
       "  0.9800781607627869,\n",
       "  0.981249988079071,\n",
       "  0.968554675579071,\n",
       "  0.9634765982627869,\n",
       "  0.9173828363418579,\n",
       "  0.9683594107627869,\n",
       "  0.9388672113418579,\n",
       "  0.8433594107627869,\n",
       "  0.948437511920929,\n",
       "  0.952343761920929,\n",
       "  0.96875,\n",
       "  0.982421875,\n",
       "  0.980273425579071,\n",
       "  0.970703125,\n",
       "  0.970898449420929,\n",
       "  0.967968761920929,\n",
       "  0.944531261920929,\n",
       "  0.971484363079071,\n",
       "  0.908203125,\n",
       "  0.9273437857627869,\n",
       "  0.938281238079071,\n",
       "  0.94140625,\n",
       "  0.890429675579071,\n",
       "  0.8714843988418579,\n",
       "  0.9166015982627869,\n",
       "  0.974609375,\n",
       "  0.911914050579071,\n",
       "  0.8951172232627869,\n",
       "  0.881640613079071,\n",
       "  0.899218738079071,\n",
       "  0.900585949420929,\n",
       "  0.889453113079071,\n",
       "  0.910937488079071,\n",
       "  0.897265613079071,\n",
       "  0.8994140625,\n",
       "  0.8626953363418579,\n",
       "  0.8814453482627869,\n",
       "  0.9828125238418579,\n",
       "  0.900195300579071,\n",
       "  0.9281250238418579,\n",
       "  0.937695324420929,\n",
       "  0.870898425579071,\n",
       "  0.898242175579071,\n",
       "  0.94140625,\n",
       "  0.8792968988418579,\n",
       "  0.9203125238418579,\n",
       "  0.9261718988418579,\n",
       "  0.822460949420929,\n",
       "  0.7789062857627869,\n",
       "  0.8619140982627869,\n",
       "  0.7601562738418579,\n",
       "  0.8023437857627869,\n",
       "  0.8472656607627869,\n",
       "  0.8804687857627869,\n",
       "  0.934765636920929,\n",
       "  0.904492199420929,\n",
       "  0.8759765625,\n",
       "  0.8783203363418579,\n",
       "  0.9173828363418579,\n",
       "  0.898632824420929,\n",
       "  0.8724609613418579,\n",
       "  0.8812500238418579,\n",
       "  0.7134765982627869,\n",
       "  0.791015625,\n",
       "  0.8189453482627869,\n",
       "  0.8662109375,\n",
       "  0.8382812738418579,\n",
       "  0.875781238079071,\n",
       "  0.800976574420929,\n",
       "  0.857617199420929,\n",
       "  0.8818359375,\n",
       "  0.840039074420929,\n",
       "  0.820507824420929,\n",
       "  0.814453125,\n",
       "  0.826367199420929,\n",
       "  0.824999988079071,\n",
       "  0.847851574420929,\n",
       "  0.8326172232627869,\n",
       "  0.8697265982627869,\n",
       "  0.895312488079071,\n",
       "  0.8785156607627869,\n",
       "  0.814648449420929,\n",
       "  0.824999988079071,\n",
       "  0.9087890982627869,\n",
       "  0.908203125,\n",
       "  0.8603515625,\n",
       "  0.832226574420929,\n",
       "  0.896679699420929,\n",
       "  0.8353515863418579,\n",
       "  0.863085925579071,\n",
       "  0.7822265625,\n",
       "  0.832812488079071,\n",
       "  0.843945324420929,\n",
       "  0.9140625,\n",
       "  0.896484375,\n",
       "  0.946484386920929,\n",
       "  0.8900390863418579,\n",
       "  0.8568359613418579,\n",
       "  0.879687488079071,\n",
       "  0.8726562857627869,\n",
       "  0.828125,\n",
       "  0.8154296875,\n",
       "  0.8226562738418579,\n",
       "  0.807812511920929,\n",
       "  0.8392578363418579,\n",
       "  0.8257812857627869,\n",
       "  0.8785156607627869,\n",
       "  0.8564453125,\n",
       "  0.7943359613418579,\n",
       "  0.8931640982627869,\n",
       "  0.871289074420929,\n",
       "  0.7787109613418579,\n",
       "  0.7447265982627869,\n",
       "  0.811718761920929,\n",
       "  0.876171886920929,\n",
       "  0.8365234732627869,\n",
       "  0.8492187857627869,\n",
       "  0.8716797232627869,\n",
       "  0.850781261920929,\n",
       "  0.8685547113418579,\n",
       "  0.87890625,\n",
       "  0.8974609375,\n",
       "  0.84765625,\n",
       "  0.851367175579071,\n",
       "  0.8501953482627869,\n",
       "  0.870898425579071,\n",
       "  0.888476550579071,\n",
       "  0.855664074420929,\n",
       "  0.861523449420929,\n",
       "  0.8121094107627869,\n",
       "  0.830273449420929,\n",
       "  0.762890636920929,\n",
       "  0.754101574420929,\n",
       "  0.8011718988418579,\n",
       "  0.7681640982627869,\n",
       "  0.800000011920929,\n",
       "  0.8291015625,\n",
       "  0.8619140982627869,\n",
       "  0.827343761920929,\n",
       "  0.7955078482627869,\n",
       "  0.8119140863418579,\n",
       "  0.800585925579071,\n",
       "  0.864062488079071,\n",
       "  0.8726562857627869,\n",
       "  0.878125011920929,\n",
       "  0.8880859613418579,\n",
       "  0.8121094107627869,\n",
       "  0.849804699420929,\n",
       "  0.9271484613418579,\n",
       "  0.8125,\n",
       "  0.8121094107627869,\n",
       "  0.8160156607627869,\n",
       "  0.6820312738418579,\n",
       "  0.7939453125,\n",
       "  0.825390636920929,\n",
       "  0.8304687738418579,\n",
       "  0.8541015982627869,\n",
       "  0.880859375,\n",
       "  0.8558593988418579,\n",
       "  0.8443359732627869,\n",
       "  0.8515625,\n",
       "  0.892773449420929,\n",
       "  0.9173828363418579,\n",
       "  0.920117199420929,\n",
       "  0.8785156607627869,\n",
       "  0.8017578125,\n",
       "  0.872851550579071,\n",
       "  0.7933593988418579,\n",
       "  0.765429675579071,\n",
       "  0.7386718988418579,\n",
       "  0.8203125,\n",
       "  0.8697265982627869,\n",
       "  0.810742199420929,\n",
       "  0.748828113079071,\n",
       "  0.8267578482627869,\n",
       "  0.8720703125,\n",
       "  0.817187488079071,\n",
       "  0.773632824420929,\n",
       "  0.7783203125,\n",
       "  0.8892578482627869,\n",
       "  0.840624988079071,\n",
       "  0.824999988079071,\n",
       "  0.873242199420929,\n",
       "  0.849804699420929,\n",
       "  0.855664074420929,\n",
       "  0.822265625,\n",
       "  0.9068359732627869,\n",
       "  0.9046875238418579,\n",
       "  0.906054675579071,\n",
       "  0.8988281488418579,\n",
       "  0.8408203125,\n",
       "  0.85546875,\n",
       "  0.9125000238418579,\n",
       "  0.8763672113418579,\n",
       "  0.904101550579071,\n",
       "  0.8296875357627869,\n",
       "  0.839062511920929,\n",
       "  0.8353515863418579,\n",
       "  0.8638672232627869,\n",
       "  0.8785156607627869,\n",
       "  0.896484375,\n",
       "  0.9251953363418579,\n",
       "  0.894726574420929,\n",
       "  0.8779296875,\n",
       "  0.905078113079071,\n",
       "  0.873828113079071,\n",
       "  0.8783203363418579],\n",
       " 'val_tp': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  29.0,\n",
       "  13.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  3.0,\n",
       "  4.0,\n",
       "  7.0,\n",
       "  8.0,\n",
       "  17.0,\n",
       "  7.0,\n",
       "  16.0,\n",
       "  41.0,\n",
       "  9.0,\n",
       "  7.0,\n",
       "  6.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  5.0,\n",
       "  7.0,\n",
       "  3.0,\n",
       "  18.0,\n",
       "  2.0,\n",
       "  16.0,\n",
       "  19.0,\n",
       "  28.0,\n",
       "  14.0,\n",
       "  36.0,\n",
       "  36.0,\n",
       "  10.0,\n",
       "  6.0,\n",
       "  27.0,\n",
       "  37.0,\n",
       "  33.0,\n",
       "  35.0,\n",
       "  32.0,\n",
       "  35.0,\n",
       "  31.0,\n",
       "  33.0,\n",
       "  30.0,\n",
       "  39.0,\n",
       "  29.0,\n",
       "  0.0,\n",
       "  33.0,\n",
       "  20.0,\n",
       "  10.0,\n",
       "  40.0,\n",
       "  36.0,\n",
       "  17.0,\n",
       "  40.0,\n",
       "  29.0,\n",
       "  23.0,\n",
       "  49.0,\n",
       "  64.0,\n",
       "  45.0,\n",
       "  60.0,\n",
       "  59.0,\n",
       "  54.0,\n",
       "  41.0,\n",
       "  25.0,\n",
       "  33.0,\n",
       "  42.0,\n",
       "  33.0,\n",
       "  30.0,\n",
       "  23.0,\n",
       "  38.0,\n",
       "  39.0,\n",
       "  74.0,\n",
       "  65.0,\n",
       "  61.0,\n",
       "  49.0,\n",
       "  57.0,\n",
       "  41.0,\n",
       "  55.0,\n",
       "  48.0,\n",
       "  50.0,\n",
       "  54.0,\n",
       "  51.0,\n",
       "  60.0,\n",
       "  55.0,\n",
       "  59.0,\n",
       "  54.0,\n",
       "  48.0,\n",
       "  38.0,\n",
       "  38.0,\n",
       "  43.0,\n",
       "  58.0,\n",
       "  55.0,\n",
       "  33.0,\n",
       "  27.0,\n",
       "  33.0,\n",
       "  48.0,\n",
       "  30.0,\n",
       "  45.0,\n",
       "  42.0,\n",
       "  57.0,\n",
       "  44.0,\n",
       "  42.0,\n",
       "  30.0,\n",
       "  33.0,\n",
       "  24.0,\n",
       "  37.0,\n",
       "  50.0,\n",
       "  43.0,\n",
       "  48.0,\n",
       "  52.0,\n",
       "  57.0,\n",
       "  50.0,\n",
       "  57.0,\n",
       "  48.0,\n",
       "  58.0,\n",
       "  49.0,\n",
       "  43.0,\n",
       "  63.0,\n",
       "  38.0,\n",
       "  44.0,\n",
       "  58.0,\n",
       "  70.0,\n",
       "  56.0,\n",
       "  43.0,\n",
       "  56.0,\n",
       "  51.0,\n",
       "  48.0,\n",
       "  52.0,\n",
       "  48.0,\n",
       "  44.0,\n",
       "  42.0,\n",
       "  48.0,\n",
       "  44.0,\n",
       "  48.0,\n",
       "  41.0,\n",
       "  42.0,\n",
       "  48.0,\n",
       "  46.0,\n",
       "  50.0,\n",
       "  46.0,\n",
       "  62.0,\n",
       "  67.0,\n",
       "  48.0,\n",
       "  67.0,\n",
       "  62.0,\n",
       "  52.0,\n",
       "  59.0,\n",
       "  58.0,\n",
       "  66.0,\n",
       "  61.0,\n",
       "  51.0,\n",
       "  50.0,\n",
       "  53.0,\n",
       "  41.0,\n",
       "  40.0,\n",
       "  61.0,\n",
       "  46.0,\n",
       "  32.0,\n",
       "  52.0,\n",
       "  62.0,\n",
       "  49.0,\n",
       "  80.0,\n",
       "  66.0,\n",
       "  52.0,\n",
       "  54.0,\n",
       "  51.0,\n",
       "  45.0,\n",
       "  44.0,\n",
       "  55.0,\n",
       "  53.0,\n",
       "  39.0,\n",
       "  42.0,\n",
       "  39.0,\n",
       "  47.0,\n",
       "  60.0,\n",
       "  45.0,\n",
       "  56.0,\n",
       "  55.0,\n",
       "  68.0,\n",
       "  56.0,\n",
       "  44.0,\n",
       "  57.0,\n",
       "  67.0,\n",
       "  58.0,\n",
       "  49.0,\n",
       "  58.0,\n",
       "  58.0,\n",
       "  64.0,\n",
       "  42.0,\n",
       "  52.0,\n",
       "  58.0,\n",
       "  45.0,\n",
       "  43.0,\n",
       "  49.0,\n",
       "  47.0,\n",
       "  36.0,\n",
       "  38.0,\n",
       "  33.0,\n",
       "  38.0,\n",
       "  45.0,\n",
       "  45.0,\n",
       "  26.0,\n",
       "  42.0,\n",
       "  45.0,\n",
       "  60.0,\n",
       "  61.0,\n",
       "  52.0,\n",
       "  49.0,\n",
       "  43.0,\n",
       "  40.0,\n",
       "  32.0,\n",
       "  41.0,\n",
       "  49.0,\n",
       "  34.0,\n",
       "  42.0,\n",
       "  44.0],\n",
       " 'val_fn': [87.0,\n",
       "  85.0,\n",
       "  88.0,\n",
       "  84.0,\n",
       "  87.0,\n",
       "  86.0,\n",
       "  89.0,\n",
       "  84.0,\n",
       "  84.0,\n",
       "  86.0,\n",
       "  84.0,\n",
       "  88.0,\n",
       "  86.0,\n",
       "  87.0,\n",
       "  86.0,\n",
       "  86.0,\n",
       "  85.0,\n",
       "  85.0,\n",
       "  85.0,\n",
       "  79.0,\n",
       "  58.0,\n",
       "  72.0,\n",
       "  86.0,\n",
       "  85.0,\n",
       "  88.0,\n",
       "  88.0,\n",
       "  88.0,\n",
       "  87.0,\n",
       "  88.0,\n",
       "  88.0,\n",
       "  85.0,\n",
       "  84.0,\n",
       "  84.0,\n",
       "  83.0,\n",
       "  80.0,\n",
       "  85.0,\n",
       "  86.0,\n",
       "  86.0,\n",
       "  78.0,\n",
       "  86.0,\n",
       "  84.0,\n",
       "  87.0,\n",
       "  87.0,\n",
       "  83.0,\n",
       "  88.0,\n",
       "  88.0,\n",
       "  82.0,\n",
       "  83.0,\n",
       "  80.0,\n",
       "  78.0,\n",
       "  70.0,\n",
       "  77.0,\n",
       "  68.0,\n",
       "  44.0,\n",
       "  77.0,\n",
       "  79.0,\n",
       "  81.0,\n",
       "  85.0,\n",
       "  82.0,\n",
       "  82.0,\n",
       "  78.0,\n",
       "  81.0,\n",
       "  66.0,\n",
       "  86.0,\n",
       "  68.0,\n",
       "  67.0,\n",
       "  58.0,\n",
       "  75.0,\n",
       "  51.0,\n",
       "  51.0,\n",
       "  75.0,\n",
       "  83.0,\n",
       "  61.0,\n",
       "  50.0,\n",
       "  48.0,\n",
       "  50.0,\n",
       "  54.0,\n",
       "  52.0,\n",
       "  53.0,\n",
       "  48.0,\n",
       "  59.0,\n",
       "  44.0,\n",
       "  59.0,\n",
       "  87.0,\n",
       "  51.0,\n",
       "  66.0,\n",
       "  76.0,\n",
       "  49.0,\n",
       "  52.0,\n",
       "  69.0,\n",
       "  46.0,\n",
       "  55.0,\n",
       "  66.0,\n",
       "  34.0,\n",
       "  27.0,\n",
       "  42.0,\n",
       "  25.0,\n",
       "  27.0,\n",
       "  32.0,\n",
       "  42.0,\n",
       "  60.0,\n",
       "  53.0,\n",
       "  44.0,\n",
       "  53.0,\n",
       "  59.0,\n",
       "  59.0,\n",
       "  46.0,\n",
       "  46.0,\n",
       "  11.0,\n",
       "  25.0,\n",
       "  26.0,\n",
       "  36.0,\n",
       "  31.0,\n",
       "  45.0,\n",
       "  31.0,\n",
       "  39.0,\n",
       "  34.0,\n",
       "  33.0,\n",
       "  35.0,\n",
       "  23.0,\n",
       "  30.0,\n",
       "  29.0,\n",
       "  33.0,\n",
       "  36.0,\n",
       "  45.0,\n",
       "  49.0,\n",
       "  43.0,\n",
       "  28.0,\n",
       "  32.0,\n",
       "  51.0,\n",
       "  61.0,\n",
       "  50.0,\n",
       "  38.0,\n",
       "  55.0,\n",
       "  42.0,\n",
       "  45.0,\n",
       "  31.0,\n",
       "  40.0,\n",
       "  41.0,\n",
       "  54.0,\n",
       "  55.0,\n",
       "  60.0,\n",
       "  50.0,\n",
       "  36.0,\n",
       "  42.0,\n",
       "  38.0,\n",
       "  34.0,\n",
       "  32.0,\n",
       "  34.0,\n",
       "  28.0,\n",
       "  37.0,\n",
       "  30.0,\n",
       "  36.0,\n",
       "  41.0,\n",
       "  23.0,\n",
       "  47.0,\n",
       "  41.0,\n",
       "  30.0,\n",
       "  16.0,\n",
       "  27.0,\n",
       "  44.0,\n",
       "  26.0,\n",
       "  35.0,\n",
       "  37.0,\n",
       "  37.0,\n",
       "  40.0,\n",
       "  44.0,\n",
       "  45.0,\n",
       "  43.0,\n",
       "  40.0,\n",
       "  40.0,\n",
       "  48.0,\n",
       "  47.0,\n",
       "  39.0,\n",
       "  44.0,\n",
       "  36.0,\n",
       "  42.0,\n",
       "  25.0,\n",
       "  20.0,\n",
       "  35.0,\n",
       "  22.0,\n",
       "  21.0,\n",
       "  34.0,\n",
       "  27.0,\n",
       "  29.0,\n",
       "  22.0,\n",
       "  27.0,\n",
       "  33.0,\n",
       "  39.0,\n",
       "  35.0,\n",
       "  42.0,\n",
       "  43.0,\n",
       "  24.0,\n",
       "  35.0,\n",
       "  54.0,\n",
       "  33.0,\n",
       "  22.0,\n",
       "  35.0,\n",
       "  6.0,\n",
       "  24.0,\n",
       "  35.0,\n",
       "  34.0,\n",
       "  35.0,\n",
       "  42.0,\n",
       "  44.0,\n",
       "  28.0,\n",
       "  31.0,\n",
       "  48.0,\n",
       "  43.0,\n",
       "  48.0,\n",
       "  37.0,\n",
       "  26.0,\n",
       "  41.0,\n",
       "  29.0,\n",
       "  27.0,\n",
       "  17.0,\n",
       "  32.0,\n",
       "  39.0,\n",
       "  26.0,\n",
       "  20.0,\n",
       "  27.0,\n",
       "  33.0,\n",
       "  27.0,\n",
       "  29.0,\n",
       "  23.0,\n",
       "  45.0,\n",
       "  35.0,\n",
       "  30.0,\n",
       "  41.0,\n",
       "  41.0,\n",
       "  37.0,\n",
       "  39.0,\n",
       "  50.0,\n",
       "  46.0,\n",
       "  53.0,\n",
       "  50.0,\n",
       "  42.0,\n",
       "  39.0,\n",
       "  61.0,\n",
       "  45.0,\n",
       "  42.0,\n",
       "  26.0,\n",
       "  24.0,\n",
       "  35.0,\n",
       "  35.0,\n",
       "  40.0,\n",
       "  43.0,\n",
       "  53.0,\n",
       "  45.0,\n",
       "  37.0,\n",
       "  52.0,\n",
       "  44.0,\n",
       "  41.0]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T09:56:41.150427Z",
     "iopub.status.busy": "2020-08-11T09:56:41.145439Z",
     "iopub.status.idle": "2020-08-11T09:56:42.964114Z",
     "shell.execute_reply": "2020-08-11T09:56:42.964941Z"
    },
    "papermill": {
     "duration": 2.313092,
     "end_time": "2020-08-11T09:56:42.965137",
     "exception": false,
     "start_time": "2020-08-11T09:56:40.652045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.460694,
     "end_time": "2020-08-11T09:56:47.923438",
     "exception": false,
     "start_time": "2020-08-11T09:56:47.462744",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "duration": 7539.140439,
   "end_time": "2020-08-11T09:56:48.490689",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-11T07:51:09.350250",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
