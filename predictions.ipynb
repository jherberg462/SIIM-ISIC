{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:17.116986Z",
     "iopub.status.busy": "2020-08-11T05:44:17.116217Z",
     "iopub.status.idle": "2020-08-11T05:44:24.404434Z",
     "shell.execute_reply": "2020-08-11T05:44:24.403625Z"
    },
    "papermill": {
     "duration": 7.317708,
     "end_time": "2020-08-11T05:44:24.404575",
     "exception": false,
     "start_time": "2020-08-11T05:44:17.086867",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got GCS path via KaggleDatasets .get_gcs_path method\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "try:\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "    dataset_gcs = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n",
    "    print('got GCS path via KaggleDatasets .get_gcs_path method')\n",
    "except ModuleNotFoundError:\n",
    "    #hardcode path while testing locally\n",
    "    dataset_gcs = 'gs://'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:24.452738Z",
     "iopub.status.busy": "2020-08-11T05:44:24.451874Z",
     "iopub.status.idle": "2020-08-11T05:44:24.456631Z",
     "shell.execute_reply": "2020-08-11T05:44:24.456002Z"
    },
    "papermill": {
     "duration": 0.030626,
     "end_time": "2020-08-11T05:44:24.456766",
     "exception": false,
     "start_time": "2020-08-11T05:44:24.426140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:24.502767Z",
     "iopub.status.busy": "2020-08-11T05:44:24.501727Z",
     "iopub.status.idle": "2020-08-11T05:44:24.505353Z",
     "shell.execute_reply": "2020-08-11T05:44:24.504679Z"
    },
    "papermill": {
     "duration": 0.028542,
     "end_time": "2020-08-11T05:44:24.505491",
     "exception": false,
     "start_time": "2020-08-11T05:44:24.476949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size' : 128,\n",
    "    'img_size' : [256, 256],\n",
    "    'epochs': 350\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:24.660512Z",
     "iopub.status.busy": "2020-08-11T05:44:24.564234Z",
     "iopub.status.idle": "2020-08-11T05:44:29.085220Z",
     "shell.execute_reply": "2020-08-11T05:44:29.086125Z"
    },
    "papermill": {
     "duration": 4.560393,
     "end_time": "2020-08-11T05:44:29.086372",
     "exception": false,
     "start_time": "2020-08-11T05:44:24.525979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:29.134923Z",
     "iopub.status.busy": "2020-08-11T05:44:29.134086Z",
     "iopub.status.idle": "2020-08-11T05:44:29.137367Z",
     "shell.execute_reply": "2020-08-11T05:44:29.136737Z"
    },
    "papermill": {
     "duration": 0.029345,
     "end_time": "2020-08-11T05:44:29.137537",
     "exception": false,
     "start_time": "2020-08-11T05:44:29.108192",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params['batch_size'] = params['batch_size'] * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:29.184875Z",
     "iopub.status.busy": "2020-08-11T05:44:29.183902Z",
     "iopub.status.idle": "2020-08-11T05:44:29.187308Z",
     "shell.execute_reply": "2020-08-11T05:44:29.186679Z"
    },
    "papermill": {
     "duration": 0.028868,
     "end_time": "2020-08-11T05:44:29.187454",
     "exception": false,
     "start_time": "2020-08-11T05:44:29.158586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub = pd.read_csv(dataset_gcs + '/sample_submission.csv')\n",
    "# sub.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:29.236012Z",
     "iopub.status.busy": "2020-08-11T05:44:29.235261Z",
     "iopub.status.idle": "2020-08-11T05:44:38.704490Z",
     "shell.execute_reply": "2020-08-11T05:44:38.703850Z"
    },
    "papermill": {
     "duration": 9.495691,
     "end_time": "2020-08-11T05:44:38.704632",
     "exception": false,
     "start_time": "2020-08-11T05:44:29.208941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32542</td>\n",
       "      <td>32542</td>\n",
       "      <td>32477</td>\n",
       "      <td>32474</td>\n",
       "      <td>32024</td>\n",
       "      <td>32542</td>\n",
       "      <td>32542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>575</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name  patient_id    sex  age_approx  \\\n",
       "target                                              \n",
       "0            32542       32542  32477       32474   \n",
       "1              584         584    584         584   \n",
       "\n",
       "        anatom_site_general_challenge  diagnosis  benign_malignant  \n",
       "target                                                              \n",
       "0                               32024      32542             32542  \n",
       "1                                 575        584               584  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(dataset_gcs + '/train.csv')\n",
    "train_df.groupby('target').count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:38.759910Z",
     "iopub.status.busy": "2020-08-11T05:44:38.758943Z",
     "iopub.status.idle": "2020-08-11T05:44:38.762495Z",
     "shell.execute_reply": "2020-08-11T05:44:38.761664Z"
    },
    "papermill": {
     "duration": 0.03552,
     "end_time": "2020-08-11T05:44:38.762641",
     "exception": false,
     "start_time": "2020-08-11T05:44:38.727121",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image_label(tfrec):\n",
    "    '''\n",
    "    function to decode an image and target label from tfrecord\n",
    "    \n",
    "    args:\n",
    "        tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "    returns:\n",
    "        decoded_image: tensor, converted image from tfrecord\n",
    "        label: tensor, integer, either 1 or 0\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "    decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "    decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "    label = features['target']\n",
    "    \n",
    "    return decoded_image, label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:38.817408Z",
     "iopub.status.busy": "2020-08-11T05:44:38.816595Z",
     "iopub.status.idle": "2020-08-11T05:44:38.819364Z",
     "shell.execute_reply": "2020-08-11T05:44:38.819899Z"
    },
    "papermill": {
     "duration": 0.034781,
     "end_time": "2020-08-11T05:44:38.820064",
     "exception": false,
     "start_time": "2020-08-11T05:44:38.785283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(tfrec):\n",
    "    '''\n",
    "    function to decode an image from tfrecord\n",
    "    \n",
    "    args:\n",
    "        tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "    returns:\n",
    "        decoded_image: tensor, converted image from tfrecord\n",
    "        img_name: tensor, string, Id of the decoded image\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "    features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "    decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "    decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "    img_name = features['image_name']\n",
    "    \n",
    "    return decoded_image, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:38.873347Z",
     "iopub.status.busy": "2020-08-11T05:44:38.872559Z",
     "iopub.status.idle": "2020-08-11T05:44:38.876122Z",
     "shell.execute_reply": "2020-08-11T05:44:38.875536Z"
    },
    "papermill": {
     "duration": 0.033752,
     "end_time": "2020-08-11T05:44:38.876274",
     "exception": false,
     "start_time": "2020-08-11T05:44:38.842522",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image_label(decoded_image, label):\n",
    "    '''\n",
    "    function to convert an image tensor values from 0 to 255 \n",
    "    -> -1 to 1\n",
    "    to be used when dealing with tfrecords containing labels\n",
    "    \n",
    "    args:\n",
    "        decoded_image: tensor that is an image with values from 0 to 255\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image_tensor: tensor that is an image with values from -1 to 1\n",
    "        label, same as input\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "    image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "    #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "    image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "    #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "    image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "    return image_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:38.929543Z",
     "iopub.status.busy": "2020-08-11T05:44:38.928718Z",
     "iopub.status.idle": "2020-08-11T05:44:38.931776Z",
     "shell.execute_reply": "2020-08-11T05:44:38.932387Z"
    },
    "papermill": {
     "duration": 0.033422,
     "end_time": "2020-08-11T05:44:38.932557",
     "exception": false,
     "start_time": "2020-08-11T05:44:38.899135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image(decoded_image):\n",
    "    '''\n",
    "    function to convert an image tensor values from 0 to 255 \n",
    "    -> -1 to 1\n",
    "    \n",
    "    args:\n",
    "        decoded_image: tensor that is an image with values from 0 to 255\n",
    "    \n",
    "    returns: \n",
    "        image_tensor: tensor that is an image with values from -1 to 1\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "    image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "    #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "    image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "    #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "    image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:38.985566Z",
     "iopub.status.busy": "2020-08-11T05:44:38.984485Z",
     "iopub.status.idle": "2020-08-11T05:44:38.987708Z",
     "shell.execute_reply": "2020-08-11T05:44:38.986959Z"
    },
    "papermill": {
     "duration": 0.032442,
     "end_time": "2020-08-11T05:44:38.987837",
     "exception": false,
     "start_time": "2020-08-11T05:44:38.955395",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_flip(image, label):\n",
    "    '''\n",
    "    function to randomly flip images on the x and/or y axis\n",
    "    \n",
    "    args:\n",
    "        image: tensor, an image\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image: tensor, same as input, but possibly flipped on x and/or y axis\n",
    "        label, tensor, same as input\n",
    "    '''\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image, label #, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:39.046280Z",
     "iopub.status.busy": "2020-08-11T05:44:39.045128Z",
     "iopub.status.idle": "2020-08-11T05:44:39.048653Z",
     "shell.execute_reply": "2020-08-11T05:44:39.047972Z"
    },
    "papermill": {
     "duration": 0.037219,
     "end_time": "2020-08-11T05:44:39.048822",
     "exception": false,
     "start_time": "2020-08-11T05:44:39.011603",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_ds(tfrecords, batch_size):\n",
    "    '''\n",
    "    function to create a ds pipeline from tfrecord files\n",
    "    \n",
    "    args:\n",
    "        tfrecords: list, tfrecord file paths\n",
    "        batch_size: int, batch size for number of records to pass into\n",
    "            model at a time\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images and labels\n",
    "    '''\n",
    "    ds = (tf.data.TFRecordDataset(filenames=[tfrecords],\n",
    "                                 num_parallel_reads=tf.data.experimental.AUTOTUNE).\n",
    "          cache(). #need to remove cache while not usnig TPUs\n",
    "          map(decode_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(normalize_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(random_flip, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          repeat().\n",
    "          shuffle(512).\n",
    "          batch(batch_size,\n",
    "               drop_remainder=True).\n",
    "          prefetch(tf.data.experimental.AUTOTUNE)\n",
    "         )\n",
    "    \n",
    "\n",
    "    \n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:39.106255Z",
     "iopub.status.busy": "2020-08-11T05:44:39.105092Z",
     "iopub.status.idle": "2020-08-11T05:44:39.108875Z",
     "shell.execute_reply": "2020-08-11T05:44:39.107986Z"
    },
    "papermill": {
     "duration": 0.037083,
     "end_time": "2020-08-11T05:44:39.109078",
     "exception": false,
     "start_time": "2020-08-11T05:44:39.071995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_ds(tfrecords, batch_size):\n",
    "    '''\n",
    "    function to create a dataset for test data\n",
    "    args:\n",
    "        tfrecords: list, tfrecord file paths\n",
    "        batch_size: int, batch size for number of records to pass into\n",
    "            model at a time\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images and labels\n",
    "    \n",
    "    '''\n",
    "\n",
    "    ds = (tf.data.TFRecordDataset(filenames=[tfrecords],\n",
    "                                 num_parallel_reads=tf.data.experimental.AUTOTUNE).\n",
    "#           cache(). #there is no reason to cache this ds -- it is only being read 1x\n",
    "          map(decode_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(normalize_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "#           map(random_flip).\n",
    "          batch(batch_size).\n",
    "#                 drop_remainder=True).\n",
    "          prefetch(tf.data.experimental.AUTOTUNE)\n",
    "         )\n",
    "    \n",
    "    return ds\n",
    "    ###come back to this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022954,
     "end_time": "2020-08-11T05:44:39.155590",
     "exception": false,
     "start_time": "2020-08-11T05:44:39.132636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:39.220670Z",
     "iopub.status.busy": "2020-08-11T05:44:39.219463Z",
     "iopub.status.idle": "2020-08-11T05:44:39.222833Z",
     "shell.execute_reply": "2020-08-11T05:44:39.222072Z"
    },
    "papermill": {
     "duration": 0.043828,
     "end_time": "2020-08-11T05:44:39.222965",
     "exception": false,
     "start_time": "2020-08-11T05:44:39.179137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_of_layers(input_layer, \n",
    "                  filters_, \n",
    "                  kernal, \n",
    "                  strides_, \n",
    "                  dense=None, \n",
    "                  dense_activation=None,\n",
    "                  dropout=None,\n",
    "                  cnn_activation=None):\n",
    "    '''\n",
    "    function to add the following layers to a model:\n",
    "    Conv2D, MaxPooling2D, BatchNormalization, LeadyReLU, Dense,\n",
    "        Dropout\n",
    "\n",
    "    args:\n",
    "      input_layer : input layer to be fed into above layers\n",
    "      filters_: int, number of filters in Conv2D layer\n",
    "      kernal: int, kernal size in Conv2D layer\n",
    "      strides_: int, stride size in MaxPooling2D layer\n",
    "      dense: int, number of units in dense layer, default is None\n",
    "          Will only add layer if value is passed\n",
    "      dense_activation: str, activation function to pass into Dense layer\n",
    "          default is None\n",
    "      dropout: float, dropout percentage in Dropout layer, default is None\n",
    "        must be less than 1.0. Will only add layer if value is passed \n",
    "      cnn_activation: tensorflow activation layer, default is None\n",
    "          will only add layer is value is passed. Activation layer will be\n",
    "          added after the BatchNormalization layer\n",
    "\n",
    "    returns:\n",
    "      x: model that is the same as the input_layer input plus above \n",
    "        layers added\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    x_dict = {}\n",
    "    for xx in range(len(kernal)):\n",
    "        x_dict[xx] = layers.Conv2D(filters_, (kernal[xx], kernal[xx]),\n",
    "                                   padding='same', activation=cnn_activation)(input_layer)\n",
    "        for _ in range(1):\n",
    "            x_dict[xx] = layers.Conv2D(filters_, (kernal[xx], kernal[xx]),\n",
    "                                       padding='same', activation=cnn_activation)(x_dict[xx])\n",
    "    x_list = [x_dict[xx] for xx in x_dict]\n",
    "    if len(x_list) > 1:\n",
    "        x = layers.Concatenate()(x_list)\n",
    "    else:\n",
    "        x = x_list[0]\n",
    "    x = layers.MaxPooling2D(strides_, strides_)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "\n",
    "    \n",
    "    if cnn_activation:\n",
    "        x = cnn_activation(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    if dense:\n",
    "        x = layers.Dense(dense, activation=dense_activation)(x)\n",
    "    if dropout:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:39.284765Z",
     "iopub.status.busy": "2020-08-11T05:44:39.283761Z",
     "iopub.status.idle": "2020-08-11T05:44:39.286298Z",
     "shell.execute_reply": "2020-08-11T05:44:39.286846Z"
    },
    "papermill": {
     "duration": 0.040653,
     "end_time": "2020-08-11T05:44:39.287017",
     "exception": false,
     "start_time": "2020-08-11T05:44:39.246364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deconv_set_of_layers(input_layer, \n",
    "                         filters_, \n",
    "                         kernal_, \n",
    "                         stride, \n",
    "                         dense=None, \n",
    "                         dense_activation=None, \n",
    "                         dropout=None,\n",
    "                         cnn_activation=None):\n",
    "    '''\n",
    "    function to add the following layers to a model:\n",
    "    Conv2DTranspose, BatchNormalization, LeadyReLU, Dense\n",
    "\n",
    "    args:\n",
    "      input_layer : input layer to be fed into above layers\n",
    "      filters_: int, number of filters in Conv2DTranspose layer\n",
    "      kernal_: int, kernal size in Conv2DTranspose layer\n",
    "      strides_: int, stride size in Conv2DTranspose layer\n",
    "      dense: int, number of units in dense layer, default is None\n",
    "          Will only add layer if value is passed\n",
    "      dense_activation: str, activation function to pass into Dense layer\n",
    "          default is None\n",
    "      dropout: float, dropout percentage in Dropout layer, default is None\n",
    "        must be less than 1.0. Will only add layer if value is passed \n",
    "      cnn_activation: tensorflow activation layer, default is None\n",
    "          will only add layer is value is passed. Activation layer will be\n",
    "          added after the BatchNormalization layer\n",
    "\n",
    "\n",
    "    returns:\n",
    "      x: model that is the same as the input_layer input plus above \n",
    "        layers added\n",
    "    '''\n",
    "\n",
    "        \n",
    "    x_dict = {}\n",
    "    for xx in range(len(kernal_)):\n",
    "        x_dict[xx] = layers.Conv2DTranspose(filters_,\n",
    "                                           kernal_[xx],\n",
    "                                           (stride, stride),\n",
    "                                           padding='same')(input_layer)\n",
    "        x_dict[xx] = layers.BatchNormalization()(x_dict[xx])\n",
    "    x_list = [x_dict[xx] for xx in x_dict]\n",
    "    if len(x_list) > 1:\n",
    "        x = layers.Concatenate()(x_list)\n",
    "    else:\n",
    "        x = x_list[0]\n",
    "    \n",
    "    if cnn_activation:\n",
    "        x = cnn_activation(x)\n",
    "   \n",
    "    if dense:\n",
    "        x = layers.Dense(dense, activation=dense_activation)(x)\n",
    "    \n",
    "    if dropout:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:39.347756Z",
     "iopub.status.busy": "2020-08-11T05:44:39.342486Z",
     "iopub.status.idle": "2020-08-11T05:44:39.359708Z",
     "shell.execute_reply": "2020-08-11T05:44:39.358889Z"
    },
    "papermill": {
     "duration": 0.049645,
     "end_time": "2020-08-11T05:44:39.359841",
     "exception": false,
     "start_time": "2020-08-11T05:44:39.310196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape=[*params['img_size'], 3], bias_output=None):\n",
    "    '''\n",
    "    function to create a model that will be trained on train DS\n",
    "    \n",
    "    args:\n",
    "        input_shape: array, default: [1024, 1024, 3], shape\n",
    "            of input tensor that will be fed into model\n",
    "    \n",
    "    returns:\n",
    "        model: tf.sequential() model\n",
    "    '''\n",
    "\n",
    "    relu = layers.ReLU()\n",
    "    leakyrelu = layers.LeakyReLU()\n",
    "    input_tensor = layers.Input(shape=input_shape, name='images_input')\n",
    "    x = input_tensor\n",
    "#     filters_list = [64, 128, 256, 512, 1024]\n",
    "    filters_list = [32, 64, 128, 256, 512]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x = set_of_layers(x, filter_, [3, 5], 2, 16,  dropout=0.35, dense_activation='tanh', \n",
    "                           cnn_activation=relu)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "#         x2 = set_of_layers(x, filter_, 5, 2, 16,  dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "#         x = layers.Concatenate()([x1, x2])\n",
    "#         x = layers.Dense(filter_, activation='elu')(x) #consider adding dropout\n",
    "#         x = layers.Dropout(0.35)(x)\n",
    "    \n",
    "    \n",
    "#     filters_list = [1024, 512, 256]\n",
    "    filters_list = [512, 256, 128]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x1 = deconv_set_of_layers(x, filter_, [2, 4], 2, 16,  dense_activation='tanh', cnn_activation=relu,\n",
    "                                 dropout=0.35)\n",
    "#         x2= deconv_set_of_layers(x, filter_, 4, 2, 16,  dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = deconv_set_of_layers(x, filter_, 4, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = deconv_set_of_layers(x, filter_, 4, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "#         x = layers.Concatenate()([x1, x2])\n",
    "#         x = layers.Dense(filter_, activation='elu')(x)\n",
    "#         x = layers.Dropout(0.35)(x)        \n",
    "    \n",
    "#     filters_list = [256, 512, 1024]\n",
    "    filters_list = [128, 256, 512]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x = set_of_layers(x, filter_, [3, 5], 2, 16,  dropout=0.35, dense_activation='tanh',\n",
    "                           cnn_activation=relu)\n",
    "#         x2 = set_of_layers(x, filter_, 5, 2, 16,  dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "#         x = layers.Concatenate()([x1, x2])\n",
    "#         x = layers.Dense(filter_, activation='elu')(x)\n",
    "#         x = layers.Dropout(0.35)(x)\n",
    "    \n",
    "\n",
    "    #layers.Concatenate\n",
    "\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "#     model.add(layers.Dense(64))\n",
    "    \n",
    "    if bias_output is not None:\n",
    "        bias_output = tf.keras.initializers.Constant(bias_output)\n",
    "    output_layer = layers.Dense(1, activation='sigmoid', bias_initializer=bias_output)(x)\n",
    "    \n",
    "    model=keras.Model(inputs=[input_tensor],\n",
    "                     outputs=[output_layer])\n",
    "\n",
    " \n",
    "           \n",
    "    metrics = [\n",
    "          keras.metrics.TruePositives(name='tp'),\n",
    "#           keras.metrics.FalsePositives(name='fp'),\n",
    "#           keras.metrics.TrueNegatives(name='tn'),\n",
    "          keras.metrics.FalseNegatives(name='fn'), \n",
    "          keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#           keras.metrics.Precision(name='precision'),\n",
    "#           keras.metrics.Recall(name='recall'),\n",
    "          keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "    schedule = None\n",
    "    \n",
    "    model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.00033),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.01),\n",
    "    metrics=metrics\n",
    ")\n",
    "    \n",
    "\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:39.414731Z",
     "iopub.status.busy": "2020-08-11T05:44:39.413921Z",
     "iopub.status.idle": "2020-08-11T05:44:39.417019Z",
     "shell.execute_reply": "2020-08-11T05:44:39.417620Z"
    },
    "papermill": {
     "duration": 0.034196,
     "end_time": "2020-08-11T05:44:39.417789",
     "exception": false,
     "start_time": "2020-08-11T05:44:39.383593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ds_size(files):\n",
    "    '''\n",
    "    function to get size of tfrecord Dataset, based on file name\n",
    "    \n",
    "    the file name has the number of records in the file, for example:\n",
    "    train09-2071.tfrec has 2017 records\n",
    "    \n",
    "    args:\n",
    "        files: list of str file names, each item should be the path to a tfrecord file\n",
    "    \n",
    "    returns:\n",
    "        size: int, size of dataset\n",
    "    '''\n",
    "    size = 0\n",
    "    for file in files:\n",
    "        file_size = int(file.split('.tfrec')[0].split('tfrecords/')[1].split('-')[1])\n",
    "        size += file_size\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:39.631482Z",
     "iopub.status.busy": "2020-08-11T05:44:39.630565Z",
     "iopub.status.idle": "2020-08-11T05:44:40.355813Z",
     "shell.execute_reply": "2020-08-11T05:44:40.354988Z"
    },
    "papermill": {
     "duration": 0.914684,
     "end_time": "2020-08-11T05:44:40.355948",
     "exception": false,
     "start_time": "2020-08-11T05:44:39.441264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get test file paths\n",
    "test_files = tf.io.gfile.glob(dataset_gcs + '/tfrecords/test*.tfrec')\n",
    "\n",
    "#get train and validation file paths\n",
    "train_files, valid_files = train_test_split(tf.io.gfile.glob(dataset_gcs + '/tfrecords/train*.tfrec'),\n",
    "                              test_size=.1, random_state=1)\n",
    "\n",
    "#create datasets\n",
    "train_ds = get_train_ds(train_files, params['batch_size'])\n",
    "valid_ds = get_train_ds(valid_files, params['batch_size'])\n",
    "test_ds = get_test_ds(test_files, params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:40.410969Z",
     "iopub.status.busy": "2020-08-11T05:44:40.409971Z",
     "iopub.status.idle": "2020-08-11T05:44:40.414173Z",
     "shell.execute_reply": "2020-08-11T05:44:40.413451Z"
    },
    "papermill": {
     "duration": 0.034873,
     "end_time": "2020-08-11T05:44:40.414305",
     "exception": false,
     "start_time": "2020-08-11T05:44:40.379432",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset consists of: 28984 training images, 4142 validation images, and 10982 test images\n"
     ]
    }
   ],
   "source": [
    "train_size, valid_size = get_ds_size(train_files), get_ds_size(valid_files)\n",
    "test_size = get_ds_size(test_files)\n",
    "print('the dataset consists of: {} training images, {} validation images, and {} test images'.\n",
    "     format(train_size, valid_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.025107,
     "end_time": "2020-08-11T05:44:40.463969",
     "exception": false,
     "start_time": "2020-08-11T05:44:40.438862",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:40.519724Z",
     "iopub.status.busy": "2020-08-11T05:44:40.518839Z",
     "iopub.status.idle": "2020-08-11T05:44:40.522746Z",
     "shell.execute_reply": "2020-08-11T05:44:40.521708Z"
    },
    "papermill": {
     "duration": 0.034182,
     "end_time": "2020-08-11T05:44:40.522897",
     "exception": false,
     "start_time": "2020-08-11T05:44:40.488715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch_steps = train_size / params['batch_size'] \n",
    "valid_steps = valid_size / params['batch_size']\n",
    "test_steps = 1.0 * test_size / params['batch_size'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:40.579392Z",
     "iopub.status.busy": "2020-08-11T05:44:40.578573Z",
     "iopub.status.idle": "2020-08-11T05:44:40.610306Z",
     "shell.execute_reply": "2020-08-11T05:44:40.609498Z"
    },
    "papermill": {
     "duration": 0.063946,
     "end_time": "2020-08-11T05:44:40.610431",
     "exception": false,
     "start_time": "2020-08-11T05:44:40.546485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate class weights\n",
    "\n",
    "targets = train_df.groupby('target').count()['diagnosis'].to_list()\n",
    "target_0 = targets[0]\n",
    "target_1 = targets[1]\n",
    "total = target_0 + target_1\n",
    "\n",
    "class_weight_0 = (1 / target_0) * (total) / 2.0\n",
    "class_weight_1 = (1 / target_1) * (total) / 2.0\n",
    "\n",
    "class_weights = {0: class_weight_0, 1: class_weight_1}\n",
    "\n",
    "initial_bias = np.log([target_1 / target_0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.02334,
     "end_time": "2020-08-11T05:44:40.657757",
     "exception": false,
     "start_time": "2020-08-11T05:44:40.634417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:40.712085Z",
     "iopub.status.busy": "2020-08-11T05:44:40.711304Z",
     "iopub.status.idle": "2020-08-11T05:44:48.440791Z",
     "shell.execute_reply": "2020-08-11T05:44:48.441722Z"
    },
    "papermill": {
     "duration": 7.760497,
     "end_time": "2020-08-11T05:44:48.441955",
     "exception": false,
     "start_time": "2020-08-11T05:44:40.681458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "images_input (InputLayer)       [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 32) 896         images_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 256, 256, 32) 2432        images_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 9248        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 32) 25632       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256, 256, 64) 0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 64) 256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 128, 128, 64) 0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128, 128, 16) 1040        re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128, 128, 16) 0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 128, 128, 64) 9280        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 64) 25664       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 64) 36928       conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 128, 128, 64) 102464      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 128 0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 128)  512         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 64, 64, 128)  0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64, 64, 16)   2064        re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 64, 16)   0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 128)  18560       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 128)  51328       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 128)  147584      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 128)  409728      conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 256)  0           conv2d_9[0][0]                   \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 256)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 256)  1024        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 32, 32, 256)  0           re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32, 32, 16)   4112        re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 16)   0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 256)  37120       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 32, 32, 256)  102656      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 256)  590080      conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 32, 32, 256)  1638656     conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 512)  0           conv2d_13[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 512)  0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 512)  2048        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 16, 16, 512)  0           re_lu[3][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16, 16, 16)   8208        re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 16, 16)   0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 16, 16, 512)  74240       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 16, 16, 512)  205312      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 16, 16, 512)  2359808     conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 16, 16, 512)  6554112     conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 1024) 0           conv2d_17[0][0]                  \n",
      "                                                                 conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 1024)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 8, 1024)   4096        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 8, 8, 1024)   0           re_lu[4][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 8, 8, 16)     16400       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 8, 8, 16)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 8, 8, 128)    18560       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 8, 8, 128)    51328       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 8, 8, 128)    147584      conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 8, 8, 128)    409728      conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 8, 8, 256)    0           conv2d_21[0][0]                  \n",
      "                                                                 conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 4, 4, 256)    0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 4, 4, 256)    1024        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 4, 4, 256)    0           re_lu[8][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 4, 4, 16)     4112        re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 4, 4, 16)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 4, 4, 256)    37120       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 4, 4, 256)    102656      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 4, 4, 256)    590080      conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 4, 4, 256)    1638656     conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 4, 4, 512)    0           conv2d_25[0][0]                  \n",
      "                                                                 conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 2, 2, 512)    0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 2, 2, 512)    2048        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 2, 2, 512)    0           re_lu[9][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 2, 2, 16)     8208        re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 2, 2, 16)     0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 2, 2, 512)    74240       dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 2, 2, 512)    205312      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 2, 2, 512)    2359808     conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 2, 2, 512)    6554112     conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 2, 2, 1024)   0           conv2d_29[0][0]                  \n",
      "                                                                 conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 1024)   0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 1, 1, 1024)   4096        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 1, 1, 1024)   0           re_lu[10][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1, 1, 16)     16400       re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 1, 1, 16)     0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 16)           0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 128)          2176        flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            129         dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 24,668,865\n",
      "Trainable params: 24,661,313\n",
      "Non-trainable params: 7,552\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model(bias_output=initial_bias)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023974,
     "end_time": "2020-08-11T05:44:48.498755",
     "exception": false,
     "start_time": "2020-08-11T05:44:48.474781",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T05:44:48.559007Z",
     "iopub.status.busy": "2020-08-11T05:44:48.557931Z",
     "iopub.status.idle": "2020-08-11T07:40:21.920506Z",
     "shell.execute_reply": "2020-08-11T07:40:21.919511Z"
    },
    "papermill": {
     "duration": 6933.39767,
     "end_time": "2020-08-11T07:40:21.920723",
     "exception": false,
     "start_time": "2020-08-11T05:44:48.523053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "29/28 [==============================] - 41s 1s/step - fn: 516.0000 - auc: 0.6083 - tp: 10.0000 - loss: 1.2643 - accuracy: 0.9664 - val_fn: 84.0000 - val_auc: 0.5000 - val_tp: 0.0000e+00 - val_loss: 0.1028 - val_accuracy: 0.9836\n",
      "Epoch 2/350\n",
      "29/28 [==============================] - 22s 766ms/step - fn: 213.0000 - auc: 0.6791 - tp: 311.0000 - loss: 0.6470 - accuracy: 0.6287 - val_fn: 86.0000 - val_auc: 0.5000 - val_tp: 0.0000e+00 - val_loss: 0.1043 - val_accuracy: 0.9832\n",
      "Epoch 3/350\n",
      "29/28 [==============================] - 22s 763ms/step - fn: 160.0000 - auc: 0.7383 - tp: 367.0000 - loss: 0.6183 - accuracy: 0.6453 - val_fn: 87.0000 - val_auc: 0.5000 - val_tp: 0.0000e+00 - val_loss: 0.1051 - val_accuracy: 0.9830\n",
      "Epoch 4/350\n",
      "29/28 [==============================] - 22s 772ms/step - fn: 154.0000 - auc: 0.7179 - tp: 375.0000 - loss: 0.6278 - accuracy: 0.6048 - val_fn: 83.0000 - val_auc: 0.5000 - val_tp: 0.0000e+00 - val_loss: 0.1021 - val_accuracy: 0.9838\n",
      "Epoch 5/350\n",
      "29/28 [==============================] - 28s 960ms/step - fn: 169.0000 - auc: 0.7091 - tp: 358.0000 - loss: 0.6323 - accuracy: 0.6098 - val_fn: 86.0000 - val_auc: 0.5000 - val_tp: 0.0000e+00 - val_loss: 0.1044 - val_accuracy: 0.9832\n",
      "Epoch 6/350\n",
      "29/28 [==============================] - 21s 715ms/step - fn: 181.0000 - auc: 0.7194 - tp: 353.0000 - loss: 0.6191 - accuracy: 0.6234 - val_fn: 87.0000 - val_auc: 0.5000 - val_tp: 0.0000e+00 - val_loss: 0.1051 - val_accuracy: 0.9830\n",
      "Epoch 7/350\n",
      "29/28 [==============================] - 22s 747ms/step - fn: 142.0000 - auc: 0.7119 - tp: 383.0000 - loss: 0.6124 - accuracy: 0.5959 - val_fn: 85.0000 - val_auc: 0.5000 - val_tp: 0.0000e+00 - val_loss: 0.1037 - val_accuracy: 0.9834\n",
      "Epoch 8/350\n",
      "29/28 [==============================] - 23s 804ms/step - fn: 165.0000 - auc: 0.7042 - tp: 363.0000 - loss: 0.6115 - accuracy: 0.6027 - val_fn: 85.0000 - val_auc: 0.5000 - val_tp: 0.0000e+00 - val_loss: 0.1038 - val_accuracy: 0.9834\n",
      "Epoch 9/350\n",
      "29/28 [==============================] - 23s 789ms/step - fn: 171.0000 - auc: 0.7016 - tp: 357.0000 - loss: 0.6216 - accuracy: 0.6045 - val_fn: 86.0000 - val_auc: 0.5000 - val_tp: 0.0000e+00 - val_loss: 0.1046 - val_accuracy: 0.9832\n",
      "Epoch 10/350\n",
      "29/28 [==============================] - 23s 788ms/step - fn: 188.0000 - auc: 0.6942 - tp: 343.0000 - loss: 0.6365 - accuracy: 0.6062 - val_fn: 87.0000 - val_auc: 0.5000 - val_tp: 0.0000e+00 - val_loss: 0.1054 - val_accuracy: 0.9830\n",
      "Epoch 11/350\n",
      "29/28 [==============================] - 23s 776ms/step - fn: 169.0000 - auc: 0.7262 - tp: 357.0000 - loss: 0.5942 - accuracy: 0.6159 - val_fn: 84.0000 - val_auc: 0.5059 - val_tp: 0.0000e+00 - val_loss: 0.1030 - val_accuracy: 0.9836\n",
      "Epoch 12/350\n",
      "29/28 [==============================] - 22s 763ms/step - fn: 147.0000 - auc: 0.7299 - tp: 389.0000 - loss: 0.6024 - accuracy: 0.6152 - val_fn: 85.0000 - val_auc: 0.5078 - val_tp: 2.0000 - val_loss: 0.1091 - val_accuracy: 0.9795\n",
      "Epoch 13/350\n",
      "29/28 [==============================] - 23s 776ms/step - fn: 134.0000 - auc: 0.7506 - tp: 389.0000 - loss: 0.5868 - accuracy: 0.6209 - val_fn: 70.0000 - val_auc: 0.5606 - val_tp: 17.0000 - val_loss: 0.1672 - val_accuracy: 0.9160\n",
      "Epoch 14/350\n",
      "29/28 [==============================] - 23s 778ms/step - fn: 152.0000 - auc: 0.7391 - tp: 384.0000 - loss: 0.5987 - accuracy: 0.6372 - val_fn: 70.0000 - val_auc: 0.5776 - val_tp: 16.0000 - val_loss: 0.1791 - val_accuracy: 0.9117\n",
      "Epoch 15/350\n",
      "29/28 [==============================] - 22s 773ms/step - fn: 137.0000 - auc: 0.7458 - tp: 392.0000 - loss: 0.5886 - accuracy: 0.6353 - val_fn: 67.0000 - val_auc: 0.6085 - val_tp: 22.0000 - val_loss: 0.2335 - val_accuracy: 0.8816\n",
      "Epoch 16/350\n",
      "29/28 [==============================] - 23s 787ms/step - fn: 154.0000 - auc: 0.7379 - tp: 366.0000 - loss: 0.5903 - accuracy: 0.6361 - val_fn: 56.0000 - val_auc: 0.6249 - val_tp: 29.0000 - val_loss: 0.2770 - val_accuracy: 0.8451\n",
      "Epoch 17/350\n",
      "29/28 [==============================] - 23s 783ms/step - fn: 125.0000 - auc: 0.7725 - tp: 402.0000 - loss: 0.5563 - accuracy: 0.6533 - val_fn: 43.0000 - val_auc: 0.6438 - val_tp: 45.0000 - val_loss: 0.3942 - val_accuracy: 0.7547\n",
      "Epoch 18/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 136.0000 - auc: 0.7626 - tp: 392.0000 - loss: 0.5751 - accuracy: 0.6502 - val_fn: 26.0000 - val_auc: 0.6664 - val_tp: 62.0000 - val_loss: 0.5289 - val_accuracy: 0.6018\n",
      "Epoch 19/350\n",
      "29/28 [==============================] - 24s 824ms/step - fn: 150.0000 - auc: 0.7338 - tp: 379.0000 - loss: 0.6059 - accuracy: 0.6253 - val_fn: 30.0000 - val_auc: 0.7329 - val_tp: 55.0000 - val_loss: 0.4433 - val_accuracy: 0.6967\n",
      "Epoch 20/350\n",
      "29/28 [==============================] - 22s 769ms/step - fn: 151.0000 - auc: 0.7497 - tp: 374.0000 - loss: 0.5739 - accuracy: 0.6396 - val_fn: 26.0000 - val_auc: 0.7023 - val_tp: 59.0000 - val_loss: 0.5612 - val_accuracy: 0.6314\n",
      "Epoch 21/350\n",
      "29/28 [==============================] - 21s 725ms/step - fn: 123.0000 - auc: 0.7661 - tp: 404.0000 - loss: 0.5579 - accuracy: 0.6476 - val_fn: 21.0000 - val_auc: 0.7024 - val_tp: 66.0000 - val_loss: 0.5789 - val_accuracy: 0.6029\n",
      "Epoch 22/350\n",
      "29/28 [==============================] - 23s 778ms/step - fn: 142.0000 - auc: 0.7444 - tp: 386.0000 - loss: 0.6012 - accuracy: 0.6364 - val_fn: 15.0000 - val_auc: 0.7348 - val_tp: 69.0000 - val_loss: 0.5203 - val_accuracy: 0.5807\n",
      "Epoch 23/350\n",
      "29/28 [==============================] - 22s 756ms/step - fn: 132.0000 - auc: 0.7423 - tp: 394.0000 - loss: 0.5811 - accuracy: 0.6331 - val_fn: 24.0000 - val_auc: 0.7623 - val_tp: 60.0000 - val_loss: 0.4095 - val_accuracy: 0.7080\n",
      "Epoch 24/350\n",
      "29/28 [==============================] - 23s 783ms/step - fn: 127.0000 - auc: 0.7407 - tp: 402.0000 - loss: 0.5891 - accuracy: 0.6300 - val_fn: 23.0000 - val_auc: 0.7538 - val_tp: 62.0000 - val_loss: 0.4433 - val_accuracy: 0.6830\n",
      "Epoch 25/350\n",
      "29/28 [==============================] - 22s 749ms/step - fn: 124.0000 - auc: 0.7592 - tp: 407.0000 - loss: 0.5695 - accuracy: 0.6334 - val_fn: 27.0000 - val_auc: 0.7431 - val_tp: 56.0000 - val_loss: 0.3953 - val_accuracy: 0.7146\n",
      "Epoch 26/350\n",
      "29/28 [==============================] - 21s 740ms/step - fn: 124.0000 - auc: 0.7481 - tp: 401.0000 - loss: 0.5781 - accuracy: 0.6216 - val_fn: 32.0000 - val_auc: 0.7610 - val_tp: 54.0000 - val_loss: 0.3657 - val_accuracy: 0.7352\n",
      "Epoch 27/350\n",
      "29/28 [==============================] - 24s 816ms/step - fn: 110.0000 - auc: 0.7718 - tp: 421.0000 - loss: 0.5561 - accuracy: 0.6493 - val_fn: 33.0000 - val_auc: 0.7359 - val_tp: 50.0000 - val_loss: 0.4039 - val_accuracy: 0.7307\n",
      "Epoch 28/350\n",
      "29/28 [==============================] - 22s 744ms/step - fn: 118.0000 - auc: 0.7642 - tp: 409.0000 - loss: 0.5606 - accuracy: 0.6524 - val_fn: 25.0000 - val_auc: 0.7612 - val_tp: 60.0000 - val_loss: 0.4340 - val_accuracy: 0.7293\n",
      "Epoch 29/350\n",
      "29/28 [==============================] - 21s 734ms/step - fn: 130.0000 - auc: 0.7627 - tp: 395.0000 - loss: 0.5640 - accuracy: 0.6528 - val_fn: 27.0000 - val_auc: 0.7352 - val_tp: 57.0000 - val_loss: 0.4921 - val_accuracy: 0.6932\n",
      "Epoch 30/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 152.0000 - auc: 0.7561 - tp: 374.0000 - loss: 0.5830 - accuracy: 0.6512 - val_fn: 20.0000 - val_auc: 0.7435 - val_tp: 70.0000 - val_loss: 0.5479 - val_accuracy: 0.6414\n",
      "Epoch 31/350\n",
      "29/28 [==============================] - 23s 802ms/step - fn: 150.0000 - auc: 0.7420 - tp: 377.0000 - loss: 0.5972 - accuracy: 0.6403 - val_fn: 27.0000 - val_auc: 0.7364 - val_tp: 55.0000 - val_loss: 0.4963 - val_accuracy: 0.7086\n",
      "Epoch 32/350\n",
      "29/28 [==============================] - 21s 730ms/step - fn: 132.0000 - auc: 0.7490 - tp: 391.0000 - loss: 0.5668 - accuracy: 0.6244 - val_fn: 9.0000 - val_auc: 0.7468 - val_tp: 73.0000 - val_loss: 0.7016 - val_accuracy: 0.5586\n",
      "Epoch 33/350\n",
      "29/28 [==============================] - 22s 749ms/step - fn: 124.0000 - auc: 0.7614 - tp: 413.0000 - loss: 0.5755 - accuracy: 0.6498 - val_fn: 23.0000 - val_auc: 0.7713 - val_tp: 60.0000 - val_loss: 0.5015 - val_accuracy: 0.7168\n",
      "Epoch 34/350\n",
      "29/28 [==============================] - 24s 840ms/step - fn: 119.0000 - auc: 0.7697 - tp: 411.0000 - loss: 0.5620 - accuracy: 0.6539 - val_fn: 20.0000 - val_auc: 0.7852 - val_tp: 65.0000 - val_loss: 0.4626 - val_accuracy: 0.7055\n",
      "Epoch 35/350\n",
      "29/28 [==============================] - 22s 775ms/step - fn: 134.0000 - auc: 0.7658 - tp: 390.0000 - loss: 0.5728 - accuracy: 0.6708 - val_fn: 18.0000 - val_auc: 0.7981 - val_tp: 68.0000 - val_loss: 0.4728 - val_accuracy: 0.7172\n",
      "Epoch 36/350\n",
      "29/28 [==============================] - 21s 727ms/step - fn: 98.0000 - auc: 0.7656 - tp: 435.0000 - loss: 0.5626 - accuracy: 0.6400 - val_fn: 15.0000 - val_auc: 0.7929 - val_tp: 71.0000 - val_loss: 0.4871 - val_accuracy: 0.6686\n",
      "Epoch 37/350\n",
      "29/28 [==============================] - 21s 726ms/step - fn: 119.0000 - auc: 0.7798 - tp: 404.0000 - loss: 0.5446 - accuracy: 0.6662 - val_fn: 53.0000 - val_auc: 0.7279 - val_tp: 33.0000 - val_loss: 0.3288 - val_accuracy: 0.8318\n",
      "Epoch 38/350\n",
      "29/28 [==============================] - 22s 772ms/step - fn: 101.0000 - auc: 0.7745 - tp: 426.0000 - loss: 0.5508 - accuracy: 0.6490 - val_fn: 51.0000 - val_auc: 0.7407 - val_tp: 38.0000 - val_loss: 0.3279 - val_accuracy: 0.8451\n",
      "Epoch 39/350\n",
      "29/28 [==============================] - 23s 786ms/step - fn: 116.0000 - auc: 0.7740 - tp: 407.0000 - loss: 0.5530 - accuracy: 0.6514 - val_fn: 23.0000 - val_auc: 0.7862 - val_tp: 63.0000 - val_loss: 0.4310 - val_accuracy: 0.7229\n",
      "Epoch 40/350\n",
      "29/28 [==============================] - 23s 791ms/step - fn: 125.0000 - auc: 0.7701 - tp: 402.0000 - loss: 0.5542 - accuracy: 0.6556 - val_fn: 19.0000 - val_auc: 0.7814 - val_tp: 65.0000 - val_loss: 0.4941 - val_accuracy: 0.7072\n",
      "Epoch 41/350\n",
      "29/28 [==============================] - 22s 750ms/step - fn: 108.0000 - auc: 0.7836 - tp: 416.0000 - loss: 0.5494 - accuracy: 0.6490 - val_fn: 9.0000 - val_auc: 0.7953 - val_tp: 79.0000 - val_loss: 0.4998 - val_accuracy: 0.6389\n",
      "Epoch 42/350\n",
      "29/28 [==============================] - 23s 805ms/step - fn: 112.0000 - auc: 0.7769 - tp: 414.0000 - loss: 0.5488 - accuracy: 0.6576 - val_fn: 21.0000 - val_auc: 0.8100 - val_tp: 59.0000 - val_loss: 0.4282 - val_accuracy: 0.7518\n",
      "Epoch 43/350\n",
      "29/28 [==============================] - 22s 766ms/step - fn: 99.0000 - auc: 0.7923 - tp: 430.0000 - loss: 0.5338 - accuracy: 0.6626 - val_fn: 34.0000 - val_auc: 0.7899 - val_tp: 49.0000 - val_loss: 0.3818 - val_accuracy: 0.8039\n",
      "Epoch 44/350\n",
      "29/28 [==============================] - 22s 764ms/step - fn: 101.0000 - auc: 0.7838 - tp: 429.0000 - loss: 0.5485 - accuracy: 0.6528 - val_fn: 30.0000 - val_auc: 0.7707 - val_tp: 58.0000 - val_loss: 0.4401 - val_accuracy: 0.7129\n",
      "Epoch 45/350\n",
      "29/28 [==============================] - 22s 763ms/step - fn: 103.0000 - auc: 0.7859 - tp: 421.0000 - loss: 0.5372 - accuracy: 0.6532 - val_fn: 30.0000 - val_auc: 0.7858 - val_tp: 56.0000 - val_loss: 0.3942 - val_accuracy: 0.7617\n",
      "Epoch 46/350\n",
      "29/28 [==============================] - 22s 772ms/step - fn: 96.0000 - auc: 0.7804 - tp: 430.0000 - loss: 0.5354 - accuracy: 0.6385 - val_fn: 14.0000 - val_auc: 0.7618 - val_tp: 73.0000 - val_loss: 0.5107 - val_accuracy: 0.6035\n",
      "Epoch 47/350\n",
      "29/28 [==============================] - 22s 746ms/step - fn: 91.0000 - auc: 0.7821 - tp: 440.0000 - loss: 0.5363 - accuracy: 0.6507 - val_fn: 20.0000 - val_auc: 0.8025 - val_tp: 66.0000 - val_loss: 0.4560 - val_accuracy: 0.7023\n",
      "Epoch 48/350\n",
      "29/28 [==============================] - 22s 763ms/step - fn: 97.0000 - auc: 0.7897 - tp: 435.0000 - loss: 0.5289 - accuracy: 0.6535 - val_fn: 33.0000 - val_auc: 0.7915 - val_tp: 54.0000 - val_loss: 0.3267 - val_accuracy: 0.7992\n",
      "Epoch 49/350\n",
      "29/28 [==============================] - 23s 806ms/step - fn: 88.0000 - auc: 0.7779 - tp: 440.0000 - loss: 0.5350 - accuracy: 0.6334 - val_fn: 19.0000 - val_auc: 0.7724 - val_tp: 70.0000 - val_loss: 0.4589 - val_accuracy: 0.6641\n",
      "Epoch 50/350\n",
      "29/28 [==============================] - 21s 726ms/step - fn: 92.0000 - auc: 0.7711 - tp: 438.0000 - loss: 0.5404 - accuracy: 0.6261 - val_fn: 21.0000 - val_auc: 0.7960 - val_tp: 64.0000 - val_loss: 0.4359 - val_accuracy: 0.7000\n",
      "Epoch 51/350\n",
      "29/28 [==============================] - 21s 725ms/step - fn: 76.0000 - auc: 0.7833 - tp: 453.0000 - loss: 0.5270 - accuracy: 0.6427 - val_fn: 29.0000 - val_auc: 0.8034 - val_tp: 60.0000 - val_loss: 0.4610 - val_accuracy: 0.7725\n",
      "Epoch 52/350\n",
      "29/28 [==============================] - 23s 785ms/step - fn: 97.0000 - auc: 0.7938 - tp: 431.0000 - loss: 0.5323 - accuracy: 0.6693 - val_fn: 22.0000 - val_auc: 0.8132 - val_tp: 62.0000 - val_loss: 0.4720 - val_accuracy: 0.7479\n",
      "Epoch 53/350\n",
      "29/28 [==============================] - 23s 792ms/step - fn: 87.0000 - auc: 0.7861 - tp: 444.0000 - loss: 0.5315 - accuracy: 0.6472 - val_fn: 8.0000 - val_auc: 0.7903 - val_tp: 80.0000 - val_loss: 0.5104 - val_accuracy: 0.6092\n",
      "Epoch 54/350\n",
      "29/28 [==============================] - 23s 783ms/step - fn: 89.0000 - auc: 0.7754 - tp: 441.0000 - loss: 0.5341 - accuracy: 0.6382 - val_fn: 11.0000 - val_auc: 0.8065 - val_tp: 74.0000 - val_loss: 0.5336 - val_accuracy: 0.6475\n",
      "Epoch 55/350\n",
      "29/28 [==============================] - 22s 771ms/step - fn: 76.0000 - auc: 0.7902 - tp: 450.0000 - loss: 0.5212 - accuracy: 0.6394 - val_fn: 11.0000 - val_auc: 0.8045 - val_tp: 73.0000 - val_loss: 0.4905 - val_accuracy: 0.6488\n",
      "Epoch 56/350\n",
      "29/28 [==============================] - 21s 726ms/step - fn: 87.0000 - auc: 0.7676 - tp: 441.0000 - loss: 0.5444 - accuracy: 0.6210 - val_fn: 25.0000 - val_auc: 0.7473 - val_tp: 58.0000 - val_loss: 0.4510 - val_accuracy: 0.6715\n",
      "Epoch 57/350\n",
      "29/28 [==============================] - 22s 757ms/step - fn: 88.0000 - auc: 0.7898 - tp: 437.0000 - loss: 0.5323 - accuracy: 0.6508 - val_fn: 22.0000 - val_auc: 0.7718 - val_tp: 63.0000 - val_loss: 0.4519 - val_accuracy: 0.7143\n",
      "Epoch 58/350\n",
      "29/28 [==============================] - 21s 741ms/step - fn: 71.0000 - auc: 0.7860 - tp: 454.0000 - loss: 0.5244 - accuracy: 0.6371 - val_fn: 32.0000 - val_auc: 0.7905 - val_tp: 57.0000 - val_loss: 0.4068 - val_accuracy: 0.7719\n",
      "Epoch 59/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 87.0000 - auc: 0.7922 - tp: 438.0000 - loss: 0.5245 - accuracy: 0.6546 - val_fn: 38.0000 - val_auc: 0.7921 - val_tp: 43.0000 - val_loss: 0.3527 - val_accuracy: 0.8301\n",
      "Epoch 60/350\n",
      "29/28 [==============================] - 23s 792ms/step - fn: 81.0000 - auc: 0.8025 - tp: 450.0000 - loss: 0.5163 - accuracy: 0.6580 - val_fn: 43.0000 - val_auc: 0.7841 - val_tp: 42.0000 - val_loss: 0.3372 - val_accuracy: 0.8508\n",
      "Epoch 61/350\n",
      "29/28 [==============================] - 22s 772ms/step - fn: 79.0000 - auc: 0.8017 - tp: 447.0000 - loss: 0.5176 - accuracy: 0.6656 - val_fn: 38.0000 - val_auc: 0.7999 - val_tp: 50.0000 - val_loss: 0.3666 - val_accuracy: 0.7742\n",
      "Epoch 62/350\n",
      "29/28 [==============================] - 21s 721ms/step - fn: 88.0000 - auc: 0.8089 - tp: 438.0000 - loss: 0.5098 - accuracy: 0.6844 - val_fn: 37.0000 - val_auc: 0.7930 - val_tp: 48.0000 - val_loss: 0.3504 - val_accuracy: 0.8201\n",
      "Epoch 63/350\n",
      "29/28 [==============================] - 22s 769ms/step - fn: 62.0000 - auc: 0.7978 - tp: 471.0000 - loss: 0.5144 - accuracy: 0.6505 - val_fn: 39.0000 - val_auc: 0.7894 - val_tp: 49.0000 - val_loss: 0.3547 - val_accuracy: 0.7639\n",
      "Epoch 64/350\n",
      "29/28 [==============================] - 22s 768ms/step - fn: 80.0000 - auc: 0.8102 - tp: 447.0000 - loss: 0.5066 - accuracy: 0.6801 - val_fn: 67.0000 - val_auc: 0.7605 - val_tp: 20.0000 - val_loss: 0.2470 - val_accuracy: 0.8885\n",
      "Epoch 65/350\n",
      "29/28 [==============================] - 23s 802ms/step - fn: 67.0000 - auc: 0.8076 - tp: 457.0000 - loss: 0.4985 - accuracy: 0.6645 - val_fn: 26.0000 - val_auc: 0.8077 - val_tp: 65.0000 - val_loss: 0.4080 - val_accuracy: 0.7135\n",
      "Epoch 66/350\n",
      "29/28 [==============================] - 23s 780ms/step - fn: 73.0000 - auc: 0.8083 - tp: 457.0000 - loss: 0.5129 - accuracy: 0.6631 - val_fn: 30.0000 - val_auc: 0.7886 - val_tp: 53.0000 - val_loss: 0.4100 - val_accuracy: 0.7809\n",
      "Epoch 67/350\n",
      "29/28 [==============================] - 23s 788ms/step - fn: 75.0000 - auc: 0.8023 - tp: 455.0000 - loss: 0.5169 - accuracy: 0.6700 - val_fn: 15.0000 - val_auc: 0.8048 - val_tp: 72.0000 - val_loss: 0.4635 - val_accuracy: 0.6965\n",
      "Epoch 68/350\n",
      "29/28 [==============================] - 22s 761ms/step - fn: 84.0000 - auc: 0.8033 - tp: 440.0000 - loss: 0.5113 - accuracy: 0.6861 - val_fn: 25.0000 - val_auc: 0.8196 - val_tp: 63.0000 - val_loss: 0.4307 - val_accuracy: 0.7592\n",
      "Epoch 69/350\n",
      "29/28 [==============================] - 22s 771ms/step - fn: 79.0000 - auc: 0.8086 - tp: 449.0000 - loss: 0.5057 - accuracy: 0.6687 - val_fn: 30.0000 - val_auc: 0.7953 - val_tp: 53.0000 - val_loss: 0.4210 - val_accuracy: 0.7568\n",
      "Epoch 70/350\n",
      "29/28 [==============================] - 21s 727ms/step - fn: 88.0000 - auc: 0.8039 - tp: 441.0000 - loss: 0.5098 - accuracy: 0.6709 - val_fn: 20.0000 - val_auc: 0.8127 - val_tp: 67.0000 - val_loss: 0.4519 - val_accuracy: 0.7066\n",
      "Epoch 71/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 77.0000 - auc: 0.8122 - tp: 449.0000 - loss: 0.5075 - accuracy: 0.6687 - val_fn: 35.0000 - val_auc: 0.7998 - val_tp: 52.0000 - val_loss: 0.3880 - val_accuracy: 0.7539\n",
      "Epoch 72/350\n",
      "29/28 [==============================] - 23s 791ms/step - fn: 62.0000 - auc: 0.8157 - tp: 462.0000 - loss: 0.4961 - accuracy: 0.6653 - val_fn: 36.0000 - val_auc: 0.8154 - val_tp: 49.0000 - val_loss: 0.3660 - val_accuracy: 0.8092\n",
      "Epoch 73/350\n",
      "29/28 [==============================] - 23s 808ms/step - fn: 79.0000 - auc: 0.8170 - tp: 450.0000 - loss: 0.4952 - accuracy: 0.6934 - val_fn: 47.0000 - val_auc: 0.7976 - val_tp: 41.0000 - val_loss: 0.3348 - val_accuracy: 0.8607\n",
      "Epoch 74/350\n",
      "29/28 [==============================] - 22s 769ms/step - fn: 68.0000 - auc: 0.8244 - tp: 461.0000 - loss: 0.4881 - accuracy: 0.6803 - val_fn: 46.0000 - val_auc: 0.8035 - val_tp: 40.0000 - val_loss: 0.3336 - val_accuracy: 0.8471\n",
      "Epoch 75/350\n",
      "29/28 [==============================] - 22s 772ms/step - fn: 64.0000 - auc: 0.8200 - tp: 470.0000 - loss: 0.4918 - accuracy: 0.6726 - val_fn: 31.0000 - val_auc: 0.8040 - val_tp: 51.0000 - val_loss: 0.3882 - val_accuracy: 0.7658\n",
      "Epoch 76/350\n",
      "29/28 [==============================] - 22s 768ms/step - fn: 90.0000 - auc: 0.8092 - tp: 438.0000 - loss: 0.5128 - accuracy: 0.6836 - val_fn: 37.0000 - val_auc: 0.7904 - val_tp: 47.0000 - val_loss: 0.4030 - val_accuracy: 0.7957\n",
      "Epoch 77/350\n",
      "29/28 [==============================] - 22s 761ms/step - fn: 79.0000 - auc: 0.8232 - tp: 446.0000 - loss: 0.4931 - accuracy: 0.6839 - val_fn: 26.0000 - val_auc: 0.8282 - val_tp: 61.0000 - val_loss: 0.3731 - val_accuracy: 0.7920\n",
      "Epoch 78/350\n",
      "29/28 [==============================] - 22s 761ms/step - fn: 72.0000 - auc: 0.8187 - tp: 456.0000 - loss: 0.4958 - accuracy: 0.6678 - val_fn: 34.0000 - val_auc: 0.8098 - val_tp: 53.0000 - val_loss: 0.4079 - val_accuracy: 0.7957\n",
      "Epoch 79/350\n",
      "29/28 [==============================] - 22s 772ms/step - fn: 73.0000 - auc: 0.8270 - tp: 446.0000 - loss: 0.4845 - accuracy: 0.6934 - val_fn: 38.0000 - val_auc: 0.8122 - val_tp: 49.0000 - val_loss: 0.3620 - val_accuracy: 0.8199\n",
      "Epoch 80/350\n",
      "29/28 [==============================] - 22s 770ms/step - fn: 78.0000 - auc: 0.8218 - tp: 453.0000 - loss: 0.4925 - accuracy: 0.6918 - val_fn: 25.0000 - val_auc: 0.8248 - val_tp: 60.0000 - val_loss: 0.4291 - val_accuracy: 0.7600\n",
      "Epoch 81/350\n",
      "29/28 [==============================] - 22s 772ms/step - fn: 68.0000 - auc: 0.8354 - tp: 455.0000 - loss: 0.4791 - accuracy: 0.7013 - val_fn: 25.0000 - val_auc: 0.8185 - val_tp: 63.0000 - val_loss: 0.4053 - val_accuracy: 0.7824\n",
      "Epoch 82/350\n",
      "29/28 [==============================] - 22s 763ms/step - fn: 78.0000 - auc: 0.8257 - tp: 449.0000 - loss: 0.4927 - accuracy: 0.6966 - val_fn: 31.0000 - val_auc: 0.8151 - val_tp: 54.0000 - val_loss: 0.3914 - val_accuracy: 0.8064\n",
      "Epoch 83/350\n",
      "29/28 [==============================] - 22s 756ms/step - fn: 79.0000 - auc: 0.8207 - tp: 445.0000 - loss: 0.5012 - accuracy: 0.6939 - val_fn: 21.0000 - val_auc: 0.8255 - val_tp: 61.0000 - val_loss: 0.4434 - val_accuracy: 0.7615\n",
      "Epoch 84/350\n",
      "29/28 [==============================] - 23s 778ms/step - fn: 79.0000 - auc: 0.8126 - tp: 451.0000 - loss: 0.5102 - accuracy: 0.6839 - val_fn: 10.0000 - val_auc: 0.8289 - val_tp: 77.0000 - val_loss: 0.5617 - val_accuracy: 0.6482\n",
      "Epoch 85/350\n",
      "29/28 [==============================] - 23s 783ms/step - fn: 63.0000 - auc: 0.8227 - tp: 464.0000 - loss: 0.4928 - accuracy: 0.6833 - val_fn: 3.0000 - val_auc: 0.7699 - val_tp: 82.0000 - val_loss: 0.8049 - val_accuracy: 0.4451\n",
      "Epoch 86/350\n",
      "29/28 [==============================] - 22s 768ms/step - fn: 77.0000 - auc: 0.8025 - tp: 452.0000 - loss: 0.5126 - accuracy: 0.6543 - val_fn: 8.0000 - val_auc: 0.8028 - val_tp: 78.0000 - val_loss: 0.5661 - val_accuracy: 0.6137\n",
      "Epoch 87/350\n",
      "29/28 [==============================] - 21s 726ms/step - fn: 63.0000 - auc: 0.8116 - tp: 464.0000 - loss: 0.4948 - accuracy: 0.6615 - val_fn: 9.0000 - val_auc: 0.7932 - val_tp: 76.0000 - val_loss: 0.6083 - val_accuracy: 0.6010\n",
      "Epoch 88/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 62.0000 - auc: 0.8050 - tp: 469.0000 - loss: 0.5036 - accuracy: 0.6531 - val_fn: 11.0000 - val_auc: 0.8106 - val_tp: 74.0000 - val_loss: 0.4571 - val_accuracy: 0.6893\n",
      "Epoch 89/350\n",
      "29/28 [==============================] - 22s 772ms/step - fn: 52.0000 - auc: 0.8147 - tp: 478.0000 - loss: 0.4970 - accuracy: 0.6535 - val_fn: 7.0000 - val_auc: 0.8293 - val_tp: 78.0000 - val_loss: 0.4934 - val_accuracy: 0.6832\n",
      "Epoch 90/350\n",
      "29/28 [==============================] - 23s 783ms/step - fn: 65.0000 - auc: 0.8097 - tp: 461.0000 - loss: 0.4986 - accuracy: 0.6652 - val_fn: 14.0000 - val_auc: 0.8314 - val_tp: 69.0000 - val_loss: 0.4371 - val_accuracy: 0.7359\n",
      "Epoch 91/350\n",
      "29/28 [==============================] - 24s 812ms/step - fn: 70.0000 - auc: 0.8143 - tp: 464.0000 - loss: 0.5033 - accuracy: 0.6696 - val_fn: 12.0000 - val_auc: 0.8389 - val_tp: 74.0000 - val_loss: 0.4507 - val_accuracy: 0.7236\n",
      "Epoch 92/350\n",
      "29/28 [==============================] - 21s 725ms/step - fn: 66.0000 - auc: 0.8279 - tp: 458.0000 - loss: 0.4789 - accuracy: 0.6991 - val_fn: 27.0000 - val_auc: 0.8259 - val_tp: 59.0000 - val_loss: 0.3889 - val_accuracy: 0.7883\n",
      "Epoch 93/350\n",
      "29/28 [==============================] - 22s 766ms/step - fn: 70.0000 - auc: 0.8139 - tp: 464.0000 - loss: 0.4994 - accuracy: 0.6638 - val_fn: 38.0000 - val_auc: 0.8167 - val_tp: 49.0000 - val_loss: 0.3092 - val_accuracy: 0.8363\n",
      "Epoch 94/350\n",
      "29/28 [==============================] - 22s 754ms/step - fn: 54.0000 - auc: 0.8143 - tp: 481.0000 - loss: 0.4908 - accuracy: 0.6675 - val_fn: 21.0000 - val_auc: 0.8283 - val_tp: 64.0000 - val_loss: 0.3782 - val_accuracy: 0.7914\n",
      "Epoch 95/350\n",
      "29/28 [==============================] - 24s 834ms/step - fn: 63.0000 - auc: 0.8267 - tp: 463.0000 - loss: 0.4820 - accuracy: 0.6872 - val_fn: 19.0000 - val_auc: 0.8311 - val_tp: 66.0000 - val_loss: 0.4302 - val_accuracy: 0.7486\n",
      "Epoch 96/350\n",
      "29/28 [==============================] - 23s 794ms/step - fn: 66.0000 - auc: 0.8298 - tp: 459.0000 - loss: 0.4741 - accuracy: 0.6914 - val_fn: 36.0000 - val_auc: 0.7977 - val_tp: 48.0000 - val_loss: 0.3479 - val_accuracy: 0.8242\n",
      "Epoch 97/350\n",
      "29/28 [==============================] - 23s 798ms/step - fn: 76.0000 - auc: 0.8367 - tp: 448.0000 - loss: 0.4766 - accuracy: 0.7084 - val_fn: 32.0000 - val_auc: 0.8155 - val_tp: 55.0000 - val_loss: 0.4024 - val_accuracy: 0.8332\n",
      "Epoch 98/350\n",
      "29/28 [==============================] - 22s 764ms/step - fn: 75.0000 - auc: 0.8392 - tp: 450.0000 - loss: 0.4715 - accuracy: 0.7111 - val_fn: 39.0000 - val_auc: 0.8274 - val_tp: 48.0000 - val_loss: 0.3638 - val_accuracy: 0.8348\n",
      "Epoch 99/350\n",
      "29/28 [==============================] - 22s 746ms/step - fn: 73.0000 - auc: 0.8361 - tp: 453.0000 - loss: 0.4758 - accuracy: 0.7302 - val_fn: 26.0000 - val_auc: 0.8462 - val_tp: 60.0000 - val_loss: 0.3899 - val_accuracy: 0.8275\n",
      "Epoch 100/350\n",
      "29/28 [==============================] - 22s 769ms/step - fn: 81.0000 - auc: 0.8400 - tp: 448.0000 - loss: 0.4755 - accuracy: 0.7305 - val_fn: 56.0000 - val_auc: 0.7786 - val_tp: 33.0000 - val_loss: 0.2730 - val_accuracy: 0.9076\n",
      "Epoch 101/350\n",
      "29/28 [==============================] - 23s 788ms/step - fn: 77.0000 - auc: 0.8435 - tp: 449.0000 - loss: 0.4721 - accuracy: 0.7183 - val_fn: 47.0000 - val_auc: 0.7814 - val_tp: 38.0000 - val_loss: 0.3062 - val_accuracy: 0.8580\n",
      "Epoch 102/350\n",
      "29/28 [==============================] - 22s 765ms/step - fn: 74.0000 - auc: 0.8334 - tp: 455.0000 - loss: 0.4852 - accuracy: 0.7151 - val_fn: 41.0000 - val_auc: 0.8111 - val_tp: 45.0000 - val_loss: 0.3729 - val_accuracy: 0.8240\n",
      "Epoch 103/350\n",
      "29/28 [==============================] - 22s 763ms/step - fn: 76.0000 - auc: 0.8475 - tp: 447.0000 - loss: 0.4637 - accuracy: 0.7127 - val_fn: 31.0000 - val_auc: 0.8264 - val_tp: 56.0000 - val_loss: 0.3524 - val_accuracy: 0.8070\n",
      "Epoch 104/350\n",
      "29/28 [==============================] - 23s 801ms/step - fn: 79.0000 - auc: 0.8423 - tp: 453.0000 - loss: 0.4798 - accuracy: 0.7171 - val_fn: 22.0000 - val_auc: 0.8126 - val_tp: 63.0000 - val_loss: 0.4881 - val_accuracy: 0.7160\n",
      "Epoch 105/350\n",
      "29/28 [==============================] - 22s 758ms/step - fn: 87.0000 - auc: 0.8407 - tp: 447.0000 - loss: 0.4774 - accuracy: 0.7301 - val_fn: 21.0000 - val_auc: 0.8363 - val_tp: 67.0000 - val_loss: 0.4336 - val_accuracy: 0.7826\n",
      "Epoch 106/350\n",
      "29/28 [==============================] - 23s 778ms/step - fn: 80.0000 - auc: 0.8451 - tp: 445.0000 - loss: 0.4686 - accuracy: 0.7248 - val_fn: 45.0000 - val_auc: 0.8217 - val_tp: 42.0000 - val_loss: 0.3394 - val_accuracy: 0.8627\n",
      "Epoch 107/350\n",
      "29/28 [==============================] - 22s 756ms/step - fn: 84.0000 - auc: 0.8444 - tp: 438.0000 - loss: 0.4725 - accuracy: 0.7311 - val_fn: 30.0000 - val_auc: 0.8059 - val_tp: 57.0000 - val_loss: 0.4721 - val_accuracy: 0.7709\n",
      "Epoch 108/350\n",
      "29/28 [==============================] - 23s 782ms/step - fn: 82.0000 - auc: 0.8374 - tp: 446.0000 - loss: 0.4796 - accuracy: 0.7226 - val_fn: 19.0000 - val_auc: 0.8245 - val_tp: 68.0000 - val_loss: 0.5088 - val_accuracy: 0.7043\n",
      "Epoch 109/350\n",
      "29/28 [==============================] - 23s 780ms/step - fn: 78.0000 - auc: 0.8392 - tp: 453.0000 - loss: 0.4760 - accuracy: 0.7117 - val_fn: 21.0000 - val_auc: 0.8249 - val_tp: 67.0000 - val_loss: 0.4991 - val_accuracy: 0.7385\n",
      "Epoch 110/350\n",
      "29/28 [==============================] - 21s 719ms/step - fn: 76.0000 - auc: 0.8476 - tp: 449.0000 - loss: 0.4630 - accuracy: 0.7312 - val_fn: 21.0000 - val_auc: 0.8257 - val_tp: 63.0000 - val_loss: 0.4998 - val_accuracy: 0.7508\n",
      "Epoch 111/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 95.0000 - auc: 0.8387 - tp: 433.0000 - loss: 0.4796 - accuracy: 0.7330 - val_fn: 24.0000 - val_auc: 0.8013 - val_tp: 61.0000 - val_loss: 0.4956 - val_accuracy: 0.7598\n",
      "Epoch 112/350\n",
      "29/28 [==============================] - 22s 751ms/step - fn: 75.0000 - auc: 0.8519 - tp: 449.0000 - loss: 0.4545 - accuracy: 0.7394 - val_fn: 42.0000 - val_auc: 0.7946 - val_tp: 44.0000 - val_loss: 0.4118 - val_accuracy: 0.8215\n",
      "Epoch 113/350\n",
      "29/28 [==============================] - 23s 778ms/step - fn: 79.0000 - auc: 0.8359 - tp: 447.0000 - loss: 0.4743 - accuracy: 0.7081 - val_fn: 64.0000 - val_auc: 0.6261 - val_tp: 24.0000 - val_loss: 0.2779 - val_accuracy: 0.8965\n",
      "Epoch 114/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 92.0000 - auc: 0.8239 - tp: 443.0000 - loss: 0.5004 - accuracy: 0.7047 - val_fn: 37.0000 - val_auc: 0.8103 - val_tp: 50.0000 - val_loss: 0.3623 - val_accuracy: 0.8535\n",
      "Epoch 115/350\n",
      "29/28 [==============================] - 22s 765ms/step - fn: 80.0000 - auc: 0.8450 - tp: 449.0000 - loss: 0.4665 - accuracy: 0.7247 - val_fn: 41.0000 - val_auc: 0.8105 - val_tp: 44.0000 - val_loss: 0.3054 - val_accuracy: 0.8451\n",
      "Epoch 116/350\n",
      "29/28 [==============================] - 23s 806ms/step - fn: 78.0000 - auc: 0.8360 - tp: 447.0000 - loss: 0.4761 - accuracy: 0.7233 - val_fn: 35.0000 - val_auc: 0.8206 - val_tp: 52.0000 - val_loss: 0.4172 - val_accuracy: 0.7963\n",
      "Epoch 117/350\n",
      "29/28 [==============================] - 22s 771ms/step - fn: 91.0000 - auc: 0.8368 - tp: 433.0000 - loss: 0.4766 - accuracy: 0.7438 - val_fn: 30.0000 - val_auc: 0.8029 - val_tp: 53.0000 - val_loss: 0.4118 - val_accuracy: 0.7992\n",
      "Epoch 118/350\n",
      "29/28 [==============================] - 21s 724ms/step - fn: 68.0000 - auc: 0.8508 - tp: 467.0000 - loss: 0.4634 - accuracy: 0.7163 - val_fn: 25.0000 - val_auc: 0.8191 - val_tp: 59.0000 - val_loss: 0.4232 - val_accuracy: 0.7811\n",
      "Epoch 119/350\n",
      "29/28 [==============================] - 23s 781ms/step - fn: 88.0000 - auc: 0.8484 - tp: 438.0000 - loss: 0.4606 - accuracy: 0.7347 - val_fn: 28.0000 - val_auc: 0.8474 - val_tp: 58.0000 - val_loss: 0.4094 - val_accuracy: 0.8139\n",
      "Epoch 120/350\n",
      "29/28 [==============================] - 23s 789ms/step - fn: 89.0000 - auc: 0.8466 - tp: 434.0000 - loss: 0.4677 - accuracy: 0.7242 - val_fn: 31.0000 - val_auc: 0.8235 - val_tp: 55.0000 - val_loss: 0.4155 - val_accuracy: 0.8066\n",
      "Epoch 121/350\n",
      "29/28 [==============================] - 21s 738ms/step - fn: 75.0000 - auc: 0.8452 - tp: 451.0000 - loss: 0.4685 - accuracy: 0.7231 - val_fn: 19.0000 - val_auc: 0.8217 - val_tp: 67.0000 - val_loss: 0.5027 - val_accuracy: 0.7463\n",
      "Epoch 122/350\n",
      "29/28 [==============================] - 23s 799ms/step - fn: 75.0000 - auc: 0.8399 - tp: 450.0000 - loss: 0.4727 - accuracy: 0.6968 - val_fn: 22.0000 - val_auc: 0.8089 - val_tp: 64.0000 - val_loss: 0.4905 - val_accuracy: 0.7379\n",
      "Epoch 123/350\n",
      "29/28 [==============================] - 23s 781ms/step - fn: 74.0000 - auc: 0.8362 - tp: 455.0000 - loss: 0.4755 - accuracy: 0.7051 - val_fn: 27.0000 - val_auc: 0.8233 - val_tp: 57.0000 - val_loss: 0.4733 - val_accuracy: 0.7844\n",
      "Epoch 124/350\n",
      "29/28 [==============================] - 24s 820ms/step - fn: 90.0000 - auc: 0.8428 - tp: 433.0000 - loss: 0.4717 - accuracy: 0.7422 - val_fn: 16.0000 - val_auc: 0.8370 - val_tp: 71.0000 - val_loss: 0.5056 - val_accuracy: 0.7391\n",
      "Epoch 125/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 52.0000 - auc: 0.8526 - tp: 477.0000 - loss: 0.4549 - accuracy: 0.7117 - val_fn: 33.0000 - val_auc: 0.8261 - val_tp: 49.0000 - val_loss: 0.3744 - val_accuracy: 0.8275\n",
      "Epoch 126/350\n",
      "29/28 [==============================] - 23s 778ms/step - fn: 77.0000 - auc: 0.8416 - tp: 452.0000 - loss: 0.4698 - accuracy: 0.7185 - val_fn: 25.0000 - val_auc: 0.8334 - val_tp: 59.0000 - val_loss: 0.4216 - val_accuracy: 0.7721\n",
      "Epoch 127/350\n",
      "29/28 [==============================] - 23s 780ms/step - fn: 64.0000 - auc: 0.8442 - tp: 464.0000 - loss: 0.4669 - accuracy: 0.7121 - val_fn: 20.0000 - val_auc: 0.8372 - val_tp: 65.0000 - val_loss: 0.4074 - val_accuracy: 0.7852\n",
      "Epoch 128/350\n",
      "29/28 [==============================] - 22s 774ms/step - fn: 67.0000 - auc: 0.8441 - tp: 459.0000 - loss: 0.4643 - accuracy: 0.7261 - val_fn: 41.0000 - val_auc: 0.8187 - val_tp: 46.0000 - val_loss: 0.3535 - val_accuracy: 0.8314\n",
      "Epoch 129/350\n",
      "29/28 [==============================] - 23s 791ms/step - fn: 66.0000 - auc: 0.8483 - tp: 466.0000 - loss: 0.4604 - accuracy: 0.7400 - val_fn: 57.0000 - val_auc: 0.7995 - val_tp: 29.0000 - val_loss: 0.3055 - val_accuracy: 0.8930\n",
      "Epoch 130/350\n",
      "29/28 [==============================] - 22s 752ms/step - fn: 77.0000 - auc: 0.8526 - tp: 448.0000 - loss: 0.4505 - accuracy: 0.7312 - val_fn: 55.0000 - val_auc: 0.7753 - val_tp: 33.0000 - val_loss: 0.3021 - val_accuracy: 0.8680\n",
      "Epoch 131/350\n",
      "29/28 [==============================] - 23s 798ms/step - fn: 69.0000 - auc: 0.8582 - tp: 463.0000 - loss: 0.4492 - accuracy: 0.7332 - val_fn: 31.0000 - val_auc: 0.8239 - val_tp: 51.0000 - val_loss: 0.3010 - val_accuracy: 0.8438\n",
      "Epoch 132/350\n",
      "29/28 [==============================] - 22s 748ms/step - fn: 77.0000 - auc: 0.8500 - tp: 450.0000 - loss: 0.4630 - accuracy: 0.7230 - val_fn: 41.0000 - val_auc: 0.8162 - val_tp: 46.0000 - val_loss: 0.3362 - val_accuracy: 0.8525\n",
      "Epoch 133/350\n",
      "29/28 [==============================] - 23s 806ms/step - fn: 66.0000 - auc: 0.8494 - tp: 467.0000 - loss: 0.4603 - accuracy: 0.7124 - val_fn: 12.0000 - val_auc: 0.8706 - val_tp: 76.0000 - val_loss: 0.4260 - val_accuracy: 0.7490\n",
      "Epoch 134/350\n",
      "29/28 [==============================] - 21s 729ms/step - fn: 67.0000 - auc: 0.8508 - tp: 463.0000 - loss: 0.4546 - accuracy: 0.7138 - val_fn: 30.0000 - val_auc: 0.8232 - val_tp: 56.0000 - val_loss: 0.3205 - val_accuracy: 0.8363\n",
      "Epoch 135/350\n",
      "29/28 [==============================] - 23s 777ms/step - fn: 82.0000 - auc: 0.8542 - tp: 444.0000 - loss: 0.4541 - accuracy: 0.7402 - val_fn: 43.0000 - val_auc: 0.8398 - val_tp: 45.0000 - val_loss: 0.3021 - val_accuracy: 0.8754\n",
      "Epoch 136/350\n",
      "29/28 [==============================] - 24s 819ms/step - fn: 77.0000 - auc: 0.8588 - tp: 452.0000 - loss: 0.4558 - accuracy: 0.7403 - val_fn: 26.0000 - val_auc: 0.8236 - val_tp: 59.0000 - val_loss: 0.4170 - val_accuracy: 0.7588\n",
      "Epoch 137/350\n",
      "29/28 [==============================] - 21s 727ms/step - fn: 73.0000 - auc: 0.8440 - tp: 457.0000 - loss: 0.4754 - accuracy: 0.7074 - val_fn: 21.0000 - val_auc: 0.8414 - val_tp: 63.0000 - val_loss: 0.4001 - val_accuracy: 0.7746\n",
      "Epoch 138/350\n",
      "29/28 [==============================] - 22s 759ms/step - fn: 68.0000 - auc: 0.8559 - tp: 458.0000 - loss: 0.4553 - accuracy: 0.7303 - val_fn: 57.0000 - val_auc: 0.7230 - val_tp: 32.0000 - val_loss: 0.2072 - val_accuracy: 0.9199\n",
      "Epoch 139/350\n",
      "29/28 [==============================] - 24s 813ms/step - fn: 58.0000 - auc: 0.8483 - tp: 464.0000 - loss: 0.4625 - accuracy: 0.7228 - val_fn: 40.0000 - val_auc: 0.8154 - val_tp: 46.0000 - val_loss: 0.3266 - val_accuracy: 0.8500\n",
      "Epoch 140/350\n",
      "29/28 [==============================] - 21s 740ms/step - fn: 72.0000 - auc: 0.8486 - tp: 458.0000 - loss: 0.4665 - accuracy: 0.7329 - val_fn: 18.0000 - val_auc: 0.8461 - val_tp: 71.0000 - val_loss: 0.4225 - val_accuracy: 0.7607\n",
      "Epoch 141/350\n",
      "29/28 [==============================] - 22s 766ms/step - fn: 69.0000 - auc: 0.8678 - tp: 464.0000 - loss: 0.4442 - accuracy: 0.7251 - val_fn: 25.0000 - val_auc: 0.8494 - val_tp: 60.0000 - val_loss: 0.3764 - val_accuracy: 0.7916\n",
      "Epoch 142/350\n",
      "29/28 [==============================] - 21s 726ms/step - fn: 79.0000 - auc: 0.8637 - tp: 439.0000 - loss: 0.4501 - accuracy: 0.7316 - val_fn: 16.0000 - val_auc: 0.8573 - val_tp: 70.0000 - val_loss: 0.4200 - val_accuracy: 0.7900\n",
      "Epoch 143/350\n",
      "29/28 [==============================] - 21s 736ms/step - fn: 60.0000 - auc: 0.8609 - tp: 467.0000 - loss: 0.4430 - accuracy: 0.7241 - val_fn: 22.0000 - val_auc: 0.8527 - val_tp: 64.0000 - val_loss: 0.3669 - val_accuracy: 0.7939\n",
      "Epoch 144/350\n",
      "29/28 [==============================] - 22s 761ms/step - fn: 78.0000 - auc: 0.8485 - tp: 447.0000 - loss: 0.4671 - accuracy: 0.7401 - val_fn: 32.0000 - val_auc: 0.8482 - val_tp: 56.0000 - val_loss: 0.3432 - val_accuracy: 0.8268\n",
      "Epoch 145/350\n",
      "29/28 [==============================] - 22s 765ms/step - fn: 78.0000 - auc: 0.8560 - tp: 455.0000 - loss: 0.4617 - accuracy: 0.7306 - val_fn: 26.0000 - val_auc: 0.8534 - val_tp: 61.0000 - val_loss: 0.4177 - val_accuracy: 0.7846\n",
      "Epoch 146/350\n",
      "29/28 [==============================] - 22s 758ms/step - fn: 64.0000 - auc: 0.8610 - tp: 466.0000 - loss: 0.4516 - accuracy: 0.7349 - val_fn: 53.0000 - val_auc: 0.8455 - val_tp: 35.0000 - val_loss: 0.2859 - val_accuracy: 0.8947\n",
      "Epoch 147/350\n",
      "29/28 [==============================] - 24s 826ms/step - fn: 71.0000 - auc: 0.8664 - tp: 454.0000 - loss: 0.4436 - accuracy: 0.7429 - val_fn: 47.0000 - val_auc: 0.8440 - val_tp: 40.0000 - val_loss: 0.3317 - val_accuracy: 0.8754\n",
      "Epoch 148/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 68.0000 - auc: 0.8569 - tp: 459.0000 - loss: 0.4549 - accuracy: 0.7271 - val_fn: 20.0000 - val_auc: 0.8194 - val_tp: 66.0000 - val_loss: 0.5324 - val_accuracy: 0.7197\n",
      "Epoch 149/350\n",
      "29/28 [==============================] - 21s 733ms/step - fn: 82.0000 - auc: 0.8524 - tp: 447.0000 - loss: 0.4631 - accuracy: 0.7164 - val_fn: 10.0000 - val_auc: 0.8429 - val_tp: 75.0000 - val_loss: 0.5722 - val_accuracy: 0.7039\n",
      "Epoch 150/350\n",
      "29/28 [==============================] - 23s 787ms/step - fn: 68.0000 - auc: 0.8653 - tp: 461.0000 - loss: 0.4424 - accuracy: 0.7394 - val_fn: 22.0000 - val_auc: 0.8457 - val_tp: 62.0000 - val_loss: 0.4333 - val_accuracy: 0.7842\n",
      "Epoch 151/350\n",
      "29/28 [==============================] - 22s 746ms/step - fn: 61.0000 - auc: 0.8688 - tp: 469.0000 - loss: 0.4380 - accuracy: 0.7387 - val_fn: 22.0000 - val_auc: 0.8417 - val_tp: 62.0000 - val_loss: 0.3893 - val_accuracy: 0.7883\n",
      "Epoch 152/350\n",
      "29/28 [==============================] - 22s 763ms/step - fn: 58.0000 - auc: 0.8626 - tp: 464.0000 - loss: 0.4360 - accuracy: 0.7128 - val_fn: 13.0000 - val_auc: 0.8407 - val_tp: 71.0000 - val_loss: 0.4932 - val_accuracy: 0.7367\n",
      "Epoch 153/350\n",
      "29/28 [==============================] - 23s 785ms/step - fn: 61.0000 - auc: 0.8628 - tp: 466.0000 - loss: 0.4428 - accuracy: 0.7296 - val_fn: 10.0000 - val_auc: 0.8175 - val_tp: 77.0000 - val_loss: 0.5875 - val_accuracy: 0.6893\n",
      "Epoch 154/350\n",
      "29/28 [==============================] - 22s 768ms/step - fn: 54.0000 - auc: 0.8534 - tp: 473.0000 - loss: 0.4491 - accuracy: 0.7083 - val_fn: 14.0000 - val_auc: 0.8254 - val_tp: 76.0000 - val_loss: 0.4792 - val_accuracy: 0.7061\n",
      "Epoch 155/350\n",
      "29/28 [==============================] - 23s 804ms/step - fn: 65.0000 - auc: 0.8576 - tp: 465.0000 - loss: 0.4447 - accuracy: 0.7187 - val_fn: 28.0000 - val_auc: 0.8219 - val_tp: 56.0000 - val_loss: 0.3566 - val_accuracy: 0.7852\n",
      "Epoch 156/350\n",
      "29/28 [==============================] - 23s 791ms/step - fn: 69.0000 - auc: 0.8523 - tp: 465.0000 - loss: 0.4634 - accuracy: 0.7202 - val_fn: 17.0000 - val_auc: 0.8282 - val_tp: 71.0000 - val_loss: 0.4191 - val_accuracy: 0.7527\n",
      "Epoch 157/350\n",
      "29/28 [==============================] - 22s 755ms/step - fn: 65.0000 - auc: 0.8614 - tp: 459.0000 - loss: 0.4374 - accuracy: 0.7277 - val_fn: 31.0000 - val_auc: 0.8082 - val_tp: 57.0000 - val_loss: 0.3353 - val_accuracy: 0.8098\n",
      "Epoch 158/350\n",
      "29/28 [==============================] - 23s 800ms/step - fn: 74.0000 - auc: 0.8624 - tp: 459.0000 - loss: 0.4466 - accuracy: 0.7358 - val_fn: 37.0000 - val_auc: 0.7811 - val_tp: 50.0000 - val_loss: 0.3033 - val_accuracy: 0.8488\n",
      "Epoch 159/350\n",
      "29/28 [==============================] - 22s 756ms/step - fn: 65.0000 - auc: 0.8663 - tp: 459.0000 - loss: 0.4449 - accuracy: 0.7310 - val_fn: 11.0000 - val_auc: 0.8426 - val_tp: 74.0000 - val_loss: 0.4687 - val_accuracy: 0.7289\n",
      "Epoch 160/350\n",
      "29/28 [==============================] - 23s 801ms/step - fn: 71.0000 - auc: 0.8722 - tp: 453.0000 - loss: 0.4359 - accuracy: 0.7393 - val_fn: 27.0000 - val_auc: 0.8552 - val_tp: 57.0000 - val_loss: 0.3789 - val_accuracy: 0.8346\n",
      "Epoch 161/350\n",
      "29/28 [==============================] - 23s 796ms/step - fn: 80.0000 - auc: 0.8620 - tp: 444.0000 - loss: 0.4517 - accuracy: 0.7435 - val_fn: 29.0000 - val_auc: 0.8441 - val_tp: 55.0000 - val_loss: 0.2794 - val_accuracy: 0.8371\n",
      "Epoch 162/350\n",
      "29/28 [==============================] - 23s 783ms/step - fn: 57.0000 - auc: 0.8651 - tp: 472.0000 - loss: 0.4489 - accuracy: 0.7204 - val_fn: 21.0000 - val_auc: 0.8584 - val_tp: 64.0000 - val_loss: 0.3425 - val_accuracy: 0.8281\n",
      "Epoch 163/350\n",
      "29/28 [==============================] - 23s 805ms/step - fn: 62.0000 - auc: 0.8768 - tp: 465.0000 - loss: 0.4235 - accuracy: 0.7522 - val_fn: 25.0000 - val_auc: 0.8545 - val_tp: 61.0000 - val_loss: 0.3049 - val_accuracy: 0.8463\n",
      "Epoch 164/350\n",
      "29/28 [==============================] - 21s 716ms/step - fn: 56.0000 - auc: 0.8702 - tp: 466.0000 - loss: 0.4351 - accuracy: 0.7327 - val_fn: 16.0000 - val_auc: 0.8695 - val_tp: 67.0000 - val_loss: 0.4604 - val_accuracy: 0.7686\n",
      "Epoch 165/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 61.0000 - auc: 0.8755 - tp: 469.0000 - loss: 0.4285 - accuracy: 0.7431 - val_fn: 19.0000 - val_auc: 0.8528 - val_tp: 67.0000 - val_loss: 0.4430 - val_accuracy: 0.7924\n",
      "Epoch 166/350\n",
      "29/28 [==============================] - 23s 782ms/step - fn: 85.0000 - auc: 0.8712 - tp: 437.0000 - loss: 0.4368 - accuracy: 0.7653 - val_fn: 40.0000 - val_auc: 0.7816 - val_tp: 43.0000 - val_loss: 0.3809 - val_accuracy: 0.8574\n",
      "Epoch 167/350\n",
      "29/28 [==============================] - 22s 768ms/step - fn: 56.0000 - auc: 0.8720 - tp: 470.0000 - loss: 0.4346 - accuracy: 0.7508 - val_fn: 20.0000 - val_auc: 0.8384 - val_tp: 68.0000 - val_loss: 0.4321 - val_accuracy: 0.7359\n",
      "Epoch 168/350\n",
      "29/28 [==============================] - 22s 741ms/step - fn: 68.0000 - auc: 0.8762 - tp: 465.0000 - loss: 0.4265 - accuracy: 0.7595 - val_fn: 31.0000 - val_auc: 0.8604 - val_tp: 55.0000 - val_loss: 0.3050 - val_accuracy: 0.8426\n",
      "Epoch 169/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 69.0000 - auc: 0.8811 - tp: 459.0000 - loss: 0.4179 - accuracy: 0.7586 - val_fn: 33.0000 - val_auc: 0.8578 - val_tp: 54.0000 - val_loss: 0.3624 - val_accuracy: 0.8396\n",
      "Epoch 170/350\n",
      "29/28 [==============================] - 23s 778ms/step - fn: 80.0000 - auc: 0.8795 - tp: 451.0000 - loss: 0.4198 - accuracy: 0.7652 - val_fn: 24.0000 - val_auc: 0.8617 - val_tp: 64.0000 - val_loss: 0.3404 - val_accuracy: 0.8223\n",
      "Epoch 171/350\n",
      "29/28 [==============================] - 22s 764ms/step - fn: 55.0000 - auc: 0.8710 - tp: 471.0000 - loss: 0.4270 - accuracy: 0.7318 - val_fn: 14.0000 - val_auc: 0.8434 - val_tp: 72.0000 - val_loss: 0.5484 - val_accuracy: 0.7305\n",
      "Epoch 172/350\n",
      "29/28 [==============================] - 22s 759ms/step - fn: 70.0000 - auc: 0.8765 - tp: 459.0000 - loss: 0.4250 - accuracy: 0.7533 - val_fn: 16.0000 - val_auc: 0.8686 - val_tp: 71.0000 - val_loss: 0.4719 - val_accuracy: 0.7854\n",
      "Epoch 173/350\n",
      "29/28 [==============================] - 23s 803ms/step - fn: 65.0000 - auc: 0.8782 - tp: 466.0000 - loss: 0.4273 - accuracy: 0.7528 - val_fn: 53.0000 - val_auc: 0.8413 - val_tp: 37.0000 - val_loss: 0.2968 - val_accuracy: 0.8717\n",
      "Epoch 174/350\n",
      "29/28 [==============================] - 23s 784ms/step - fn: 79.0000 - auc: 0.8755 - tp: 451.0000 - loss: 0.4282 - accuracy: 0.7649 - val_fn: 17.0000 - val_auc: 0.8359 - val_tp: 69.0000 - val_loss: 0.5116 - val_accuracy: 0.7604\n",
      "Epoch 175/350\n",
      "29/28 [==============================] - 23s 795ms/step - fn: 66.0000 - auc: 0.8774 - tp: 469.0000 - loss: 0.4271 - accuracy: 0.7529 - val_fn: 33.0000 - val_auc: 0.7452 - val_tp: 49.0000 - val_loss: 0.5575 - val_accuracy: 0.7799\n",
      "Epoch 176/350\n",
      "29/28 [==============================] - 22s 772ms/step - fn: 68.0000 - auc: 0.8775 - tp: 461.0000 - loss: 0.4288 - accuracy: 0.7629 - val_fn: 21.0000 - val_auc: 0.8531 - val_tp: 64.0000 - val_loss: 0.4567 - val_accuracy: 0.7822\n",
      "Epoch 177/350\n",
      "29/28 [==============================] - 22s 760ms/step - fn: 65.0000 - auc: 0.8835 - tp: 459.0000 - loss: 0.4140 - accuracy: 0.7624 - val_fn: 22.0000 - val_auc: 0.8589 - val_tp: 63.0000 - val_loss: 0.4148 - val_accuracy: 0.8041\n",
      "Epoch 178/350\n",
      "29/28 [==============================] - 24s 823ms/step - fn: 70.0000 - auc: 0.8866 - tp: 460.0000 - loss: 0.4110 - accuracy: 0.7656 - val_fn: 24.0000 - val_auc: 0.8407 - val_tp: 59.0000 - val_loss: 0.4079 - val_accuracy: 0.8008\n",
      "Epoch 179/350\n",
      "29/28 [==============================] - 22s 765ms/step - fn: 63.0000 - auc: 0.8784 - tp: 460.0000 - loss: 0.4201 - accuracy: 0.7517 - val_fn: 27.0000 - val_auc: 0.8533 - val_tp: 56.0000 - val_loss: 0.3850 - val_accuracy: 0.8240\n",
      "Epoch 180/350\n",
      "29/28 [==============================] - 22s 756ms/step - fn: 78.0000 - auc: 0.8771 - tp: 444.0000 - loss: 0.4192 - accuracy: 0.7593 - val_fn: 17.0000 - val_auc: 0.8575 - val_tp: 71.0000 - val_loss: 0.5214 - val_accuracy: 0.7354\n",
      "Epoch 181/350\n",
      "29/28 [==============================] - 22s 763ms/step - fn: 57.0000 - auc: 0.8799 - tp: 474.0000 - loss: 0.4249 - accuracy: 0.7380 - val_fn: 42.0000 - val_auc: 0.7971 - val_tp: 42.0000 - val_loss: 0.2950 - val_accuracy: 0.8756\n",
      "Epoch 182/350\n",
      "29/28 [==============================] - 23s 794ms/step - fn: 56.0000 - auc: 0.8832 - tp: 468.0000 - loss: 0.4172 - accuracy: 0.7487 - val_fn: 26.0000 - val_auc: 0.8539 - val_tp: 59.0000 - val_loss: 0.3385 - val_accuracy: 0.8326\n",
      "Epoch 183/350\n",
      "29/28 [==============================] - 23s 780ms/step - fn: 65.0000 - auc: 0.8850 - tp: 463.0000 - loss: 0.4113 - accuracy: 0.7607 - val_fn: 8.0000 - val_auc: 0.8666 - val_tp: 77.0000 - val_loss: 0.5146 - val_accuracy: 0.7049\n",
      "Epoch 184/350\n",
      "29/28 [==============================] - 21s 741ms/step - fn: 58.0000 - auc: 0.8722 - tp: 472.0000 - loss: 0.4316 - accuracy: 0.7285 - val_fn: 35.0000 - val_auc: 0.7832 - val_tp: 52.0000 - val_loss: 0.3286 - val_accuracy: 0.8232\n",
      "Epoch 185/350\n",
      "29/28 [==============================] - 23s 783ms/step - fn: 70.0000 - auc: 0.8763 - tp: 453.0000 - loss: 0.4239 - accuracy: 0.7466 - val_fn: 29.0000 - val_auc: 0.8347 - val_tp: 60.0000 - val_loss: 0.3806 - val_accuracy: 0.8041\n",
      "Epoch 186/350\n",
      "29/28 [==============================] - 22s 770ms/step - fn: 64.0000 - auc: 0.8829 - tp: 473.0000 - loss: 0.4192 - accuracy: 0.7431 - val_fn: 29.0000 - val_auc: 0.8327 - val_tp: 55.0000 - val_loss: 0.3634 - val_accuracy: 0.8148\n",
      "Epoch 187/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 62.0000 - auc: 0.8845 - tp: 461.0000 - loss: 0.4089 - accuracy: 0.7562 - val_fn: 26.0000 - val_auc: 0.8618 - val_tp: 59.0000 - val_loss: 0.3577 - val_accuracy: 0.8107\n",
      "Epoch 188/350\n",
      "29/28 [==============================] - 21s 737ms/step - fn: 56.0000 - auc: 0.8832 - tp: 468.0000 - loss: 0.4110 - accuracy: 0.7491 - val_fn: 26.0000 - val_auc: 0.8296 - val_tp: 60.0000 - val_loss: 0.4155 - val_accuracy: 0.7828\n",
      "Epoch 189/350\n",
      "29/28 [==============================] - 22s 765ms/step - fn: 53.0000 - auc: 0.8819 - tp: 478.0000 - loss: 0.4116 - accuracy: 0.7365 - val_fn: 23.0000 - val_auc: 0.8677 - val_tp: 59.0000 - val_loss: 0.3303 - val_accuracy: 0.8184\n",
      "Epoch 190/350\n",
      "29/28 [==============================] - 21s 723ms/step - fn: 71.0000 - auc: 0.8798 - tp: 461.0000 - loss: 0.4240 - accuracy: 0.7482 - val_fn: 20.0000 - val_auc: 0.8628 - val_tp: 64.0000 - val_loss: 0.3914 - val_accuracy: 0.7873\n",
      "Epoch 191/350\n",
      "29/28 [==============================] - 21s 738ms/step - fn: 55.0000 - auc: 0.8857 - tp: 470.0000 - loss: 0.4118 - accuracy: 0.7543 - val_fn: 15.0000 - val_auc: 0.8712 - val_tp: 71.0000 - val_loss: 0.4173 - val_accuracy: 0.7867\n",
      "Epoch 192/350\n",
      "29/28 [==============================] - 22s 762ms/step - fn: 54.0000 - auc: 0.8857 - tp: 472.0000 - loss: 0.4058 - accuracy: 0.7497 - val_fn: 12.0000 - val_auc: 0.8629 - val_tp: 75.0000 - val_loss: 0.4751 - val_accuracy: 0.7252\n",
      "Epoch 193/350\n",
      "29/28 [==============================] - 23s 802ms/step - fn: 63.0000 - auc: 0.8917 - tp: 462.0000 - loss: 0.4002 - accuracy: 0.7646 - val_fn: 21.0000 - val_auc: 0.8608 - val_tp: 68.0000 - val_loss: 0.4330 - val_accuracy: 0.7580\n",
      "Epoch 194/350\n",
      "29/28 [==============================] - 21s 724ms/step - fn: 67.0000 - auc: 0.8801 - tp: 457.0000 - loss: 0.4253 - accuracy: 0.7427 - val_fn: 13.0000 - val_auc: 0.8583 - val_tp: 68.0000 - val_loss: 0.6161 - val_accuracy: 0.6961\n",
      "Epoch 195/350\n",
      "29/28 [==============================] - 22s 750ms/step - fn: 64.0000 - auc: 0.8867 - tp: 466.0000 - loss: 0.4099 - accuracy: 0.7552 - val_fn: 20.0000 - val_auc: 0.8542 - val_tp: 67.0000 - val_loss: 0.3858 - val_accuracy: 0.8039\n",
      "Epoch 196/350\n",
      "29/28 [==============================] - 23s 782ms/step - fn: 61.0000 - auc: 0.8973 - tp: 476.0000 - loss: 0.3946 - accuracy: 0.7609 - val_fn: 34.0000 - val_auc: 0.8237 - val_tp: 53.0000 - val_loss: 0.3148 - val_accuracy: 0.8350\n",
      "Epoch 197/350\n",
      "29/28 [==============================] - 24s 831ms/step - fn: 72.0000 - auc: 0.8689 - tp: 451.0000 - loss: 0.4352 - accuracy: 0.7345 - val_fn: 22.0000 - val_auc: 0.8497 - val_tp: 67.0000 - val_loss: 0.3781 - val_accuracy: 0.7660\n",
      "Epoch 198/350\n",
      "29/28 [==============================] - 22s 770ms/step - fn: 63.0000 - auc: 0.8813 - tp: 468.0000 - loss: 0.4220 - accuracy: 0.7417 - val_fn: 18.0000 - val_auc: 0.8583 - val_tp: 72.0000 - val_loss: 0.3850 - val_accuracy: 0.8041\n",
      "Epoch 199/350\n",
      "29/28 [==============================] - 22s 745ms/step - fn: 60.0000 - auc: 0.8889 - tp: 465.0000 - loss: 0.4053 - accuracy: 0.7695 - val_fn: 31.0000 - val_auc: 0.8684 - val_tp: 54.0000 - val_loss: 0.2978 - val_accuracy: 0.8566\n",
      "Epoch 200/350\n",
      "29/28 [==============================] - 22s 768ms/step - fn: 63.0000 - auc: 0.8852 - tp: 469.0000 - loss: 0.4206 - accuracy: 0.7552 - val_fn: 12.0000 - val_auc: 0.8652 - val_tp: 73.0000 - val_loss: 0.4526 - val_accuracy: 0.7527\n",
      "Epoch 201/350\n",
      "29/28 [==============================] - 22s 774ms/step - fn: 56.0000 - auc: 0.8849 - tp: 463.0000 - loss: 0.4166 - accuracy: 0.7632 - val_fn: 14.0000 - val_auc: 0.8648 - val_tp: 70.0000 - val_loss: 0.5088 - val_accuracy: 0.7377\n",
      "Epoch 202/350\n",
      "29/28 [==============================] - 22s 774ms/step - fn: 61.0000 - auc: 0.8878 - tp: 465.0000 - loss: 0.4075 - accuracy: 0.7536 - val_fn: 13.0000 - val_auc: 0.8720 - val_tp: 75.0000 - val_loss: 0.4516 - val_accuracy: 0.7426\n",
      "Epoch 203/350\n",
      "29/28 [==============================] - 22s 769ms/step - fn: 56.0000 - auc: 0.8902 - tp: 468.0000 - loss: 0.4001 - accuracy: 0.7630 - val_fn: 18.0000 - val_auc: 0.8687 - val_tp: 67.0000 - val_loss: 0.3330 - val_accuracy: 0.8016\n",
      "Epoch 204/350\n",
      "29/28 [==============================] - 23s 790ms/step - fn: 67.0000 - auc: 0.8893 - tp: 463.0000 - loss: 0.4024 - accuracy: 0.7557 - val_fn: 28.0000 - val_auc: 0.8725 - val_tp: 57.0000 - val_loss: 0.3043 - val_accuracy: 0.8273\n",
      "Epoch 205/350\n",
      "29/28 [==============================] - 23s 786ms/step - fn: 60.0000 - auc: 0.8907 - tp: 463.0000 - loss: 0.4022 - accuracy: 0.7507 - val_fn: 20.0000 - val_auc: 0.8641 - val_tp: 63.0000 - val_loss: 0.3350 - val_accuracy: 0.8203\n",
      "Epoch 206/350\n",
      "29/28 [==============================] - 21s 736ms/step - fn: 57.0000 - auc: 0.8920 - tp: 473.0000 - loss: 0.4075 - accuracy: 0.7656 - val_fn: 30.0000 - val_auc: 0.8539 - val_tp: 56.0000 - val_loss: 0.3523 - val_accuracy: 0.8314\n",
      "Epoch 207/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 60.0000 - auc: 0.8943 - tp: 470.0000 - loss: 0.3945 - accuracy: 0.7753 - val_fn: 46.0000 - val_auc: 0.8225 - val_tp: 42.0000 - val_loss: 0.2866 - val_accuracy: 0.8586\n",
      "Epoch 208/350\n",
      "29/28 [==============================] - 23s 783ms/step - fn: 45.0000 - auc: 0.8906 - tp: 483.0000 - loss: 0.3959 - accuracy: 0.7568 - val_fn: 21.0000 - val_auc: 0.8731 - val_tp: 65.0000 - val_loss: 0.3582 - val_accuracy: 0.8213\n",
      "Epoch 209/350\n",
      "29/28 [==============================] - 22s 762ms/step - fn: 61.0000 - auc: 0.8925 - tp: 463.0000 - loss: 0.3997 - accuracy: 0.7612 - val_fn: 19.0000 - val_auc: 0.8601 - val_tp: 66.0000 - val_loss: 0.4694 - val_accuracy: 0.7604\n",
      "Epoch 210/350\n",
      "29/28 [==============================] - 23s 776ms/step - fn: 53.0000 - auc: 0.8920 - tp: 476.0000 - loss: 0.3990 - accuracy: 0.7551 - val_fn: 26.0000 - val_auc: 0.8630 - val_tp: 61.0000 - val_loss: 0.3466 - val_accuracy: 0.8213\n",
      "Epoch 211/350\n",
      "29/28 [==============================] - 22s 768ms/step - fn: 48.0000 - auc: 0.8968 - tp: 482.0000 - loss: 0.3886 - accuracy: 0.7594 - val_fn: 29.0000 - val_auc: 0.8623 - val_tp: 54.0000 - val_loss: 0.3056 - val_accuracy: 0.8383\n",
      "Epoch 212/350\n",
      "29/28 [==============================] - 23s 787ms/step - fn: 51.0000 - auc: 0.8950 - tp: 473.0000 - loss: 0.3923 - accuracy: 0.7651 - val_fn: 34.0000 - val_auc: 0.8507 - val_tp: 50.0000 - val_loss: 0.3257 - val_accuracy: 0.8588\n",
      "Epoch 213/350\n",
      "29/28 [==============================] - 22s 750ms/step - fn: 45.0000 - auc: 0.8940 - tp: 488.0000 - loss: 0.3990 - accuracy: 0.7437 - val_fn: 26.0000 - val_auc: 0.8607 - val_tp: 61.0000 - val_loss: 0.3373 - val_accuracy: 0.8146\n",
      "Epoch 214/350\n",
      "29/28 [==============================] - 22s 745ms/step - fn: 47.0000 - auc: 0.8986 - tp: 483.0000 - loss: 0.3898 - accuracy: 0.7630 - val_fn: 24.0000 - val_auc: 0.8620 - val_tp: 62.0000 - val_loss: 0.3217 - val_accuracy: 0.8395\n",
      "Epoch 215/350\n",
      "29/28 [==============================] - 22s 766ms/step - fn: 49.0000 - auc: 0.8934 - tp: 483.0000 - loss: 0.3934 - accuracy: 0.7674 - val_fn: 22.0000 - val_auc: 0.8505 - val_tp: 64.0000 - val_loss: 0.4352 - val_accuracy: 0.7693\n",
      "Epoch 216/350\n",
      "29/28 [==============================] - 23s 789ms/step - fn: 49.0000 - auc: 0.8920 - tp: 484.0000 - loss: 0.3959 - accuracy: 0.7570 - val_fn: 20.0000 - val_auc: 0.8520 - val_tp: 66.0000 - val_loss: 0.4423 - val_accuracy: 0.7785\n",
      "Epoch 217/350\n",
      "29/28 [==============================] - 24s 817ms/step - fn: 40.0000 - auc: 0.8932 - tp: 486.0000 - loss: 0.3940 - accuracy: 0.7591 - val_fn: 12.0000 - val_auc: 0.8697 - val_tp: 73.0000 - val_loss: 0.4495 - val_accuracy: 0.7627\n",
      "Epoch 218/350\n",
      "29/28 [==============================] - 23s 780ms/step - fn: 51.0000 - auc: 0.9080 - tp: 478.0000 - loss: 0.3698 - accuracy: 0.7755 - val_fn: 19.0000 - val_auc: 0.8766 - val_tp: 71.0000 - val_loss: 0.3579 - val_accuracy: 0.8172\n",
      "Epoch 219/350\n",
      "29/28 [==============================] - 22s 766ms/step - fn: 54.0000 - auc: 0.8931 - tp: 468.0000 - loss: 0.4006 - accuracy: 0.7535 - val_fn: 20.0000 - val_auc: 0.8621 - val_tp: 63.0000 - val_loss: 0.3740 - val_accuracy: 0.7824\n",
      "Epoch 220/350\n",
      "29/28 [==============================] - 24s 817ms/step - fn: 60.0000 - auc: 0.8994 - tp: 471.0000 - loss: 0.3888 - accuracy: 0.7786 - val_fn: 19.0000 - val_auc: 0.8787 - val_tp: 64.0000 - val_loss: 0.4093 - val_accuracy: 0.7980\n",
      "Epoch 221/350\n",
      "29/28 [==============================] - 21s 729ms/step - fn: 56.0000 - auc: 0.8960 - tp: 468.0000 - loss: 0.3900 - accuracy: 0.7709 - val_fn: 29.0000 - val_auc: 0.8719 - val_tp: 59.0000 - val_loss: 0.3179 - val_accuracy: 0.8430\n",
      "Epoch 222/350\n",
      "29/28 [==============================] - 22s 771ms/step - fn: 48.0000 - auc: 0.8984 - tp: 479.0000 - loss: 0.3879 - accuracy: 0.7614 - val_fn: 21.0000 - val_auc: 0.8689 - val_tp: 61.0000 - val_loss: 0.3741 - val_accuracy: 0.8219\n",
      "Epoch 223/350\n",
      "29/28 [==============================] - 22s 770ms/step - fn: 42.0000 - auc: 0.8948 - tp: 486.0000 - loss: 0.3954 - accuracy: 0.7548 - val_fn: 34.0000 - val_auc: 0.8670 - val_tp: 53.0000 - val_loss: 0.2769 - val_accuracy: 0.8613\n",
      "Epoch 224/350\n",
      "29/28 [==============================] - 22s 766ms/step - fn: 51.0000 - auc: 0.8996 - tp: 476.0000 - loss: 0.3833 - accuracy: 0.7628 - val_fn: 35.0000 - val_auc: 0.8365 - val_tp: 53.0000 - val_loss: 0.3093 - val_accuracy: 0.8504\n",
      "Epoch 225/350\n",
      "29/28 [==============================] - 22s 757ms/step - fn: 44.0000 - auc: 0.9037 - tp: 481.0000 - loss: 0.3771 - accuracy: 0.7630 - val_fn: 21.0000 - val_auc: 0.8752 - val_tp: 65.0000 - val_loss: 0.3180 - val_accuracy: 0.8375\n",
      "Epoch 226/350\n",
      "29/28 [==============================] - 23s 790ms/step - fn: 50.0000 - auc: 0.9027 - tp: 479.0000 - loss: 0.3800 - accuracy: 0.7772 - val_fn: 17.0000 - val_auc: 0.8577 - val_tp: 69.0000 - val_loss: 0.4091 - val_accuracy: 0.7682\n",
      "Epoch 227/350\n",
      "29/28 [==============================] - 22s 764ms/step - fn: 39.0000 - auc: 0.9049 - tp: 489.0000 - loss: 0.3774 - accuracy: 0.7678 - val_fn: 12.0000 - val_auc: 0.8760 - val_tp: 75.0000 - val_loss: 0.4754 - val_accuracy: 0.7404\n",
      "Epoch 228/350\n",
      "29/28 [==============================] - 24s 842ms/step - fn: 53.0000 - auc: 0.8906 - tp: 476.0000 - loss: 0.4054 - accuracy: 0.7508 - val_fn: 25.0000 - val_auc: 0.8585 - val_tp: 56.0000 - val_loss: 0.3929 - val_accuracy: 0.8193\n",
      "Epoch 229/350\n",
      "29/28 [==============================] - 22s 762ms/step - fn: 50.0000 - auc: 0.8939 - tp: 472.0000 - loss: 0.3927 - accuracy: 0.7678 - val_fn: 21.0000 - val_auc: 0.8732 - val_tp: 67.0000 - val_loss: 0.3864 - val_accuracy: 0.7873\n",
      "Epoch 230/350\n",
      "29/28 [==============================] - 21s 731ms/step - fn: 50.0000 - auc: 0.8964 - tp: 484.0000 - loss: 0.3901 - accuracy: 0.7730 - val_fn: 40.0000 - val_auc: 0.8502 - val_tp: 46.0000 - val_loss: 0.2889 - val_accuracy: 0.8615\n",
      "Epoch 231/350\n",
      "29/28 [==============================] - 21s 729ms/step - fn: 53.0000 - auc: 0.9025 - tp: 475.0000 - loss: 0.3799 - accuracy: 0.7753 - val_fn: 41.0000 - val_auc: 0.8190 - val_tp: 47.0000 - val_loss: 0.3209 - val_accuracy: 0.8781\n",
      "Epoch 232/350\n",
      "29/28 [==============================] - 22s 753ms/step - fn: 64.0000 - auc: 0.8982 - tp: 465.0000 - loss: 0.3906 - accuracy: 0.7751 - val_fn: 29.0000 - val_auc: 0.8638 - val_tp: 60.0000 - val_loss: 0.3518 - val_accuracy: 0.8232\n",
      "Epoch 233/350\n",
      "29/28 [==============================] - 22s 774ms/step - fn: 42.0000 - auc: 0.9035 - tp: 477.0000 - loss: 0.3752 - accuracy: 0.7678 - val_fn: 17.0000 - val_auc: 0.8702 - val_tp: 68.0000 - val_loss: 0.4168 - val_accuracy: 0.7635\n",
      "Epoch 234/350\n",
      "29/28 [==============================] - 23s 790ms/step - fn: 52.0000 - auc: 0.9055 - tp: 478.0000 - loss: 0.3748 - accuracy: 0.7794 - val_fn: 15.0000 - val_auc: 0.8551 - val_tp: 70.0000 - val_loss: 0.4679 - val_accuracy: 0.7402\n",
      "Epoch 235/350\n",
      "29/28 [==============================] - 23s 781ms/step - fn: 63.0000 - auc: 0.9080 - tp: 462.0000 - loss: 0.3758 - accuracy: 0.7904 - val_fn: 24.0000 - val_auc: 0.8524 - val_tp: 61.0000 - val_loss: 0.4361 - val_accuracy: 0.7578\n",
      "Epoch 236/350\n",
      "29/28 [==============================] - 24s 813ms/step - fn: 58.0000 - auc: 0.9105 - tp: 475.0000 - loss: 0.3718 - accuracy: 0.7818 - val_fn: 29.0000 - val_auc: 0.8588 - val_tp: 54.0000 - val_loss: 0.3182 - val_accuracy: 0.8438\n",
      "Epoch 237/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 54.0000 - auc: 0.9081 - tp: 480.0000 - loss: 0.3682 - accuracy: 0.7807 - val_fn: 27.0000 - val_auc: 0.8688 - val_tp: 61.0000 - val_loss: 0.3121 - val_accuracy: 0.8361\n",
      "Epoch 238/350\n",
      "29/28 [==============================] - 22s 770ms/step - fn: 53.0000 - auc: 0.9075 - tp: 467.0000 - loss: 0.3743 - accuracy: 0.7763 - val_fn: 28.0000 - val_auc: 0.8564 - val_tp: 59.0000 - val_loss: 0.3619 - val_accuracy: 0.8221\n",
      "Epoch 239/350\n",
      "29/28 [==============================] - 24s 825ms/step - fn: 45.0000 - auc: 0.8995 - tp: 487.0000 - loss: 0.3803 - accuracy: 0.7626 - val_fn: 21.0000 - val_auc: 0.8866 - val_tp: 63.0000 - val_loss: 0.2957 - val_accuracy: 0.8449\n",
      "Epoch 240/350\n",
      "29/28 [==============================] - 23s 794ms/step - fn: 45.0000 - auc: 0.9074 - tp: 481.0000 - loss: 0.3701 - accuracy: 0.7837 - val_fn: 24.0000 - val_auc: 0.8567 - val_tp: 61.0000 - val_loss: 0.3373 - val_accuracy: 0.8191\n",
      "Epoch 241/350\n",
      "29/28 [==============================] - 22s 763ms/step - fn: 42.0000 - auc: 0.9206 - tp: 485.0000 - loss: 0.3436 - accuracy: 0.8013 - val_fn: 25.0000 - val_auc: 0.8807 - val_tp: 60.0000 - val_loss: 0.3260 - val_accuracy: 0.8428\n",
      "Epoch 242/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 39.0000 - auc: 0.9056 - tp: 484.0000 - loss: 0.3695 - accuracy: 0.7690 - val_fn: 18.0000 - val_auc: 0.8584 - val_tp: 69.0000 - val_loss: 0.3851 - val_accuracy: 0.7928\n",
      "Epoch 243/350\n",
      "29/28 [==============================] - 22s 772ms/step - fn: 52.0000 - auc: 0.9210 - tp: 478.0000 - loss: 0.3474 - accuracy: 0.7894 - val_fn: 21.0000 - val_auc: 0.8613 - val_tp: 66.0000 - val_loss: 0.3334 - val_accuracy: 0.8156\n",
      "Epoch 244/350\n",
      "29/28 [==============================] - 24s 836ms/step - fn: 45.0000 - auc: 0.9150 - tp: 479.0000 - loss: 0.3583 - accuracy: 0.7866 - val_fn: 19.0000 - val_auc: 0.8820 - val_tp: 68.0000 - val_loss: 0.3538 - val_accuracy: 0.8066\n",
      "Epoch 245/350\n",
      "29/28 [==============================] - 22s 757ms/step - fn: 43.0000 - auc: 0.9100 - tp: 481.0000 - loss: 0.3614 - accuracy: 0.7701 - val_fn: 27.0000 - val_auc: 0.8461 - val_tp: 63.0000 - val_loss: 0.3841 - val_accuracy: 0.7924\n",
      "Epoch 246/350\n",
      "29/28 [==============================] - 22s 766ms/step - fn: 42.0000 - auc: 0.9129 - tp: 481.0000 - loss: 0.3611 - accuracy: 0.7906 - val_fn: 35.0000 - val_auc: 0.8449 - val_tp: 53.0000 - val_loss: 0.3250 - val_accuracy: 0.8410\n",
      "Epoch 247/350\n",
      "29/28 [==============================] - 22s 771ms/step - fn: 65.0000 - auc: 0.8912 - tp: 465.0000 - loss: 0.4058 - accuracy: 0.7578 - val_fn: 28.0000 - val_auc: 0.8504 - val_tp: 57.0000 - val_loss: 0.3539 - val_accuracy: 0.8182\n",
      "Epoch 248/350\n",
      "29/28 [==============================] - 22s 758ms/step - fn: 63.0000 - auc: 0.9066 - tp: 470.0000 - loss: 0.3793 - accuracy: 0.7866 - val_fn: 29.0000 - val_auc: 0.8604 - val_tp: 56.0000 - val_loss: 0.2983 - val_accuracy: 0.8514\n",
      "Epoch 249/350\n",
      "29/28 [==============================] - 23s 802ms/step - fn: 45.0000 - auc: 0.9071 - tp: 482.0000 - loss: 0.3721 - accuracy: 0.7792 - val_fn: 26.0000 - val_auc: 0.8781 - val_tp: 61.0000 - val_loss: 0.3032 - val_accuracy: 0.8514\n",
      "Epoch 250/350\n",
      "29/28 [==============================] - 21s 728ms/step - fn: 44.0000 - auc: 0.9142 - tp: 484.0000 - loss: 0.3537 - accuracy: 0.7987 - val_fn: 16.0000 - val_auc: 0.8852 - val_tp: 70.0000 - val_loss: 0.3880 - val_accuracy: 0.8012\n",
      "Epoch 251/350\n",
      "29/28 [==============================] - 24s 814ms/step - fn: 43.0000 - auc: 0.9145 - tp: 486.0000 - loss: 0.3563 - accuracy: 0.7858 - val_fn: 20.0000 - val_auc: 0.8597 - val_tp: 66.0000 - val_loss: 0.3762 - val_accuracy: 0.7967\n",
      "Epoch 252/350\n",
      "29/28 [==============================] - 22s 766ms/step - fn: 54.0000 - auc: 0.9139 - tp: 478.0000 - loss: 0.3581 - accuracy: 0.7950 - val_fn: 12.0000 - val_auc: 0.8700 - val_tp: 75.0000 - val_loss: 0.4720 - val_accuracy: 0.7570\n",
      "Epoch 253/350\n",
      "29/28 [==============================] - 22s 750ms/step - fn: 51.0000 - auc: 0.8980 - tp: 475.0000 - loss: 0.3880 - accuracy: 0.7689 - val_fn: 9.0000 - val_auc: 0.8541 - val_tp: 77.0000 - val_loss: 0.7104 - val_accuracy: 0.6506\n",
      "Epoch 254/350\n",
      "29/28 [==============================] - 22s 768ms/step - fn: 47.0000 - auc: 0.8965 - tp: 480.0000 - loss: 0.3890 - accuracy: 0.7735 - val_fn: 14.0000 - val_auc: 0.8699 - val_tp: 72.0000 - val_loss: 0.4896 - val_accuracy: 0.7502\n",
      "Epoch 255/350\n",
      "29/28 [==============================] - 23s 784ms/step - fn: 47.0000 - auc: 0.9017 - tp: 480.0000 - loss: 0.3847 - accuracy: 0.7758 - val_fn: 9.0000 - val_auc: 0.8723 - val_tp: 76.0000 - val_loss: 0.5917 - val_accuracy: 0.7121\n",
      "Epoch 256/350\n",
      "29/28 [==============================] - 23s 809ms/step - fn: 47.0000 - auc: 0.8958 - tp: 487.0000 - loss: 0.3911 - accuracy: 0.7679 - val_fn: 17.0000 - val_auc: 0.8634 - val_tp: 72.0000 - val_loss: 0.4693 - val_accuracy: 0.7670\n",
      "Epoch 257/350\n",
      "29/28 [==============================] - 21s 722ms/step - fn: 45.0000 - auc: 0.9148 - tp: 485.0000 - loss: 0.3596 - accuracy: 0.7950 - val_fn: 33.0000 - val_auc: 0.8777 - val_tp: 51.0000 - val_loss: 0.2991 - val_accuracy: 0.8639\n",
      "Epoch 258/350\n",
      "29/28 [==============================] - 22s 764ms/step - fn: 46.0000 - auc: 0.9150 - tp: 481.0000 - loss: 0.3575 - accuracy: 0.7904 - val_fn: 18.0000 - val_auc: 0.8701 - val_tp: 66.0000 - val_loss: 0.3798 - val_accuracy: 0.7930\n",
      "Epoch 259/350\n",
      "29/28 [==============================] - 23s 801ms/step - fn: 46.0000 - auc: 0.9177 - tp: 482.0000 - loss: 0.3531 - accuracy: 0.7933 - val_fn: 33.0000 - val_auc: 0.8598 - val_tp: 51.0000 - val_loss: 0.2955 - val_accuracy: 0.8656\n",
      "Epoch 260/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 36.0000 - auc: 0.9158 - tp: 487.0000 - loss: 0.3548 - accuracy: 0.7880 - val_fn: 40.0000 - val_auc: 0.8693 - val_tp: 47.0000 - val_loss: 0.2901 - val_accuracy: 0.8711\n",
      "Epoch 261/350\n",
      "29/28 [==============================] - 22s 750ms/step - fn: 43.0000 - auc: 0.9147 - tp: 487.0000 - loss: 0.3571 - accuracy: 0.7884 - val_fn: 39.0000 - val_auc: 0.8649 - val_tp: 52.0000 - val_loss: 0.2849 - val_accuracy: 0.8688\n",
      "Epoch 262/350\n",
      "29/28 [==============================] - 22s 768ms/step - fn: 46.0000 - auc: 0.9188 - tp: 477.0000 - loss: 0.3506 - accuracy: 0.7960 - val_fn: 26.0000 - val_auc: 0.8798 - val_tp: 60.0000 - val_loss: 0.3186 - val_accuracy: 0.8482\n",
      "Epoch 263/350\n",
      "29/28 [==============================] - 22s 763ms/step - fn: 45.0000 - auc: 0.9209 - tp: 488.0000 - loss: 0.3521 - accuracy: 0.7982 - val_fn: 33.0000 - val_auc: 0.8723 - val_tp: 54.0000 - val_loss: 0.2752 - val_accuracy: 0.8609\n",
      "Epoch 264/350\n",
      "29/28 [==============================] - 23s 776ms/step - fn: 46.0000 - auc: 0.9197 - tp: 482.0000 - loss: 0.3471 - accuracy: 0.8016 - val_fn: 32.0000 - val_auc: 0.8682 - val_tp: 55.0000 - val_loss: 0.3083 - val_accuracy: 0.8555\n",
      "Epoch 265/350\n",
      "29/28 [==============================] - 22s 768ms/step - fn: 46.0000 - auc: 0.9214 - tp: 476.0000 - loss: 0.3438 - accuracy: 0.7968 - val_fn: 18.0000 - val_auc: 0.8518 - val_tp: 70.0000 - val_loss: 0.4411 - val_accuracy: 0.7498\n",
      "Epoch 266/350\n",
      "29/28 [==============================] - 22s 757ms/step - fn: 49.0000 - auc: 0.9126 - tp: 478.0000 - loss: 0.3598 - accuracy: 0.7876 - val_fn: 33.0000 - val_auc: 0.8618 - val_tp: 56.0000 - val_loss: 0.2774 - val_accuracy: 0.8670\n",
      "Epoch 267/350\n",
      "29/28 [==============================] - 23s 785ms/step - fn: 42.0000 - auc: 0.9220 - tp: 486.0000 - loss: 0.3403 - accuracy: 0.7990 - val_fn: 32.0000 - val_auc: 0.8683 - val_tp: 51.0000 - val_loss: 0.2664 - val_accuracy: 0.8600\n",
      "Epoch 268/350\n",
      "29/28 [==============================] - 22s 768ms/step - fn: 50.0000 - auc: 0.9101 - tp: 483.0000 - loss: 0.3716 - accuracy: 0.7828 - val_fn: 35.0000 - val_auc: 0.8661 - val_tp: 54.0000 - val_loss: 0.2807 - val_accuracy: 0.8633\n",
      "Epoch 269/350\n",
      "29/28 [==============================] - 22s 743ms/step - fn: 47.0000 - auc: 0.9175 - tp: 476.0000 - loss: 0.3550 - accuracy: 0.8053 - val_fn: 32.0000 - val_auc: 0.8586 - val_tp: 54.0000 - val_loss: 0.3433 - val_accuracy: 0.8379\n",
      "Epoch 270/350\n",
      "29/28 [==============================] - 23s 779ms/step - fn: 42.0000 - auc: 0.9132 - tp: 488.0000 - loss: 0.3626 - accuracy: 0.7838 - val_fn: 18.0000 - val_auc: 0.8697 - val_tp: 67.0000 - val_loss: 0.4276 - val_accuracy: 0.7814\n",
      "Epoch 271/350\n",
      "29/28 [==============================] - 22s 771ms/step - fn: 59.0000 - auc: 0.9162 - tp: 469.0000 - loss: 0.3582 - accuracy: 0.8135 - val_fn: 21.0000 - val_auc: 0.8687 - val_tp: 68.0000 - val_loss: 0.4185 - val_accuracy: 0.7975\n",
      "Epoch 272/350\n",
      "29/28 [==============================] - 23s 781ms/step - fn: 34.0000 - auc: 0.9154 - tp: 495.0000 - loss: 0.3532 - accuracy: 0.7812 - val_fn: 28.0000 - val_auc: 0.8618 - val_tp: 58.0000 - val_loss: 0.2998 - val_accuracy: 0.8502\n",
      "Epoch 273/350\n",
      "29/28 [==============================] - 23s 785ms/step - fn: 44.0000 - auc: 0.9207 - tp: 476.0000 - loss: 0.3366 - accuracy: 0.7941 - val_fn: 24.0000 - val_auc: 0.8725 - val_tp: 55.0000 - val_loss: 0.2895 - val_accuracy: 0.8695\n",
      "Epoch 274/350\n",
      "29/28 [==============================] - 22s 747ms/step - fn: 43.0000 - auc: 0.9200 - tp: 488.0000 - loss: 0.3457 - accuracy: 0.7941 - val_fn: 31.0000 - val_auc: 0.8702 - val_tp: 55.0000 - val_loss: 0.2913 - val_accuracy: 0.8496\n",
      "Epoch 275/350\n",
      "29/28 [==============================] - 23s 802ms/step - fn: 34.0000 - auc: 0.9252 - tp: 496.0000 - loss: 0.3346 - accuracy: 0.8055 - val_fn: 25.0000 - val_auc: 0.8698 - val_tp: 65.0000 - val_loss: 0.3472 - val_accuracy: 0.8225\n",
      "Epoch 276/350\n",
      "29/28 [==============================] - 21s 721ms/step - fn: 44.0000 - auc: 0.9216 - tp: 480.0000 - loss: 0.3408 - accuracy: 0.8005 - val_fn: 25.0000 - val_auc: 0.8770 - val_tp: 58.0000 - val_loss: 0.3029 - val_accuracy: 0.8576\n",
      "Epoch 277/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 53.0000 - auc: 0.9051 - tp: 477.0000 - loss: 0.3853 - accuracy: 0.7821 - val_fn: 17.0000 - val_auc: 0.8624 - val_tp: 65.0000 - val_loss: 0.4057 - val_accuracy: 0.7994\n",
      "Epoch 278/350\n",
      "29/28 [==============================] - 24s 810ms/step - fn: 43.0000 - auc: 0.9202 - tp: 484.0000 - loss: 0.3493 - accuracy: 0.7996 - val_fn: 26.0000 - val_auc: 0.8560 - val_tp: 60.0000 - val_loss: 0.3799 - val_accuracy: 0.8227\n",
      "Epoch 279/350\n",
      "29/28 [==============================] - 23s 779ms/step - fn: 43.0000 - auc: 0.9242 - tp: 488.0000 - loss: 0.3383 - accuracy: 0.8002 - val_fn: 24.0000 - val_auc: 0.8705 - val_tp: 60.0000 - val_loss: 0.3550 - val_accuracy: 0.8256\n",
      "Epoch 280/350\n",
      "29/28 [==============================] - 22s 764ms/step - fn: 37.0000 - auc: 0.9318 - tp: 494.0000 - loss: 0.3230 - accuracy: 0.8157 - val_fn: 25.0000 - val_auc: 0.8831 - val_tp: 58.0000 - val_loss: 0.3031 - val_accuracy: 0.8494\n",
      "Epoch 281/350\n",
      "29/28 [==============================] - 22s 770ms/step - fn: 42.0000 - auc: 0.9282 - tp: 483.0000 - loss: 0.3244 - accuracy: 0.8147 - val_fn: 33.0000 - val_auc: 0.8586 - val_tp: 54.0000 - val_loss: 0.3284 - val_accuracy: 0.8486\n",
      "Epoch 282/350\n",
      "29/28 [==============================] - 22s 746ms/step - fn: 45.0000 - auc: 0.9194 - tp: 478.0000 - loss: 0.3486 - accuracy: 0.7988 - val_fn: 19.0000 - val_auc: 0.8838 - val_tp: 70.0000 - val_loss: 0.3671 - val_accuracy: 0.8068\n",
      "Epoch 283/350\n",
      "29/28 [==============================] - 23s 785ms/step - fn: 43.0000 - auc: 0.9032 - tp: 482.0000 - loss: 0.3725 - accuracy: 0.7686 - val_fn: 20.0000 - val_auc: 0.8433 - val_tp: 65.0000 - val_loss: 0.4248 - val_accuracy: 0.7668\n",
      "Epoch 284/350\n",
      "29/28 [==============================] - 23s 784ms/step - fn: 34.0000 - auc: 0.9132 - tp: 499.0000 - loss: 0.3533 - accuracy: 0.7758 - val_fn: 21.0000 - val_auc: 0.8459 - val_tp: 66.0000 - val_loss: 0.3420 - val_accuracy: 0.8055\n",
      "Epoch 285/350\n",
      "29/28 [==============================] - 22s 744ms/step - fn: 41.0000 - auc: 0.9125 - tp: 480.0000 - loss: 0.3563 - accuracy: 0.7807 - val_fn: 19.0000 - val_auc: 0.8607 - val_tp: 68.0000 - val_loss: 0.3914 - val_accuracy: 0.7742\n",
      "Epoch 286/350\n",
      "29/28 [==============================] - 23s 803ms/step - fn: 37.0000 - auc: 0.9142 - tp: 489.0000 - loss: 0.3490 - accuracy: 0.7753 - val_fn: 25.0000 - val_auc: 0.8543 - val_tp: 64.0000 - val_loss: 0.3633 - val_accuracy: 0.8205\n",
      "Epoch 287/350\n",
      "29/28 [==============================] - 23s 784ms/step - fn: 52.0000 - auc: 0.9083 - tp: 472.0000 - loss: 0.3711 - accuracy: 0.7779 - val_fn: 30.0000 - val_auc: 0.8619 - val_tp: 55.0000 - val_loss: 0.2867 - val_accuracy: 0.8613\n",
      "Epoch 288/350\n",
      "29/28 [==============================] - 22s 748ms/step - fn: 42.0000 - auc: 0.9200 - tp: 487.0000 - loss: 0.3440 - accuracy: 0.8062 - val_fn: 27.0000 - val_auc: 0.8567 - val_tp: 62.0000 - val_loss: 0.3324 - val_accuracy: 0.8375\n",
      "Epoch 289/350\n",
      "29/28 [==============================] - 23s 776ms/step - fn: 39.0000 - auc: 0.9203 - tp: 493.0000 - loss: 0.3479 - accuracy: 0.7950 - val_fn: 42.0000 - val_auc: 0.8586 - val_tp: 45.0000 - val_loss: 0.2239 - val_accuracy: 0.8914\n",
      "Epoch 290/350\n",
      "29/28 [==============================] - 21s 741ms/step - fn: 43.0000 - auc: 0.9171 - tp: 480.0000 - loss: 0.3485 - accuracy: 0.7919 - val_fn: 26.0000 - val_auc: 0.8659 - val_tp: 62.0000 - val_loss: 0.3232 - val_accuracy: 0.8287\n",
      "Epoch 291/350\n",
      "29/28 [==============================] - 23s 800ms/step - fn: 37.0000 - auc: 0.9261 - tp: 495.0000 - loss: 0.3288 - accuracy: 0.8141 - val_fn: 39.0000 - val_auc: 0.8394 - val_tp: 46.0000 - val_loss: 0.2766 - val_accuracy: 0.8672\n",
      "Epoch 292/350\n",
      "29/28 [==============================] - 22s 774ms/step - fn: 35.0000 - auc: 0.9241 - tp: 495.0000 - loss: 0.3386 - accuracy: 0.8070 - val_fn: 28.0000 - val_auc: 0.8641 - val_tp: 62.0000 - val_loss: 0.3430 - val_accuracy: 0.8328\n",
      "Epoch 293/350\n",
      "29/28 [==============================] - 23s 806ms/step - fn: 44.0000 - auc: 0.9225 - tp: 482.0000 - loss: 0.3394 - accuracy: 0.8078 - val_fn: 25.0000 - val_auc: 0.8614 - val_tp: 58.0000 - val_loss: 0.3289 - val_accuracy: 0.8320\n",
      "Epoch 294/350\n",
      "29/28 [==============================] - 22s 745ms/step - fn: 47.0000 - auc: 0.9287 - tp: 478.0000 - loss: 0.3335 - accuracy: 0.8169 - val_fn: 34.0000 - val_auc: 0.8592 - val_tp: 55.0000 - val_loss: 0.2731 - val_accuracy: 0.8717\n",
      "Epoch 295/350\n",
      "29/28 [==============================] - 23s 797ms/step - fn: 36.0000 - auc: 0.9290 - tp: 498.0000 - loss: 0.3262 - accuracy: 0.8121 - val_fn: 23.0000 - val_auc: 0.8659 - val_tp: 64.0000 - val_loss: 0.3792 - val_accuracy: 0.8061\n",
      "Epoch 296/350\n",
      "29/28 [==============================] - 22s 767ms/step - fn: 31.0000 - auc: 0.9306 - tp: 495.0000 - loss: 0.3254 - accuracy: 0.8064 - val_fn: 22.0000 - val_auc: 0.8574 - val_tp: 69.0000 - val_loss: 0.3502 - val_accuracy: 0.8238\n",
      "Epoch 297/350\n",
      "29/28 [==============================] - 22s 770ms/step - fn: 35.0000 - auc: 0.9326 - tp: 504.0000 - loss: 0.3215 - accuracy: 0.8133 - val_fn: 38.0000 - val_auc: 0.8701 - val_tp: 51.0000 - val_loss: 0.2713 - val_accuracy: 0.8715\n",
      "Epoch 298/350\n",
      "29/28 [==============================] - 23s 782ms/step - fn: 40.0000 - auc: 0.9302 - tp: 490.0000 - loss: 0.3242 - accuracy: 0.8176 - val_fn: 28.0000 - val_auc: 0.8564 - val_tp: 57.0000 - val_loss: 0.3849 - val_accuracy: 0.8176\n",
      "Epoch 299/350\n",
      "29/28 [==============================] - 22s 771ms/step - fn: 42.0000 - auc: 0.9259 - tp: 483.0000 - loss: 0.3364 - accuracy: 0.8137 - val_fn: 21.0000 - val_auc: 0.8565 - val_tp: 64.0000 - val_loss: 0.4838 - val_accuracy: 0.7842\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', #val_auc\n",
    "                                patience=60,\n",
    "                                mode='max',\n",
    "                                restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "#     batch_size=params['batch_size'],\n",
    "    epochs= params['epochs'], \n",
    "    steps_per_epoch=epoch_steps,\n",
    "    validation_data=valid_ds,\n",
    "    validation_steps=valid_steps,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:40:23.340649Z",
     "iopub.status.busy": "2020-08-11T07:40:23.311713Z",
     "iopub.status.idle": "2020-08-11T07:41:14.559019Z",
     "shell.execute_reply": "2020-08-11T07:41:14.558313Z"
    },
    "papermill": {
     "duration": 51.905754,
     "end_time": "2020-08-11T07:41:14.559174",
     "exception": false,
     "start_time": "2020-08-11T07:40:22.653420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_ds.map(lambda img, igs: img), steps=test_steps)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:41:15.916385Z",
     "iopub.status.busy": "2020-08-11T07:41:15.915608Z",
     "iopub.status.idle": "2020-08-11T07:41:20.292077Z",
     "shell.execute_reply": "2020-08-11T07:41:20.292715Z"
    },
    "papermill": {
     "duration": 5.028378,
     "end_time": "2020-08-11T07:41:20.292891",
     "exception": false,
     "start_time": "2020-08-11T07:41:15.264513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7fefcd9ca3b0> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "                          map(lambda img, ids:ids).\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction_ids = next(iter(test_ds.\n",
    "                          map(lambda img, ids:ids).\n",
    "                          unbatch().\n",
    "                          batch(test_size))).numpy().astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:41:21.658465Z",
     "iopub.status.busy": "2020-08-11T07:41:21.657673Z",
     "iopub.status.idle": "2020-08-11T07:41:21.672034Z",
     "shell.execute_reply": "2020-08-11T07:41:21.671356Z"
    },
    "papermill": {
     "duration": 0.667521,
     "end_time": "2020-08-11T07:41:21.672183",
     "exception": false,
     "start_time": "2020-08-11T07:41:21.004662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_dict = {\n",
    "    'image_name': prediction_ids,\n",
    "    'target': np.concatenate(predictions)\n",
    "}\n",
    "submission_ds = pd.DataFrame(prediction_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:41:23.013130Z",
     "iopub.status.busy": "2020-08-11T07:41:23.012113Z",
     "iopub.status.idle": "2020-08-11T07:41:23.017143Z",
     "shell.execute_reply": "2020-08-11T07:41:23.016339Z"
    },
    "papermill": {
     "duration": 0.709024,
     "end_time": "2020-08-11T07:41:23.017299",
     "exception": false,
     "start_time": "2020-08-11T07:41:22.308275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6381819</td>\n",
       "      <td>0.565404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_5583376</td>\n",
       "      <td>0.796683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_6408546</td>\n",
       "      <td>0.012651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_6932354</td>\n",
       "      <td>0.138173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_8191278</td>\n",
       "      <td>0.683800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name    target\n",
       "0  ISIC_6381819  0.565404\n",
       "1  ISIC_5583376  0.796683\n",
       "2  ISIC_6408546  0.012651\n",
       "3  ISIC_6932354  0.138173\n",
       "4  ISIC_8191278  0.683800"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:41:24.329095Z",
     "iopub.status.busy": "2020-08-11T07:41:24.328120Z",
     "iopub.status.idle": "2020-08-11T07:41:24.394196Z",
     "shell.execute_reply": "2020-08-11T07:41:24.393409Z"
    },
    "papermill": {
     "duration": 0.700405,
     "end_time": "2020-08-11T07:41:24.394323",
     "exception": false,
     "start_time": "2020-08-11T07:41:23.693918",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_ds.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.635954,
     "end_time": "2020-08-11T07:41:25.728125",
     "exception": false,
     "start_time": "2020-08-11T07:41:25.092171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:41:27.006130Z",
     "iopub.status.busy": "2020-08-11T07:41:27.005064Z",
     "iopub.status.idle": "2020-08-11T07:41:27.008724Z",
     "shell.execute_reply": "2020-08-11T07:41:27.007970Z"
    },
    "papermill": {
     "duration": 0.645972,
     "end_time": "2020-08-11T07:41:27.008850",
     "exception": false,
     "start_time": "2020-08-11T07:41:26.362878",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_metric(metric1, metric2, ylabel):\n",
    "    plt.plot(history.history[metric1], label=metric1)\n",
    "    plt.plot(history.history[metric2], label=metric2)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:41:28.352965Z",
     "iopub.status.busy": "2020-08-11T07:41:28.352196Z",
     "iopub.status.idle": "2020-08-11T07:41:29.026136Z",
     "shell.execute_reply": "2020-08-11T07:41:29.026791Z"
    },
    "papermill": {
     "duration": 1.315442,
     "end_time": "2020-08-11T07:41:29.026973",
     "exception": false,
     "start_time": "2020-08-11T07:41:27.711531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('auc', 'val_auc', 'auc')\n",
    "plot_metric('loss', 'val_loss', 'loss')\n",
    "plot_metric('accuracy', 'val_accuracy', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:41:30.467664Z",
     "iopub.status.busy": "2020-08-11T07:41:30.458442Z",
     "iopub.status.idle": "2020-08-11T07:41:30.477171Z",
     "shell.execute_reply": "2020-08-11T07:41:30.477873Z"
    },
    "papermill": {
     "duration": 0.694758,
     "end_time": "2020-08-11T07:41:30.478052",
     "exception": false,
     "start_time": "2020-08-11T07:41:29.783294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fn': [516.0,\n",
       "  213.0,\n",
       "  160.0,\n",
       "  154.0,\n",
       "  169.0,\n",
       "  181.0,\n",
       "  142.0,\n",
       "  165.0,\n",
       "  171.0,\n",
       "  188.0,\n",
       "  169.0,\n",
       "  147.0,\n",
       "  134.0,\n",
       "  152.0,\n",
       "  137.0,\n",
       "  154.0,\n",
       "  125.0,\n",
       "  136.0,\n",
       "  150.0,\n",
       "  151.0,\n",
       "  123.0,\n",
       "  142.0,\n",
       "  132.0,\n",
       "  127.0,\n",
       "  124.0,\n",
       "  124.0,\n",
       "  110.0,\n",
       "  118.0,\n",
       "  130.0,\n",
       "  152.0,\n",
       "  150.0,\n",
       "  132.0,\n",
       "  124.0,\n",
       "  119.0,\n",
       "  134.0,\n",
       "  98.0,\n",
       "  119.0,\n",
       "  101.0,\n",
       "  116.0,\n",
       "  125.0,\n",
       "  108.0,\n",
       "  112.0,\n",
       "  99.0,\n",
       "  101.0,\n",
       "  103.0,\n",
       "  96.0,\n",
       "  91.0,\n",
       "  97.0,\n",
       "  88.0,\n",
       "  92.0,\n",
       "  76.0,\n",
       "  97.0,\n",
       "  87.0,\n",
       "  89.0,\n",
       "  76.0,\n",
       "  87.0,\n",
       "  88.0,\n",
       "  71.0,\n",
       "  87.0,\n",
       "  81.0,\n",
       "  79.0,\n",
       "  88.0,\n",
       "  62.0,\n",
       "  80.0,\n",
       "  67.0,\n",
       "  73.0,\n",
       "  75.0,\n",
       "  84.0,\n",
       "  79.0,\n",
       "  88.0,\n",
       "  77.0,\n",
       "  62.0,\n",
       "  79.0,\n",
       "  68.0,\n",
       "  64.0,\n",
       "  90.0,\n",
       "  79.0,\n",
       "  72.0,\n",
       "  73.0,\n",
       "  78.0,\n",
       "  68.0,\n",
       "  78.0,\n",
       "  79.0,\n",
       "  79.0,\n",
       "  63.0,\n",
       "  77.0,\n",
       "  63.0,\n",
       "  62.0,\n",
       "  52.0,\n",
       "  65.0,\n",
       "  70.0,\n",
       "  66.0,\n",
       "  70.0,\n",
       "  54.0,\n",
       "  63.0,\n",
       "  66.0,\n",
       "  76.0,\n",
       "  75.0,\n",
       "  73.0,\n",
       "  81.0,\n",
       "  77.0,\n",
       "  74.0,\n",
       "  76.0,\n",
       "  79.0,\n",
       "  87.0,\n",
       "  80.0,\n",
       "  84.0,\n",
       "  82.0,\n",
       "  78.0,\n",
       "  76.0,\n",
       "  95.0,\n",
       "  75.0,\n",
       "  79.0,\n",
       "  92.0,\n",
       "  80.0,\n",
       "  78.0,\n",
       "  91.0,\n",
       "  68.0,\n",
       "  88.0,\n",
       "  89.0,\n",
       "  75.0,\n",
       "  75.0,\n",
       "  74.0,\n",
       "  90.0,\n",
       "  52.0,\n",
       "  77.0,\n",
       "  64.0,\n",
       "  67.0,\n",
       "  66.0,\n",
       "  77.0,\n",
       "  69.0,\n",
       "  77.0,\n",
       "  66.0,\n",
       "  67.0,\n",
       "  82.0,\n",
       "  77.0,\n",
       "  73.0,\n",
       "  68.0,\n",
       "  58.0,\n",
       "  72.0,\n",
       "  69.0,\n",
       "  79.0,\n",
       "  60.0,\n",
       "  78.0,\n",
       "  78.0,\n",
       "  64.0,\n",
       "  71.0,\n",
       "  68.0,\n",
       "  82.0,\n",
       "  68.0,\n",
       "  61.0,\n",
       "  58.0,\n",
       "  61.0,\n",
       "  54.0,\n",
       "  65.0,\n",
       "  69.0,\n",
       "  65.0,\n",
       "  74.0,\n",
       "  65.0,\n",
       "  71.0,\n",
       "  80.0,\n",
       "  57.0,\n",
       "  62.0,\n",
       "  56.0,\n",
       "  61.0,\n",
       "  85.0,\n",
       "  56.0,\n",
       "  68.0,\n",
       "  69.0,\n",
       "  80.0,\n",
       "  55.0,\n",
       "  70.0,\n",
       "  65.0,\n",
       "  79.0,\n",
       "  66.0,\n",
       "  68.0,\n",
       "  65.0,\n",
       "  70.0,\n",
       "  63.0,\n",
       "  78.0,\n",
       "  57.0,\n",
       "  56.0,\n",
       "  65.0,\n",
       "  58.0,\n",
       "  70.0,\n",
       "  64.0,\n",
       "  62.0,\n",
       "  56.0,\n",
       "  53.0,\n",
       "  71.0,\n",
       "  55.0,\n",
       "  54.0,\n",
       "  63.0,\n",
       "  67.0,\n",
       "  64.0,\n",
       "  61.0,\n",
       "  72.0,\n",
       "  63.0,\n",
       "  60.0,\n",
       "  63.0,\n",
       "  56.0,\n",
       "  61.0,\n",
       "  56.0,\n",
       "  67.0,\n",
       "  60.0,\n",
       "  57.0,\n",
       "  60.0,\n",
       "  45.0,\n",
       "  61.0,\n",
       "  53.0,\n",
       "  48.0,\n",
       "  51.0,\n",
       "  45.0,\n",
       "  47.0,\n",
       "  49.0,\n",
       "  49.0,\n",
       "  40.0,\n",
       "  51.0,\n",
       "  54.0,\n",
       "  60.0,\n",
       "  56.0,\n",
       "  48.0,\n",
       "  42.0,\n",
       "  51.0,\n",
       "  44.0,\n",
       "  50.0,\n",
       "  39.0,\n",
       "  53.0,\n",
       "  50.0,\n",
       "  50.0,\n",
       "  53.0,\n",
       "  64.0,\n",
       "  42.0,\n",
       "  52.0,\n",
       "  63.0,\n",
       "  58.0,\n",
       "  54.0,\n",
       "  53.0,\n",
       "  45.0,\n",
       "  45.0,\n",
       "  42.0,\n",
       "  39.0,\n",
       "  52.0,\n",
       "  45.0,\n",
       "  43.0,\n",
       "  42.0,\n",
       "  65.0,\n",
       "  63.0,\n",
       "  45.0,\n",
       "  44.0,\n",
       "  43.0,\n",
       "  54.0,\n",
       "  51.0,\n",
       "  47.0,\n",
       "  47.0,\n",
       "  47.0,\n",
       "  45.0,\n",
       "  46.0,\n",
       "  46.0,\n",
       "  36.0,\n",
       "  43.0,\n",
       "  46.0,\n",
       "  45.0,\n",
       "  46.0,\n",
       "  46.0,\n",
       "  49.0,\n",
       "  42.0,\n",
       "  50.0,\n",
       "  47.0,\n",
       "  42.0,\n",
       "  59.0,\n",
       "  34.0,\n",
       "  44.0,\n",
       "  43.0,\n",
       "  34.0,\n",
       "  44.0,\n",
       "  53.0,\n",
       "  43.0,\n",
       "  43.0,\n",
       "  37.0,\n",
       "  42.0,\n",
       "  45.0,\n",
       "  43.0,\n",
       "  34.0,\n",
       "  41.0,\n",
       "  37.0,\n",
       "  52.0,\n",
       "  42.0,\n",
       "  39.0,\n",
       "  43.0,\n",
       "  37.0,\n",
       "  35.0,\n",
       "  44.0,\n",
       "  47.0,\n",
       "  36.0,\n",
       "  31.0,\n",
       "  35.0,\n",
       "  40.0,\n",
       "  42.0],\n",
       " 'auc': [0.6083309054374695,\n",
       "  0.6790660619735718,\n",
       "  0.7383288145065308,\n",
       "  0.7179258465766907,\n",
       "  0.7090834975242615,\n",
       "  0.7194247841835022,\n",
       "  0.7119327783584595,\n",
       "  0.7042341828346252,\n",
       "  0.701616644859314,\n",
       "  0.6942099928855896,\n",
       "  0.7262381315231323,\n",
       "  0.729934573173523,\n",
       "  0.7505750060081482,\n",
       "  0.7391365766525269,\n",
       "  0.745758056640625,\n",
       "  0.7378560304641724,\n",
       "  0.7724617719650269,\n",
       "  0.7625585794448853,\n",
       "  0.7337700128555298,\n",
       "  0.7496841549873352,\n",
       "  0.7661212682723999,\n",
       "  0.7444201111793518,\n",
       "  0.7422984838485718,\n",
       "  0.7407417893409729,\n",
       "  0.759244978427887,\n",
       "  0.748073935508728,\n",
       "  0.7718010544776917,\n",
       "  0.7642238140106201,\n",
       "  0.7626884579658508,\n",
       "  0.7560986280441284,\n",
       "  0.7419670820236206,\n",
       "  0.7490161657333374,\n",
       "  0.7613731026649475,\n",
       "  0.7696998119354248,\n",
       "  0.7657912969589233,\n",
       "  0.7655653357505798,\n",
       "  0.7797625064849854,\n",
       "  0.7745290994644165,\n",
       "  0.774008572101593,\n",
       "  0.7700762152671814,\n",
       "  0.7835786938667297,\n",
       "  0.7769131660461426,\n",
       "  0.7923370599746704,\n",
       "  0.7837727069854736,\n",
       "  0.7858861684799194,\n",
       "  0.7804130911827087,\n",
       "  0.782069742679596,\n",
       "  0.7897387146949768,\n",
       "  0.7778519988059998,\n",
       "  0.7710921764373779,\n",
       "  0.7833031415939331,\n",
       "  0.7938112020492554,\n",
       "  0.7860935926437378,\n",
       "  0.7753826379776001,\n",
       "  0.7902350425720215,\n",
       "  0.7675654888153076,\n",
       "  0.7898232936859131,\n",
       "  0.7860015630722046,\n",
       "  0.7922430634498596,\n",
       "  0.8024994730949402,\n",
       "  0.801685094833374,\n",
       "  0.8088901042938232,\n",
       "  0.7978245615959167,\n",
       "  0.810202956199646,\n",
       "  0.8076306581497192,\n",
       "  0.8083152770996094,\n",
       "  0.8023279905319214,\n",
       "  0.8033215403556824,\n",
       "  0.8086225986480713,\n",
       "  0.8039270639419556,\n",
       "  0.812233030796051,\n",
       "  0.8157215118408203,\n",
       "  0.816974401473999,\n",
       "  0.8244261741638184,\n",
       "  0.8199767470359802,\n",
       "  0.8092467188835144,\n",
       "  0.8231942057609558,\n",
       "  0.8186754584312439,\n",
       "  0.8270331621170044,\n",
       "  0.8217807412147522,\n",
       "  0.8353770971298218,\n",
       "  0.8257195353507996,\n",
       "  0.8207243084907532,\n",
       "  0.8125876188278198,\n",
       "  0.8227494359016418,\n",
       "  0.802466630935669,\n",
       "  0.8116396069526672,\n",
       "  0.8050417304039001,\n",
       "  0.8147230744361877,\n",
       "  0.8096982836723328,\n",
       "  0.8142998218536377,\n",
       "  0.8279446959495544,\n",
       "  0.8138773441314697,\n",
       "  0.8142988085746765,\n",
       "  0.8267346024513245,\n",
       "  0.8297576308250427,\n",
       "  0.836743175983429,\n",
       "  0.8391929864883423,\n",
       "  0.8360720276832581,\n",
       "  0.8400046229362488,\n",
       "  0.8435096144676208,\n",
       "  0.8333835005760193,\n",
       "  0.8474891781806946,\n",
       "  0.8422837257385254,\n",
       "  0.8406838178634644,\n",
       "  0.8451005816459656,\n",
       "  0.8444230556488037,\n",
       "  0.8374487161636353,\n",
       "  0.8392316699028015,\n",
       "  0.8476306200027466,\n",
       "  0.8387290239334106,\n",
       "  0.851895272731781,\n",
       "  0.8358844518661499,\n",
       "  0.8238593339920044,\n",
       "  0.8450000286102295,\n",
       "  0.8359965682029724,\n",
       "  0.8367891907691956,\n",
       "  0.8508132100105286,\n",
       "  0.8484189510345459,\n",
       "  0.8465728759765625,\n",
       "  0.8451594114303589,\n",
       "  0.8398903012275696,\n",
       "  0.8362284898757935,\n",
       "  0.8428291082382202,\n",
       "  0.8526078462600708,\n",
       "  0.8416262269020081,\n",
       "  0.8441826105117798,\n",
       "  0.8440921902656555,\n",
       "  0.8482507467269897,\n",
       "  0.8526455163955688,\n",
       "  0.8581573963165283,\n",
       "  0.8500070571899414,\n",
       "  0.8494393229484558,\n",
       "  0.8508471846580505,\n",
       "  0.8542269468307495,\n",
       "  0.858762800693512,\n",
       "  0.8439698815345764,\n",
       "  0.8559234142303467,\n",
       "  0.8483051061630249,\n",
       "  0.8486073613166809,\n",
       "  0.8678171038627625,\n",
       "  0.8636556267738342,\n",
       "  0.8609160780906677,\n",
       "  0.8485165238380432,\n",
       "  0.8560001254081726,\n",
       "  0.8610066771507263,\n",
       "  0.8664296269416809,\n",
       "  0.856911838054657,\n",
       "  0.8524009585380554,\n",
       "  0.8652954697608948,\n",
       "  0.8687968254089355,\n",
       "  0.8625853061676025,\n",
       "  0.8627916574478149,\n",
       "  0.85342937707901,\n",
       "  0.8576327562332153,\n",
       "  0.8522856831550598,\n",
       "  0.8613764643669128,\n",
       "  0.8623981475830078,\n",
       "  0.8663076162338257,\n",
       "  0.8721683025360107,\n",
       "  0.8619574308395386,\n",
       "  0.865095317363739,\n",
       "  0.8768011331558228,\n",
       "  0.8702499866485596,\n",
       "  0.8754509687423706,\n",
       "  0.8711661100387573,\n",
       "  0.8719640970230103,\n",
       "  0.8761681914329529,\n",
       "  0.8811308145523071,\n",
       "  0.8794823288917542,\n",
       "  0.8709856867790222,\n",
       "  0.8765079379081726,\n",
       "  0.8782342076301575,\n",
       "  0.875518262386322,\n",
       "  0.8774394392967224,\n",
       "  0.877465009689331,\n",
       "  0.8835018277168274,\n",
       "  0.8865926861763,\n",
       "  0.8784307837486267,\n",
       "  0.8771321177482605,\n",
       "  0.8799183368682861,\n",
       "  0.8831994533538818,\n",
       "  0.8850086331367493,\n",
       "  0.872186541557312,\n",
       "  0.8762573599815369,\n",
       "  0.8828880786895752,\n",
       "  0.8845301866531372,\n",
       "  0.8832361102104187,\n",
       "  0.8819379210472107,\n",
       "  0.8797786235809326,\n",
       "  0.8857041001319885,\n",
       "  0.8856985569000244,\n",
       "  0.8916692733764648,\n",
       "  0.880128026008606,\n",
       "  0.8866943120956421,\n",
       "  0.8972665071487427,\n",
       "  0.8689424395561218,\n",
       "  0.8812602758407593,\n",
       "  0.8888941407203674,\n",
       "  0.8851696848869324,\n",
       "  0.8848891258239746,\n",
       "  0.8878154158592224,\n",
       "  0.8901936411857605,\n",
       "  0.889286458492279,\n",
       "  0.8907080292701721,\n",
       "  0.8919613361358643,\n",
       "  0.8943094611167908,\n",
       "  0.8906422257423401,\n",
       "  0.89247727394104,\n",
       "  0.8920208215713501,\n",
       "  0.896809458732605,\n",
       "  0.8950148820877075,\n",
       "  0.8940446376800537,\n",
       "  0.8985573053359985,\n",
       "  0.8933847546577454,\n",
       "  0.8919970393180847,\n",
       "  0.893189549446106,\n",
       "  0.9079840779304504,\n",
       "  0.8931227922439575,\n",
       "  0.8994080424308777,\n",
       "  0.8959509134292603,\n",
       "  0.8983982801437378,\n",
       "  0.8947917819023132,\n",
       "  0.8996490836143494,\n",
       "  0.9037342071533203,\n",
       "  0.902650773525238,\n",
       "  0.9049065113067627,\n",
       "  0.8906089663505554,\n",
       "  0.8939008116722107,\n",
       "  0.8964101672172546,\n",
       "  0.9024780988693237,\n",
       "  0.8982177972793579,\n",
       "  0.9034906029701233,\n",
       "  0.9054537415504456,\n",
       "  0.9080401659011841,\n",
       "  0.9105333089828491,\n",
       "  0.908119797706604,\n",
       "  0.9074753522872925,\n",
       "  0.8994859457015991,\n",
       "  0.9074023962020874,\n",
       "  0.9205503463745117,\n",
       "  0.9055875539779663,\n",
       "  0.9210291504859924,\n",
       "  0.9150405526161194,\n",
       "  0.9100183248519897,\n",
       "  0.9129491448402405,\n",
       "  0.8912498354911804,\n",
       "  0.9066054821014404,\n",
       "  0.9070514440536499,\n",
       "  0.914155900478363,\n",
       "  0.914503276348114,\n",
       "  0.9139266014099121,\n",
       "  0.8980265259742737,\n",
       "  0.8964502215385437,\n",
       "  0.9017266035079956,\n",
       "  0.8958242535591125,\n",
       "  0.9147714376449585,\n",
       "  0.9149673581123352,\n",
       "  0.9176599383354187,\n",
       "  0.9158368706703186,\n",
       "  0.9146955013275146,\n",
       "  0.9188483953475952,\n",
       "  0.9209246635437012,\n",
       "  0.9196860194206238,\n",
       "  0.921422004699707,\n",
       "  0.9126273989677429,\n",
       "  0.9220308661460876,\n",
       "  0.9101207256317139,\n",
       "  0.9175240397453308,\n",
       "  0.9131709933280945,\n",
       "  0.916203498840332,\n",
       "  0.9154036641120911,\n",
       "  0.9207147359848022,\n",
       "  0.920024573802948,\n",
       "  0.9252479076385498,\n",
       "  0.921625554561615,\n",
       "  0.905129611492157,\n",
       "  0.9202065467834473,\n",
       "  0.9241859316825867,\n",
       "  0.931751012802124,\n",
       "  0.9282016754150391,\n",
       "  0.9193778038024902,\n",
       "  0.9031959176063538,\n",
       "  0.9132127165794373,\n",
       "  0.9125126600265503,\n",
       "  0.9142335653305054,\n",
       "  0.9083477854728699,\n",
       "  0.9199972748756409,\n",
       "  0.9202935099601746,\n",
       "  0.917094886302948,\n",
       "  0.9261411428451538,\n",
       "  0.9240627884864807,\n",
       "  0.922479510307312,\n",
       "  0.9287006855010986,\n",
       "  0.9289752840995789,\n",
       "  0.9306271076202393,\n",
       "  0.9325957894325256,\n",
       "  0.9301644563674927,\n",
       "  0.9258978366851807],\n",
       " 'tp': [10.0,\n",
       "  311.0,\n",
       "  367.0,\n",
       "  375.0,\n",
       "  358.0,\n",
       "  353.0,\n",
       "  383.0,\n",
       "  363.0,\n",
       "  357.0,\n",
       "  343.0,\n",
       "  357.0,\n",
       "  389.0,\n",
       "  389.0,\n",
       "  384.0,\n",
       "  392.0,\n",
       "  366.0,\n",
       "  402.0,\n",
       "  392.0,\n",
       "  379.0,\n",
       "  374.0,\n",
       "  404.0,\n",
       "  386.0,\n",
       "  394.0,\n",
       "  402.0,\n",
       "  407.0,\n",
       "  401.0,\n",
       "  421.0,\n",
       "  409.0,\n",
       "  395.0,\n",
       "  374.0,\n",
       "  377.0,\n",
       "  391.0,\n",
       "  413.0,\n",
       "  411.0,\n",
       "  390.0,\n",
       "  435.0,\n",
       "  404.0,\n",
       "  426.0,\n",
       "  407.0,\n",
       "  402.0,\n",
       "  416.0,\n",
       "  414.0,\n",
       "  430.0,\n",
       "  429.0,\n",
       "  421.0,\n",
       "  430.0,\n",
       "  440.0,\n",
       "  435.0,\n",
       "  440.0,\n",
       "  438.0,\n",
       "  453.0,\n",
       "  431.0,\n",
       "  444.0,\n",
       "  441.0,\n",
       "  450.0,\n",
       "  441.0,\n",
       "  437.0,\n",
       "  454.0,\n",
       "  438.0,\n",
       "  450.0,\n",
       "  447.0,\n",
       "  438.0,\n",
       "  471.0,\n",
       "  447.0,\n",
       "  457.0,\n",
       "  457.0,\n",
       "  455.0,\n",
       "  440.0,\n",
       "  449.0,\n",
       "  441.0,\n",
       "  449.0,\n",
       "  462.0,\n",
       "  450.0,\n",
       "  461.0,\n",
       "  470.0,\n",
       "  438.0,\n",
       "  446.0,\n",
       "  456.0,\n",
       "  446.0,\n",
       "  453.0,\n",
       "  455.0,\n",
       "  449.0,\n",
       "  445.0,\n",
       "  451.0,\n",
       "  464.0,\n",
       "  452.0,\n",
       "  464.0,\n",
       "  469.0,\n",
       "  478.0,\n",
       "  461.0,\n",
       "  464.0,\n",
       "  458.0,\n",
       "  464.0,\n",
       "  481.0,\n",
       "  463.0,\n",
       "  459.0,\n",
       "  448.0,\n",
       "  450.0,\n",
       "  453.0,\n",
       "  448.0,\n",
       "  449.0,\n",
       "  455.0,\n",
       "  447.0,\n",
       "  453.0,\n",
       "  447.0,\n",
       "  445.0,\n",
       "  438.0,\n",
       "  446.0,\n",
       "  453.0,\n",
       "  449.0,\n",
       "  433.0,\n",
       "  449.0,\n",
       "  447.0,\n",
       "  443.0,\n",
       "  449.0,\n",
       "  447.0,\n",
       "  433.0,\n",
       "  467.0,\n",
       "  438.0,\n",
       "  434.0,\n",
       "  451.0,\n",
       "  450.0,\n",
       "  455.0,\n",
       "  433.0,\n",
       "  477.0,\n",
       "  452.0,\n",
       "  464.0,\n",
       "  459.0,\n",
       "  466.0,\n",
       "  448.0,\n",
       "  463.0,\n",
       "  450.0,\n",
       "  467.0,\n",
       "  463.0,\n",
       "  444.0,\n",
       "  452.0,\n",
       "  457.0,\n",
       "  458.0,\n",
       "  464.0,\n",
       "  458.0,\n",
       "  464.0,\n",
       "  439.0,\n",
       "  467.0,\n",
       "  447.0,\n",
       "  455.0,\n",
       "  466.0,\n",
       "  454.0,\n",
       "  459.0,\n",
       "  447.0,\n",
       "  461.0,\n",
       "  469.0,\n",
       "  464.0,\n",
       "  466.0,\n",
       "  473.0,\n",
       "  465.0,\n",
       "  465.0,\n",
       "  459.0,\n",
       "  459.0,\n",
       "  459.0,\n",
       "  453.0,\n",
       "  444.0,\n",
       "  472.0,\n",
       "  465.0,\n",
       "  466.0,\n",
       "  469.0,\n",
       "  437.0,\n",
       "  470.0,\n",
       "  465.0,\n",
       "  459.0,\n",
       "  451.0,\n",
       "  471.0,\n",
       "  459.0,\n",
       "  466.0,\n",
       "  451.0,\n",
       "  469.0,\n",
       "  461.0,\n",
       "  459.0,\n",
       "  460.0,\n",
       "  460.0,\n",
       "  444.0,\n",
       "  474.0,\n",
       "  468.0,\n",
       "  463.0,\n",
       "  472.0,\n",
       "  453.0,\n",
       "  473.0,\n",
       "  461.0,\n",
       "  468.0,\n",
       "  478.0,\n",
       "  461.0,\n",
       "  470.0,\n",
       "  472.0,\n",
       "  462.0,\n",
       "  457.0,\n",
       "  466.0,\n",
       "  476.0,\n",
       "  451.0,\n",
       "  468.0,\n",
       "  465.0,\n",
       "  469.0,\n",
       "  463.0,\n",
       "  465.0,\n",
       "  468.0,\n",
       "  463.0,\n",
       "  463.0,\n",
       "  473.0,\n",
       "  470.0,\n",
       "  483.0,\n",
       "  463.0,\n",
       "  476.0,\n",
       "  482.0,\n",
       "  473.0,\n",
       "  488.0,\n",
       "  483.0,\n",
       "  483.0,\n",
       "  484.0,\n",
       "  486.0,\n",
       "  478.0,\n",
       "  468.0,\n",
       "  471.0,\n",
       "  468.0,\n",
       "  479.0,\n",
       "  486.0,\n",
       "  476.0,\n",
       "  481.0,\n",
       "  479.0,\n",
       "  489.0,\n",
       "  476.0,\n",
       "  472.0,\n",
       "  484.0,\n",
       "  475.0,\n",
       "  465.0,\n",
       "  477.0,\n",
       "  478.0,\n",
       "  462.0,\n",
       "  475.0,\n",
       "  480.0,\n",
       "  467.0,\n",
       "  487.0,\n",
       "  481.0,\n",
       "  485.0,\n",
       "  484.0,\n",
       "  478.0,\n",
       "  479.0,\n",
       "  481.0,\n",
       "  481.0,\n",
       "  465.0,\n",
       "  470.0,\n",
       "  482.0,\n",
       "  484.0,\n",
       "  486.0,\n",
       "  478.0,\n",
       "  475.0,\n",
       "  480.0,\n",
       "  480.0,\n",
       "  487.0,\n",
       "  485.0,\n",
       "  481.0,\n",
       "  482.0,\n",
       "  487.0,\n",
       "  487.0,\n",
       "  477.0,\n",
       "  488.0,\n",
       "  482.0,\n",
       "  476.0,\n",
       "  478.0,\n",
       "  486.0,\n",
       "  483.0,\n",
       "  476.0,\n",
       "  488.0,\n",
       "  469.0,\n",
       "  495.0,\n",
       "  476.0,\n",
       "  488.0,\n",
       "  496.0,\n",
       "  480.0,\n",
       "  477.0,\n",
       "  484.0,\n",
       "  488.0,\n",
       "  494.0,\n",
       "  483.0,\n",
       "  478.0,\n",
       "  482.0,\n",
       "  499.0,\n",
       "  480.0,\n",
       "  489.0,\n",
       "  472.0,\n",
       "  487.0,\n",
       "  493.0,\n",
       "  480.0,\n",
       "  495.0,\n",
       "  495.0,\n",
       "  482.0,\n",
       "  478.0,\n",
       "  498.0,\n",
       "  495.0,\n",
       "  504.0,\n",
       "  490.0,\n",
       "  483.0],\n",
       " 'loss': [1.2642991542816162,\n",
       "  0.6470063328742981,\n",
       "  0.618323028087616,\n",
       "  0.6277849674224854,\n",
       "  0.6323260068893433,\n",
       "  0.6191362738609314,\n",
       "  0.6123723387718201,\n",
       "  0.6114603877067566,\n",
       "  0.6215556263923645,\n",
       "  0.6364834308624268,\n",
       "  0.5941662788391113,\n",
       "  0.6024304628372192,\n",
       "  0.586773157119751,\n",
       "  0.5986840724945068,\n",
       "  0.5886332988739014,\n",
       "  0.5902541279792786,\n",
       "  0.5562684535980225,\n",
       "  0.575081467628479,\n",
       "  0.6059442758560181,\n",
       "  0.5739016532897949,\n",
       "  0.5579105019569397,\n",
       "  0.6011667847633362,\n",
       "  0.581058144569397,\n",
       "  0.5890656113624573,\n",
       "  0.5694739818572998,\n",
       "  0.5781437158584595,\n",
       "  0.5561192035675049,\n",
       "  0.5606028437614441,\n",
       "  0.5639567971229553,\n",
       "  0.5829686522483826,\n",
       "  0.5972352027893066,\n",
       "  0.5668106079101562,\n",
       "  0.5755245685577393,\n",
       "  0.5620397925376892,\n",
       "  0.5728042125701904,\n",
       "  0.5625711679458618,\n",
       "  0.5445581674575806,\n",
       "  0.5508209466934204,\n",
       "  0.5530165433883667,\n",
       "  0.5542202591896057,\n",
       "  0.5494387745857239,\n",
       "  0.5488028526306152,\n",
       "  0.533789873123169,\n",
       "  0.5485012531280518,\n",
       "  0.5372073650360107,\n",
       "  0.5353701710700989,\n",
       "  0.5362711548805237,\n",
       "  0.5288980603218079,\n",
       "  0.5350348949432373,\n",
       "  0.5403652191162109,\n",
       "  0.5270341038703918,\n",
       "  0.532319188117981,\n",
       "  0.5315006971359253,\n",
       "  0.534075140953064,\n",
       "  0.5211666822433472,\n",
       "  0.5443586707115173,\n",
       "  0.5322982668876648,\n",
       "  0.5244296193122864,\n",
       "  0.5244960188865662,\n",
       "  0.5162826180458069,\n",
       "  0.5176376104354858,\n",
       "  0.5098456740379333,\n",
       "  0.5144003629684448,\n",
       "  0.5065520405769348,\n",
       "  0.49849021434783936,\n",
       "  0.5129166841506958,\n",
       "  0.5169179439544678,\n",
       "  0.511305034160614,\n",
       "  0.505714476108551,\n",
       "  0.5097941160202026,\n",
       "  0.5075120329856873,\n",
       "  0.4960657060146332,\n",
       "  0.4952346980571747,\n",
       "  0.48810872435569763,\n",
       "  0.49182501435279846,\n",
       "  0.5128065347671509,\n",
       "  0.4931447207927704,\n",
       "  0.49578553438186646,\n",
       "  0.48449552059173584,\n",
       "  0.49253642559051514,\n",
       "  0.47912299633026123,\n",
       "  0.49267685413360596,\n",
       "  0.5012491345405579,\n",
       "  0.510195791721344,\n",
       "  0.49275079369544983,\n",
       "  0.5125874876976013,\n",
       "  0.49478015303611755,\n",
       "  0.5036157369613647,\n",
       "  0.497031033039093,\n",
       "  0.49858909845352173,\n",
       "  0.5033016800880432,\n",
       "  0.47890231013298035,\n",
       "  0.4993906617164612,\n",
       "  0.4908134639263153,\n",
       "  0.4819996953010559,\n",
       "  0.4741339683532715,\n",
       "  0.47661304473876953,\n",
       "  0.4715237319469452,\n",
       "  0.47581949830055237,\n",
       "  0.4755480885505676,\n",
       "  0.47208601236343384,\n",
       "  0.4851948916912079,\n",
       "  0.46369779109954834,\n",
       "  0.47975027561187744,\n",
       "  0.47740092873573303,\n",
       "  0.4685748517513275,\n",
       "  0.4725484848022461,\n",
       "  0.4795646369457245,\n",
       "  0.4759754538536072,\n",
       "  0.46296054124832153,\n",
       "  0.47956758737564087,\n",
       "  0.4544503390789032,\n",
       "  0.47431206703186035,\n",
       "  0.5004143714904785,\n",
       "  0.4664897918701172,\n",
       "  0.47613731026649475,\n",
       "  0.47656112909317017,\n",
       "  0.46340465545654297,\n",
       "  0.46060386300086975,\n",
       "  0.4676532447338104,\n",
       "  0.46849945187568665,\n",
       "  0.4727477729320526,\n",
       "  0.4754633605480194,\n",
       "  0.4717467725276947,\n",
       "  0.4548806846141815,\n",
       "  0.46978846192359924,\n",
       "  0.46692270040512085,\n",
       "  0.464275985956192,\n",
       "  0.4604114592075348,\n",
       "  0.4504801034927368,\n",
       "  0.44920286536216736,\n",
       "  0.4630243480205536,\n",
       "  0.4603419899940491,\n",
       "  0.45463937520980835,\n",
       "  0.4540763795375824,\n",
       "  0.4558103382587433,\n",
       "  0.4753739833831787,\n",
       "  0.45527827739715576,\n",
       "  0.46251553297042847,\n",
       "  0.4664566218852997,\n",
       "  0.4442221522331238,\n",
       "  0.4501281678676605,\n",
       "  0.4430481195449829,\n",
       "  0.46705925464630127,\n",
       "  0.4617426097393036,\n",
       "  0.451564759016037,\n",
       "  0.44364044070243835,\n",
       "  0.45494648814201355,\n",
       "  0.46305975317955017,\n",
       "  0.4423559010028839,\n",
       "  0.4380076825618744,\n",
       "  0.43597501516342163,\n",
       "  0.4428037106990814,\n",
       "  0.4490675926208496,\n",
       "  0.44470351934432983,\n",
       "  0.46340876817703247,\n",
       "  0.4374377131462097,\n",
       "  0.44661614298820496,\n",
       "  0.44493040442466736,\n",
       "  0.43594229221343994,\n",
       "  0.4516718089580536,\n",
       "  0.4489389657974243,\n",
       "  0.42346033453941345,\n",
       "  0.4350699782371521,\n",
       "  0.4284522235393524,\n",
       "  0.4367932677268982,\n",
       "  0.43460431694984436,\n",
       "  0.4264581501483917,\n",
       "  0.4179098904132843,\n",
       "  0.41983699798583984,\n",
       "  0.4270099401473999,\n",
       "  0.4249989688396454,\n",
       "  0.4272737205028534,\n",
       "  0.42820873856544495,\n",
       "  0.4271235466003418,\n",
       "  0.42878589034080505,\n",
       "  0.41401851177215576,\n",
       "  0.411000519990921,\n",
       "  0.4200964868068695,\n",
       "  0.4192483425140381,\n",
       "  0.4249124825000763,\n",
       "  0.417181134223938,\n",
       "  0.4113009572029114,\n",
       "  0.4316164255142212,\n",
       "  0.42393428087234497,\n",
       "  0.41924354434013367,\n",
       "  0.40890005230903625,\n",
       "  0.41098758578300476,\n",
       "  0.4115772545337677,\n",
       "  0.4240078032016754,\n",
       "  0.4118335247039795,\n",
       "  0.4057769477367401,\n",
       "  0.40015390515327454,\n",
       "  0.4253093898296356,\n",
       "  0.4098954498767853,\n",
       "  0.3946246802806854,\n",
       "  0.4352407455444336,\n",
       "  0.4220319986343384,\n",
       "  0.40532657504081726,\n",
       "  0.4206180274486542,\n",
       "  0.4165923595428467,\n",
       "  0.407464861869812,\n",
       "  0.40011733770370483,\n",
       "  0.40244442224502563,\n",
       "  0.4021698832511902,\n",
       "  0.40746334195137024,\n",
       "  0.394510954618454,\n",
       "  0.3958534002304077,\n",
       "  0.39970657229423523,\n",
       "  0.39897799491882324,\n",
       "  0.38860252499580383,\n",
       "  0.392269104719162,\n",
       "  0.39903125166893005,\n",
       "  0.38984349370002747,\n",
       "  0.3933512568473816,\n",
       "  0.39585191011428833,\n",
       "  0.39395758509635925,\n",
       "  0.36984458565711975,\n",
       "  0.40062418580055237,\n",
       "  0.38882726430892944,\n",
       "  0.3900128901004791,\n",
       "  0.387905478477478,\n",
       "  0.39543065428733826,\n",
       "  0.38330379128456116,\n",
       "  0.3770867586135864,\n",
       "  0.3800305128097534,\n",
       "  0.3774093985557556,\n",
       "  0.4054271876811981,\n",
       "  0.3926680386066437,\n",
       "  0.39006221294403076,\n",
       "  0.37989333271980286,\n",
       "  0.39064493775367737,\n",
       "  0.37519213557243347,\n",
       "  0.3748093545436859,\n",
       "  0.3757637143135071,\n",
       "  0.37183257937431335,\n",
       "  0.36820194125175476,\n",
       "  0.37430986762046814,\n",
       "  0.38026663661003113,\n",
       "  0.3700532913208008,\n",
       "  0.3435764014720917,\n",
       "  0.36953601241111755,\n",
       "  0.3473929762840271,\n",
       "  0.3582681119441986,\n",
       "  0.3613587021827698,\n",
       "  0.36109498143196106,\n",
       "  0.4058188796043396,\n",
       "  0.3793167769908905,\n",
       "  0.37210920453071594,\n",
       "  0.3537272810935974,\n",
       "  0.3563373386859894,\n",
       "  0.3580767810344696,\n",
       "  0.38799095153808594,\n",
       "  0.3890429735183716,\n",
       "  0.38468095660209656,\n",
       "  0.39110952615737915,\n",
       "  0.35958483815193176,\n",
       "  0.35747793316841125,\n",
       "  0.3531029224395752,\n",
       "  0.3547765910625458,\n",
       "  0.3570632040500641,\n",
       "  0.35057514905929565,\n",
       "  0.35213950276374817,\n",
       "  0.347063273191452,\n",
       "  0.34377187490463257,\n",
       "  0.3598219156265259,\n",
       "  0.34026846289634705,\n",
       "  0.37160706520080566,\n",
       "  0.3550046980381012,\n",
       "  0.3626415729522705,\n",
       "  0.3582240641117096,\n",
       "  0.3532494902610779,\n",
       "  0.336555540561676,\n",
       "  0.34571579098701477,\n",
       "  0.3346465826034546,\n",
       "  0.3408472537994385,\n",
       "  0.38525718450546265,\n",
       "  0.3492587208747864,\n",
       "  0.33831116557121277,\n",
       "  0.3229672908782959,\n",
       "  0.3243735134601593,\n",
       "  0.3485518991947174,\n",
       "  0.37249094247817993,\n",
       "  0.353321373462677,\n",
       "  0.3563095033168793,\n",
       "  0.3490331768989563,\n",
       "  0.37108924984931946,\n",
       "  0.344010591506958,\n",
       "  0.34788182377815247,\n",
       "  0.3484824001789093,\n",
       "  0.32882753014564514,\n",
       "  0.33855730295181274,\n",
       "  0.3393692076206207,\n",
       "  0.33347514271736145,\n",
       "  0.3262231647968292,\n",
       "  0.3253662884235382,\n",
       "  0.32150736451148987,\n",
       "  0.3242150545120239,\n",
       "  0.33637335896492004],\n",
       " 'accuracy': [0.9663927555084229,\n",
       "  0.6287041902542114,\n",
       "  0.6453057527542114,\n",
       "  0.6047616004943848,\n",
       "  0.6097791194915771,\n",
       "  0.623383641242981,\n",
       "  0.5959051847457886,\n",
       "  0.6026737689971924,\n",
       "  0.6044585108757019,\n",
       "  0.6062432527542114,\n",
       "  0.6159415245056152,\n",
       "  0.6152006983757019,\n",
       "  0.6208916902542114,\n",
       "  0.6371901631355286,\n",
       "  0.6353043913841248,\n",
       "  0.6361463069915771,\n",
       "  0.6532529592514038,\n",
       "  0.6501548886299133,\n",
       "  0.6253030896186829,\n",
       "  0.6396147608757019,\n",
       "  0.6476293206214905,\n",
       "  0.636381983757019,\n",
       "  0.6330819129943848,\n",
       "  0.6299501657485962,\n",
       "  0.6333512663841248,\n",
       "  0.6215651631355286,\n",
       "  0.6493467092514038,\n",
       "  0.6523774266242981,\n",
       "  0.6528488397598267,\n",
       "  0.6512324810028076,\n",
       "  0.640288233757019,\n",
       "  0.6244275569915771,\n",
       "  0.649784505367279,\n",
       "  0.6538927555084229,\n",
       "  0.6707974076271057,\n",
       "  0.6399515271186829,\n",
       "  0.6661503314971924,\n",
       "  0.6489762663841248,\n",
       "  0.6513671875,\n",
       "  0.655610203742981,\n",
       "  0.6490099430084229,\n",
       "  0.657563328742981,\n",
       "  0.6625807881355286,\n",
       "  0.6528488397598267,\n",
       "  0.6531856060028076,\n",
       "  0.6385034918785095,\n",
       "  0.6506937146186829,\n",
       "  0.6534886956214905,\n",
       "  0.633418619632721,\n",
       "  0.6261112689971924,\n",
       "  0.6426791548728943,\n",
       "  0.6693494319915771,\n",
       "  0.6471915245056152,\n",
       "  0.6382340788841248,\n",
       "  0.6394127011299133,\n",
       "  0.6209590435028076,\n",
       "  0.6507947444915771,\n",
       "  0.6371228694915771,\n",
       "  0.6545999646186829,\n",
       "  0.6580347418785095,\n",
       "  0.665645182132721,\n",
       "  0.6843682527542114,\n",
       "  0.6504579782485962,\n",
       "  0.6801252961158752,\n",
       "  0.6644666194915771,\n",
       "  0.6630522608757019,\n",
       "  0.6699892282485962,\n",
       "  0.6860519647598267,\n",
       "  0.6687095761299133,\n",
       "  0.6708647608757019,\n",
       "  0.6687095761299133,\n",
       "  0.6652747988700867,\n",
       "  0.693359375,\n",
       "  0.6802599430084229,\n",
       "  0.6726495027542114,\n",
       "  0.6835600733757019,\n",
       "  0.6838631629943848,\n",
       "  0.6678003668785095,\n",
       "  0.693359375,\n",
       "  0.6918103694915771,\n",
       "  0.7013402581214905,\n",
       "  0.696625828742981,\n",
       "  0.6938644647598267,\n",
       "  0.683930516242981,\n",
       "  0.683256983757019,\n",
       "  0.6542631983757019,\n",
       "  0.661503255367279,\n",
       "  0.6530845761299133,\n",
       "  0.6535223722457886,\n",
       "  0.6651737689971924,\n",
       "  0.6696187853813171,\n",
       "  0.6990503668785095,\n",
       "  0.6637930870056152,\n",
       "  0.6675309538841248,\n",
       "  0.687163233757019,\n",
       "  0.69140625,\n",
       "  0.7084456086158752,\n",
       "  0.7110722064971924,\n",
       "  0.7302330136299133,\n",
       "  0.73046875,\n",
       "  0.7183458805084229,\n",
       "  0.7151131629943848,\n",
       "  0.7126548886299133,\n",
       "  0.7170999646186829,\n",
       "  0.7300646305084229,\n",
       "  0.7248114347457886,\n",
       "  0.731074869632721,\n",
       "  0.7226225733757019,\n",
       "  0.7117120027542114,\n",
       "  0.7312432527542114,\n",
       "  0.7329943180084229,\n",
       "  0.7394261956214905,\n",
       "  0.7080751657485962,\n",
       "  0.704741358757019,\n",
       "  0.7247440814971924,\n",
       "  0.723296046257019,\n",
       "  0.7438375353813171,\n",
       "  0.7163254022598267,\n",
       "  0.7346780896186829,\n",
       "  0.7241715788841248,\n",
       "  0.7230940461158752,\n",
       "  0.6967604756355286,\n",
       "  0.7051118016242981,\n",
       "  0.7421538233757019,\n",
       "  0.7117456793785095,\n",
       "  0.7185142636299133,\n",
       "  0.7121497988700867,\n",
       "  0.7261247038841248,\n",
       "  0.7399986386299133,\n",
       "  0.7312095761299133,\n",
       "  0.7331627011299133,\n",
       "  0.722993016242981,\n",
       "  0.7123854756355286,\n",
       "  0.7137661576271057,\n",
       "  0.740234375,\n",
       "  0.7403354048728943,\n",
       "  0.7074353694915771,\n",
       "  0.7303003668785095,\n",
       "  0.7227909564971924,\n",
       "  0.7328596711158752,\n",
       "  0.7250807881355286,\n",
       "  0.7315800189971924,\n",
       "  0.7241379022598267,\n",
       "  0.7400996685028076,\n",
       "  0.7305697798728943,\n",
       "  0.7348800897598267,\n",
       "  0.7428946495056152,\n",
       "  0.7271012663841248,\n",
       "  0.716426432132721,\n",
       "  0.7393925189971924,\n",
       "  0.738651692867279,\n",
       "  0.7127559185028076,\n",
       "  0.7296268939971924,\n",
       "  0.7083109021186829,\n",
       "  0.7187163233757019,\n",
       "  0.7201643586158752,\n",
       "  0.7277074456214905,\n",
       "  0.7357556819915771,\n",
       "  0.7310411930084229,\n",
       "  0.7392578125,\n",
       "  0.7434671521186829,\n",
       "  0.7204000353813171,\n",
       "  0.7521888613700867,\n",
       "  0.7326912879943848,\n",
       "  0.7430630326271057,\n",
       "  0.765288233757019,\n",
       "  0.7507745027542114,\n",
       "  0.7594625353813171,\n",
       "  0.7586206793785095,\n",
       "  0.7651872038841248,\n",
       "  0.7318494319915771,\n",
       "  0.753300130367279,\n",
       "  0.7527613043785095,\n",
       "  0.7649178504943848,\n",
       "  0.7528960108757019,\n",
       "  0.7629310488700867,\n",
       "  0.762358546257019,\n",
       "  0.7655913233757019,\n",
       "  0.7517173886299133,\n",
       "  0.7592604756355286,\n",
       "  0.7380118370056152,\n",
       "  0.748686671257019,\n",
       "  0.7607085108757019,\n",
       "  0.7285493016242981,\n",
       "  0.7466325163841248,\n",
       "  0.7430967092514038,\n",
       "  0.756229817867279,\n",
       "  0.7491244673728943,\n",
       "  0.7364628314971924,\n",
       "  0.7481815814971924,\n",
       "  0.754276692867279,\n",
       "  0.7496969103813171,\n",
       "  0.7646484375,\n",
       "  0.7427262663841248,\n",
       "  0.7551522254943848,\n",
       "  0.7608768939971924,\n",
       "  0.7345433831214905,\n",
       "  0.7417160272598267,\n",
       "  0.7694638967514038,\n",
       "  0.755219578742981,\n",
       "  0.7631667256355286,\n",
       "  0.7536368370056152,\n",
       "  0.7629647254943848,\n",
       "  0.7557246685028076,\n",
       "  0.7506734728813171,\n",
       "  0.7655576467514038,\n",
       "  0.7752559185028076,\n",
       "  0.7567685842514038,\n",
       "  0.7612472772598267,\n",
       "  0.7550511956214905,\n",
       "  0.7593615055084229,\n",
       "  0.7651198506355286,\n",
       "  0.7436691522598267,\n",
       "  0.7629647254943848,\n",
       "  0.7674434185028076,\n",
       "  0.7570043206214905,\n",
       "  0.759125828742981,\n",
       "  0.7754916548728943,\n",
       "  0.7535021305084229,\n",
       "  0.7785897254943848,\n",
       "  0.770878255367279,\n",
       "  0.761381983757019,\n",
       "  0.7548154592514038,\n",
       "  0.7628300189971924,\n",
       "  0.7629647254943848,\n",
       "  0.7772427201271057,\n",
       "  0.7678138613700867,\n",
       "  0.7508418560028076,\n",
       "  0.7678475379943848,\n",
       "  0.7729997038841248,\n",
       "  0.7752895951271057,\n",
       "  0.775053858757019,\n",
       "  0.7677801847457886,\n",
       "  0.7793642282485962,\n",
       "  0.790375828742981,\n",
       "  0.7818224430084229,\n",
       "  0.7807112336158752,\n",
       "  0.7762661576271057,\n",
       "  0.7625606060028076,\n",
       "  0.7837418913841248,\n",
       "  0.8012526631355286,\n",
       "  0.7689924836158752,\n",
       "  0.789432942867279,\n",
       "  0.7866379022598267,\n",
       "  0.7701036930084229,\n",
       "  0.7906115055084229,\n",
       "  0.7577788233757019,\n",
       "  0.7866379022598267,\n",
       "  0.7792295217514038,\n",
       "  0.7986934185028076,\n",
       "  0.785762369632721,\n",
       "  0.7950229048728943,\n",
       "  0.768925130367279,\n",
       "  0.7735048532485962,\n",
       "  0.7757947444915771,\n",
       "  0.7678812146186829,\n",
       "  0.7950229048728943,\n",
       "  0.790375828742981,\n",
       "  0.793339192867279,\n",
       "  0.7879849076271057,\n",
       "  0.7883553504943848,\n",
       "  0.7959994673728943,\n",
       "  0.798222005367279,\n",
       "  0.8015557527542114,\n",
       "  0.7967739701271057,\n",
       "  0.7876481413841248,\n",
       "  0.7989965081214905,\n",
       "  0.7827653288841248,\n",
       "  0.805293619632721,\n",
       "  0.783842921257019,\n",
       "  0.8135439157485962,\n",
       "  0.7811826467514038,\n",
       "  0.7941136956214905,\n",
       "  0.7941136956214905,\n",
       "  0.8054620027542114,\n",
       "  0.8005455136299133,\n",
       "  0.7820581793785095,\n",
       "  0.7995689511299133,\n",
       "  0.800175130367279,\n",
       "  0.8156654238700867,\n",
       "  0.8146888613700867,\n",
       "  0.7987944483757019,\n",
       "  0.7686220407485962,\n",
       "  0.775761067867279,\n",
       "  0.7807112336158752,\n",
       "  0.7753232717514038,\n",
       "  0.7778825163841248,\n",
       "  0.8061691522598267,\n",
       "  0.7950229048728943,\n",
       "  0.7918911576271057,\n",
       "  0.814116358757019,\n",
       "  0.806977391242981,\n",
       "  0.8077518939971924,\n",
       "  0.8168776631355286,\n",
       "  0.8120622038841248,\n",
       "  0.8064048886299133,\n",
       "  0.8132745027542114,\n",
       "  0.8176185488700867,\n",
       "  0.8137122988700867],\n",
       " 'val_fn': [84.0,\n",
       "  86.0,\n",
       "  87.0,\n",
       "  83.0,\n",
       "  86.0,\n",
       "  87.0,\n",
       "  85.0,\n",
       "  85.0,\n",
       "  86.0,\n",
       "  87.0,\n",
       "  84.0,\n",
       "  85.0,\n",
       "  70.0,\n",
       "  70.0,\n",
       "  67.0,\n",
       "  56.0,\n",
       "  43.0,\n",
       "  26.0,\n",
       "  30.0,\n",
       "  26.0,\n",
       "  21.0,\n",
       "  15.0,\n",
       "  24.0,\n",
       "  23.0,\n",
       "  27.0,\n",
       "  32.0,\n",
       "  33.0,\n",
       "  25.0,\n",
       "  27.0,\n",
       "  20.0,\n",
       "  27.0,\n",
       "  9.0,\n",
       "  23.0,\n",
       "  20.0,\n",
       "  18.0,\n",
       "  15.0,\n",
       "  53.0,\n",
       "  51.0,\n",
       "  23.0,\n",
       "  19.0,\n",
       "  9.0,\n",
       "  21.0,\n",
       "  34.0,\n",
       "  30.0,\n",
       "  30.0,\n",
       "  14.0,\n",
       "  20.0,\n",
       "  33.0,\n",
       "  19.0,\n",
       "  21.0,\n",
       "  29.0,\n",
       "  22.0,\n",
       "  8.0,\n",
       "  11.0,\n",
       "  11.0,\n",
       "  25.0,\n",
       "  22.0,\n",
       "  32.0,\n",
       "  38.0,\n",
       "  43.0,\n",
       "  38.0,\n",
       "  37.0,\n",
       "  39.0,\n",
       "  67.0,\n",
       "  26.0,\n",
       "  30.0,\n",
       "  15.0,\n",
       "  25.0,\n",
       "  30.0,\n",
       "  20.0,\n",
       "  35.0,\n",
       "  36.0,\n",
       "  47.0,\n",
       "  46.0,\n",
       "  31.0,\n",
       "  37.0,\n",
       "  26.0,\n",
       "  34.0,\n",
       "  38.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  31.0,\n",
       "  21.0,\n",
       "  10.0,\n",
       "  3.0,\n",
       "  8.0,\n",
       "  9.0,\n",
       "  11.0,\n",
       "  7.0,\n",
       "  14.0,\n",
       "  12.0,\n",
       "  27.0,\n",
       "  38.0,\n",
       "  21.0,\n",
       "  19.0,\n",
       "  36.0,\n",
       "  32.0,\n",
       "  39.0,\n",
       "  26.0,\n",
       "  56.0,\n",
       "  47.0,\n",
       "  41.0,\n",
       "  31.0,\n",
       "  22.0,\n",
       "  21.0,\n",
       "  45.0,\n",
       "  30.0,\n",
       "  19.0,\n",
       "  21.0,\n",
       "  21.0,\n",
       "  24.0,\n",
       "  42.0,\n",
       "  64.0,\n",
       "  37.0,\n",
       "  41.0,\n",
       "  35.0,\n",
       "  30.0,\n",
       "  25.0,\n",
       "  28.0,\n",
       "  31.0,\n",
       "  19.0,\n",
       "  22.0,\n",
       "  27.0,\n",
       "  16.0,\n",
       "  33.0,\n",
       "  25.0,\n",
       "  20.0,\n",
       "  41.0,\n",
       "  57.0,\n",
       "  55.0,\n",
       "  31.0,\n",
       "  41.0,\n",
       "  12.0,\n",
       "  30.0,\n",
       "  43.0,\n",
       "  26.0,\n",
       "  21.0,\n",
       "  57.0,\n",
       "  40.0,\n",
       "  18.0,\n",
       "  25.0,\n",
       "  16.0,\n",
       "  22.0,\n",
       "  32.0,\n",
       "  26.0,\n",
       "  53.0,\n",
       "  47.0,\n",
       "  20.0,\n",
       "  10.0,\n",
       "  22.0,\n",
       "  22.0,\n",
       "  13.0,\n",
       "  10.0,\n",
       "  14.0,\n",
       "  28.0,\n",
       "  17.0,\n",
       "  31.0,\n",
       "  37.0,\n",
       "  11.0,\n",
       "  27.0,\n",
       "  29.0,\n",
       "  21.0,\n",
       "  25.0,\n",
       "  16.0,\n",
       "  19.0,\n",
       "  40.0,\n",
       "  20.0,\n",
       "  31.0,\n",
       "  33.0,\n",
       "  24.0,\n",
       "  14.0,\n",
       "  16.0,\n",
       "  53.0,\n",
       "  17.0,\n",
       "  33.0,\n",
       "  21.0,\n",
       "  22.0,\n",
       "  24.0,\n",
       "  27.0,\n",
       "  17.0,\n",
       "  42.0,\n",
       "  26.0,\n",
       "  8.0,\n",
       "  35.0,\n",
       "  29.0,\n",
       "  29.0,\n",
       "  26.0,\n",
       "  26.0,\n",
       "  23.0,\n",
       "  20.0,\n",
       "  15.0,\n",
       "  12.0,\n",
       "  21.0,\n",
       "  13.0,\n",
       "  20.0,\n",
       "  34.0,\n",
       "  22.0,\n",
       "  18.0,\n",
       "  31.0,\n",
       "  12.0,\n",
       "  14.0,\n",
       "  13.0,\n",
       "  18.0,\n",
       "  28.0,\n",
       "  20.0,\n",
       "  30.0,\n",
       "  46.0,\n",
       "  21.0,\n",
       "  19.0,\n",
       "  26.0,\n",
       "  29.0,\n",
       "  34.0,\n",
       "  26.0,\n",
       "  24.0,\n",
       "  22.0,\n",
       "  20.0,\n",
       "  12.0,\n",
       "  19.0,\n",
       "  20.0,\n",
       "  19.0,\n",
       "  29.0,\n",
       "  21.0,\n",
       "  34.0,\n",
       "  35.0,\n",
       "  21.0,\n",
       "  17.0,\n",
       "  12.0,\n",
       "  25.0,\n",
       "  21.0,\n",
       "  40.0,\n",
       "  41.0,\n",
       "  29.0,\n",
       "  17.0,\n",
       "  15.0,\n",
       "  24.0,\n",
       "  29.0,\n",
       "  27.0,\n",
       "  28.0,\n",
       "  21.0,\n",
       "  24.0,\n",
       "  25.0,\n",
       "  18.0,\n",
       "  21.0,\n",
       "  19.0,\n",
       "  27.0,\n",
       "  35.0,\n",
       "  28.0,\n",
       "  29.0,\n",
       "  26.0,\n",
       "  16.0,\n",
       "  20.0,\n",
       "  12.0,\n",
       "  9.0,\n",
       "  14.0,\n",
       "  9.0,\n",
       "  17.0,\n",
       "  33.0,\n",
       "  18.0,\n",
       "  33.0,\n",
       "  40.0,\n",
       "  39.0,\n",
       "  26.0,\n",
       "  33.0,\n",
       "  32.0,\n",
       "  18.0,\n",
       "  33.0,\n",
       "  32.0,\n",
       "  35.0,\n",
       "  32.0,\n",
       "  18.0,\n",
       "  21.0,\n",
       "  28.0,\n",
       "  24.0,\n",
       "  31.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  17.0,\n",
       "  26.0,\n",
       "  24.0,\n",
       "  25.0,\n",
       "  33.0,\n",
       "  19.0,\n",
       "  20.0,\n",
       "  21.0,\n",
       "  19.0,\n",
       "  25.0,\n",
       "  30.0,\n",
       "  27.0,\n",
       "  42.0,\n",
       "  26.0,\n",
       "  39.0,\n",
       "  28.0,\n",
       "  25.0,\n",
       "  34.0,\n",
       "  23.0,\n",
       "  22.0,\n",
       "  38.0,\n",
       "  28.0,\n",
       "  21.0],\n",
       " 'val_auc': [0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.4999999701976776,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5058543086051941,\n",
       "  0.5078485012054443,\n",
       "  0.5606204867362976,\n",
       "  0.5775643587112427,\n",
       "  0.6085059642791748,\n",
       "  0.6248741149902344,\n",
       "  0.6438034772872925,\n",
       "  0.6664494276046753,\n",
       "  0.7329119443893433,\n",
       "  0.7022885680198669,\n",
       "  0.702407717704773,\n",
       "  0.7348059415817261,\n",
       "  0.7622845768928528,\n",
       "  0.7538129091262817,\n",
       "  0.7431190013885498,\n",
       "  0.7610411643981934,\n",
       "  0.7359050512313843,\n",
       "  0.7612195014953613,\n",
       "  0.7352019548416138,\n",
       "  0.7435354590415955,\n",
       "  0.7363632321357727,\n",
       "  0.7468180060386658,\n",
       "  0.7713185548782349,\n",
       "  0.7851767539978027,\n",
       "  0.7981029748916626,\n",
       "  0.7928921580314636,\n",
       "  0.7278991937637329,\n",
       "  0.7407466173171997,\n",
       "  0.7861947417259216,\n",
       "  0.7813883423805237,\n",
       "  0.7952828407287598,\n",
       "  0.8099961876869202,\n",
       "  0.7898827791213989,\n",
       "  0.7707197666168213,\n",
       "  0.7858168482780457,\n",
       "  0.7618089318275452,\n",
       "  0.8024712800979614,\n",
       "  0.7915047407150269,\n",
       "  0.7723898887634277,\n",
       "  0.7960090637207031,\n",
       "  0.803411066532135,\n",
       "  0.8132396340370178,\n",
       "  0.7903485298156738,\n",
       "  0.8064967393875122,\n",
       "  0.8045050501823425,\n",
       "  0.7472927570343018,\n",
       "  0.7718008756637573,\n",
       "  0.7904888391494751,\n",
       "  0.7920724749565125,\n",
       "  0.7841193675994873,\n",
       "  0.7999359965324402,\n",
       "  0.7930138111114502,\n",
       "  0.7893911004066467,\n",
       "  0.7605493068695068,\n",
       "  0.8077327013015747,\n",
       "  0.7885730266571045,\n",
       "  0.80484539270401,\n",
       "  0.8196325898170471,\n",
       "  0.7952882647514343,\n",
       "  0.8126605153083801,\n",
       "  0.7998405694961548,\n",
       "  0.8153605461120605,\n",
       "  0.7975796461105347,\n",
       "  0.8034631609916687,\n",
       "  0.8039510250091553,\n",
       "  0.7903745770454407,\n",
       "  0.82823246717453,\n",
       "  0.8098219037055969,\n",
       "  0.8122230172157288,\n",
       "  0.8247675895690918,\n",
       "  0.8185025453567505,\n",
       "  0.8150567412376404,\n",
       "  0.8254702687263489,\n",
       "  0.828916609287262,\n",
       "  0.769940972328186,\n",
       "  0.8027840256690979,\n",
       "  0.7931630611419678,\n",
       "  0.8105741143226624,\n",
       "  0.8292632102966309,\n",
       "  0.8313516974449158,\n",
       "  0.8389383554458618,\n",
       "  0.8259024620056152,\n",
       "  0.8166674375534058,\n",
       "  0.8283028602600098,\n",
       "  0.8310976028442383,\n",
       "  0.7976700067520142,\n",
       "  0.8155053853988647,\n",
       "  0.8274035453796387,\n",
       "  0.84618079662323,\n",
       "  0.7785865068435669,\n",
       "  0.7814277410507202,\n",
       "  0.8111263513565063,\n",
       "  0.8263713121414185,\n",
       "  0.8126270174980164,\n",
       "  0.8363269567489624,\n",
       "  0.8217454552650452,\n",
       "  0.8058846592903137,\n",
       "  0.8245430588722229,\n",
       "  0.8249014616012573,\n",
       "  0.8257439136505127,\n",
       "  0.801298201084137,\n",
       "  0.794562041759491,\n",
       "  0.6261461973190308,\n",
       "  0.8102602362632751,\n",
       "  0.8104727268218994,\n",
       "  0.8205751776695251,\n",
       "  0.8029065728187561,\n",
       "  0.8190799355506897,\n",
       "  0.8474215865135193,\n",
       "  0.8235428333282471,\n",
       "  0.8216544985771179,\n",
       "  0.8089145421981812,\n",
       "  0.8233113884925842,\n",
       "  0.8370240926742554,\n",
       "  0.8260729312896729,\n",
       "  0.8333759307861328,\n",
       "  0.8372054100036621,\n",
       "  0.8186671733856201,\n",
       "  0.7994509935379028,\n",
       "  0.7753481268882751,\n",
       "  0.8239209651947021,\n",
       "  0.8162427544593811,\n",
       "  0.8706100583076477,\n",
       "  0.8231836557388306,\n",
       "  0.8397741913795471,\n",
       "  0.8236007690429688,\n",
       "  0.8413752913475037,\n",
       "  0.7230240106582642,\n",
       "  0.8153740763664246,\n",
       "  0.8460643291473389,\n",
       "  0.849429190158844,\n",
       "  0.8572901487350464,\n",
       "  0.852698028087616,\n",
       "  0.8481977581977844,\n",
       "  0.8533770442008972,\n",
       "  0.8454899787902832,\n",
       "  0.8439894914627075,\n",
       "  0.8194118142127991,\n",
       "  0.8428739905357361,\n",
       "  0.8456918597221375,\n",
       "  0.8416874408721924,\n",
       "  0.8407477140426636,\n",
       "  0.8174951076507568,\n",
       "  0.8254407644271851,\n",
       "  0.8219180703163147,\n",
       "  0.8281713724136353,\n",
       "  0.8082196116447449,\n",
       "  0.7810840010643005,\n",
       "  0.8426112532615662,\n",
       "  0.8551525473594666,\n",
       "  0.8440691232681274,\n",
       "  0.8584191799163818,\n",
       "  0.8544758558273315,\n",
       "  0.8694693446159363,\n",
       "  0.8527756929397583,\n",
       "  0.7816135883331299,\n",
       "  0.8383923768997192,\n",
       "  0.8604224324226379,\n",
       "  0.8577558994293213,\n",
       "  0.8616580963134766,\n",
       "  0.8434193730354309,\n",
       "  0.8686048984527588,\n",
       "  0.8412669897079468,\n",
       "  0.8359135389328003,\n",
       "  0.7451949715614319,\n",
       "  0.8531129956245422,\n",
       "  0.8588936924934387,\n",
       "  0.8407183885574341,\n",
       "  0.8532902002334595,\n",
       "  0.8575378656387329,\n",
       "  0.7970613241195679,\n",
       "  0.8538546562194824,\n",
       "  0.86663818359375,\n",
       "  0.7832237482070923,\n",
       "  0.8346956372261047,\n",
       "  0.8327470421791077,\n",
       "  0.8617956638336182,\n",
       "  0.8295773863792419,\n",
       "  0.8676982522010803,\n",
       "  0.86284339427948,\n",
       "  0.8711646199226379,\n",
       "  0.8629106283187866,\n",
       "  0.8608116507530212,\n",
       "  0.8582660555839539,\n",
       "  0.8542184233665466,\n",
       "  0.8237152099609375,\n",
       "  0.8496657013893127,\n",
       "  0.8583036065101624,\n",
       "  0.868445873260498,\n",
       "  0.8651755452156067,\n",
       "  0.8647831082344055,\n",
       "  0.871971607208252,\n",
       "  0.8686910271644592,\n",
       "  0.8725476264953613,\n",
       "  0.8641353845596313,\n",
       "  0.8539235591888428,\n",
       "  0.8224917650222778,\n",
       "  0.8731244802474976,\n",
       "  0.8601495027542114,\n",
       "  0.863000750541687,\n",
       "  0.8623318076133728,\n",
       "  0.8506631851196289,\n",
       "  0.8606680631637573,\n",
       "  0.8619874119758606,\n",
       "  0.8505290150642395,\n",
       "  0.8519589304924011,\n",
       "  0.8697189688682556,\n",
       "  0.8766093850135803,\n",
       "  0.8621262311935425,\n",
       "  0.8786774277687073,\n",
       "  0.8718814849853516,\n",
       "  0.8689485788345337,\n",
       "  0.8669768571853638,\n",
       "  0.8365470767021179,\n",
       "  0.8752377033233643,\n",
       "  0.85768061876297,\n",
       "  0.8759886622428894,\n",
       "  0.8584914803504944,\n",
       "  0.8731595277786255,\n",
       "  0.8501976132392883,\n",
       "  0.8190467953681946,\n",
       "  0.8637773394584656,\n",
       "  0.8702296018600464,\n",
       "  0.8550896048545837,\n",
       "  0.8524282574653625,\n",
       "  0.8587761521339417,\n",
       "  0.8688189387321472,\n",
       "  0.8563583493232727,\n",
       "  0.8865512609481812,\n",
       "  0.8566552996635437,\n",
       "  0.8806880116462708,\n",
       "  0.8583920001983643,\n",
       "  0.8612948060035706,\n",
       "  0.8819742202758789,\n",
       "  0.8460747003555298,\n",
       "  0.844918429851532,\n",
       "  0.8503836393356323,\n",
       "  0.8603785634040833,\n",
       "  0.8781078457832336,\n",
       "  0.8851786255836487,\n",
       "  0.8596867918968201,\n",
       "  0.8700244426727295,\n",
       "  0.8540889024734497,\n",
       "  0.8698536157608032,\n",
       "  0.8722681999206543,\n",
       "  0.8633683919906616,\n",
       "  0.8776639699935913,\n",
       "  0.8701243996620178,\n",
       "  0.8598084449768066,\n",
       "  0.8692892789840698,\n",
       "  0.8648670315742493,\n",
       "  0.8797723054885864,\n",
       "  0.8723081350326538,\n",
       "  0.8681597709655762,\n",
       "  0.8517780900001526,\n",
       "  0.8617749214172363,\n",
       "  0.868261456489563,\n",
       "  0.8660942912101746,\n",
       "  0.8586451411247253,\n",
       "  0.8697060942649841,\n",
       "  0.8687115907669067,\n",
       "  0.8617920875549316,\n",
       "  0.8725073337554932,\n",
       "  0.8702043890953064,\n",
       "  0.8698443174362183,\n",
       "  0.8770459890365601,\n",
       "  0.8623921275138855,\n",
       "  0.8559504151344299,\n",
       "  0.8704504370689392,\n",
       "  0.8830795884132385,\n",
       "  0.8586330413818359,\n",
       "  0.8837612271308899,\n",
       "  0.8433460593223572,\n",
       "  0.8459295034408569,\n",
       "  0.8606873154640198,\n",
       "  0.8543179035186768,\n",
       "  0.8619255423545837,\n",
       "  0.8567296862602234,\n",
       "  0.8586376309394836,\n",
       "  0.8658542037010193,\n",
       "  0.839367687702179,\n",
       "  0.8641155362129211,\n",
       "  0.861376166343689,\n",
       "  0.859185516834259,\n",
       "  0.8659433126449585,\n",
       "  0.8574038743972778,\n",
       "  0.8700898289680481,\n",
       "  0.8563922643661499,\n",
       "  0.8565078973770142],\n",
       " 'val_tp': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  17.0,\n",
       "  16.0,\n",
       "  22.0,\n",
       "  29.0,\n",
       "  45.0,\n",
       "  62.0,\n",
       "  55.0,\n",
       "  59.0,\n",
       "  66.0,\n",
       "  69.0,\n",
       "  60.0,\n",
       "  62.0,\n",
       "  56.0,\n",
       "  54.0,\n",
       "  50.0,\n",
       "  60.0,\n",
       "  57.0,\n",
       "  70.0,\n",
       "  55.0,\n",
       "  73.0,\n",
       "  60.0,\n",
       "  65.0,\n",
       "  68.0,\n",
       "  71.0,\n",
       "  33.0,\n",
       "  38.0,\n",
       "  63.0,\n",
       "  65.0,\n",
       "  79.0,\n",
       "  59.0,\n",
       "  49.0,\n",
       "  58.0,\n",
       "  56.0,\n",
       "  73.0,\n",
       "  66.0,\n",
       "  54.0,\n",
       "  70.0,\n",
       "  64.0,\n",
       "  60.0,\n",
       "  62.0,\n",
       "  80.0,\n",
       "  74.0,\n",
       "  73.0,\n",
       "  58.0,\n",
       "  63.0,\n",
       "  57.0,\n",
       "  43.0,\n",
       "  42.0,\n",
       "  50.0,\n",
       "  48.0,\n",
       "  49.0,\n",
       "  20.0,\n",
       "  65.0,\n",
       "  53.0,\n",
       "  72.0,\n",
       "  63.0,\n",
       "  53.0,\n",
       "  67.0,\n",
       "  52.0,\n",
       "  49.0,\n",
       "  41.0,\n",
       "  40.0,\n",
       "  51.0,\n",
       "  47.0,\n",
       "  61.0,\n",
       "  53.0,\n",
       "  49.0,\n",
       "  60.0,\n",
       "  63.0,\n",
       "  54.0,\n",
       "  61.0,\n",
       "  77.0,\n",
       "  82.0,\n",
       "  78.0,\n",
       "  76.0,\n",
       "  74.0,\n",
       "  78.0,\n",
       "  69.0,\n",
       "  74.0,\n",
       "  59.0,\n",
       "  49.0,\n",
       "  64.0,\n",
       "  66.0,\n",
       "  48.0,\n",
       "  55.0,\n",
       "  48.0,\n",
       "  60.0,\n",
       "  33.0,\n",
       "  38.0,\n",
       "  45.0,\n",
       "  56.0,\n",
       "  63.0,\n",
       "  67.0,\n",
       "  42.0,\n",
       "  57.0,\n",
       "  68.0,\n",
       "  67.0,\n",
       "  63.0,\n",
       "  61.0,\n",
       "  44.0,\n",
       "  24.0,\n",
       "  50.0,\n",
       "  44.0,\n",
       "  52.0,\n",
       "  53.0,\n",
       "  59.0,\n",
       "  58.0,\n",
       "  55.0,\n",
       "  67.0,\n",
       "  64.0,\n",
       "  57.0,\n",
       "  71.0,\n",
       "  49.0,\n",
       "  59.0,\n",
       "  65.0,\n",
       "  46.0,\n",
       "  29.0,\n",
       "  33.0,\n",
       "  51.0,\n",
       "  46.0,\n",
       "  76.0,\n",
       "  56.0,\n",
       "  45.0,\n",
       "  59.0,\n",
       "  63.0,\n",
       "  32.0,\n",
       "  46.0,\n",
       "  71.0,\n",
       "  60.0,\n",
       "  70.0,\n",
       "  64.0,\n",
       "  56.0,\n",
       "  61.0,\n",
       "  35.0,\n",
       "  40.0,\n",
       "  66.0,\n",
       "  75.0,\n",
       "  62.0,\n",
       "  62.0,\n",
       "  71.0,\n",
       "  77.0,\n",
       "  76.0,\n",
       "  56.0,\n",
       "  71.0,\n",
       "  57.0,\n",
       "  50.0,\n",
       "  74.0,\n",
       "  57.0,\n",
       "  55.0,\n",
       "  64.0,\n",
       "  61.0,\n",
       "  67.0,\n",
       "  67.0,\n",
       "  43.0,\n",
       "  68.0,\n",
       "  55.0,\n",
       "  54.0,\n",
       "  64.0,\n",
       "  72.0,\n",
       "  71.0,\n",
       "  37.0,\n",
       "  69.0,\n",
       "  49.0,\n",
       "  64.0,\n",
       "  63.0,\n",
       "  59.0,\n",
       "  56.0,\n",
       "  71.0,\n",
       "  42.0,\n",
       "  59.0,\n",
       "  77.0,\n",
       "  52.0,\n",
       "  60.0,\n",
       "  55.0,\n",
       "  59.0,\n",
       "  60.0,\n",
       "  59.0,\n",
       "  64.0,\n",
       "  71.0,\n",
       "  75.0,\n",
       "  68.0,\n",
       "  68.0,\n",
       "  67.0,\n",
       "  53.0,\n",
       "  67.0,\n",
       "  72.0,\n",
       "  54.0,\n",
       "  73.0,\n",
       "  70.0,\n",
       "  75.0,\n",
       "  67.0,\n",
       "  57.0,\n",
       "  63.0,\n",
       "  56.0,\n",
       "  42.0,\n",
       "  65.0,\n",
       "  66.0,\n",
       "  61.0,\n",
       "  54.0,\n",
       "  50.0,\n",
       "  61.0,\n",
       "  62.0,\n",
       "  64.0,\n",
       "  66.0,\n",
       "  73.0,\n",
       "  71.0,\n",
       "  63.0,\n",
       "  64.0,\n",
       "  59.0,\n",
       "  61.0,\n",
       "  53.0,\n",
       "  53.0,\n",
       "  65.0,\n",
       "  69.0,\n",
       "  75.0,\n",
       "  56.0,\n",
       "  67.0,\n",
       "  46.0,\n",
       "  47.0,\n",
       "  60.0,\n",
       "  68.0,\n",
       "  70.0,\n",
       "  61.0,\n",
       "  54.0,\n",
       "  61.0,\n",
       "  59.0,\n",
       "  63.0,\n",
       "  61.0,\n",
       "  60.0,\n",
       "  69.0,\n",
       "  66.0,\n",
       "  68.0,\n",
       "  63.0,\n",
       "  53.0,\n",
       "  57.0,\n",
       "  56.0,\n",
       "  61.0,\n",
       "  70.0,\n",
       "  66.0,\n",
       "  75.0,\n",
       "  77.0,\n",
       "  72.0,\n",
       "  76.0,\n",
       "  72.0,\n",
       "  51.0,\n",
       "  66.0,\n",
       "  51.0,\n",
       "  47.0,\n",
       "  52.0,\n",
       "  60.0,\n",
       "  54.0,\n",
       "  55.0,\n",
       "  70.0,\n",
       "  56.0,\n",
       "  51.0,\n",
       "  54.0,\n",
       "  54.0,\n",
       "  67.0,\n",
       "  68.0,\n",
       "  58.0,\n",
       "  55.0,\n",
       "  55.0,\n",
       "  65.0,\n",
       "  58.0,\n",
       "  65.0,\n",
       "  60.0,\n",
       "  60.0,\n",
       "  58.0,\n",
       "  54.0,\n",
       "  70.0,\n",
       "  65.0,\n",
       "  66.0,\n",
       "  68.0,\n",
       "  64.0,\n",
       "  55.0,\n",
       "  62.0,\n",
       "  45.0,\n",
       "  62.0,\n",
       "  46.0,\n",
       "  62.0,\n",
       "  58.0,\n",
       "  55.0,\n",
       "  64.0,\n",
       "  69.0,\n",
       "  51.0,\n",
       "  57.0,\n",
       "  64.0],\n",
       " 'val_loss': [0.10284765809774399,\n",
       "  0.10431468486785889,\n",
       "  0.10505294799804688,\n",
       "  0.10213375091552734,\n",
       "  0.10436004400253296,\n",
       "  0.1051284670829773,\n",
       "  0.10373234748840332,\n",
       "  0.10377933830022812,\n",
       "  0.10457511246204376,\n",
       "  0.1054176613688469,\n",
       "  0.10296308994293213,\n",
       "  0.10905569791793823,\n",
       "  0.16724276542663574,\n",
       "  0.17914815247058868,\n",
       "  0.23347187042236328,\n",
       "  0.27700570225715637,\n",
       "  0.3941604197025299,\n",
       "  0.5288872122764587,\n",
       "  0.4433217942714691,\n",
       "  0.5611785054206848,\n",
       "  0.578886866569519,\n",
       "  0.5202703475952148,\n",
       "  0.409512996673584,\n",
       "  0.4432738423347473,\n",
       "  0.3953354060649872,\n",
       "  0.3657059669494629,\n",
       "  0.40386882424354553,\n",
       "  0.4339620769023895,\n",
       "  0.4921450614929199,\n",
       "  0.5479170083999634,\n",
       "  0.49628373980522156,\n",
       "  0.70159912109375,\n",
       "  0.5014967918395996,\n",
       "  0.46261048316955566,\n",
       "  0.47277045249938965,\n",
       "  0.4870883524417877,\n",
       "  0.32880523800849915,\n",
       "  0.327860027551651,\n",
       "  0.43103280663490295,\n",
       "  0.49407050013542175,\n",
       "  0.499766081571579,\n",
       "  0.4282337725162506,\n",
       "  0.38176780939102173,\n",
       "  0.4400579631328583,\n",
       "  0.39422640204429626,\n",
       "  0.5107061266899109,\n",
       "  0.4559568464756012,\n",
       "  0.3266984224319458,\n",
       "  0.45893797278404236,\n",
       "  0.43593689799308777,\n",
       "  0.46098214387893677,\n",
       "  0.4720326066017151,\n",
       "  0.5103587508201599,\n",
       "  0.533566415309906,\n",
       "  0.49054718017578125,\n",
       "  0.45099517703056335,\n",
       "  0.45191526412963867,\n",
       "  0.4068048596382141,\n",
       "  0.35269808769226074,\n",
       "  0.33715754747390747,\n",
       "  0.3666161894798279,\n",
       "  0.3503686785697937,\n",
       "  0.35472026467323303,\n",
       "  0.24702568352222443,\n",
       "  0.4079655706882477,\n",
       "  0.40997791290283203,\n",
       "  0.46352314949035645,\n",
       "  0.4306723177433014,\n",
       "  0.4209917485713959,\n",
       "  0.4519403576850891,\n",
       "  0.3880032002925873,\n",
       "  0.36604562401771545,\n",
       "  0.3347610831260681,\n",
       "  0.3335626721382141,\n",
       "  0.3881910443305969,\n",
       "  0.4030403792858124,\n",
       "  0.3731209337711334,\n",
       "  0.40787360072135925,\n",
       "  0.3620212972164154,\n",
       "  0.4290623664855957,\n",
       "  0.4053153693675995,\n",
       "  0.3914279639720917,\n",
       "  0.44338732957839966,\n",
       "  0.5617370009422302,\n",
       "  0.8049122095108032,\n",
       "  0.5661246180534363,\n",
       "  0.6083489060401917,\n",
       "  0.45713505148887634,\n",
       "  0.4934482276439667,\n",
       "  0.4371279776096344,\n",
       "  0.45066019892692566,\n",
       "  0.3888850808143616,\n",
       "  0.30915212631225586,\n",
       "  0.37816122174263,\n",
       "  0.4302390515804291,\n",
       "  0.3479326665401459,\n",
       "  0.4024488627910614,\n",
       "  0.36375191807746887,\n",
       "  0.38989612460136414,\n",
       "  0.2730327844619751,\n",
       "  0.30622598528862,\n",
       "  0.37290582060813904,\n",
       "  0.35238486528396606,\n",
       "  0.48810458183288574,\n",
       "  0.4336073100566864,\n",
       "  0.3394184112548828,\n",
       "  0.47207140922546387,\n",
       "  0.5087913870811462,\n",
       "  0.49912744760513306,\n",
       "  0.4997749924659729,\n",
       "  0.4956323802471161,\n",
       "  0.41177448630332947,\n",
       "  0.2779107987880707,\n",
       "  0.36225584149360657,\n",
       "  0.30542227625846863,\n",
       "  0.4172220230102539,\n",
       "  0.4117755889892578,\n",
       "  0.4232397675514221,\n",
       "  0.40944185853004456,\n",
       "  0.4154633581638336,\n",
       "  0.5026670098304749,\n",
       "  0.49049338698387146,\n",
       "  0.4733436107635498,\n",
       "  0.5056418180465698,\n",
       "  0.3744347393512726,\n",
       "  0.42156100273132324,\n",
       "  0.40736937522888184,\n",
       "  0.353494256734848,\n",
       "  0.30547332763671875,\n",
       "  0.3020676374435425,\n",
       "  0.3009791374206543,\n",
       "  0.336249440908432,\n",
       "  0.4259650707244873,\n",
       "  0.32054778933525085,\n",
       "  0.30205783247947693,\n",
       "  0.4170013964176178,\n",
       "  0.4000742435455322,\n",
       "  0.20724068582057953,\n",
       "  0.32664018869400024,\n",
       "  0.42246705293655396,\n",
       "  0.3763701021671295,\n",
       "  0.4199690520763397,\n",
       "  0.36690041422843933,\n",
       "  0.3432311713695526,\n",
       "  0.4176517426967621,\n",
       "  0.2858809530735016,\n",
       "  0.3317061960697174,\n",
       "  0.532417356967926,\n",
       "  0.5722153186798096,\n",
       "  0.4333478510379791,\n",
       "  0.38929954171180725,\n",
       "  0.49316635727882385,\n",
       "  0.5875243544578552,\n",
       "  0.4791540205478668,\n",
       "  0.35656872391700745,\n",
       "  0.4191280007362366,\n",
       "  0.33527252078056335,\n",
       "  0.3033064305782318,\n",
       "  0.46872422099113464,\n",
       "  0.37886855006217957,\n",
       "  0.27939659357070923,\n",
       "  0.3424876928329468,\n",
       "  0.30488428473472595,\n",
       "  0.4603760838508606,\n",
       "  0.44299474358558655,\n",
       "  0.38089272379875183,\n",
       "  0.432140588760376,\n",
       "  0.3050192892551422,\n",
       "  0.3623807728290558,\n",
       "  0.34035730361938477,\n",
       "  0.5483800768852234,\n",
       "  0.4718947410583496,\n",
       "  0.2968159317970276,\n",
       "  0.5116043090820312,\n",
       "  0.5575275421142578,\n",
       "  0.45669636130332947,\n",
       "  0.41475406289100647,\n",
       "  0.40790611505508423,\n",
       "  0.3849804997444153,\n",
       "  0.5213597416877747,\n",
       "  0.29504522681236267,\n",
       "  0.33852145075798035,\n",
       "  0.5145517587661743,\n",
       "  0.32857099175453186,\n",
       "  0.38056251406669617,\n",
       "  0.3633720874786377,\n",
       "  0.35773563385009766,\n",
       "  0.4154743254184723,\n",
       "  0.3302900195121765,\n",
       "  0.3913857042789459,\n",
       "  0.41731640696525574,\n",
       "  0.4751400053501129,\n",
       "  0.4330168664455414,\n",
       "  0.6161354184150696,\n",
       "  0.3857792317867279,\n",
       "  0.3148370087146759,\n",
       "  0.37809666991233826,\n",
       "  0.38503238558769226,\n",
       "  0.2977738082408905,\n",
       "  0.45260754227638245,\n",
       "  0.5087695121765137,\n",
       "  0.4516223967075348,\n",
       "  0.3329871594905853,\n",
       "  0.30426347255706787,\n",
       "  0.334977924823761,\n",
       "  0.3522854745388031,\n",
       "  0.28656768798828125,\n",
       "  0.35816869139671326,\n",
       "  0.4693530201911926,\n",
       "  0.34659048914909363,\n",
       "  0.3056493401527405,\n",
       "  0.3256686329841614,\n",
       "  0.3372926414012909,\n",
       "  0.3217224180698395,\n",
       "  0.43518733978271484,\n",
       "  0.4423046112060547,\n",
       "  0.4495391845703125,\n",
       "  0.3578519821166992,\n",
       "  0.3739924132823944,\n",
       "  0.40929660201072693,\n",
       "  0.31785279512405396,\n",
       "  0.3741156756877899,\n",
       "  0.27693256735801697,\n",
       "  0.3093487024307251,\n",
       "  0.3180432915687561,\n",
       "  0.40910306572914124,\n",
       "  0.47535809874534607,\n",
       "  0.3929079473018646,\n",
       "  0.3863970935344696,\n",
       "  0.2889237701892853,\n",
       "  0.32088229060173035,\n",
       "  0.3517599403858185,\n",
       "  0.41682901978492737,\n",
       "  0.4678857922554016,\n",
       "  0.43610426783561707,\n",
       "  0.31819626688957214,\n",
       "  0.3121283948421478,\n",
       "  0.3619140684604645,\n",
       "  0.2956930696964264,\n",
       "  0.3372916877269745,\n",
       "  0.32599183917045593,\n",
       "  0.3851434290409088,\n",
       "  0.3334086835384369,\n",
       "  0.35382792353630066,\n",
       "  0.3840824067592621,\n",
       "  0.324960321187973,\n",
       "  0.3538969159126282,\n",
       "  0.2983185648918152,\n",
       "  0.30322739481925964,\n",
       "  0.38796040415763855,\n",
       "  0.3761650621891022,\n",
       "  0.4719640910625458,\n",
       "  0.710403561592102,\n",
       "  0.48957663774490356,\n",
       "  0.5916577577590942,\n",
       "  0.4693211019039154,\n",
       "  0.29911479353904724,\n",
       "  0.379804790019989,\n",
       "  0.2955339550971985,\n",
       "  0.290140837430954,\n",
       "  0.2848837971687317,\n",
       "  0.3186250627040863,\n",
       "  0.27521657943725586,\n",
       "  0.3083406388759613,\n",
       "  0.44111233949661255,\n",
       "  0.27744194865226746,\n",
       "  0.2663803994655609,\n",
       "  0.2807101905345917,\n",
       "  0.3433437645435333,\n",
       "  0.4275527596473694,\n",
       "  0.4185056686401367,\n",
       "  0.299750953912735,\n",
       "  0.289518803358078,\n",
       "  0.29128357768058777,\n",
       "  0.34719473123550415,\n",
       "  0.30285143852233887,\n",
       "  0.4056735634803772,\n",
       "  0.37993279099464417,\n",
       "  0.3549613654613495,\n",
       "  0.3030899167060852,\n",
       "  0.32842713594436646,\n",
       "  0.36709365248680115,\n",
       "  0.424769788980484,\n",
       "  0.34197378158569336,\n",
       "  0.39139920473098755,\n",
       "  0.3633333146572113,\n",
       "  0.2866648733615875,\n",
       "  0.3324178159236908,\n",
       "  0.22393766045570374,\n",
       "  0.323167622089386,\n",
       "  0.2766338884830475,\n",
       "  0.34299540519714355,\n",
       "  0.32892438769340515,\n",
       "  0.2730596363544464,\n",
       "  0.37917107343673706,\n",
       "  0.35024553537368774,\n",
       "  0.2712612450122833,\n",
       "  0.38488826155662537,\n",
       "  0.4837730824947357],\n",
       " 'val_accuracy': [0.983593761920929,\n",
       "  0.983203113079071,\n",
       "  0.9830078482627869,\n",
       "  0.9837890863418579,\n",
       "  0.983203113079071,\n",
       "  0.9830078482627869,\n",
       "  0.9833984375,\n",
       "  0.9833984375,\n",
       "  0.983203113079071,\n",
       "  0.9830078482627869,\n",
       "  0.983593761920929,\n",
       "  0.9794921875,\n",
       "  0.916015625,\n",
       "  0.9117187857627869,\n",
       "  0.881640613079071,\n",
       "  0.8451172113418579,\n",
       "  0.754687488079071,\n",
       "  0.601757824420929,\n",
       "  0.6966797113418579,\n",
       "  0.6314453482627869,\n",
       "  0.6029297113418579,\n",
       "  0.5806640982627869,\n",
       "  0.7080078125,\n",
       "  0.6830078363418579,\n",
       "  0.714648425579071,\n",
       "  0.735156238079071,\n",
       "  0.730664074420929,\n",
       "  0.729296863079071,\n",
       "  0.693164050579071,\n",
       "  0.641406238079071,\n",
       "  0.7085937857627869,\n",
       "  0.55859375,\n",
       "  0.716796875,\n",
       "  0.7054687738418579,\n",
       "  0.7171875238418579,\n",
       "  0.6685547232627869,\n",
       "  0.831835925579071,\n",
       "  0.8451172113418579,\n",
       "  0.722851574420929,\n",
       "  0.707226574420929,\n",
       "  0.638867199420929,\n",
       "  0.751757800579071,\n",
       "  0.803906261920929,\n",
       "  0.712890625,\n",
       "  0.76171875,\n",
       "  0.603515625,\n",
       "  0.702343761920929,\n",
       "  0.7992187738418579,\n",
       "  0.6640625,\n",
       "  0.699999988079071,\n",
       "  0.7724609375,\n",
       "  0.747851550579071,\n",
       "  0.609179675579071,\n",
       "  0.6474609375,\n",
       "  0.6488281488418579,\n",
       "  0.6714844107627869,\n",
       "  0.7142578363418579,\n",
       "  0.7718750238418579,\n",
       "  0.830078125,\n",
       "  0.850781261920929,\n",
       "  0.774218738079071,\n",
       "  0.820117175579071,\n",
       "  0.763867199420929,\n",
       "  0.888476550579071,\n",
       "  0.7134765982627869,\n",
       "  0.7808594107627869,\n",
       "  0.696484386920929,\n",
       "  0.7591797113418579,\n",
       "  0.7568359375,\n",
       "  0.7066406607627869,\n",
       "  0.75390625,\n",
       "  0.8091797232627869,\n",
       "  0.8607422113418579,\n",
       "  0.8470703363418579,\n",
       "  0.765820324420929,\n",
       "  0.795703113079071,\n",
       "  0.7919921875,\n",
       "  0.795703113079071,\n",
       "  0.8199219107627869,\n",
       "  0.759960949420929,\n",
       "  0.782421886920929,\n",
       "  0.806445300579071,\n",
       "  0.761523425579071,\n",
       "  0.648242175579071,\n",
       "  0.44511720538139343,\n",
       "  0.6136718988418579,\n",
       "  0.6009765863418579,\n",
       "  0.689257800579071,\n",
       "  0.6832031607627869,\n",
       "  0.7359375357627869,\n",
       "  0.7236328125,\n",
       "  0.788281261920929,\n",
       "  0.8363281488418579,\n",
       "  0.7914062738418579,\n",
       "  0.7486328482627869,\n",
       "  0.82421875,\n",
       "  0.833203136920929,\n",
       "  0.834765613079071,\n",
       "  0.8275390863418579,\n",
       "  0.9076172113418579,\n",
       "  0.8580078482627869,\n",
       "  0.824023425579071,\n",
       "  0.8070312738418579,\n",
       "  0.716015636920929,\n",
       "  0.7826172113418579,\n",
       "  0.8626953363418579,\n",
       "  0.7708984613418579,\n",
       "  0.704296886920929,\n",
       "  0.738476574420929,\n",
       "  0.750781238079071,\n",
       "  0.759765625,\n",
       "  0.821484386920929,\n",
       "  0.896484375,\n",
       "  0.853515625,\n",
       "  0.8451172113418579,\n",
       "  0.7962890863418579,\n",
       "  0.7992187738418579,\n",
       "  0.781054675579071,\n",
       "  0.8138672113418579,\n",
       "  0.806640625,\n",
       "  0.746289074420929,\n",
       "  0.7378906607627869,\n",
       "  0.784375011920929,\n",
       "  0.739062488079071,\n",
       "  0.8275390863418579,\n",
       "  0.7720703482627869,\n",
       "  0.78515625,\n",
       "  0.8314453363418579,\n",
       "  0.8929687738418579,\n",
       "  0.867968738079071,\n",
       "  0.84375,\n",
       "  0.8525390625,\n",
       "  0.7490234375,\n",
       "  0.8363281488418579,\n",
       "  0.8753906488418579,\n",
       "  0.7587890625,\n",
       "  0.774609386920929,\n",
       "  0.919921875,\n",
       "  0.8500000238418579,\n",
       "  0.7607421875,\n",
       "  0.7916015982627869,\n",
       "  0.7900390625,\n",
       "  0.7939453125,\n",
       "  0.8267578482627869,\n",
       "  0.7845703363418579,\n",
       "  0.894726574420929,\n",
       "  0.8753906488418579,\n",
       "  0.7197265625,\n",
       "  0.703906238079071,\n",
       "  0.7841796875,\n",
       "  0.788281261920929,\n",
       "  0.7367187738418579,\n",
       "  0.689257800579071,\n",
       "  0.7060546875,\n",
       "  0.78515625,\n",
       "  0.752734363079071,\n",
       "  0.809765636920929,\n",
       "  0.848828136920929,\n",
       "  0.7289062738418579,\n",
       "  0.8345703482627869,\n",
       "  0.837109386920929,\n",
       "  0.828125,\n",
       "  0.8462890982627869,\n",
       "  0.7685546875,\n",
       "  0.7923828363418579,\n",
       "  0.857421875,\n",
       "  0.7359375357627869,\n",
       "  0.842578113079071,\n",
       "  0.839648425579071,\n",
       "  0.822265625,\n",
       "  0.73046875,\n",
       "  0.785351574420929,\n",
       "  0.8716797232627869,\n",
       "  0.7603515982627869,\n",
       "  0.7798828482627869,\n",
       "  0.7822265625,\n",
       "  0.8041015863418579,\n",
       "  0.80078125,\n",
       "  0.824023425579071,\n",
       "  0.7353515625,\n",
       "  0.8755859732627869,\n",
       "  0.8326172232627869,\n",
       "  0.704882800579071,\n",
       "  0.8232421875,\n",
       "  0.8041015863418579,\n",
       "  0.8148437738418579,\n",
       "  0.810742199420929,\n",
       "  0.7828125357627869,\n",
       "  0.818359375,\n",
       "  0.787304699420929,\n",
       "  0.7867187857627869,\n",
       "  0.7251953482627869,\n",
       "  0.758007824420929,\n",
       "  0.696093738079071,\n",
       "  0.803906261920929,\n",
       "  0.8349609375,\n",
       "  0.7660156488418579,\n",
       "  0.8041015863418579,\n",
       "  0.856640636920929,\n",
       "  0.752734363079071,\n",
       "  0.7376953363418579,\n",
       "  0.7425781488418579,\n",
       "  0.801562488079071,\n",
       "  0.827343761920929,\n",
       "  0.8203125,\n",
       "  0.8314453363418579,\n",
       "  0.858593761920929,\n",
       "  0.8212890625,\n",
       "  0.7603515982627869,\n",
       "  0.8212890625,\n",
       "  0.8382812738418579,\n",
       "  0.8587890863418579,\n",
       "  0.814648449420929,\n",
       "  0.8394531607627869,\n",
       "  0.769335925579071,\n",
       "  0.778515636920929,\n",
       "  0.7626953125,\n",
       "  0.817187488079071,\n",
       "  0.782421886920929,\n",
       "  0.798046886920929,\n",
       "  0.842968761920929,\n",
       "  0.8218750357627869,\n",
       "  0.861328125,\n",
       "  0.850390613079071,\n",
       "  0.8375000357627869,\n",
       "  0.7681640982627869,\n",
       "  0.740429699420929,\n",
       "  0.8193359375,\n",
       "  0.787304699420929,\n",
       "  0.861523449420929,\n",
       "  0.878125011920929,\n",
       "  0.8232421875,\n",
       "  0.763476550579071,\n",
       "  0.740234375,\n",
       "  0.7578125,\n",
       "  0.84375,\n",
       "  0.836132824420929,\n",
       "  0.822070300579071,\n",
       "  0.844921886920929,\n",
       "  0.819140613079071,\n",
       "  0.8427734375,\n",
       "  0.792773425579071,\n",
       "  0.815625011920929,\n",
       "  0.806640625,\n",
       "  0.7923828363418579,\n",
       "  0.841015636920929,\n",
       "  0.818164050579071,\n",
       "  0.851367175579071,\n",
       "  0.851367175579071,\n",
       "  0.8011718988418579,\n",
       "  0.796679675579071,\n",
       "  0.757031261920929,\n",
       "  0.650585949420929,\n",
       "  0.750195324420929,\n",
       "  0.712109386920929,\n",
       "  0.7669922113418579,\n",
       "  0.8638672232627869,\n",
       "  0.79296875,\n",
       "  0.8656250238418579,\n",
       "  0.87109375,\n",
       "  0.8687500357627869,\n",
       "  0.8482422232627869,\n",
       "  0.8609375357627869,\n",
       "  0.85546875,\n",
       "  0.749804675579071,\n",
       "  0.866992175579071,\n",
       "  0.8599609732627869,\n",
       "  0.86328125,\n",
       "  0.837890625,\n",
       "  0.781445324420929,\n",
       "  0.7974609732627869,\n",
       "  0.8501953482627869,\n",
       "  0.8695312738418579,\n",
       "  0.849609375,\n",
       "  0.822460949420929,\n",
       "  0.857617199420929,\n",
       "  0.7994140982627869,\n",
       "  0.8226562738418579,\n",
       "  0.8255859613418579,\n",
       "  0.849414050579071,\n",
       "  0.8486328125,\n",
       "  0.806835949420929,\n",
       "  0.766796886920929,\n",
       "  0.805468738079071,\n",
       "  0.774218738079071,\n",
       "  0.820507824420929,\n",
       "  0.861328125,\n",
       "  0.8375000357627869,\n",
       "  0.891406238079071,\n",
       "  0.8287109732627869,\n",
       "  0.8671875,\n",
       "  0.832812488079071,\n",
       "  0.83203125,\n",
       "  0.8716797232627869,\n",
       "  0.8060547113418579,\n",
       "  0.8238281607627869,\n",
       "  0.8714843988418579,\n",
       "  0.817578136920929,\n",
       "  0.7841796875]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-11T07:41:31.800522Z",
     "iopub.status.busy": "2020-08-11T07:41:31.785098Z",
     "iopub.status.idle": "2020-08-11T07:41:33.530251Z",
     "shell.execute_reply": "2020-08-11T07:41:33.529424Z"
    },
    "papermill": {
     "duration": 2.411762,
     "end_time": "2020-08-11T07:41:33.530391",
     "exception": false,
     "start_time": "2020-08-11T07:41:31.118629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.635493,
     "end_time": "2020-08-11T07:41:40.136797",
     "exception": false,
     "start_time": "2020-08-11T07:41:39.501304",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "duration": 7048.917955,
   "end_time": "2020-08-11T07:41:40.968963",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-11T05:44:12.051008",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
