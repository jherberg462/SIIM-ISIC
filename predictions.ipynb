{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:05.046274Z",
     "iopub.status.busy": "2020-08-10T05:29:05.045400Z",
     "iopub.status.idle": "2020-08-10T05:29:12.636858Z",
     "shell.execute_reply": "2020-08-10T05:29:12.637518Z"
    },
    "papermill": {
     "duration": 7.621096,
     "end_time": "2020-08-10T05:29:12.637757",
     "exception": false,
     "start_time": "2020-08-10T05:29:05.016661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got GCS path via KaggleDatasets .get_gcs_path method\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "try:\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "    dataset_gcs = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n",
    "    print('got GCS path via KaggleDatasets .get_gcs_path method')\n",
    "except ModuleNotFoundError:\n",
    "    #hardcode path while testing locally\n",
    "    dataset_gcs = 'gs://'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:12.686320Z",
     "iopub.status.busy": "2020-08-10T05:29:12.685158Z",
     "iopub.status.idle": "2020-08-10T05:29:12.690065Z",
     "shell.execute_reply": "2020-08-10T05:29:12.689312Z"
    },
    "papermill": {
     "duration": 0.030991,
     "end_time": "2020-08-10T05:29:12.690195",
     "exception": false,
     "start_time": "2020-08-10T05:29:12.659204",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:12.736349Z",
     "iopub.status.busy": "2020-08-10T05:29:12.735260Z",
     "iopub.status.idle": "2020-08-10T05:29:12.738583Z",
     "shell.execute_reply": "2020-08-10T05:29:12.737845Z"
    },
    "papermill": {
     "duration": 0.028214,
     "end_time": "2020-08-10T05:29:12.738719",
     "exception": false,
     "start_time": "2020-08-10T05:29:12.710505",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size' : 128,\n",
    "    'img_size' : [256, 256],\n",
    "    'epochs': 350\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:12.890509Z",
     "iopub.status.busy": "2020-08-10T05:29:12.786292Z",
     "iopub.status.idle": "2020-08-10T05:29:17.045160Z",
     "shell.execute_reply": "2020-08-10T05:29:17.044059Z"
    },
    "papermill": {
     "duration": 4.287003,
     "end_time": "2020-08-10T05:29:17.045350",
     "exception": false,
     "start_time": "2020-08-10T05:29:12.758347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:17.098573Z",
     "iopub.status.busy": "2020-08-10T05:29:17.097557Z",
     "iopub.status.idle": "2020-08-10T05:29:17.101236Z",
     "shell.execute_reply": "2020-08-10T05:29:17.100579Z"
    },
    "papermill": {
     "duration": 0.030113,
     "end_time": "2020-08-10T05:29:17.101371",
     "exception": false,
     "start_time": "2020-08-10T05:29:17.071258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params['batch_size'] = params['batch_size'] * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:17.149207Z",
     "iopub.status.busy": "2020-08-10T05:29:17.148291Z",
     "iopub.status.idle": "2020-08-10T05:29:17.150875Z",
     "shell.execute_reply": "2020-08-10T05:29:17.151459Z"
    },
    "papermill": {
     "duration": 0.028759,
     "end_time": "2020-08-10T05:29:17.151631",
     "exception": false,
     "start_time": "2020-08-10T05:29:17.122872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub = pd.read_csv(dataset_gcs + '/sample_submission.csv')\n",
    "# sub.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:17.201629Z",
     "iopub.status.busy": "2020-08-10T05:29:17.200809Z",
     "iopub.status.idle": "2020-08-10T05:29:26.666973Z",
     "shell.execute_reply": "2020-08-10T05:29:26.666355Z"
    },
    "papermill": {
     "duration": 9.493676,
     "end_time": "2020-08-10T05:29:26.667129",
     "exception": false,
     "start_time": "2020-08-10T05:29:17.173453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32542</td>\n",
       "      <td>32542</td>\n",
       "      <td>32477</td>\n",
       "      <td>32474</td>\n",
       "      <td>32024</td>\n",
       "      <td>32542</td>\n",
       "      <td>32542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>575</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name  patient_id    sex  age_approx  \\\n",
       "target                                              \n",
       "0            32542       32542  32477       32474   \n",
       "1              584         584    584         584   \n",
       "\n",
       "        anatom_site_general_challenge  diagnosis  benign_malignant  \n",
       "target                                                              \n",
       "0                               32024      32542             32542  \n",
       "1                                 575        584               584  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(dataset_gcs + '/train.csv')\n",
    "train_df.groupby('target').count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:26.721346Z",
     "iopub.status.busy": "2020-08-10T05:29:26.720466Z",
     "iopub.status.idle": "2020-08-10T05:29:26.723851Z",
     "shell.execute_reply": "2020-08-10T05:29:26.723121Z"
    },
    "papermill": {
     "duration": 0.034585,
     "end_time": "2020-08-10T05:29:26.723985",
     "exception": false,
     "start_time": "2020-08-10T05:29:26.689400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image_label(tfrec):\n",
    "    '''\n",
    "    function to decode an image and target label from tfrecord\n",
    "    \n",
    "    args:\n",
    "        tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "    returns:\n",
    "        decoded_image: tensor, converted image from tfrecord\n",
    "        label: tensor, integer, either 1 or 0\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "    decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "    decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "    label = features['target']\n",
    "    \n",
    "    return decoded_image, label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:26.777665Z",
     "iopub.status.busy": "2020-08-10T05:29:26.776646Z",
     "iopub.status.idle": "2020-08-10T05:29:26.779776Z",
     "shell.execute_reply": "2020-08-10T05:29:26.779192Z"
    },
    "papermill": {
     "duration": 0.034023,
     "end_time": "2020-08-10T05:29:26.779907",
     "exception": false,
     "start_time": "2020-08-10T05:29:26.745884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(tfrec):\n",
    "    '''\n",
    "    function to decode an image from tfrecord\n",
    "    \n",
    "    args:\n",
    "        tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "    returns:\n",
    "        decoded_image: tensor, converted image from tfrecord\n",
    "        img_name: tensor, string, Id of the decoded image\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "    features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "    decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "    decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "    img_name = features['image_name']\n",
    "    \n",
    "    return decoded_image, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:26.833829Z",
     "iopub.status.busy": "2020-08-10T05:29:26.832680Z",
     "iopub.status.idle": "2020-08-10T05:29:26.836282Z",
     "shell.execute_reply": "2020-08-10T05:29:26.835513Z"
    },
    "papermill": {
     "duration": 0.034237,
     "end_time": "2020-08-10T05:29:26.836412",
     "exception": false,
     "start_time": "2020-08-10T05:29:26.802175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image_label(decoded_image, label):\n",
    "    '''\n",
    "    function to convert an image tensor values from 0 to 255 \n",
    "    -> -1 to 1\n",
    "    to be used when dealing with tfrecords containing labels\n",
    "    \n",
    "    args:\n",
    "        decoded_image: tensor that is an image with values from 0 to 255\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image_tensor: tensor that is an image with values from -1 to 1\n",
    "        label, same as input\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "    image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "    #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "    image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "    #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "    image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "    return image_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:26.888985Z",
     "iopub.status.busy": "2020-08-10T05:29:26.887989Z",
     "iopub.status.idle": "2020-08-10T05:29:26.890522Z",
     "shell.execute_reply": "2020-08-10T05:29:26.891092Z"
    },
    "papermill": {
     "duration": 0.032336,
     "end_time": "2020-08-10T05:29:26.891259",
     "exception": false,
     "start_time": "2020-08-10T05:29:26.858923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image(decoded_image):\n",
    "    '''\n",
    "    function to convert an image tensor values from 0 to 255 \n",
    "    -> -1 to 1\n",
    "    \n",
    "    args:\n",
    "        decoded_image: tensor that is an image with values from 0 to 255\n",
    "    \n",
    "    returns: \n",
    "        image_tensor: tensor that is an image with values from -1 to 1\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "    image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "    #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "    image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "    #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "    image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:26.944221Z",
     "iopub.status.busy": "2020-08-10T05:29:26.943211Z",
     "iopub.status.idle": "2020-08-10T05:29:26.946291Z",
     "shell.execute_reply": "2020-08-10T05:29:26.945626Z"
    },
    "papermill": {
     "duration": 0.032591,
     "end_time": "2020-08-10T05:29:26.946428",
     "exception": false,
     "start_time": "2020-08-10T05:29:26.913837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_flip(image, label):\n",
    "    '''\n",
    "    function to randomly flip images on the x and/or y axis\n",
    "    \n",
    "    args:\n",
    "        image: tensor, an image\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image: tensor, same as input, but possibly flipped on x and/or y axis\n",
    "        label, tensor, same as input\n",
    "    '''\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image, label #, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:27.001465Z",
     "iopub.status.busy": "2020-08-10T05:29:27.000601Z",
     "iopub.status.idle": "2020-08-10T05:29:27.005541Z",
     "shell.execute_reply": "2020-08-10T05:29:27.004731Z"
    },
    "papermill": {
     "duration": 0.036311,
     "end_time": "2020-08-10T05:29:27.005674",
     "exception": false,
     "start_time": "2020-08-10T05:29:26.969363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_ds(tfrecords, batch_size):\n",
    "    '''\n",
    "    function to create a ds pipeline from tfrecord files\n",
    "    \n",
    "    args:\n",
    "        tfrecords: list, tfrecord file paths\n",
    "        batch_size: int, batch size for number of records to pass into\n",
    "            model at a time\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images and labels\n",
    "    '''\n",
    "    ds = (tf.data.TFRecordDataset(filenames=[tfrecords],\n",
    "                                 num_parallel_reads=tf.data.experimental.AUTOTUNE).\n",
    "#           cache(). #need to remove cache while not usnig TPUs\n",
    "          map(decode_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(normalize_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(random_flip, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          repeat().\n",
    "          shuffle(512).\n",
    "          batch(batch_size,\n",
    "               drop_remainder=True).\n",
    "          prefetch(tf.data.experimental.AUTOTUNE)\n",
    "         )\n",
    "    \n",
    "\n",
    "    \n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:27.060905Z",
     "iopub.status.busy": "2020-08-10T05:29:27.059951Z",
     "iopub.status.idle": "2020-08-10T05:29:27.063151Z",
     "shell.execute_reply": "2020-08-10T05:29:27.062464Z"
    },
    "papermill": {
     "duration": 0.034685,
     "end_time": "2020-08-10T05:29:27.063280",
     "exception": false,
     "start_time": "2020-08-10T05:29:27.028595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_ds(tfrecords, batch_size):\n",
    "    '''\n",
    "    function to create a dataset for test data\n",
    "    args:\n",
    "        tfrecords: list, tfrecord file paths\n",
    "        batch_size: int, batch size for number of records to pass into\n",
    "            model at a time\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images and labels\n",
    "    \n",
    "    '''\n",
    "\n",
    "    ds = (tf.data.TFRecordDataset(filenames=[tfrecords],\n",
    "                                 num_parallel_reads=tf.data.experimental.AUTOTUNE).\n",
    "#           cache(). #there is no reason to cache this ds -- it is only being read 1x\n",
    "          map(decode_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(normalize_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "#           map(random_flip).\n",
    "          batch(batch_size).\n",
    "#                 drop_remainder=True).\n",
    "          prefetch(tf.data.experimental.AUTOTUNE)\n",
    "         )\n",
    "    \n",
    "    return ds\n",
    "    ###come back to this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022544,
     "end_time": "2020-08-10T05:29:27.108722",
     "exception": false,
     "start_time": "2020-08-10T05:29:27.086178",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:27.170147Z",
     "iopub.status.busy": "2020-08-10T05:29:27.169308Z",
     "iopub.status.idle": "2020-08-10T05:29:27.172297Z",
     "shell.execute_reply": "2020-08-10T05:29:27.172850Z"
    },
    "papermill": {
     "duration": 0.041151,
     "end_time": "2020-08-10T05:29:27.173043",
     "exception": false,
     "start_time": "2020-08-10T05:29:27.131892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_of_layers(input_layer, \n",
    "                  filters_, \n",
    "                  kernal, \n",
    "                  strides_, \n",
    "                  dense=None, \n",
    "                  dense_activation=None,\n",
    "                  dropout=None,\n",
    "                  cnn_activation=None):\n",
    "    '''\n",
    "    function to add the following layers to a model:\n",
    "    Conv2D, MaxPooling2D, BatchNormalization, LeadyReLU, Dense,\n",
    "        Dropout\n",
    "\n",
    "    args:\n",
    "      input_layer : input layer to be fed into above layers\n",
    "      filters_: int, number of filters in Conv2D layer\n",
    "      kernal: int, kernal size in Conv2D layer\n",
    "      strides_: int, stride size in MaxPooling2D layer\n",
    "      dense: int, number of units in dense layer, default is None\n",
    "          Will only add layer if value is passed\n",
    "      dense_activation: str, activation function to pass into Dense layer\n",
    "          default is None\n",
    "      dropout: float, dropout percentage in Dropout layer, default is None\n",
    "        must be less than 1.0. Will only add layer if value is passed \n",
    "      cnn_activation: tensorflow activation layer, default is None\n",
    "          will only add layer is value is passed. Activation layer will be\n",
    "          added after the BatchNormalization layer\n",
    "\n",
    "    returns:\n",
    "      x: model that is the same as the input_layer input plus above \n",
    "        layers added\n",
    "        \n",
    "        \n",
    "    '''\n",
    "    x_dict = {}\n",
    "    for xx in range(len(kernal)):\n",
    "        x_dict[xx] = layers.Conv2D(filters_, (kernal[xx], kernal[xx]), padding='same')(input_layer)\n",
    "    x_list = [x_dict[xx] for xx in x_dict]\n",
    "    if len(x_list) > 1:\n",
    "        x = layers.Concatenate()(x_list)\n",
    "    else:\n",
    "        x = x_list[0]\n",
    "    x = layers.MaxPooling2D(strides_, strides_)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "\n",
    "    \n",
    "    if cnn_activation:\n",
    "        x = cnn_activation(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    if dense:\n",
    "        x = layers.Dense(dense, activation=dense_activation)(x)\n",
    "    if dropout:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:27.235107Z",
     "iopub.status.busy": "2020-08-10T05:29:27.234208Z",
     "iopub.status.idle": "2020-08-10T05:29:27.237745Z",
     "shell.execute_reply": "2020-08-10T05:29:27.236995Z"
    },
    "papermill": {
     "duration": 0.041647,
     "end_time": "2020-08-10T05:29:27.237867",
     "exception": false,
     "start_time": "2020-08-10T05:29:27.196220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deconv_set_of_layers(input_layer, \n",
    "                         filters_, \n",
    "                         kernal_, \n",
    "                         stride, \n",
    "                         dense=None, \n",
    "                         dense_activation=None, \n",
    "                         dropout=None,\n",
    "                         cnn_activation=None):\n",
    "    '''\n",
    "    function to add the following layers to a model:\n",
    "    Conv2DTranspose, BatchNormalization, LeadyReLU, Dense\n",
    "\n",
    "    args:\n",
    "      input_layer : input layer to be fed into above layers\n",
    "      filters_: int, number of filters in Conv2DTranspose layer\n",
    "      kernal_: int, kernal size in Conv2DTranspose layer\n",
    "      strides_: int, stride size in Conv2DTranspose layer\n",
    "      dense: int, number of units in dense layer, default is None\n",
    "          Will only add layer if value is passed\n",
    "      dense_activation: str, activation function to pass into Dense layer\n",
    "          default is None\n",
    "      dropout: float, dropout percentage in Dropout layer, default is None\n",
    "        must be less than 1.0. Will only add layer if value is passed \n",
    "      cnn_activation: tensorflow activation layer, default is None\n",
    "          will only add layer is value is passed. Activation layer will be\n",
    "          added after the BatchNormalization layer\n",
    "\n",
    "\n",
    "    returns:\n",
    "      x: model that is the same as the input_layer input plus above \n",
    "        layers added\n",
    "    '''\n",
    "\n",
    "        \n",
    "    x_dict = {}\n",
    "    for xx in range(len(kernal_)):\n",
    "        x_dict[xx] = layers.Conv2DTranspose(filters_,\n",
    "                                           kernal_[xx],\n",
    "                                           (stride, stride),\n",
    "                                           padding='same')(input_layer)\n",
    "        x_dict[xx] = layers.BatchNormalization()(x_dict[xx])\n",
    "    x_list = [x_dict[xx] for xx in x_dict]\n",
    "    if len(x_list) > 1:\n",
    "        x = layers.Concatenate()(x_list)\n",
    "    else:\n",
    "        x = x_list[0]\n",
    "    \n",
    "    if cnn_activation:\n",
    "        x = cnn_activation(x)\n",
    "   \n",
    "    if dense:\n",
    "        x = layers.Dense(dense, activation=dense_activation)(x)\n",
    "    \n",
    "    if dropout:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:27.307725Z",
     "iopub.status.busy": "2020-08-10T05:29:27.306683Z",
     "iopub.status.idle": "2020-08-10T05:29:27.309381Z",
     "shell.execute_reply": "2020-08-10T05:29:27.309913Z"
    },
    "papermill": {
     "duration": 0.048823,
     "end_time": "2020-08-10T05:29:27.310105",
     "exception": false,
     "start_time": "2020-08-10T05:29:27.261282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape=[*params['img_size'], 3], bias_output=None):\n",
    "    '''\n",
    "    function to create a model that will be trained on train DS\n",
    "    \n",
    "    args:\n",
    "        input_shape: array, default: [1024, 1024, 3], shape\n",
    "            of input tensor that will be fed into model\n",
    "    \n",
    "    returns:\n",
    "        model: tf.sequential() model\n",
    "    '''\n",
    "\n",
    "    relu = layers.ReLU()\n",
    "    leakyrelu = layers.LeakyReLU()\n",
    "    input_tensor = layers.Input(shape=input_shape, name='images_input')\n",
    "    x = input_tensor\n",
    "    filters_list = [64, 128, 256, 512, 1024]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x = set_of_layers(x, filter_, [3, 5], 2, 16,  dropout=0.35, dense_activation='tanh', \n",
    "                           cnn_activation=relu)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "#         x2 = set_of_layers(x, filter_, 5, 2, 16,  dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "#         x = layers.Concatenate()([x1, x2])\n",
    "#         x = layers.Dense(filter_, activation='elu')(x) #consider adding dropout\n",
    "#         x = layers.Dropout(0.35)(x)\n",
    "    \n",
    "    \n",
    "    filters_list = [1024, 512, 256]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x = deconv_set_of_layers(x, filter_, [2, 4], 2, 16,  dense_activation='tanh', cnn_activation=relu,\n",
    "                                 dropout=0.35)\n",
    "#         x2= deconv_set_of_layers(x, filter_, 4, 2, 16,  dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = deconv_set_of_layers(x, filter_, 4, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = deconv_set_of_layers(x, filter_, 4, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "#         x = layers.Concatenate()([x1, x2])\n",
    "#         x = layers.Dense(filter_, activation='elu')(x)\n",
    "#         x = layers.Dropout(0.35)(x)        \n",
    "    \n",
    "    filters_list = [256, 512, 1024]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x = set_of_layers(x, filter_, [3, 5], 2, 16,  dropout=0.35, dense_activation='tanh',\n",
    "                           cnn_activation=relu)\n",
    "#         x2 = set_of_layers(x, filter_, 5, 2, 16,  dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "#         x = layers.Concatenate()([x1, x2])\n",
    "#         x = layers.Dense(filter_, activation='elu')(x)\n",
    "#         x = layers.Dropout(0.35)(x)\n",
    "    \n",
    "\n",
    "    #layers.Concatenate\n",
    "\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "#     model.add(layers.Dense(64))\n",
    "    \n",
    "    if bias_output is not None:\n",
    "        bias_output = tf.keras.initializers.Constant(bias_output)\n",
    "    output_layer = layers.Dense(1, activation='sigmoid', bias_initializer=bias_output)(x)\n",
    "    \n",
    "    model=keras.Model(inputs=[input_tensor],\n",
    "                     outputs=[output_layer])\n",
    "\n",
    " \n",
    "           \n",
    "    metrics = [\n",
    "          keras.metrics.TruePositives(name='tp'),\n",
    "#           keras.metrics.FalsePositives(name='fp'),\n",
    "#           keras.metrics.TrueNegatives(name='tn'),\n",
    "          keras.metrics.FalseNegatives(name='fn'), \n",
    "          keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#           keras.metrics.Precision(name='precision'),\n",
    "#           keras.metrics.Recall(name='recall'),\n",
    "          keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "    schedule = None\n",
    "    \n",
    "    model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.00033),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.01),\n",
    "    metrics=metrics\n",
    ")\n",
    "    \n",
    "\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:27.365550Z",
     "iopub.status.busy": "2020-08-10T05:29:27.364537Z",
     "iopub.status.idle": "2020-08-10T05:29:27.367978Z",
     "shell.execute_reply": "2020-08-10T05:29:27.367223Z"
    },
    "papermill": {
     "duration": 0.034554,
     "end_time": "2020-08-10T05:29:27.368133",
     "exception": false,
     "start_time": "2020-08-10T05:29:27.333579",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ds_size(files):\n",
    "    '''\n",
    "    function to get size of tfrecord Dataset, based on file name\n",
    "    \n",
    "    the file name has the number of records in the file, for example:\n",
    "    train09-2071.tfrec has 2017 records\n",
    "    \n",
    "    args:\n",
    "        files: list of str file names, each item should be the path to a tfrecord file\n",
    "    \n",
    "    returns:\n",
    "        size: int, size of dataset\n",
    "    '''\n",
    "    size = 0\n",
    "    for file in files:\n",
    "        file_size = int(file.split('.tfrec')[0].split('tfrecords/')[1].split('-')[1])\n",
    "        size += file_size\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:27.591545Z",
     "iopub.status.busy": "2020-08-10T05:29:27.586562Z",
     "iopub.status.idle": "2020-08-10T05:29:28.311476Z",
     "shell.execute_reply": "2020-08-10T05:29:28.310631Z"
    },
    "papermill": {
     "duration": 0.919898,
     "end_time": "2020-08-10T05:29:28.311604",
     "exception": false,
     "start_time": "2020-08-10T05:29:27.391706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get test file paths\n",
    "test_files = tf.io.gfile.glob(dataset_gcs + '/tfrecords/test*.tfrec')\n",
    "\n",
    "#get train and validation file paths\n",
    "train_files, valid_files = train_test_split(tf.io.gfile.glob(dataset_gcs + '/tfrecords/train*.tfrec'),\n",
    "                              test_size=.1, random_state=1)\n",
    "\n",
    "#create datasets\n",
    "train_ds = get_train_ds(train_files, params['batch_size'])\n",
    "valid_ds = get_train_ds(valid_files, params['batch_size'])\n",
    "test_ds = get_test_ds(test_files, params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:28.365324Z",
     "iopub.status.busy": "2020-08-10T05:29:28.364523Z",
     "iopub.status.idle": "2020-08-10T05:29:28.367784Z",
     "shell.execute_reply": "2020-08-10T05:29:28.368736Z"
    },
    "papermill": {
     "duration": 0.034059,
     "end_time": "2020-08-10T05:29:28.368958",
     "exception": false,
     "start_time": "2020-08-10T05:29:28.334899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset consists of: 28984 training images, 4142 validation images, and 10982 test images\n"
     ]
    }
   ],
   "source": [
    "train_size, valid_size = get_ds_size(train_files), get_ds_size(valid_files)\n",
    "test_size = get_ds_size(test_files)\n",
    "print('the dataset consists of: {} training images, {} validation images, and {} test images'.\n",
    "     format(train_size, valid_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.024878,
     "end_time": "2020-08-10T05:29:28.418699",
     "exception": false,
     "start_time": "2020-08-10T05:29:28.393821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:28.473067Z",
     "iopub.status.busy": "2020-08-10T05:29:28.471947Z",
     "iopub.status.idle": "2020-08-10T05:29:28.475504Z",
     "shell.execute_reply": "2020-08-10T05:29:28.474867Z"
    },
    "papermill": {
     "duration": 0.033353,
     "end_time": "2020-08-10T05:29:28.475640",
     "exception": false,
     "start_time": "2020-08-10T05:29:28.442287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch_steps = train_size / params['batch_size'] \n",
    "valid_steps = valid_size / params['batch_size']\n",
    "test_steps = 1.0 * test_size / params['batch_size'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:28.534284Z",
     "iopub.status.busy": "2020-08-10T05:29:28.533405Z",
     "iopub.status.idle": "2020-08-10T05:29:28.574657Z",
     "shell.execute_reply": "2020-08-10T05:29:28.575364Z"
    },
    "papermill": {
     "duration": 0.076334,
     "end_time": "2020-08-10T05:29:28.575543",
     "exception": false,
     "start_time": "2020-08-10T05:29:28.499209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate class weights\n",
    "\n",
    "targets = train_df.groupby('target').count()['diagnosis'].to_list()\n",
    "target_0 = targets[0]\n",
    "target_1 = targets[1]\n",
    "total = target_0 + target_1\n",
    "\n",
    "class_weight_0 = (1 / target_0) * (total) / 2.0\n",
    "class_weight_1 = (1 / target_1) * (total) / 2.0\n",
    "\n",
    "class_weights = {0: class_weight_0, 1: class_weight_1}\n",
    "\n",
    "initial_bias = np.log([target_1 / target_0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.025821,
     "end_time": "2020-08-10T05:29:28.626335",
     "exception": false,
     "start_time": "2020-08-10T05:29:28.600514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:28.680038Z",
     "iopub.status.busy": "2020-08-10T05:29:28.679268Z",
     "iopub.status.idle": "2020-08-10T05:29:34.746441Z",
     "shell.execute_reply": "2020-08-10T05:29:34.747377Z"
    },
    "papermill": {
     "duration": 6.097709,
     "end_time": "2020-08-10T05:29:34.747615",
     "exception": false,
     "start_time": "2020-08-10T05:29:28.649906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "images_input (InputLayer)       [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 64) 1792        images_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 4864        images_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256, 256, 128 0           conv2d[0][0]                     \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 128 0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 128 512         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 concatenate_5[0][0]              \n",
      "                                                                 concatenate_6[0][0]              \n",
      "                                                                 concatenate_7[0][0]              \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 128, 128, 128 0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128, 128, 16) 2064        re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128, 128, 16) 0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 18560       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 51328       dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 256 0           conv2d_2[0][0]                   \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 256)  0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 64, 64, 256)  1024        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 64, 64, 256)  0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64, 64, 16)   4112        re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 64, 64, 16)   0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  37120       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  102656      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 64, 64, 512)  0           conv2d_4[0][0]                   \n",
      "                                                                 conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 512)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 32, 32, 512)  2048        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 32, 32, 512)  0           re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 32, 32, 16)   8208        re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 32, 32, 16)   0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 512)  74240       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  205312      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 1024) 0           conv2d_6[0][0]                   \n",
      "                                                                 conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 16, 16, 1024) 0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 16, 16, 1024) 4096        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 16, 16, 1024) 0           re_lu[3][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 16, 16, 16)   16400       re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 16, 16, 16)   0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 1024) 148480      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 410624      dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 2048) 0           conv2d_8[0][0]                   \n",
      "                                                                 conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 2048)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 8, 8, 2048)   8192        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 8, 8, 2048)   0           re_lu[4][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 8, 8, 16)     32784       re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 8, 8, 16)     0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 16, 16, 1024) 66560       dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 1024) 263168      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 16, 16, 1024) 4096        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 1024) 4096        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 2048) 0           batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 16, 16, 16)   32784       re_lu[5][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 16)   0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 512)  33280       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 32, 32, 512)  131584      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 32, 32, 512)  2048        conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 32, 32, 512)  2048        conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 1024) 0           batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 32, 32, 16)   16400       re_lu[6][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 32, 32, 16)   0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 64, 64, 256)  16640       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 256)  65792       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 256)  1024        conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 256)  1024        conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 512)  0           batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 64, 64, 16)   8208        re_lu[7][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64, 64, 16)   0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 256)  37120       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 256)  102656      dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 64, 64, 512)  0           conv2d_10[0][0]                  \n",
      "                                                                 conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 512)  0           concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 512)  2048        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 32, 32, 512)  0           re_lu[8][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 32, 32, 16)   8208        re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 32, 32, 16)   0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 512)  74240       dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 512)  205312      dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 32, 32, 1024) 0           conv2d_12[0][0]                  \n",
      "                                                                 conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 1024) 0           concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 16, 16, 1024) 4096        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 16, 16, 1024) 0           re_lu[9][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 16, 16, 16)   16400       re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 16, 16, 16)   0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 1024) 148480      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 1024) 410624      dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 16, 16, 2048) 0           conv2d_14[0][0]                  \n",
      "                                                                 conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 8, 8, 2048)   0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 8, 8, 2048)   8192        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 8, 8, 2048)   0           re_lu[10][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 8, 8, 16)     32784       re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 8, 8, 16)     0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 1024)         0           dropout_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 128)          131200      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            129         dense_11[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,964,657\n",
      "Trainable params: 2,942,385\n",
      "Non-trainable params: 22,272\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model(bias_output=initial_bias)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023785,
     "end_time": "2020-08-10T05:29:34.802909",
     "exception": false,
     "start_time": "2020-08-10T05:29:34.779124",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T05:29:34.863831Z",
     "iopub.status.busy": "2020-08-10T05:29:34.862857Z",
     "iopub.status.idle": "2020-08-10T07:26:16.782372Z",
     "shell.execute_reply": "2020-08-10T07:26:16.781673Z"
    },
    "papermill": {
     "duration": 7001.954688,
     "end_time": "2020-08-10T07:26:16.782530",
     "exception": false,
     "start_time": "2020-08-10T05:29:34.827842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "29/28 [==============================] - 45s 2s/step - accuracy: 0.5018 - fn: 274.0000 - tp: 252.0000 - loss: 1.0096 - auc: 0.4870 - val_accuracy: 0.9834 - val_fn: 85.0000 - val_tp: 0.0000e+00 - val_loss: 0.1039 - val_auc: 0.5000\n",
      "Epoch 2/350\n",
      "29/28 [==============================] - 25s 865ms/step - accuracy: 0.6068 - fn: 198.0000 - tp: 329.0000 - loss: 0.7592 - auc: 0.6530 - val_accuracy: 0.9828 - val_fn: 88.0000 - val_tp: 0.0000e+00 - val_loss: 0.1062 - val_auc: 0.5000\n",
      "Epoch 3/350\n",
      "29/28 [==============================] - 25s 861ms/step - accuracy: 0.6021 - fn: 175.0000 - tp: 348.0000 - loss: 0.6744 - auc: 0.7055 - val_accuracy: 0.9834 - val_fn: 85.0000 - val_tp: 0.0000e+00 - val_loss: 0.1039 - val_auc: 0.5000\n",
      "Epoch 4/350\n",
      "29/28 [==============================] - 25s 858ms/step - accuracy: 0.6070 - fn: 161.0000 - tp: 368.0000 - loss: 0.6539 - auc: 0.7090 - val_accuracy: 0.9832 - val_fn: 86.0000 - val_tp: 0.0000e+00 - val_loss: 0.1046 - val_auc: 0.5000\n",
      "Epoch 5/350\n",
      "29/28 [==============================] - 25s 875ms/step - accuracy: 0.6058 - fn: 140.0000 - tp: 388.0000 - loss: 0.6154 - auc: 0.7261 - val_accuracy: 0.9838 - val_fn: 83.0000 - val_tp: 0.0000e+00 - val_loss: 0.1023 - val_auc: 0.5000\n",
      "Epoch 6/350\n",
      "29/28 [==============================] - 26s 889ms/step - accuracy: 0.6136 - fn: 123.0000 - tp: 407.0000 - loss: 0.5946 - auc: 0.7414 - val_accuracy: 0.9832 - val_fn: 86.0000 - val_tp: 0.0000e+00 - val_loss: 0.1046 - val_auc: 0.5000\n",
      "Epoch 7/350\n",
      "29/28 [==============================] - 25s 869ms/step - accuracy: 0.6127 - fn: 133.0000 - tp: 393.0000 - loss: 0.6054 - auc: 0.7334 - val_accuracy: 0.9840 - val_fn: 82.0000 - val_tp: 0.0000e+00 - val_loss: 0.1016 - val_auc: 0.5000\n",
      "Epoch 8/350\n",
      "29/28 [==============================] - 25s 873ms/step - accuracy: 0.6094 - fn: 113.0000 - tp: 419.0000 - loss: 0.5825 - auc: 0.7464 - val_accuracy: 0.9828 - val_fn: 88.0000 - val_tp: 0.0000e+00 - val_loss: 0.1062 - val_auc: 0.5000\n",
      "Epoch 9/350\n",
      "29/28 [==============================] - 25s 851ms/step - accuracy: 0.6029 - fn: 110.0000 - tp: 417.0000 - loss: 0.5885 - auc: 0.7422 - val_accuracy: 0.9840 - val_fn: 82.0000 - val_tp: 0.0000e+00 - val_loss: 0.1016 - val_auc: 0.5000\n",
      "Epoch 10/350\n",
      "29/28 [==============================] - 32s 1s/step - accuracy: 0.6413 - fn: 127.0000 - tp: 401.0000 - loss: 0.5905 - auc: 0.7575 - val_accuracy: 0.9826 - val_fn: 89.0000 - val_tp: 0.0000e+00 - val_loss: 0.1072 - val_auc: 0.5000\n",
      "Epoch 11/350\n",
      "29/28 [==============================] - 27s 920ms/step - accuracy: 0.6283 - fn: 108.0000 - tp: 427.0000 - loss: 0.5715 - auc: 0.7677 - val_accuracy: 0.9832 - val_fn: 86.0000 - val_tp: 0.0000e+00 - val_loss: 0.1048 - val_auc: 0.5000\n",
      "Epoch 12/350\n",
      "29/28 [==============================] - 27s 940ms/step - accuracy: 0.6273 - fn: 101.0000 - tp: 430.0000 - loss: 0.5615 - auc: 0.7681 - val_accuracy: 0.9836 - val_fn: 84.0000 - val_tp: 0.0000e+00 - val_loss: 0.1032 - val_auc: 0.5000\n",
      "Epoch 13/350\n",
      "29/28 [==============================] - 27s 925ms/step - accuracy: 0.6283 - fn: 100.0000 - tp: 434.0000 - loss: 0.5530 - auc: 0.7754 - val_accuracy: 0.9836 - val_fn: 84.0000 - val_tp: 0.0000e+00 - val_loss: 0.1032 - val_auc: 0.5000\n",
      "Epoch 14/350\n",
      "29/28 [==============================] - 25s 848ms/step - accuracy: 0.6215 - fn: 85.0000 - tp: 437.0000 - loss: 0.5491 - auc: 0.7732 - val_accuracy: 0.9834 - val_fn: 85.0000 - val_tp: 0.0000e+00 - val_loss: 0.1040 - val_auc: 0.5000\n",
      "Epoch 15/350\n",
      "29/28 [==============================] - 25s 846ms/step - accuracy: 0.6221 - fn: 98.0000 - tp: 425.0000 - loss: 0.5551 - auc: 0.7696 - val_accuracy: 0.9830 - val_fn: 87.0000 - val_tp: 0.0000e+00 - val_loss: 0.1056 - val_auc: 0.5000\n",
      "Epoch 16/350\n",
      "29/28 [==============================] - 26s 892ms/step - accuracy: 0.6205 - fn: 100.0000 - tp: 431.0000 - loss: 0.5572 - auc: 0.7683 - val_accuracy: 0.9834 - val_fn: 85.0000 - val_tp: 0.0000e+00 - val_loss: 0.1041 - val_auc: 0.5000\n",
      "Epoch 17/350\n",
      "29/28 [==============================] - 27s 933ms/step - accuracy: 0.6343 - fn: 94.0000 - tp: 429.0000 - loss: 0.5570 - auc: 0.7663 - val_accuracy: 0.9836 - val_fn: 84.0000 - val_tp: 0.0000e+00 - val_loss: 0.1010 - val_auc: 0.6164\n",
      "Epoch 18/350\n",
      "29/28 [==============================] - 26s 907ms/step - accuracy: 0.6247 - fn: 90.0000 - tp: 441.0000 - loss: 0.5463 - auc: 0.7740 - val_accuracy: 0.9840 - val_fn: 82.0000 - val_tp: 0.0000e+00 - val_loss: 0.0985 - val_auc: 0.6831\n",
      "Epoch 19/350\n",
      "29/28 [==============================] - 26s 885ms/step - accuracy: 0.6269 - fn: 108.0000 - tp: 418.0000 - loss: 0.5665 - auc: 0.7601 - val_accuracy: 0.9830 - val_fn: 87.0000 - val_tp: 0.0000e+00 - val_loss: 0.1071 - val_auc: 0.7497\n",
      "Epoch 20/350\n",
      "29/28 [==============================] - 25s 859ms/step - accuracy: 0.6169 - fn: 83.0000 - tp: 443.0000 - loss: 0.5442 - auc: 0.7729 - val_accuracy: 0.9830 - val_fn: 87.0000 - val_tp: 0.0000e+00 - val_loss: 0.1305 - val_auc: 0.6568\n",
      "Epoch 21/350\n",
      "29/28 [==============================] - 26s 899ms/step - accuracy: 0.6347 - fn: 88.0000 - tp: 439.0000 - loss: 0.5425 - auc: 0.7792 - val_accuracy: 0.9830 - val_fn: 87.0000 - val_tp: 0.0000e+00 - val_loss: 0.1272 - val_auc: 0.7074\n",
      "Epoch 22/350\n",
      "29/28 [==============================] - 28s 956ms/step - accuracy: 0.6562 - fn: 98.0000 - tp: 428.0000 - loss: 0.5436 - auc: 0.7890 - val_accuracy: 0.9832 - val_fn: 86.0000 - val_tp: 0.0000e+00 - val_loss: 0.1313 - val_auc: 0.7082\n",
      "Epoch 23/350\n",
      "29/28 [==============================] - 26s 912ms/step - accuracy: 0.6207 - fn: 95.0000 - tp: 438.0000 - loss: 0.5441 - auc: 0.7769 - val_accuracy: 0.9828 - val_fn: 88.0000 - val_tp: 0.0000e+00 - val_loss: 0.1252 - val_auc: 0.7490\n",
      "Epoch 24/350\n",
      "29/28 [==============================] - 28s 956ms/step - accuracy: 0.6208 - fn: 86.0000 - tp: 440.0000 - loss: 0.5420 - auc: 0.7794 - val_accuracy: 0.9006 - val_fn: 61.0000 - val_tp: 24.0000 - val_loss: 0.1829 - val_auc: 0.7599\n",
      "Epoch 25/350\n",
      "29/28 [==============================] - 27s 938ms/step - accuracy: 0.6381 - fn: 87.0000 - tp: 436.0000 - loss: 0.5446 - auc: 0.7817 - val_accuracy: 0.9187 - val_fn: 68.0000 - val_tp: 18.0000 - val_loss: 0.1742 - val_auc: 0.7363\n",
      "Epoch 26/350\n",
      "29/28 [==============================] - 28s 948ms/step - accuracy: 0.6292 - fn: 79.0000 - tp: 449.0000 - loss: 0.5238 - auc: 0.7940 - val_accuracy: 0.9309 - val_fn: 71.0000 - val_tp: 14.0000 - val_loss: 0.1576 - val_auc: 0.7374\n",
      "Epoch 27/350\n",
      "29/28 [==============================] - 28s 981ms/step - accuracy: 0.6405 - fn: 75.0000 - tp: 452.0000 - loss: 0.5124 - auc: 0.8002 - val_accuracy: 0.9186 - val_fn: 60.0000 - val_tp: 21.0000 - val_loss: 0.1648 - val_auc: 0.7483\n",
      "Epoch 28/350\n",
      "29/28 [==============================] - 25s 877ms/step - accuracy: 0.6320 - fn: 70.0000 - tp: 459.0000 - loss: 0.5197 - auc: 0.7960 - val_accuracy: 0.9141 - val_fn: 65.0000 - val_tp: 18.0000 - val_loss: 0.1677 - val_auc: 0.7294\n",
      "Epoch 29/350\n",
      "29/28 [==============================] - 26s 907ms/step - accuracy: 0.6368 - fn: 75.0000 - tp: 456.0000 - loss: 0.5185 - auc: 0.7959 - val_accuracy: 0.9229 - val_fn: 68.0000 - val_tp: 17.0000 - val_loss: 0.1686 - val_auc: 0.7084\n",
      "Epoch 30/350\n",
      "29/28 [==============================] - 25s 850ms/step - accuracy: 0.6447 - fn: 68.0000 - tp: 458.0000 - loss: 0.5057 - auc: 0.8060 - val_accuracy: 0.9268 - val_fn: 67.0000 - val_tp: 20.0000 - val_loss: 0.1597 - val_auc: 0.7560\n",
      "Epoch 31/350\n",
      "29/28 [==============================] - 25s 870ms/step - accuracy: 0.6481 - fn: 95.0000 - tp: 429.0000 - loss: 0.5289 - auc: 0.7949 - val_accuracy: 0.9035 - val_fn: 60.0000 - val_tp: 24.0000 - val_loss: 0.1746 - val_auc: 0.7678\n",
      "Epoch 32/350\n",
      "29/28 [==============================] - 27s 916ms/step - accuracy: 0.6631 - fn: 92.0000 - tp: 438.0000 - loss: 0.5278 - auc: 0.7988 - val_accuracy: 0.9369 - val_fn: 72.0000 - val_tp: 10.0000 - val_loss: 0.1440 - val_auc: 0.7438\n",
      "Epoch 33/350\n",
      "29/28 [==============================] - 27s 923ms/step - accuracy: 0.6523 - fn: 90.0000 - tp: 440.0000 - loss: 0.5285 - auc: 0.7928 - val_accuracy: 0.8900 - val_fn: 58.0000 - val_tp: 25.0000 - val_loss: 0.1991 - val_auc: 0.7531\n",
      "Epoch 34/350\n",
      "29/28 [==============================] - 25s 879ms/step - accuracy: 0.6483 - fn: 88.0000 - tp: 442.0000 - loss: 0.5280 - auc: 0.7965 - val_accuracy: 0.9295 - val_fn: 71.0000 - val_tp: 12.0000 - val_loss: 0.1635 - val_auc: 0.7389\n",
      "Epoch 35/350\n",
      "29/28 [==============================] - 28s 970ms/step - accuracy: 0.6632 - fn: 86.0000 - tp: 441.0000 - loss: 0.5210 - auc: 0.8027 - val_accuracy: 0.8336 - val_fn: 51.0000 - val_tp: 36.0000 - val_loss: 0.3461 - val_auc: 0.7674\n",
      "Epoch 36/350\n",
      "29/28 [==============================] - 27s 917ms/step - accuracy: 0.6604 - fn: 85.0000 - tp: 445.0000 - loss: 0.5308 - auc: 0.7978 - val_accuracy: 0.8691 - val_fn: 57.0000 - val_tp: 30.0000 - val_loss: 0.2676 - val_auc: 0.7465\n",
      "Epoch 37/350\n",
      "29/28 [==============================] - 28s 956ms/step - accuracy: 0.6802 - fn: 86.0000 - tp: 437.0000 - loss: 0.5006 - auc: 0.8173 - val_accuracy: 0.8703 - val_fn: 56.0000 - val_tp: 28.0000 - val_loss: 0.2915 - val_auc: 0.7480\n",
      "Epoch 38/350\n",
      "29/28 [==============================] - 27s 932ms/step - accuracy: 0.6571 - fn: 76.0000 - tp: 452.0000 - loss: 0.5202 - auc: 0.8022 - val_accuracy: 0.8678 - val_fn: 59.0000 - val_tp: 26.0000 - val_loss: 0.2616 - val_auc: 0.7633\n",
      "Epoch 39/350\n",
      "29/28 [==============================] - 25s 869ms/step - accuracy: 0.6657 - fn: 83.0000 - tp: 436.0000 - loss: 0.5058 - auc: 0.8129 - val_accuracy: 0.9025 - val_fn: 59.0000 - val_tp: 26.0000 - val_loss: 0.2051 - val_auc: 0.7612\n",
      "Epoch 40/350\n",
      "29/28 [==============================] - 25s 860ms/step - accuracy: 0.6643 - fn: 70.0000 - tp: 460.0000 - loss: 0.5004 - auc: 0.8126 - val_accuracy: 0.9045 - val_fn: 60.0000 - val_tp: 22.0000 - val_loss: 0.2064 - val_auc: 0.7447\n",
      "Epoch 41/350\n",
      "29/28 [==============================] - 26s 906ms/step - accuracy: 0.6546 - fn: 63.0000 - tp: 465.0000 - loss: 0.5165 - auc: 0.8054 - val_accuracy: 0.8900 - val_fn: 53.0000 - val_tp: 27.0000 - val_loss: 0.1946 - val_auc: 0.7934\n",
      "Epoch 42/350\n",
      "29/28 [==============================] - 25s 864ms/step - accuracy: 0.6828 - fn: 85.0000 - tp: 438.0000 - loss: 0.5052 - auc: 0.8139 - val_accuracy: 0.8793 - val_fn: 61.0000 - val_tp: 26.0000 - val_loss: 0.2238 - val_auc: 0.7394\n",
      "Epoch 43/350\n",
      "29/28 [==============================] - 26s 909ms/step - accuracy: 0.6623 - fn: 79.0000 - tp: 452.0000 - loss: 0.5188 - auc: 0.8038 - val_accuracy: 0.8779 - val_fn: 58.0000 - val_tp: 27.0000 - val_loss: 0.2046 - val_auc: 0.7622\n",
      "Epoch 44/350\n",
      "29/28 [==============================] - 28s 976ms/step - accuracy: 0.6719 - fn: 79.0000 - tp: 449.0000 - loss: 0.4987 - auc: 0.8136 - val_accuracy: 0.9016 - val_fn: 69.0000 - val_tp: 16.0000 - val_loss: 0.2046 - val_auc: 0.6801\n",
      "Epoch 45/350\n",
      "29/28 [==============================] - 27s 918ms/step - accuracy: 0.6672 - fn: 83.0000 - tp: 441.0000 - loss: 0.5082 - auc: 0.8095 - val_accuracy: 0.9021 - val_fn: 66.0000 - val_tp: 21.0000 - val_loss: 0.2175 - val_auc: 0.7504\n",
      "Epoch 46/350\n",
      "29/28 [==============================] - 26s 910ms/step - accuracy: 0.6844 - fn: 87.0000 - tp: 442.0000 - loss: 0.5026 - auc: 0.8219 - val_accuracy: 0.8848 - val_fn: 57.0000 - val_tp: 28.0000 - val_loss: 0.2231 - val_auc: 0.7875\n",
      "Epoch 47/350\n",
      "29/28 [==============================] - 27s 933ms/step - accuracy: 0.6703 - fn: 87.0000 - tp: 443.0000 - loss: 0.5157 - auc: 0.8092 - val_accuracy: 0.8928 - val_fn: 65.0000 - val_tp: 22.0000 - val_loss: 0.2013 - val_auc: 0.7435\n",
      "Epoch 48/350\n",
      "29/28 [==============================] - 25s 854ms/step - accuracy: 0.6676 - fn: 84.0000 - tp: 451.0000 - loss: 0.5164 - auc: 0.8075 - val_accuracy: 0.8559 - val_fn: 55.0000 - val_tp: 31.0000 - val_loss: 0.2832 - val_auc: 0.7774\n",
      "Epoch 49/350\n",
      "29/28 [==============================] - 26s 908ms/step - accuracy: 0.6698 - fn: 92.0000 - tp: 430.0000 - loss: 0.5088 - auc: 0.8116 - val_accuracy: 0.8783 - val_fn: 55.0000 - val_tp: 29.0000 - val_loss: 0.2734 - val_auc: 0.7400\n",
      "Epoch 50/350\n",
      "29/28 [==============================] - 28s 981ms/step - accuracy: 0.6729 - fn: 69.0000 - tp: 459.0000 - loss: 0.4919 - auc: 0.8232 - val_accuracy: 0.8898 - val_fn: 61.0000 - val_tp: 25.0000 - val_loss: 0.2297 - val_auc: 0.7394\n",
      "Epoch 51/350\n",
      "29/28 [==============================] - 26s 895ms/step - accuracy: 0.6402 - fn: 73.0000 - tp: 459.0000 - loss: 0.5149 - auc: 0.8041 - val_accuracy: 0.8764 - val_fn: 55.0000 - val_tp: 31.0000 - val_loss: 0.2552 - val_auc: 0.7893\n",
      "Epoch 52/350\n",
      "29/28 [==============================] - 28s 974ms/step - accuracy: 0.6790 - fn: 63.0000 - tp: 467.0000 - loss: 0.4816 - auc: 0.8266 - val_accuracy: 0.8768 - val_fn: 59.0000 - val_tp: 31.0000 - val_loss: 0.2568 - val_auc: 0.7830\n",
      "Epoch 53/350\n",
      "29/28 [==============================] - 25s 877ms/step - accuracy: 0.6673 - fn: 77.0000 - tp: 459.0000 - loss: 0.5084 - auc: 0.8134 - val_accuracy: 0.9006 - val_fn: 62.0000 - val_tp: 25.0000 - val_loss: 0.2218 - val_auc: 0.7514\n",
      "Epoch 54/350\n",
      "29/28 [==============================] - 28s 954ms/step - accuracy: 0.6644 - fn: 71.0000 - tp: 451.0000 - loss: 0.5005 - auc: 0.8146 - val_accuracy: 0.9133 - val_fn: 66.0000 - val_tp: 20.0000 - val_loss: 0.2055 - val_auc: 0.7606\n",
      "Epoch 55/350\n",
      "29/28 [==============================] - 25s 859ms/step - accuracy: 0.6633 - fn: 88.0000 - tp: 439.0000 - loss: 0.5081 - auc: 0.8133 - val_accuracy: 0.8936 - val_fn: 64.0000 - val_tp: 24.0000 - val_loss: 0.2166 - val_auc: 0.7926\n",
      "Epoch 56/350\n",
      "29/28 [==============================] - 25s 865ms/step - accuracy: 0.6849 - fn: 81.0000 - tp: 445.0000 - loss: 0.4897 - auc: 0.8242 - val_accuracy: 0.8648 - val_fn: 57.0000 - val_tp: 31.0000 - val_loss: 0.2389 - val_auc: 0.8078\n",
      "Epoch 57/350\n",
      "29/28 [==============================] - 25s 874ms/step - accuracy: 0.6650 - fn: 73.0000 - tp: 455.0000 - loss: 0.5037 - auc: 0.8087 - val_accuracy: 0.9254 - val_fn: 66.0000 - val_tp: 21.0000 - val_loss: 0.1620 - val_auc: 0.7759\n",
      "Epoch 58/350\n",
      "29/28 [==============================] - 26s 903ms/step - accuracy: 0.6646 - fn: 71.0000 - tp: 452.0000 - loss: 0.5025 - auc: 0.8116 - val_accuracy: 0.8984 - val_fn: 61.0000 - val_tp: 22.0000 - val_loss: 0.1781 - val_auc: 0.7619\n",
      "Epoch 59/350\n",
      "29/28 [==============================] - 28s 963ms/step - accuracy: 0.6750 - fn: 79.0000 - tp: 451.0000 - loss: 0.5055 - auc: 0.8194 - val_accuracy: 0.9088 - val_fn: 63.0000 - val_tp: 24.0000 - val_loss: 0.1702 - val_auc: 0.7792\n",
      "Epoch 60/350\n",
      "29/28 [==============================] - 26s 913ms/step - accuracy: 0.6790 - fn: 73.0000 - tp: 455.0000 - loss: 0.4902 - auc: 0.8253 - val_accuracy: 0.9258 - val_fn: 64.0000 - val_tp: 21.0000 - val_loss: 0.1632 - val_auc: 0.7473\n",
      "Epoch 61/350\n",
      "29/28 [==============================] - 27s 945ms/step - accuracy: 0.6871 - fn: 92.0000 - tp: 438.0000 - loss: 0.4909 - auc: 0.8264 - val_accuracy: 0.8951 - val_fn: 62.0000 - val_tp: 25.0000 - val_loss: 0.2045 - val_auc: 0.7660\n",
      "Epoch 62/350\n",
      "29/28 [==============================] - 25s 863ms/step - accuracy: 0.6648 - fn: 77.0000 - tp: 448.0000 - loss: 0.4932 - auc: 0.8217 - val_accuracy: 0.8936 - val_fn: 60.0000 - val_tp: 27.0000 - val_loss: 0.2141 - val_auc: 0.7695\n",
      "Epoch 63/350\n",
      "29/28 [==============================] - 26s 892ms/step - accuracy: 0.6753 - fn: 72.0000 - tp: 453.0000 - loss: 0.4916 - auc: 0.8244 - val_accuracy: 0.8896 - val_fn: 56.0000 - val_tp: 30.0000 - val_loss: 0.2226 - val_auc: 0.7587\n",
      "Epoch 64/350\n",
      "29/28 [==============================] - 25s 853ms/step - accuracy: 0.7003 - fn: 75.0000 - tp: 457.0000 - loss: 0.4879 - auc: 0.8320 - val_accuracy: 0.8145 - val_fn: 42.0000 - val_tp: 44.0000 - val_loss: 0.3319 - val_auc: 0.7945\n",
      "Epoch 65/350\n",
      "29/28 [==============================] - 25s 856ms/step - accuracy: 0.6759 - fn: 67.0000 - tp: 455.0000 - loss: 0.4777 - auc: 0.8264 - val_accuracy: 0.8883 - val_fn: 58.0000 - val_tp: 27.0000 - val_loss: 0.2421 - val_auc: 0.7475\n",
      "Epoch 66/350\n",
      "29/28 [==============================] - 25s 855ms/step - accuracy: 0.6896 - fn: 71.0000 - tp: 458.0000 - loss: 0.4761 - auc: 0.8314 - val_accuracy: 0.8264 - val_fn: 48.0000 - val_tp: 41.0000 - val_loss: 0.3543 - val_auc: 0.7943\n",
      "Epoch 67/350\n",
      "29/28 [==============================] - 26s 885ms/step - accuracy: 0.6727 - fn: 77.0000 - tp: 455.0000 - loss: 0.4963 - auc: 0.8246 - val_accuracy: 0.8063 - val_fn: 43.0000 - val_tp: 45.0000 - val_loss: 0.3681 - val_auc: 0.7883\n",
      "Epoch 68/350\n",
      "29/28 [==============================] - 25s 850ms/step - accuracy: 0.6960 - fn: 82.0000 - tp: 445.0000 - loss: 0.4888 - auc: 0.8288 - val_accuracy: 0.8330 - val_fn: 41.0000 - val_tp: 45.0000 - val_loss: 0.2690 - val_auc: 0.7865\n",
      "Epoch 69/350\n",
      "29/28 [==============================] - 25s 863ms/step - accuracy: 0.6871 - fn: 71.0000 - tp: 456.0000 - loss: 0.4792 - auc: 0.8370 - val_accuracy: 0.8789 - val_fn: 61.0000 - val_tp: 28.0000 - val_loss: 0.2087 - val_auc: 0.7727\n",
      "Epoch 70/350\n",
      "29/28 [==============================] - 25s 860ms/step - accuracy: 0.6734 - fn: 65.0000 - tp: 458.0000 - loss: 0.4803 - auc: 0.8355 - val_accuracy: 0.9689 - val_fn: 85.0000 - val_tp: 3.0000 - val_loss: 0.1629 - val_auc: 0.7626\n",
      "Epoch 71/350\n",
      "29/28 [==============================] - 25s 863ms/step - accuracy: 0.6793 - fn: 64.0000 - tp: 466.0000 - loss: 0.4731 - auc: 0.8341 - val_accuracy: 0.9006 - val_fn: 64.0000 - val_tp: 22.0000 - val_loss: 0.1777 - val_auc: 0.7852\n",
      "Epoch 72/350\n",
      "29/28 [==============================] - 25s 856ms/step - accuracy: 0.6934 - fn: 88.0000 - tp: 435.0000 - loss: 0.4825 - auc: 0.8353 - val_accuracy: 0.8574 - val_fn: 50.0000 - val_tp: 35.0000 - val_loss: 0.2531 - val_auc: 0.7732\n",
      "Epoch 73/350\n",
      "29/28 [==============================] - 25s 856ms/step - accuracy: 0.6877 - fn: 72.0000 - tp: 460.0000 - loss: 0.4928 - auc: 0.8262 - val_accuracy: 0.8814 - val_fn: 51.0000 - val_tp: 36.0000 - val_loss: 0.2549 - val_auc: 0.7985\n",
      "Epoch 74/350\n",
      "29/28 [==============================] - 26s 904ms/step - accuracy: 0.6924 - fn: 84.0000 - tp: 448.0000 - loss: 0.4849 - auc: 0.8325 - val_accuracy: 0.8945 - val_fn: 56.0000 - val_tp: 30.0000 - val_loss: 0.1960 - val_auc: 0.8002\n",
      "Epoch 75/350\n",
      "29/28 [==============================] - 25s 876ms/step - accuracy: 0.6899 - fn: 67.0000 - tp: 462.0000 - loss: 0.4753 - auc: 0.8379 - val_accuracy: 0.9359 - val_fn: 70.0000 - val_tp: 18.0000 - val_loss: 0.1635 - val_auc: 0.7783\n",
      "Epoch 76/350\n",
      "29/28 [==============================] - 25s 856ms/step - accuracy: 0.6949 - fn: 78.0000 - tp: 445.0000 - loss: 0.4818 - auc: 0.8351 - val_accuracy: 0.8928 - val_fn: 57.0000 - val_tp: 30.0000 - val_loss: 0.1848 - val_auc: 0.8036\n",
      "Epoch 77/350\n",
      "29/28 [==============================] - 26s 896ms/step - accuracy: 0.6796 - fn: 66.0000 - tp: 464.0000 - loss: 0.4858 - auc: 0.8293 - val_accuracy: 0.9461 - val_fn: 77.0000 - val_tp: 12.0000 - val_loss: 0.1733 - val_auc: 0.8115\n",
      "Epoch 78/350\n",
      "29/28 [==============================] - 25s 861ms/step - accuracy: 0.6860 - fn: 81.0000 - tp: 447.0000 - loss: 0.4879 - auc: 0.8296 - val_accuracy: 0.9035 - val_fn: 55.0000 - val_tp: 29.0000 - val_loss: 0.1857 - val_auc: 0.8015\n",
      "Epoch 79/350\n",
      "29/28 [==============================] - 27s 926ms/step - accuracy: 0.7020 - fn: 68.0000 - tp: 455.0000 - loss: 0.4781 - auc: 0.8391 - val_accuracy: 0.8676 - val_fn: 53.0000 - val_tp: 35.0000 - val_loss: 0.2719 - val_auc: 0.7669\n",
      "Epoch 80/350\n",
      "29/28 [==============================] - 27s 945ms/step - accuracy: 0.6915 - fn: 74.0000 - tp: 449.0000 - loss: 0.4752 - auc: 0.8376 - val_accuracy: 0.8803 - val_fn: 53.0000 - val_tp: 33.0000 - val_loss: 0.2411 - val_auc: 0.7750\n",
      "Epoch 81/350\n",
      "29/28 [==============================] - 27s 926ms/step - accuracy: 0.7058 - fn: 75.0000 - tp: 452.0000 - loss: 0.4827 - auc: 0.8378 - val_accuracy: 0.8902 - val_fn: 57.0000 - val_tp: 32.0000 - val_loss: 0.2421 - val_auc: 0.7376\n",
      "Epoch 82/350\n",
      "29/28 [==============================] - 28s 953ms/step - accuracy: 0.6728 - fn: 68.0000 - tp: 461.0000 - loss: 0.4913 - auc: 0.8273 - val_accuracy: 0.8961 - val_fn: 60.0000 - val_tp: 28.0000 - val_loss: 0.2069 - val_auc: 0.7974\n",
      "Epoch 83/350\n",
      "29/28 [==============================] - 26s 896ms/step - accuracy: 0.6951 - fn: 76.0000 - tp: 454.0000 - loss: 0.4766 - auc: 0.8416 - val_accuracy: 0.9381 - val_fn: 69.0000 - val_tp: 17.0000 - val_loss: 0.1963 - val_auc: 0.7814\n",
      "Epoch 84/350\n",
      "29/28 [==============================] - 25s 849ms/step - accuracy: 0.7039 - fn: 64.0000 - tp: 460.0000 - loss: 0.4671 - auc: 0.8447 - val_accuracy: 0.8781 - val_fn: 54.0000 - val_tp: 33.0000 - val_loss: 0.1997 - val_auc: 0.8013\n",
      "Epoch 85/350\n",
      "29/28 [==============================] - 26s 892ms/step - accuracy: 0.6903 - fn: 78.0000 - tp: 447.0000 - loss: 0.4804 - auc: 0.8336 - val_accuracy: 0.8363 - val_fn: 43.0000 - val_tp: 42.0000 - val_loss: 0.2440 - val_auc: 0.8030\n",
      "Epoch 86/350\n",
      "29/28 [==============================] - 26s 904ms/step - accuracy: 0.6934 - fn: 85.0000 - tp: 445.0000 - loss: 0.4869 - auc: 0.8331 - val_accuracy: 0.8809 - val_fn: 57.0000 - val_tp: 32.0000 - val_loss: 0.2228 - val_auc: 0.7980\n",
      "Epoch 87/350\n",
      "29/28 [==============================] - 27s 934ms/step - accuracy: 0.6841 - fn: 74.0000 - tp: 456.0000 - loss: 0.4931 - auc: 0.8314 - val_accuracy: 0.8820 - val_fn: 55.0000 - val_tp: 32.0000 - val_loss: 0.2207 - val_auc: 0.7770\n",
      "Epoch 88/350\n",
      "29/28 [==============================] - 27s 933ms/step - accuracy: 0.6750 - fn: 70.0000 - tp: 456.0000 - loss: 0.4747 - auc: 0.8341 - val_accuracy: 0.8277 - val_fn: 42.0000 - val_tp: 42.0000 - val_loss: 0.2807 - val_auc: 0.8159\n",
      "Epoch 89/350\n",
      "29/28 [==============================] - 28s 951ms/step - accuracy: 0.6950 - fn: 80.0000 - tp: 452.0000 - loss: 0.4743 - auc: 0.8411 - val_accuracy: 0.9154 - val_fn: 62.0000 - val_tp: 24.0000 - val_loss: 0.1716 - val_auc: 0.7921\n",
      "Epoch 90/350\n",
      "29/28 [==============================] - 27s 921ms/step - accuracy: 0.6935 - fn: 65.0000 - tp: 459.0000 - loss: 0.4737 - auc: 0.8404 - val_accuracy: 0.8729 - val_fn: 54.0000 - val_tp: 33.0000 - val_loss: 0.2153 - val_auc: 0.7958\n",
      "Epoch 91/350\n",
      "29/28 [==============================] - 26s 900ms/step - accuracy: 0.7025 - fn: 85.0000 - tp: 446.0000 - loss: 0.4727 - auc: 0.8440 - val_accuracy: 0.8605 - val_fn: 52.0000 - val_tp: 36.0000 - val_loss: 0.2339 - val_auc: 0.7784\n",
      "Epoch 92/350\n",
      "29/28 [==============================] - 28s 953ms/step - accuracy: 0.6906 - fn: 68.0000 - tp: 461.0000 - loss: 0.4765 - auc: 0.8421 - val_accuracy: 0.7830 - val_fn: 31.0000 - val_tp: 54.0000 - val_loss: 0.3622 - val_auc: 0.8077\n",
      "Epoch 93/350\n",
      "29/28 [==============================] - 26s 883ms/step - accuracy: 0.7009 - fn: 74.0000 - tp: 453.0000 - loss: 0.4663 - auc: 0.8454 - val_accuracy: 0.8438 - val_fn: 43.0000 - val_tp: 43.0000 - val_loss: 0.3070 - val_auc: 0.7873\n",
      "Epoch 94/350\n",
      "29/28 [==============================] - 25s 865ms/step - accuracy: 0.6973 - fn: 66.0000 - tp: 468.0000 - loss: 0.4630 - auc: 0.8469 - val_accuracy: 0.8408 - val_fn: 46.0000 - val_tp: 41.0000 - val_loss: 0.2805 - val_auc: 0.7934\n",
      "Epoch 95/350\n",
      "29/28 [==============================] - 25s 871ms/step - accuracy: 0.7032 - fn: 76.0000 - tp: 456.0000 - loss: 0.4649 - auc: 0.8518 - val_accuracy: 0.8041 - val_fn: 34.0000 - val_tp: 53.0000 - val_loss: 0.3411 - val_auc: 0.8144\n",
      "Epoch 96/350\n",
      "29/28 [==============================] - 26s 880ms/step - accuracy: 0.7095 - fn: 83.0000 - tp: 445.0000 - loss: 0.4805 - auc: 0.8408 - val_accuracy: 0.8359 - val_fn: 36.0000 - val_tp: 50.0000 - val_loss: 0.3048 - val_auc: 0.8078\n",
      "Epoch 97/350\n",
      "29/28 [==============================] - 27s 929ms/step - accuracy: 0.6987 - fn: 74.0000 - tp: 451.0000 - loss: 0.4660 - auc: 0.8458 - val_accuracy: 0.8477 - val_fn: 46.0000 - val_tp: 39.0000 - val_loss: 0.2726 - val_auc: 0.7864\n",
      "Epoch 98/350\n",
      "29/28 [==============================] - 26s 906ms/step - accuracy: 0.7145 - fn: 78.0000 - tp: 444.0000 - loss: 0.4543 - auc: 0.8542 - val_accuracy: 0.9119 - val_fn: 63.0000 - val_tp: 23.0000 - val_loss: 0.2161 - val_auc: 0.8058\n",
      "Epoch 99/350\n",
      "29/28 [==============================] - 28s 961ms/step - accuracy: 0.7034 - fn: 84.0000 - tp: 445.0000 - loss: 0.4672 - auc: 0.8475 - val_accuracy: 0.8154 - val_fn: 28.0000 - val_tp: 57.0000 - val_loss: 0.3154 - val_auc: 0.8355\n",
      "Epoch 100/350\n",
      "29/28 [==============================] - 26s 886ms/step - accuracy: 0.7055 - fn: 76.0000 - tp: 447.0000 - loss: 0.4616 - auc: 0.8523 - val_accuracy: 0.8645 - val_fn: 48.0000 - val_tp: 38.0000 - val_loss: 0.2309 - val_auc: 0.8117\n",
      "Epoch 101/350\n",
      "29/28 [==============================] - 25s 862ms/step - accuracy: 0.7023 - fn: 72.0000 - tp: 457.0000 - loss: 0.4711 - auc: 0.8463 - val_accuracy: 0.8904 - val_fn: 50.0000 - val_tp: 35.0000 - val_loss: 0.2072 - val_auc: 0.8055\n",
      "Epoch 102/350\n",
      "29/28 [==============================] - 25s 868ms/step - accuracy: 0.7114 - fn: 78.0000 - tp: 451.0000 - loss: 0.4718 - auc: 0.8455 - val_accuracy: 0.9084 - val_fn: 60.0000 - val_tp: 25.0000 - val_loss: 0.1906 - val_auc: 0.7947\n",
      "Epoch 103/350\n",
      "29/28 [==============================] - 27s 917ms/step - accuracy: 0.7052 - fn: 71.0000 - tp: 455.0000 - loss: 0.4577 - auc: 0.8522 - val_accuracy: 0.8496 - val_fn: 51.0000 - val_tp: 33.0000 - val_loss: 0.2404 - val_auc: 0.8074\n",
      "Epoch 104/350\n",
      "29/28 [==============================] - 27s 931ms/step - accuracy: 0.7022 - fn: 91.0000 - tp: 439.0000 - loss: 0.4749 - auc: 0.8408 - val_accuracy: 0.8426 - val_fn: 47.0000 - val_tp: 37.0000 - val_loss: 0.2683 - val_auc: 0.7828\n",
      "Epoch 105/350\n",
      "29/28 [==============================] - 27s 927ms/step - accuracy: 0.6952 - fn: 83.0000 - tp: 443.0000 - loss: 0.4800 - auc: 0.8328 - val_accuracy: 0.8539 - val_fn: 50.0000 - val_tp: 37.0000 - val_loss: 0.2531 - val_auc: 0.7923\n",
      "Epoch 106/350\n",
      "29/28 [==============================] - 26s 882ms/step - accuracy: 0.6986 - fn: 69.0000 - tp: 462.0000 - loss: 0.4640 - auc: 0.8489 - val_accuracy: 0.8447 - val_fn: 35.0000 - val_tp: 50.0000 - val_loss: 0.2789 - val_auc: 0.8164\n",
      "Epoch 107/350\n",
      "29/28 [==============================] - 25s 869ms/step - accuracy: 0.7072 - fn: 69.0000 - tp: 451.0000 - loss: 0.4565 - auc: 0.8513 - val_accuracy: 0.8611 - val_fn: 38.0000 - val_tp: 48.0000 - val_loss: 0.2491 - val_auc: 0.8165\n",
      "Epoch 108/350\n",
      "29/28 [==============================] - 25s 874ms/step - accuracy: 0.7040 - fn: 84.0000 - tp: 450.0000 - loss: 0.4729 - auc: 0.8440 - val_accuracy: 0.7285 - val_fn: 26.0000 - val_tp: 62.0000 - val_loss: 0.4192 - val_auc: 0.7864\n",
      "Epoch 109/350\n",
      "29/28 [==============================] - 25s 847ms/step - accuracy: 0.6741 - fn: 78.0000 - tp: 452.0000 - loss: 0.4927 - auc: 0.8220 - val_accuracy: 0.8297 - val_fn: 41.0000 - val_tp: 44.0000 - val_loss: 0.3049 - val_auc: 0.8088\n",
      "Epoch 110/350\n",
      "29/28 [==============================] - 27s 933ms/step - accuracy: 0.7007 - fn: 76.0000 - tp: 450.0000 - loss: 0.4708 - auc: 0.8440 - val_accuracy: 0.8262 - val_fn: 41.0000 - val_tp: 48.0000 - val_loss: 0.2989 - val_auc: 0.8183\n",
      "Epoch 111/350\n",
      "29/28 [==============================] - 27s 944ms/step - accuracy: 0.7009 - fn: 72.0000 - tp: 455.0000 - loss: 0.4757 - auc: 0.8410 - val_accuracy: 0.8359 - val_fn: 37.0000 - val_tp: 52.0000 - val_loss: 0.2854 - val_auc: 0.8202\n",
      "Epoch 112/350\n",
      "29/28 [==============================] - 27s 916ms/step - accuracy: 0.6923 - fn: 78.0000 - tp: 446.0000 - loss: 0.4757 - auc: 0.8400 - val_accuracy: 0.7516 - val_fn: 21.0000 - val_tp: 61.0000 - val_loss: 0.4365 - val_auc: 0.8141\n",
      "Epoch 113/350\n",
      "29/28 [==============================] - 27s 925ms/step - accuracy: 0.7017 - fn: 87.0000 - tp: 438.0000 - loss: 0.4673 - auc: 0.8498 - val_accuracy: 0.7951 - val_fn: 31.0000 - val_tp: 57.0000 - val_loss: 0.3364 - val_auc: 0.8197\n",
      "Epoch 114/350\n",
      "29/28 [==============================] - 27s 916ms/step - accuracy: 0.7056 - fn: 73.0000 - tp: 459.0000 - loss: 0.4664 - auc: 0.8498 - val_accuracy: 0.8293 - val_fn: 36.0000 - val_tp: 46.0000 - val_loss: 0.3367 - val_auc: 0.8213\n",
      "Epoch 115/350\n",
      "29/28 [==============================] - 26s 902ms/step - accuracy: 0.6960 - fn: 66.0000 - tp: 466.0000 - loss: 0.4649 - auc: 0.8472 - val_accuracy: 0.7666 - val_fn: 22.0000 - val_tp: 62.0000 - val_loss: 0.4061 - val_auc: 0.8243\n",
      "Epoch 116/350\n",
      "29/28 [==============================] - 25s 877ms/step - accuracy: 0.7005 - fn: 70.0000 - tp: 459.0000 - loss: 0.4628 - auc: 0.8476 - val_accuracy: 0.7363 - val_fn: 18.0000 - val_tp: 67.0000 - val_loss: 0.4666 - val_auc: 0.8256\n",
      "Epoch 117/350\n",
      "29/28 [==============================] - 26s 912ms/step - accuracy: 0.7128 - fn: 71.0000 - tp: 454.0000 - loss: 0.4619 - auc: 0.8497 - val_accuracy: 0.7617 - val_fn: 20.0000 - val_tp: 66.0000 - val_loss: 0.4579 - val_auc: 0.8247\n",
      "Epoch 118/350\n",
      "29/28 [==============================] - 29s 996ms/step - accuracy: 0.6966 - fn: 84.0000 - tp: 444.0000 - loss: 0.4703 - auc: 0.8447 - val_accuracy: 0.7852 - val_fn: 26.0000 - val_tp: 59.0000 - val_loss: 0.4113 - val_auc: 0.8248\n",
      "Epoch 119/350\n",
      "29/28 [==============================] - 26s 890ms/step - accuracy: 0.6938 - fn: 75.0000 - tp: 449.0000 - loss: 0.4779 - auc: 0.8371 - val_accuracy: 0.6447 - val_fn: 14.0000 - val_tp: 74.0000 - val_loss: 0.6777 - val_auc: 0.7836\n",
      "Epoch 120/350\n",
      "29/28 [==============================] - 26s 912ms/step - accuracy: 0.6720 - fn: 72.0000 - tp: 453.0000 - loss: 0.4951 - auc: 0.8244 - val_accuracy: 0.7803 - val_fn: 27.0000 - val_tp: 61.0000 - val_loss: 0.4146 - val_auc: 0.8152\n",
      "Epoch 121/350\n",
      "29/28 [==============================] - 26s 906ms/step - accuracy: 0.7041 - fn: 69.0000 - tp: 457.0000 - loss: 0.4753 - auc: 0.8389 - val_accuracy: 0.7393 - val_fn: 19.0000 - val_tp: 66.0000 - val_loss: 0.4767 - val_auc: 0.8199\n",
      "Epoch 122/350\n",
      "29/28 [==============================] - 27s 924ms/step - accuracy: 0.6804 - fn: 72.0000 - tp: 460.0000 - loss: 0.4742 - auc: 0.8428 - val_accuracy: 0.7518 - val_fn: 26.0000 - val_tp: 60.0000 - val_loss: 0.4076 - val_auc: 0.8280\n",
      "Epoch 123/350\n",
      "29/28 [==============================] - 28s 950ms/step - accuracy: 0.7002 - fn: 67.0000 - tp: 453.0000 - loss: 0.4613 - auc: 0.8489 - val_accuracy: 0.7613 - val_fn: 27.0000 - val_tp: 61.0000 - val_loss: 0.4097 - val_auc: 0.8116\n",
      "Epoch 124/350\n",
      "29/28 [==============================] - 26s 885ms/step - accuracy: 0.6997 - fn: 75.0000 - tp: 456.0000 - loss: 0.4686 - auc: 0.8424 - val_accuracy: 0.8014 - val_fn: 35.0000 - val_tp: 51.0000 - val_loss: 0.3188 - val_auc: 0.8118\n",
      "Epoch 125/350\n",
      "29/28 [==============================] - 25s 857ms/step - accuracy: 0.6956 - fn: 74.0000 - tp: 453.0000 - loss: 0.4658 - auc: 0.8476 - val_accuracy: 0.8645 - val_fn: 41.0000 - val_tp: 45.0000 - val_loss: 0.2447 - val_auc: 0.8281\n",
      "Epoch 126/350\n",
      "29/28 [==============================] - 25s 856ms/step - accuracy: 0.7022 - fn: 60.0000 - tp: 465.0000 - loss: 0.4480 - auc: 0.8556 - val_accuracy: 0.7762 - val_fn: 28.0000 - val_tp: 59.0000 - val_loss: 0.3357 - val_auc: 0.8154\n",
      "Epoch 127/350\n",
      "29/28 [==============================] - 25s 866ms/step - accuracy: 0.7054 - fn: 77.0000 - tp: 447.0000 - loss: 0.4527 - auc: 0.8539 - val_accuracy: 0.8436 - val_fn: 34.0000 - val_tp: 52.0000 - val_loss: 0.2702 - val_auc: 0.8400\n",
      "Epoch 128/350\n",
      "29/28 [==============================] - 26s 895ms/step - accuracy: 0.7003 - fn: 71.0000 - tp: 457.0000 - loss: 0.4682 - auc: 0.8461 - val_accuracy: 0.8588 - val_fn: 51.0000 - val_tp: 36.0000 - val_loss: 0.2532 - val_auc: 0.8169\n",
      "Epoch 129/350\n",
      "29/28 [==============================] - 27s 924ms/step - accuracy: 0.7167 - fn: 67.0000 - tp: 467.0000 - loss: 0.4405 - auc: 0.8657 - val_accuracy: 0.8781 - val_fn: 53.0000 - val_tp: 35.0000 - val_loss: 0.2350 - val_auc: 0.8105\n",
      "Epoch 130/350\n",
      "29/28 [==============================] - 26s 908ms/step - accuracy: 0.7102 - fn: 70.0000 - tp: 458.0000 - loss: 0.4518 - auc: 0.8565 - val_accuracy: 0.8131 - val_fn: 35.0000 - val_tp: 55.0000 - val_loss: 0.3093 - val_auc: 0.8149\n",
      "Epoch 131/350\n",
      "29/28 [==============================] - 26s 881ms/step - accuracy: 0.7063 - fn: 79.0000 - tp: 452.0000 - loss: 0.4747 - auc: 0.8462 - val_accuracy: 0.8875 - val_fn: 52.0000 - val_tp: 34.0000 - val_loss: 0.2246 - val_auc: 0.8220\n",
      "Epoch 132/350\n",
      "29/28 [==============================] - 25s 860ms/step - accuracy: 0.6930 - fn: 75.0000 - tp: 453.0000 - loss: 0.4772 - auc: 0.8399 - val_accuracy: 0.8564 - val_fn: 49.0000 - val_tp: 40.0000 - val_loss: 0.2461 - val_auc: 0.7977\n",
      "Epoch 133/350\n",
      "29/28 [==============================] - 24s 838ms/step - accuracy: 0.7043 - fn: 66.0000 - tp: 464.0000 - loss: 0.4549 - auc: 0.8553 - val_accuracy: 0.8672 - val_fn: 52.0000 - val_tp: 33.0000 - val_loss: 0.2325 - val_auc: 0.8093\n",
      "Epoch 134/350\n",
      "29/28 [==============================] - 25s 861ms/step - accuracy: 0.7001 - fn: 71.0000 - tp: 460.0000 - loss: 0.4602 - auc: 0.8525 - val_accuracy: 0.7955 - val_fn: 34.0000 - val_tp: 51.0000 - val_loss: 0.3315 - val_auc: 0.8096\n",
      "Epoch 135/350\n",
      "29/28 [==============================] - 27s 930ms/step - accuracy: 0.6963 - fn: 67.0000 - tp: 463.0000 - loss: 0.4638 - auc: 0.8484 - val_accuracy: 0.7836 - val_fn: 22.0000 - val_tp: 64.0000 - val_loss: 0.4062 - val_auc: 0.8270\n",
      "Epoch 136/350\n",
      "29/28 [==============================] - 25s 870ms/step - accuracy: 0.7053 - fn: 68.0000 - tp: 462.0000 - loss: 0.4596 - auc: 0.8513 - val_accuracy: 0.8018 - val_fn: 31.0000 - val_tp: 56.0000 - val_loss: 0.3374 - val_auc: 0.8258\n",
      "Epoch 137/350\n",
      "29/28 [==============================] - 26s 909ms/step - accuracy: 0.7020 - fn: 63.0000 - tp: 462.0000 - loss: 0.4524 - auc: 0.8555 - val_accuracy: 0.7508 - val_fn: 24.0000 - val_tp: 62.0000 - val_loss: 0.4056 - val_auc: 0.8134\n",
      "Epoch 138/350\n",
      "29/28 [==============================] - 25s 867ms/step - accuracy: 0.7113 - fn: 67.0000 - tp: 458.0000 - loss: 0.4487 - auc: 0.8609 - val_accuracy: 0.7896 - val_fn: 27.0000 - val_tp: 58.0000 - val_loss: 0.3511 - val_auc: 0.8231\n",
      "Epoch 139/350\n",
      "29/28 [==============================] - 25s 872ms/step - accuracy: 0.7027 - fn: 61.0000 - tp: 463.0000 - loss: 0.4457 - auc: 0.8581 - val_accuracy: 0.7951 - val_fn: 31.0000 - val_tp: 53.0000 - val_loss: 0.3333 - val_auc: 0.8212\n",
      "Epoch 140/350\n",
      "29/28 [==============================] - 25s 867ms/step - accuracy: 0.7070 - fn: 74.0000 - tp: 453.0000 - loss: 0.4528 - auc: 0.8547 - val_accuracy: 0.8379 - val_fn: 42.0000 - val_tp: 44.0000 - val_loss: 0.2902 - val_auc: 0.8150\n",
      "Epoch 141/350\n",
      "29/28 [==============================] - 27s 917ms/step - accuracy: 0.7093 - fn: 64.0000 - tp: 464.0000 - loss: 0.4533 - auc: 0.8549 - val_accuracy: 0.7568 - val_fn: 25.0000 - val_tp: 62.0000 - val_loss: 0.3888 - val_auc: 0.8316\n",
      "Epoch 142/350\n",
      "29/28 [==============================] - 27s 918ms/step - accuracy: 0.7046 - fn: 69.0000 - tp: 460.0000 - loss: 0.4614 - auc: 0.8502 - val_accuracy: 0.8008 - val_fn: 29.0000 - val_tp: 58.0000 - val_loss: 0.3610 - val_auc: 0.8168\n",
      "Epoch 143/350\n",
      "29/28 [==============================] - 25s 875ms/step - accuracy: 0.7094 - fn: 64.0000 - tp: 462.0000 - loss: 0.4478 - auc: 0.8599 - val_accuracy: 0.7537 - val_fn: 24.0000 - val_tp: 64.0000 - val_loss: 0.3769 - val_auc: 0.8354\n",
      "Epoch 144/350\n",
      "29/28 [==============================] - 26s 897ms/step - accuracy: 0.7116 - fn: 62.0000 - tp: 466.0000 - loss: 0.4443 - auc: 0.8601 - val_accuracy: 0.7666 - val_fn: 26.0000 - val_tp: 55.0000 - val_loss: 0.4025 - val_auc: 0.8109\n",
      "Epoch 145/350\n",
      "29/28 [==============================] - 25s 877ms/step - accuracy: 0.7037 - fn: 61.0000 - tp: 470.0000 - loss: 0.4382 - auc: 0.8620 - val_accuracy: 0.8912 - val_fn: 54.0000 - val_tp: 33.0000 - val_loss: 0.2425 - val_auc: 0.8218\n",
      "Epoch 146/350\n",
      "29/28 [==============================] - 25s 865ms/step - accuracy: 0.7102 - fn: 68.0000 - tp: 459.0000 - loss: 0.4470 - auc: 0.8604 - val_accuracy: 0.8076 - val_fn: 37.0000 - val_tp: 50.0000 - val_loss: 0.3107 - val_auc: 0.8101\n",
      "Epoch 147/350\n",
      "29/28 [==============================] - 25s 858ms/step - accuracy: 0.7022 - fn: 73.0000 - tp: 454.0000 - loss: 0.4517 - auc: 0.8548 - val_accuracy: 0.8193 - val_fn: 33.0000 - val_tp: 54.0000 - val_loss: 0.2961 - val_auc: 0.8384\n",
      "Epoch 148/350\n",
      "29/28 [==============================] - 27s 934ms/step - accuracy: 0.7159 - fn: 71.0000 - tp: 456.0000 - loss: 0.4484 - auc: 0.8588 - val_accuracy: 0.8131 - val_fn: 29.0000 - val_tp: 56.0000 - val_loss: 0.3201 - val_auc: 0.8434\n",
      "Epoch 149/350\n",
      "29/28 [==============================] - 27s 943ms/step - accuracy: 0.7044 - fn: 65.0000 - tp: 459.0000 - loss: 0.4587 - auc: 0.8516 - val_accuracy: 0.8211 - val_fn: 31.0000 - val_tp: 55.0000 - val_loss: 0.3115 - val_auc: 0.8409\n",
      "Epoch 150/350\n",
      "29/28 [==============================] - 26s 913ms/step - accuracy: 0.7031 - fn: 67.0000 - tp: 463.0000 - loss: 0.4638 - auc: 0.8518 - val_accuracy: 0.8014 - val_fn: 34.0000 - val_tp: 53.0000 - val_loss: 0.3315 - val_auc: 0.8132\n",
      "Epoch 151/350\n",
      "29/28 [==============================] - 25s 874ms/step - accuracy: 0.7124 - fn: 66.0000 - tp: 461.0000 - loss: 0.4435 - auc: 0.8601 - val_accuracy: 0.7949 - val_fn: 28.0000 - val_tp: 58.0000 - val_loss: 0.3276 - val_auc: 0.8392\n",
      "Epoch 152/350\n",
      "29/28 [==============================] - 25s 854ms/step - accuracy: 0.7169 - fn: 70.0000 - tp: 456.0000 - loss: 0.4411 - auc: 0.8626 - val_accuracy: 0.7525 - val_fn: 18.0000 - val_tp: 69.0000 - val_loss: 0.4262 - val_auc: 0.8359\n",
      "Epoch 153/350\n",
      "29/28 [==============================] - 25s 869ms/step - accuracy: 0.7245 - fn: 71.0000 - tp: 455.0000 - loss: 0.4436 - auc: 0.8654 - val_accuracy: 0.7832 - val_fn: 20.0000 - val_tp: 69.0000 - val_loss: 0.3535 - val_auc: 0.8550\n",
      "Epoch 154/350\n",
      "29/28 [==============================] - 24s 835ms/step - accuracy: 0.7246 - fn: 59.0000 - tp: 463.0000 - loss: 0.4360 - auc: 0.8678 - val_accuracy: 0.7828 - val_fn: 18.0000 - val_tp: 66.0000 - val_loss: 0.3393 - val_auc: 0.8471\n",
      "Epoch 155/350\n",
      "29/28 [==============================] - 26s 912ms/step - accuracy: 0.7056 - fn: 70.0000 - tp: 469.0000 - loss: 0.4499 - auc: 0.8596 - val_accuracy: 0.7740 - val_fn: 35.0000 - val_tp: 51.0000 - val_loss: 0.3830 - val_auc: 0.8041\n",
      "Epoch 156/350\n",
      "29/28 [==============================] - 28s 964ms/step - accuracy: 0.7017 - fn: 73.0000 - tp: 459.0000 - loss: 0.4564 - auc: 0.8565 - val_accuracy: 0.7826 - val_fn: 31.0000 - val_tp: 53.0000 - val_loss: 0.3961 - val_auc: 0.7923\n",
      "Epoch 157/350\n",
      "29/28 [==============================] - 27s 934ms/step - accuracy: 0.7143 - fn: 69.0000 - tp: 457.0000 - loss: 0.4486 - auc: 0.8570 - val_accuracy: 0.8279 - val_fn: 36.0000 - val_tp: 52.0000 - val_loss: 0.3162 - val_auc: 0.8139\n",
      "Epoch 158/350\n",
      "29/28 [==============================] - 25s 847ms/step - accuracy: 0.7255 - fn: 72.0000 - tp: 453.0000 - loss: 0.4413 - auc: 0.8651 - val_accuracy: 0.8332 - val_fn: 36.0000 - val_tp: 47.0000 - val_loss: 0.3081 - val_auc: 0.8102\n",
      "Epoch 159/350\n",
      "29/28 [==============================] - 25s 862ms/step - accuracy: 0.7124 - fn: 69.0000 - tp: 457.0000 - loss: 0.4417 - auc: 0.8655 - val_accuracy: 0.8057 - val_fn: 25.0000 - val_tp: 57.0000 - val_loss: 0.3672 - val_auc: 0.8367\n",
      "Epoch 160/350\n",
      "29/28 [==============================] - 25s 851ms/step - accuracy: 0.7049 - fn: 74.0000 - tp: 455.0000 - loss: 0.4549 - auc: 0.8577 - val_accuracy: 0.7736 - val_fn: 23.0000 - val_tp: 61.0000 - val_loss: 0.3878 - val_auc: 0.8310\n",
      "Epoch 161/350\n",
      "29/28 [==============================] - 25s 871ms/step - accuracy: 0.7081 - fn: 68.0000 - tp: 455.0000 - loss: 0.4487 - auc: 0.8590 - val_accuracy: 0.8152 - val_fn: 34.0000 - val_tp: 54.0000 - val_loss: 0.3110 - val_auc: 0.8371\n",
      "Epoch 162/350\n",
      "29/28 [==============================] - 26s 892ms/step - accuracy: 0.7184 - fn: 66.0000 - tp: 461.0000 - loss: 0.4329 - auc: 0.8690 - val_accuracy: 0.8227 - val_fn: 30.0000 - val_tp: 53.0000 - val_loss: 0.3113 - val_auc: 0.8398\n",
      "Epoch 163/350\n",
      "29/28 [==============================] - 28s 957ms/step - accuracy: 0.7105 - fn: 65.0000 - tp: 459.0000 - loss: 0.4445 - auc: 0.8611 - val_accuracy: 0.7936 - val_fn: 33.0000 - val_tp: 56.0000 - val_loss: 0.3644 - val_auc: 0.8244\n",
      "Epoch 164/350\n",
      "29/28 [==============================] - 27s 923ms/step - accuracy: 0.7036 - fn: 72.0000 - tp: 458.0000 - loss: 0.4508 - auc: 0.8583 - val_accuracy: 0.7400 - val_fn: 24.0000 - val_tp: 62.0000 - val_loss: 0.4450 - val_auc: 0.8204\n",
      "Epoch 165/350\n",
      "29/28 [==============================] - 25s 868ms/step - accuracy: 0.7250 - fn: 71.0000 - tp: 458.0000 - loss: 0.4491 - auc: 0.8638 - val_accuracy: 0.8555 - val_fn: 42.0000 - val_tp: 43.0000 - val_loss: 0.2933 - val_auc: 0.8181\n",
      "Epoch 166/350\n",
      "29/28 [==============================] - 26s 885ms/step - accuracy: 0.7085 - fn: 62.0000 - tp: 459.0000 - loss: 0.4431 - auc: 0.8615 - val_accuracy: 0.9062 - val_fn: 54.0000 - val_tp: 31.0000 - val_loss: 0.2116 - val_auc: 0.7744\n",
      "Epoch 167/350\n",
      "29/28 [==============================] - 25s 865ms/step - accuracy: 0.7126 - fn: 80.0000 - tp: 451.0000 - loss: 0.4562 - auc: 0.8592 - val_accuracy: 0.7551 - val_fn: 22.0000 - val_tp: 62.0000 - val_loss: 0.3922 - val_auc: 0.8369\n",
      "Epoch 168/350\n",
      "29/28 [==============================] - 24s 843ms/step - accuracy: 0.7073 - fn: 63.0000 - tp: 466.0000 - loss: 0.4516 - auc: 0.8594 - val_accuracy: 0.7018 - val_fn: 15.0000 - val_tp: 69.0000 - val_loss: 0.4636 - val_auc: 0.8281\n",
      "Epoch 169/350\n",
      "29/28 [==============================] - 27s 929ms/step - accuracy: 0.7164 - fn: 64.0000 - tp: 461.0000 - loss: 0.4344 - auc: 0.8703 - val_accuracy: 0.8357 - val_fn: 34.0000 - val_tp: 57.0000 - val_loss: 0.2838 - val_auc: 0.8326\n",
      "Epoch 170/350\n",
      "29/28 [==============================] - 26s 890ms/step - accuracy: 0.7137 - fn: 57.0000 - tp: 473.0000 - loss: 0.4403 - auc: 0.8632 - val_accuracy: 0.8213 - val_fn: 31.0000 - val_tp: 55.0000 - val_loss: 0.3029 - val_auc: 0.8510\n",
      "Epoch 171/350\n",
      "29/28 [==============================] - 28s 955ms/step - accuracy: 0.7159 - fn: 67.0000 - tp: 464.0000 - loss: 0.4488 - auc: 0.8620 - val_accuracy: 0.7789 - val_fn: 30.0000 - val_tp: 56.0000 - val_loss: 0.3868 - val_auc: 0.8336\n",
      "Epoch 172/350\n",
      "29/28 [==============================] - 25s 873ms/step - accuracy: 0.7296 - fn: 65.0000 - tp: 462.0000 - loss: 0.4296 - auc: 0.8728 - val_accuracy: 0.8158 - val_fn: 34.0000 - val_tp: 50.0000 - val_loss: 0.3251 - val_auc: 0.8394\n",
      "Epoch 173/350\n",
      "29/28 [==============================] - 27s 917ms/step - accuracy: 0.7196 - fn: 74.0000 - tp: 456.0000 - loss: 0.4394 - auc: 0.8661 - val_accuracy: 0.7881 - val_fn: 28.0000 - val_tp: 55.0000 - val_loss: 0.3740 - val_auc: 0.8385\n",
      "Epoch 174/350\n",
      "29/28 [==============================] - 25s 864ms/step - accuracy: 0.7250 - fn: 67.0000 - tp: 461.0000 - loss: 0.4362 - auc: 0.8681 - val_accuracy: 0.8121 - val_fn: 33.0000 - val_tp: 54.0000 - val_loss: 0.3413 - val_auc: 0.8191\n",
      "Epoch 175/350\n",
      "29/28 [==============================] - 27s 941ms/step - accuracy: 0.7181 - fn: 65.0000 - tp: 471.0000 - loss: 0.4374 - auc: 0.8705 - val_accuracy: 0.8121 - val_fn: 36.0000 - val_tp: 52.0000 - val_loss: 0.3442 - val_auc: 0.8303\n",
      "Epoch 176/350\n",
      "29/28 [==============================] - 27s 940ms/step - accuracy: 0.7262 - fn: 62.0000 - tp: 468.0000 - loss: 0.4251 - auc: 0.8755 - val_accuracy: 0.8037 - val_fn: 31.0000 - val_tp: 54.0000 - val_loss: 0.3534 - val_auc: 0.8282\n",
      "Epoch 177/350\n",
      "29/28 [==============================] - 26s 895ms/step - accuracy: 0.7191 - fn: 52.0000 - tp: 472.0000 - loss: 0.4166 - auc: 0.8806 - val_accuracy: 0.7631 - val_fn: 19.0000 - val_tp: 67.0000 - val_loss: 0.4131 - val_auc: 0.8450\n",
      "Epoch 178/350\n",
      "29/28 [==============================] - 28s 961ms/step - accuracy: 0.7301 - fn: 71.0000 - tp: 453.0000 - loss: 0.4278 - auc: 0.8742 - val_accuracy: 0.7533 - val_fn: 21.0000 - val_tp: 68.0000 - val_loss: 0.4370 - val_auc: 0.8372\n",
      "Epoch 179/350\n",
      "29/28 [==============================] - 25s 873ms/step - accuracy: 0.7166 - fn: 66.0000 - tp: 462.0000 - loss: 0.4434 - auc: 0.8642 - val_accuracy: 0.8016 - val_fn: 33.0000 - val_tp: 49.0000 - val_loss: 0.3569 - val_auc: 0.8197\n",
      "Epoch 180/350\n",
      "29/28 [==============================] - 28s 952ms/step - accuracy: 0.7176 - fn: 54.0000 - tp: 470.0000 - loss: 0.4284 - auc: 0.8688 - val_accuracy: 0.8246 - val_fn: 35.0000 - val_tp: 53.0000 - val_loss: 0.3213 - val_auc: 0.8332\n",
      "Epoch 181/350\n",
      "29/28 [==============================] - 25s 874ms/step - accuracy: 0.7267 - fn: 64.0000 - tp: 468.0000 - loss: 0.4261 - auc: 0.8751 - val_accuracy: 0.7914 - val_fn: 28.0000 - val_tp: 58.0000 - val_loss: 0.3860 - val_auc: 0.8316\n",
      "Epoch 182/350\n",
      "29/28 [==============================] - 27s 925ms/step - accuracy: 0.7136 - fn: 58.0000 - tp: 471.0000 - loss: 0.4297 - auc: 0.8716 - val_accuracy: 0.7531 - val_fn: 20.0000 - val_tp: 69.0000 - val_loss: 0.4121 - val_auc: 0.8289\n",
      "Epoch 183/350\n",
      "29/28 [==============================] - 25s 867ms/step - accuracy: 0.7053 - fn: 59.0000 - tp: 464.0000 - loss: 0.4331 - auc: 0.8678 - val_accuracy: 0.8484 - val_fn: 42.0000 - val_tp: 44.0000 - val_loss: 0.3149 - val_auc: 0.8331\n",
      "Epoch 184/350\n",
      "29/28 [==============================] - 26s 886ms/step - accuracy: 0.7205 - fn: 76.0000 - tp: 448.0000 - loss: 0.4424 - auc: 0.8657 - val_accuracy: 0.8342 - val_fn: 37.0000 - val_tp: 50.0000 - val_loss: 0.3125 - val_auc: 0.8250\n",
      "Epoch 185/350\n",
      "29/28 [==============================] - 27s 935ms/step - accuracy: 0.7127 - fn: 58.0000 - tp: 474.0000 - loss: 0.4456 - auc: 0.8606 - val_accuracy: 0.7299 - val_fn: 18.0000 - val_tp: 62.0000 - val_loss: 0.4494 - val_auc: 0.8078\n",
      "Epoch 186/350\n",
      "29/28 [==============================] - 27s 919ms/step - accuracy: 0.6968 - fn: 65.0000 - tp: 462.0000 - loss: 0.4534 - auc: 0.8542 - val_accuracy: 0.8146 - val_fn: 33.0000 - val_tp: 53.0000 - val_loss: 0.3092 - val_auc: 0.8217\n",
      "Epoch 187/350\n",
      "29/28 [==============================] - 27s 939ms/step - accuracy: 0.6819 - fn: 69.0000 - tp: 462.0000 - loss: 0.4784 - auc: 0.8410 - val_accuracy: 0.7908 - val_fn: 19.0000 - val_tp: 61.0000 - val_loss: 0.3881 - val_auc: 0.8497\n",
      "Epoch 188/350\n",
      "29/28 [==============================] - 25s 866ms/step - accuracy: 0.7042 - fn: 77.0000 - tp: 449.0000 - loss: 0.4684 - auc: 0.8468 - val_accuracy: 0.7943 - val_fn: 29.0000 - val_tp: 59.0000 - val_loss: 0.3430 - val_auc: 0.8302\n",
      "Epoch 189/350\n",
      "29/28 [==============================] - 25s 860ms/step - accuracy: 0.6976 - fn: 65.0000 - tp: 463.0000 - loss: 0.4530 - auc: 0.8564 - val_accuracy: 0.8297 - val_fn: 34.0000 - val_tp: 53.0000 - val_loss: 0.2932 - val_auc: 0.8385\n",
      "Epoch 190/350\n",
      "29/28 [==============================] - 25s 858ms/step - accuracy: 0.7043 - fn: 64.0000 - tp: 459.0000 - loss: 0.4522 - auc: 0.8572 - val_accuracy: 0.8482 - val_fn: 36.0000 - val_tp: 53.0000 - val_loss: 0.2648 - val_auc: 0.8338\n",
      "Epoch 191/350\n",
      "29/28 [==============================] - 25s 861ms/step - accuracy: 0.6985 - fn: 50.0000 - tp: 479.0000 - loss: 0.4415 - auc: 0.8607 - val_accuracy: 0.8635 - val_fn: 48.0000 - val_tp: 39.0000 - val_loss: 0.2506 - val_auc: 0.8327\n",
      "Epoch 192/350\n",
      "29/28 [==============================] - 25s 861ms/step - accuracy: 0.7256 - fn: 74.0000 - tp: 453.0000 - loss: 0.4396 - auc: 0.8651 - val_accuracy: 0.8582 - val_fn: 41.0000 - val_tp: 47.0000 - val_loss: 0.2737 - val_auc: 0.8367\n",
      "Epoch 193/350\n",
      "29/28 [==============================] - 27s 916ms/step - accuracy: 0.7113 - fn: 71.0000 - tp: 457.0000 - loss: 0.4459 - auc: 0.8627 - val_accuracy: 0.8152 - val_fn: 36.0000 - val_tp: 50.0000 - val_loss: 0.3383 - val_auc: 0.8140\n",
      "Epoch 194/350\n",
      "29/28 [==============================] - 27s 927ms/step - accuracy: 0.7048 - fn: 67.0000 - tp: 457.0000 - loss: 0.4487 - auc: 0.8568 - val_accuracy: 0.7598 - val_fn: 25.0000 - val_tp: 61.0000 - val_loss: 0.3755 - val_auc: 0.8265\n",
      "Epoch 195/350\n",
      "29/28 [==============================] - 26s 908ms/step - accuracy: 0.7046 - fn: 58.0000 - tp: 473.0000 - loss: 0.4451 - auc: 0.8603 - val_accuracy: 0.8600 - val_fn: 41.0000 - val_tp: 39.0000 - val_loss: 0.2800 - val_auc: 0.8278\n",
      "Epoch 196/350\n",
      "29/28 [==============================] - 25s 874ms/step - accuracy: 0.7177 - fn: 65.0000 - tp: 469.0000 - loss: 0.4353 - auc: 0.8661 - val_accuracy: 0.7705 - val_fn: 24.0000 - val_tp: 63.0000 - val_loss: 0.3943 - val_auc: 0.8369\n",
      "Epoch 197/350\n",
      "29/28 [==============================] - 25s 876ms/step - accuracy: 0.7169 - fn: 57.0000 - tp: 469.0000 - loss: 0.4375 - auc: 0.8656 - val_accuracy: 0.7973 - val_fn: 22.0000 - val_tp: 67.0000 - val_loss: 0.3392 - val_auc: 0.8643\n",
      "Epoch 198/350\n",
      "29/28 [==============================] - 27s 923ms/step - accuracy: 0.7153 - fn: 67.0000 - tp: 459.0000 - loss: 0.4349 - auc: 0.8659 - val_accuracy: 0.7676 - val_fn: 21.0000 - val_tp: 64.0000 - val_loss: 0.3952 - val_auc: 0.8436\n",
      "Epoch 199/350\n",
      "29/28 [==============================] - 28s 960ms/step - accuracy: 0.7198 - fn: 67.0000 - tp: 464.0000 - loss: 0.4434 - auc: 0.8658 - val_accuracy: 0.8051 - val_fn: 32.0000 - val_tp: 57.0000 - val_loss: 0.3471 - val_auc: 0.8345\n",
      "Epoch 200/350\n",
      "29/28 [==============================] - 27s 916ms/step - accuracy: 0.7000 - fn: 62.0000 - tp: 465.0000 - loss: 0.4492 - auc: 0.8560 - val_accuracy: 0.7752 - val_fn: 32.0000 - val_tp: 52.0000 - val_loss: 0.4045 - val_auc: 0.8054\n",
      "Epoch 201/350\n",
      "29/28 [==============================] - 27s 936ms/step - accuracy: 0.7011 - fn: 62.0000 - tp: 462.0000 - loss: 0.4487 - auc: 0.8560 - val_accuracy: 0.7836 - val_fn: 27.0000 - val_tp: 57.0000 - val_loss: 0.3861 - val_auc: 0.8226\n",
      "Epoch 202/350\n",
      "29/28 [==============================] - 26s 904ms/step - accuracy: 0.7179 - fn: 59.0000 - tp: 465.0000 - loss: 0.4427 - auc: 0.8611 - val_accuracy: 0.7393 - val_fn: 23.0000 - val_tp: 65.0000 - val_loss: 0.4619 - val_auc: 0.8178\n",
      "Epoch 203/350\n",
      "29/28 [==============================] - 28s 981ms/step - accuracy: 0.7077 - fn: 57.0000 - tp: 470.0000 - loss: 0.4427 - auc: 0.8579 - val_accuracy: 0.7521 - val_fn: 20.0000 - val_tp: 64.0000 - val_loss: 0.4294 - val_auc: 0.8358\n",
      "Epoch 204/350\n",
      "29/28 [==============================] - 26s 906ms/step - accuracy: 0.7123 - fn: 70.0000 - tp: 460.0000 - loss: 0.4403 - auc: 0.8665 - val_accuracy: 0.7496 - val_fn: 14.0000 - val_tp: 74.0000 - val_loss: 0.4425 - val_auc: 0.8424\n",
      "Epoch 205/350\n",
      "29/28 [==============================] - 27s 931ms/step - accuracy: 0.7180 - fn: 55.0000 - tp: 466.0000 - loss: 0.4295 - auc: 0.8666 - val_accuracy: 0.8340 - val_fn: 28.0000 - val_tp: 60.0000 - val_loss: 0.3119 - val_auc: 0.8440\n",
      "Epoch 206/350\n",
      "29/28 [==============================] - 25s 873ms/step - accuracy: 0.7206 - fn: 55.0000 - tp: 471.0000 - loss: 0.4167 - auc: 0.8775 - val_accuracy: 0.7863 - val_fn: 19.0000 - val_tp: 66.0000 - val_loss: 0.4060 - val_auc: 0.8473\n",
      "Epoch 207/350\n",
      "29/28 [==============================] - 25s 870ms/step - accuracy: 0.7300 - fn: 56.0000 - tp: 472.0000 - loss: 0.4245 - auc: 0.8744 - val_accuracy: 0.8338 - val_fn: 36.0000 - val_tp: 53.0000 - val_loss: 0.3184 - val_auc: 0.8248\n",
      "Epoch 208/350\n",
      "29/28 [==============================] - 25s 873ms/step - accuracy: 0.7183 - fn: 69.0000 - tp: 460.0000 - loss: 0.4386 - auc: 0.8674 - val_accuracy: 0.8900 - val_fn: 45.0000 - val_tp: 41.0000 - val_loss: 0.2417 - val_auc: 0.8300\n",
      "Epoch 209/350\n",
      "29/28 [==============================] - 27s 928ms/step - accuracy: 0.7263 - fn: 61.0000 - tp: 465.0000 - loss: 0.4267 - auc: 0.8729 - val_accuracy: 0.8811 - val_fn: 47.0000 - val_tp: 39.0000 - val_loss: 0.2456 - val_auc: 0.7981\n",
      "Epoch 210/350\n",
      "29/28 [==============================] - 27s 926ms/step - accuracy: 0.7028 - fn: 62.0000 - tp: 468.0000 - loss: 0.4542 - auc: 0.8559 - val_accuracy: 0.8379 - val_fn: 37.0000 - val_tp: 48.0000 - val_loss: 0.2810 - val_auc: 0.8303\n",
      "Epoch 211/350\n",
      "29/28 [==============================] - 28s 950ms/step - accuracy: 0.7045 - fn: 59.0000 - tp: 474.0000 - loss: 0.4395 - auc: 0.8677 - val_accuracy: 0.8078 - val_fn: 32.0000 - val_tp: 56.0000 - val_loss: 0.3436 - val_auc: 0.8293\n",
      "Epoch 212/350\n",
      "29/28 [==============================] - 25s 867ms/step - accuracy: 0.7161 - fn: 54.0000 - tp: 472.0000 - loss: 0.4264 - auc: 0.8722 - val_accuracy: 0.8127 - val_fn: 30.0000 - val_tp: 53.0000 - val_loss: 0.3274 - val_auc: 0.8329\n",
      "Epoch 213/350\n",
      "29/28 [==============================] - 27s 933ms/step - accuracy: 0.7262 - fn: 65.0000 - tp: 463.0000 - loss: 0.4276 - auc: 0.8721 - val_accuracy: 0.8250 - val_fn: 32.0000 - val_tp: 52.0000 - val_loss: 0.3346 - val_auc: 0.8317\n",
      "Epoch 214/350\n",
      "29/28 [==============================] - 24s 843ms/step - accuracy: 0.7085 - fn: 62.0000 - tp: 471.0000 - loss: 0.4398 - auc: 0.8654 - val_accuracy: 0.7754 - val_fn: 27.0000 - val_tp: 57.0000 - val_loss: 0.3974 - val_auc: 0.8070\n",
      "Epoch 215/350\n",
      "29/28 [==============================] - 26s 913ms/step - accuracy: 0.7248 - fn: 64.0000 - tp: 465.0000 - loss: 0.4351 - auc: 0.8672 - val_accuracy: 0.8029 - val_fn: 31.0000 - val_tp: 58.0000 - val_loss: 0.3444 - val_auc: 0.8249\n",
      "Epoch 216/350\n",
      "29/28 [==============================] - 28s 954ms/step - accuracy: 0.7322 - fn: 55.0000 - tp: 477.0000 - loss: 0.4186 - auc: 0.8796 - val_accuracy: 0.8334 - val_fn: 32.0000 - val_tp: 57.0000 - val_loss: 0.3206 - val_auc: 0.8474\n",
      "Epoch 217/350\n",
      "29/28 [==============================] - 25s 879ms/step - accuracy: 0.7198 - fn: 62.0000 - tp: 464.0000 - loss: 0.4358 - auc: 0.8652 - val_accuracy: 0.8387 - val_fn: 32.0000 - val_tp: 53.0000 - val_loss: 0.3114 - val_auc: 0.8431\n",
      "Epoch 218/350\n",
      "29/28 [==============================] - 27s 936ms/step - accuracy: 0.7157 - fn: 57.0000 - tp: 474.0000 - loss: 0.4311 - auc: 0.8690 - val_accuracy: 0.7926 - val_fn: 24.0000 - val_tp: 62.0000 - val_loss: 0.3771 - val_auc: 0.8430\n",
      "Epoch 219/350\n",
      "29/28 [==============================] - 25s 866ms/step - accuracy: 0.7127 - fn: 59.0000 - tp: 465.0000 - loss: 0.4349 - auc: 0.8654 - val_accuracy: 0.8070 - val_fn: 27.0000 - val_tp: 61.0000 - val_loss: 0.3682 - val_auc: 0.8364\n",
      "Epoch 220/350\n",
      "29/28 [==============================] - 27s 944ms/step - accuracy: 0.7165 - fn: 58.0000 - tp: 465.0000 - loss: 0.4313 - auc: 0.8662 - val_accuracy: 0.7742 - val_fn: 24.0000 - val_tp: 64.0000 - val_loss: 0.4040 - val_auc: 0.8347\n",
      "Epoch 221/350\n",
      "29/28 [==============================] - 25s 853ms/step - accuracy: 0.7202 - fn: 62.0000 - tp: 464.0000 - loss: 0.4350 - auc: 0.8682 - val_accuracy: 0.7211 - val_fn: 16.0000 - val_tp: 69.0000 - val_loss: 0.5028 - val_auc: 0.8349\n",
      "Epoch 222/350\n",
      "29/28 [==============================] - 26s 889ms/step - accuracy: 0.7059 - fn: 56.0000 - tp: 475.0000 - loss: 0.4393 - auc: 0.8657 - val_accuracy: 0.7020 - val_fn: 10.0000 - val_tp: 73.0000 - val_loss: 0.4885 - val_auc: 0.8218\n",
      "Epoch 223/350\n",
      "29/28 [==============================] - 25s 853ms/step - accuracy: 0.7136 - fn: 51.0000 - tp: 479.0000 - loss: 0.4345 - auc: 0.8678 - val_accuracy: 0.8094 - val_fn: 39.0000 - val_tp: 46.0000 - val_loss: 0.3142 - val_auc: 0.8096\n",
      "Epoch 224/350\n",
      "29/28 [==============================] - 26s 912ms/step - accuracy: 0.7074 - fn: 61.0000 - tp: 457.0000 - loss: 0.4383 - auc: 0.8625 - val_accuracy: 0.7953 - val_fn: 27.0000 - val_tp: 59.0000 - val_loss: 0.3432 - val_auc: 0.8329\n",
      "Epoch 225/350\n",
      "29/28 [==============================] - 27s 915ms/step - accuracy: 0.7229 - fn: 52.0000 - tp: 477.0000 - loss: 0.4254 - auc: 0.8714 - val_accuracy: 0.7809 - val_fn: 29.0000 - val_tp: 59.0000 - val_loss: 0.3601 - val_auc: 0.8384\n",
      "Epoch 226/350\n",
      "29/28 [==============================] - 25s 857ms/step - accuracy: 0.7100 - fn: 71.0000 - tp: 458.0000 - loss: 0.4468 - auc: 0.8575 - val_accuracy: 0.8014 - val_fn: 23.0000 - val_tp: 62.0000 - val_loss: 0.3484 - val_auc: 0.8509\n",
      "Epoch 227/350\n",
      "29/28 [==============================] - 26s 906ms/step - accuracy: 0.7221 - fn: 52.0000 - tp: 479.0000 - loss: 0.4289 - auc: 0.8735 - val_accuracy: 0.7672 - val_fn: 22.0000 - val_tp: 62.0000 - val_loss: 0.3677 - val_auc: 0.8412\n",
      "Epoch 228/350\n",
      "29/28 [==============================] - 25s 852ms/step - accuracy: 0.7004 - fn: 53.0000 - tp: 476.0000 - loss: 0.4354 - auc: 0.8592 - val_accuracy: 0.8447 - val_fn: 34.0000 - val_tp: 52.0000 - val_loss: 0.2825 - val_auc: 0.8406\n",
      "Epoch 229/350\n",
      "29/28 [==============================] - 26s 897ms/step - accuracy: 0.7112 - fn: 64.0000 - tp: 460.0000 - loss: 0.4388 - auc: 0.8630 - val_accuracy: 0.8168 - val_fn: 25.0000 - val_tp: 63.0000 - val_loss: 0.3396 - val_auc: 0.8359\n",
      "Epoch 230/350\n",
      "29/28 [==============================] - 25s 868ms/step - accuracy: 0.7135 - fn: 60.0000 - tp: 471.0000 - loss: 0.4342 - auc: 0.8679 - val_accuracy: 0.8537 - val_fn: 40.0000 - val_tp: 47.0000 - val_loss: 0.2713 - val_auc: 0.8384\n",
      "Epoch 231/350\n",
      "29/28 [==============================] - 27s 935ms/step - accuracy: 0.7264 - fn: 57.0000 - tp: 473.0000 - loss: 0.4184 - auc: 0.8797 - val_accuracy: 0.8248 - val_fn: 35.0000 - val_tp: 53.0000 - val_loss: 0.3085 - val_auc: 0.8319\n",
      "Epoch 232/350\n",
      "29/28 [==============================] - 28s 965ms/step - accuracy: 0.7232 - fn: 66.0000 - tp: 457.0000 - loss: 0.4308 - auc: 0.8700 - val_accuracy: 0.8500 - val_fn: 39.0000 - val_tp: 45.0000 - val_loss: 0.2644 - val_auc: 0.8270\n",
      "Epoch 233/350\n",
      "29/28 [==============================] - 26s 912ms/step - accuracy: 0.7125 - fn: 62.0000 - tp: 463.0000 - loss: 0.4337 - auc: 0.8692 - val_accuracy: 0.8426 - val_fn: 45.0000 - val_tp: 41.0000 - val_loss: 0.2846 - val_auc: 0.7889\n",
      "Epoch 234/350\n",
      "29/28 [==============================] - 25s 867ms/step - accuracy: 0.7194 - fn: 68.0000 - tp: 456.0000 - loss: 0.4355 - auc: 0.8666 - val_accuracy: 0.8572 - val_fn: 45.0000 - val_tp: 42.0000 - val_loss: 0.2709 - val_auc: 0.8132\n",
      "Epoch 235/350\n",
      "29/28 [==============================] - 25s 860ms/step - accuracy: 0.7194 - fn: 59.0000 - tp: 473.0000 - loss: 0.4258 - auc: 0.8726 - val_accuracy: 0.8334 - val_fn: 35.0000 - val_tp: 50.0000 - val_loss: 0.3074 - val_auc: 0.8186\n",
      "Epoch 236/350\n",
      "29/28 [==============================] - 25s 865ms/step - accuracy: 0.7255 - fn: 60.0000 - tp: 471.0000 - loss: 0.4321 - auc: 0.8725 - val_accuracy: 0.7996 - val_fn: 29.0000 - val_tp: 58.0000 - val_loss: 0.3414 - val_auc: 0.8401\n",
      "Epoch 237/350\n",
      "29/28 [==============================] - 27s 917ms/step - accuracy: 0.7203 - fn: 61.0000 - tp: 470.0000 - loss: 0.4335 - auc: 0.8705 - val_accuracy: 0.8316 - val_fn: 33.0000 - val_tp: 55.0000 - val_loss: 0.3106 - val_auc: 0.8337\n",
      "Epoch 238/350\n",
      "29/28 [==============================] - 27s 915ms/step - accuracy: 0.7202 - fn: 62.0000 - tp: 462.0000 - loss: 0.4296 - auc: 0.8686 - val_accuracy: 0.7838 - val_fn: 29.0000 - val_tp: 59.0000 - val_loss: 0.3670 - val_auc: 0.8296\n",
      "Epoch 239/350\n",
      "29/28 [==============================] - 27s 946ms/step - accuracy: 0.7303 - fn: 60.0000 - tp: 467.0000 - loss: 0.4255 - auc: 0.8733 - val_accuracy: 0.8520 - val_fn: 41.0000 - val_tp: 40.0000 - val_loss: 0.3086 - val_auc: 0.8025\n",
      "Epoch 240/350\n",
      "29/28 [==============================] - 26s 909ms/step - accuracy: 0.7284 - fn: 60.0000 - tp: 472.0000 - loss: 0.4183 - auc: 0.8788 - val_accuracy: 0.7779 - val_fn: 31.0000 - val_tp: 57.0000 - val_loss: 0.3764 - val_auc: 0.8252\n",
      "Epoch 241/350\n",
      "29/28 [==============================] - 26s 897ms/step - accuracy: 0.7221 - fn: 59.0000 - tp: 466.0000 - loss: 0.4185 - auc: 0.8755 - val_accuracy: 0.7807 - val_fn: 27.0000 - val_tp: 62.0000 - val_loss: 0.3866 - val_auc: 0.8248\n",
      "Epoch 242/350\n",
      "29/28 [==============================] - 27s 939ms/step - accuracy: 0.7175 - fn: 54.0000 - tp: 470.0000 - loss: 0.4272 - auc: 0.8722 - val_accuracy: 0.7303 - val_fn: 16.0000 - val_tp: 72.0000 - val_loss: 0.4510 - val_auc: 0.8298\n",
      "Epoch 243/350\n",
      "29/28 [==============================] - 25s 853ms/step - accuracy: 0.7088 - fn: 56.0000 - tp: 468.0000 - loss: 0.4349 - auc: 0.8638 - val_accuracy: 0.7404 - val_fn: 16.0000 - val_tp: 68.0000 - val_loss: 0.4597 - val_auc: 0.8309\n",
      "Epoch 244/350\n",
      "29/28 [==============================] - 26s 900ms/step - accuracy: 0.7211 - fn: 67.0000 - tp: 458.0000 - loss: 0.4350 - auc: 0.8666 - val_accuracy: 0.7637 - val_fn: 26.0000 - val_tp: 57.0000 - val_loss: 0.4068 - val_auc: 0.8212\n",
      "Epoch 245/350\n",
      "29/28 [==============================] - 27s 932ms/step - accuracy: 0.7114 - fn: 58.0000 - tp: 470.0000 - loss: 0.4311 - auc: 0.8707 - val_accuracy: 0.7816 - val_fn: 27.0000 - val_tp: 55.0000 - val_loss: 0.3734 - val_auc: 0.8359\n",
      "Epoch 246/350\n",
      "29/28 [==============================] - 26s 880ms/step - accuracy: 0.7244 - fn: 63.0000 - tp: 462.0000 - loss: 0.4331 - auc: 0.8684 - val_accuracy: 0.8680 - val_fn: 40.0000 - val_tp: 47.0000 - val_loss: 0.2770 - val_auc: 0.8433\n",
      "Epoch 247/350\n",
      "29/28 [==============================] - 26s 913ms/step - accuracy: 0.7159 - fn: 67.0000 - tp: 466.0000 - loss: 0.4421 - auc: 0.8653 - val_accuracy: 0.8305 - val_fn: 32.0000 - val_tp: 56.0000 - val_loss: 0.3122 - val_auc: 0.8423\n",
      "Epoch 248/350\n",
      "29/28 [==============================] - 28s 958ms/step - accuracy: 0.7082 - fn: 59.0000 - tp: 464.0000 - loss: 0.4369 - auc: 0.8637 - val_accuracy: 0.8129 - val_fn: 26.0000 - val_tp: 60.0000 - val_loss: 0.3252 - val_auc: 0.8435\n",
      "Epoch 249/350\n",
      "29/28 [==============================] - 28s 958ms/step - accuracy: 0.7028 - fn: 56.0000 - tp: 473.0000 - loss: 0.4414 - auc: 0.8625 - val_accuracy: 0.7791 - val_fn: 25.0000 - val_tp: 63.0000 - val_loss: 0.3705 - val_auc: 0.8424\n",
      "Epoch 250/350\n",
      "29/28 [==============================] - 27s 935ms/step - accuracy: 0.7083 - fn: 62.0000 - tp: 466.0000 - loss: 0.4383 - auc: 0.8669 - val_accuracy: 0.8744 - val_fn: 47.0000 - val_tp: 40.0000 - val_loss: 0.2414 - val_auc: 0.7852\n",
      "Epoch 251/350\n",
      "29/28 [==============================] - 27s 945ms/step - accuracy: 0.7008 - fn: 69.0000 - tp: 465.0000 - loss: 0.4523 - auc: 0.8574 - val_accuracy: 0.8449 - val_fn: 45.0000 - val_tp: 44.0000 - val_loss: 0.2894 - val_auc: 0.8126\n",
      "Epoch 252/350\n",
      "29/28 [==============================] - 25s 849ms/step - accuracy: 0.7013 - fn: 52.0000 - tp: 470.0000 - loss: 0.4295 - auc: 0.8647 - val_accuracy: 0.8588 - val_fn: 45.0000 - val_tp: 40.0000 - val_loss: 0.2344 - val_auc: 0.8295\n",
      "Epoch 253/350\n",
      "29/28 [==============================] - 24s 836ms/step - accuracy: 0.7079 - fn: 54.0000 - tp: 478.0000 - loss: 0.4344 - auc: 0.8661 - val_accuracy: 0.8674 - val_fn: 50.0000 - val_tp: 36.0000 - val_loss: 0.2629 - val_auc: 0.8189\n",
      "Epoch 254/350\n",
      "29/28 [==============================] - 25s 863ms/step - accuracy: 0.7286 - fn: 63.0000 - tp: 463.0000 - loss: 0.4303 - auc: 0.8698 - val_accuracy: 0.8188 - val_fn: 34.0000 - val_tp: 54.0000 - val_loss: 0.3201 - val_auc: 0.8305\n",
      "Epoch 255/350\n",
      "29/28 [==============================] - 25s 869ms/step - accuracy: 0.6914 - fn: 55.0000 - tp: 473.0000 - loss: 0.4496 - auc: 0.8509 - val_accuracy: 0.7613 - val_fn: 20.0000 - val_tp: 64.0000 - val_loss: 0.3915 - val_auc: 0.8371\n",
      "Epoch 256/350\n",
      "29/28 [==============================] - 27s 938ms/step - accuracy: 0.7197 - fn: 54.0000 - tp: 483.0000 - loss: 0.4278 - auc: 0.8712 - val_accuracy: 0.7662 - val_fn: 22.0000 - val_tp: 64.0000 - val_loss: 0.4004 - val_auc: 0.8482\n",
      "Epoch 257/350\n",
      "29/28 [==============================] - 26s 883ms/step - accuracy: 0.7182 - fn: 62.0000 - tp: 470.0000 - loss: 0.4273 - auc: 0.8715 - val_accuracy: 0.7912 - val_fn: 26.0000 - val_tp: 58.0000 - val_loss: 0.3756 - val_auc: 0.8249\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', #val_auc\n",
    "                                patience=60,\n",
    "                                mode='max',\n",
    "                                restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "#     batch_size=params['batch_size'],\n",
    "    epochs= params['epochs'], \n",
    "    steps_per_epoch=epoch_steps,\n",
    "    validation_data=valid_ds,\n",
    "    validation_steps=valid_steps,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T07:26:17.988752Z",
     "iopub.status.busy": "2020-08-10T07:26:17.987551Z",
     "iopub.status.idle": "2020-08-10T07:27:05.467405Z",
     "shell.execute_reply": "2020-08-10T07:27:05.466555Z"
    },
    "papermill": {
     "duration": 48.044916,
     "end_time": "2020-08-10T07:27:05.467551",
     "exception": false,
     "start_time": "2020-08-10T07:26:17.422635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_ds.map(lambda img, igs: img), steps=test_steps)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T07:27:06.572095Z",
     "iopub.status.busy": "2020-08-10T07:27:06.571043Z",
     "iopub.status.idle": "2020-08-10T07:27:10.897767Z",
     "shell.execute_reply": "2020-08-10T07:27:10.896877Z"
    },
    "papermill": {
     "duration": 4.884037,
     "end_time": "2020-08-10T07:27:10.897906",
     "exception": false,
     "start_time": "2020-08-10T07:27:06.013869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7faad2637440> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "                          map(lambda img, ids:ids).\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction_ids = next(iter(test_ds.\n",
    "                          map(lambda img, ids:ids).\n",
    "                          unbatch().\n",
    "                          batch(test_size))).numpy().astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T07:27:12.128064Z",
     "iopub.status.busy": "2020-08-10T07:27:12.127208Z",
     "iopub.status.idle": "2020-08-10T07:27:12.142643Z",
     "shell.execute_reply": "2020-08-10T07:27:12.141837Z"
    },
    "papermill": {
     "duration": 0.574152,
     "end_time": "2020-08-10T07:27:12.142772",
     "exception": false,
     "start_time": "2020-08-10T07:27:11.568620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_dict = {\n",
    "    'image_name': prediction_ids,\n",
    "    'target': np.concatenate(predictions)\n",
    "}\n",
    "submission_ds = pd.DataFrame(prediction_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T07:27:13.356629Z",
     "iopub.status.busy": "2020-08-10T07:27:13.355341Z",
     "iopub.status.idle": "2020-08-10T07:27:13.360912Z",
     "shell.execute_reply": "2020-08-10T07:27:13.360045Z"
    },
    "papermill": {
     "duration": 0.660873,
     "end_time": "2020-08-10T07:27:13.361076",
     "exception": false,
     "start_time": "2020-08-10T07:27:12.700203",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6381819</td>\n",
       "      <td>0.683408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_5583376</td>\n",
       "      <td>0.125497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_6408546</td>\n",
       "      <td>0.009980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_6932354</td>\n",
       "      <td>0.729044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_8191278</td>\n",
       "      <td>0.015577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name    target\n",
       "0  ISIC_6381819  0.683408\n",
       "1  ISIC_5583376  0.125497\n",
       "2  ISIC_6408546  0.009980\n",
       "3  ISIC_6932354  0.729044\n",
       "4  ISIC_8191278  0.015577"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T07:27:14.495784Z",
     "iopub.status.busy": "2020-08-10T07:27:14.494636Z",
     "iopub.status.idle": "2020-08-10T07:27:14.562995Z",
     "shell.execute_reply": "2020-08-10T07:27:14.562184Z"
    },
    "papermill": {
     "duration": 0.640161,
     "end_time": "2020-08-10T07:27:14.563171",
     "exception": false,
     "start_time": "2020-08-10T07:27:13.923010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_ds.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.560236,
     "end_time": "2020-08-10T07:27:15.750840",
     "exception": false,
     "start_time": "2020-08-10T07:27:15.190604",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T07:27:16.938779Z",
     "iopub.status.busy": "2020-08-10T07:27:16.937645Z",
     "iopub.status.idle": "2020-08-10T07:27:16.940763Z",
     "shell.execute_reply": "2020-08-10T07:27:16.941337Z"
    },
    "papermill": {
     "duration": 0.629839,
     "end_time": "2020-08-10T07:27:16.941507",
     "exception": false,
     "start_time": "2020-08-10T07:27:16.311668",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_metric(metric1, metric2, ylabel):\n",
    "    plt.plot(history.history[metric1], label=metric1)\n",
    "    plt.plot(history.history[metric2], label=metric2)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T07:27:18.076192Z",
     "iopub.status.busy": "2020-08-10T07:27:18.075358Z",
     "iopub.status.idle": "2020-08-10T07:27:18.785477Z",
     "shell.execute_reply": "2020-08-10T07:27:18.784625Z"
    },
    "papermill": {
     "duration": 1.275459,
     "end_time": "2020-08-10T07:27:18.785617",
     "exception": false,
     "start_time": "2020-08-10T07:27:17.510158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('auc', 'val_auc', 'auc')\n",
    "plot_metric('loss', 'val_loss', 'loss')\n",
    "plot_metric('accuracy', 'val_accuracy', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T07:27:20.013676Z",
     "iopub.status.busy": "2020-08-10T07:27:19.987689Z",
     "iopub.status.idle": "2020-08-10T07:27:20.026708Z",
     "shell.execute_reply": "2020-08-10T07:27:20.027321Z"
    },
    "papermill": {
     "duration": 0.603291,
     "end_time": "2020-08-10T07:27:20.027521",
     "exception": false,
     "start_time": "2020-08-10T07:27:19.424230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.5018184185028076,\n",
       "  0.606815755367279,\n",
       "  0.6021012663841248,\n",
       "  0.6070177555084229,\n",
       "  0.605805516242981,\n",
       "  0.6135506629943848,\n",
       "  0.612675130367279,\n",
       "  0.6094423532485962,\n",
       "  0.6029431819915771,\n",
       "  0.6412984728813171,\n",
       "  0.6283338069915771,\n",
       "  0.627289891242981,\n",
       "  0.6283338069915771,\n",
       "  0.621464192867279,\n",
       "  0.6221039891242981,\n",
       "  0.620487630367279,\n",
       "  0.6342941522598267,\n",
       "  0.6247305870056152,\n",
       "  0.6269194483757019,\n",
       "  0.6169180870056152,\n",
       "  0.6346645951271057,\n",
       "  0.6561826467514038,\n",
       "  0.620723307132721,\n",
       "  0.620756983757019,\n",
       "  0.638065755367279,\n",
       "  0.6291756629943848,\n",
       "  0.6405239701271057,\n",
       "  0.6320379972457886,\n",
       "  0.6367861032485962,\n",
       "  0.6446659564971924,\n",
       "  0.6481344103813171,\n",
       "  0.6631196141242981,\n",
       "  0.6522763967514038,\n",
       "  0.6482691168785095,\n",
       "  0.6632206439971924,\n",
       "  0.6603583097457886,\n",
       "  0.6802262663841248,\n",
       "  0.6570581793785095,\n",
       "  0.665678858757019,\n",
       "  0.6642982363700867,\n",
       "  0.654633641242981,\n",
       "  0.6827518939971924,\n",
       "  0.6623114347457886,\n",
       "  0.6719086766242981,\n",
       "  0.6671942472457886,\n",
       "  0.6843682527542114,\n",
       "  0.670292317867279,\n",
       "  0.6675646305084229,\n",
       "  0.6697534918785095,\n",
       "  0.6728852391242981,\n",
       "  0.6401535272598267,\n",
       "  0.6789803504943848,\n",
       "  0.667328953742981,\n",
       "  0.6643655896186829,\n",
       "  0.6633216738700867,\n",
       "  0.684907078742981,\n",
       "  0.6650390625,\n",
       "  0.6645675897598267,\n",
       "  0.6750404238700867,\n",
       "  0.6789803504943848,\n",
       "  0.687129557132721,\n",
       "  0.6647696495056152,\n",
       "  0.6752761006355286,\n",
       "  0.7002963423728943,\n",
       "  0.6759496331214905,\n",
       "  0.6895541548728943,\n",
       "  0.6726831793785095,\n",
       "  0.695952296257019,\n",
       "  0.687129557132721,\n",
       "  0.6734240055084229,\n",
       "  0.6792833805084229,\n",
       "  0.6934267282485962,\n",
       "  0.6876683831214905,\n",
       "  0.6924164891242981,\n",
       "  0.6898572444915771,\n",
       "  0.6948747038841248,\n",
       "  0.6795527935028076,\n",
       "  0.6859846711158752,\n",
       "  0.7020137310028076,\n",
       "  0.6915072798728943,\n",
       "  0.7057515978813171,\n",
       "  0.6727505326271057,\n",
       "  0.6951441168785095,\n",
       "  0.7039331793785095,\n",
       "  0.6903286576271057,\n",
       "  0.6933930516242981,\n",
       "  0.6841325163841248,\n",
       "  0.6750067472457886,\n",
       "  0.6950430870056152,\n",
       "  0.6934604048728943,\n",
       "  0.7024515271186829,\n",
       "  0.6906317472457886,\n",
       "  0.7008687853813171,\n",
       "  0.697265625,\n",
       "  0.7032260298728943,\n",
       "  0.7095231413841248,\n",
       "  0.6986799836158752,\n",
       "  0.714506983757019,\n",
       "  0.7034280896186829,\n",
       "  0.7054822444915771,\n",
       "  0.7022831439971924,\n",
       "  0.7114089131355286,\n",
       "  0.7051791548728943,\n",
       "  0.7022494673728943,\n",
       "  0.6952114701271057,\n",
       "  0.6986463069915771,\n",
       "  0.7072333097457886,\n",
       "  0.7040005326271057,\n",
       "  0.6740975379943848,\n",
       "  0.7007004022598267,\n",
       "  0.7009361386299133,\n",
       "  0.6922817826271057,\n",
       "  0.7017443180084229,\n",
       "  0.7055832147598267,\n",
       "  0.695952296257019,\n",
       "  0.700532078742981,\n",
       "  0.7128232717514038,\n",
       "  0.6965921521186829,\n",
       "  0.6937634944915771,\n",
       "  0.6719760298728943,\n",
       "  0.7041015625,\n",
       "  0.6803609728813171,\n",
       "  0.7002289891242981,\n",
       "  0.6996901631355286,\n",
       "  0.6956155896186829,\n",
       "  0.7022494673728943,\n",
       "  0.705414891242981,\n",
       "  0.7002626657485962,\n",
       "  0.7166621685028076,\n",
       "  0.7101966738700867,\n",
       "  0.7063241004943848,\n",
       "  0.692988932132721,\n",
       "  0.7042699456214905,\n",
       "  0.7000606060028076,\n",
       "  0.6963227391242981,\n",
       "  0.7053475379943848,\n",
       "  0.7020137310028076,\n",
       "  0.711274266242981,\n",
       "  0.7027208805084229,\n",
       "  0.7069638967514038,\n",
       "  0.709321141242981,\n",
       "  0.7046403288841248,\n",
       "  0.7094221711158752,\n",
       "  0.7116446495056152,\n",
       "  0.7036637663841248,\n",
       "  0.7101629972457886,\n",
       "  0.7021821141242981,\n",
       "  0.7158876657485962,\n",
       "  0.704438328742981,\n",
       "  0.703125,\n",
       "  0.7123518586158752,\n",
       "  0.7168979048728943,\n",
       "  0.7245083451271057,\n",
       "  0.7246430516242981,\n",
       "  0.7055832147598267,\n",
       "  0.7016769647598267,\n",
       "  0.7143049836158752,\n",
       "  0.7254512310028076,\n",
       "  0.7123854756355286,\n",
       "  0.7048760652542114,\n",
       "  0.7081425189971924,\n",
       "  0.718413233757019,\n",
       "  0.7104997038841248,\n",
       "  0.7035627961158752,\n",
       "  0.724979817867279,\n",
       "  0.7085129022598267,\n",
       "  0.7126212120056152,\n",
       "  0.7072669863700867,\n",
       "  0.7163590788841248,\n",
       "  0.7137324810028076,\n",
       "  0.7158876657485962,\n",
       "  0.7295932173728943,\n",
       "  0.7196255326271057,\n",
       "  0.724979817867279,\n",
       "  0.7180765271186829,\n",
       "  0.726225733757019,\n",
       "  0.719086766242981,\n",
       "  0.730098307132721,\n",
       "  0.7165611386299133,\n",
       "  0.7176050543785095,\n",
       "  0.7266635298728943,\n",
       "  0.7136314511299133,\n",
       "  0.7052801847457886,\n",
       "  0.7205010652542114,\n",
       "  0.7127222418785095,\n",
       "  0.6967604756355286,\n",
       "  0.6819100379943848,\n",
       "  0.7042025923728943,\n",
       "  0.697636067867279,\n",
       "  0.7043036222457886,\n",
       "  0.6984779238700867,\n",
       "  0.7255522608757019,\n",
       "  0.711274266242981,\n",
       "  0.7047750353813171,\n",
       "  0.7046403288841248,\n",
       "  0.7176724076271057,\n",
       "  0.7168979048728943,\n",
       "  0.7152815461158752,\n",
       "  0.7197939157485962,\n",
       "  0.6999595761299133,\n",
       "  0.7011045217514038,\n",
       "  0.7178744673728943,\n",
       "  0.7077383995056152,\n",
       "  0.712250828742981,\n",
       "  0.7179754972457886,\n",
       "  0.7206020951271057,\n",
       "  0.7299972772598267,\n",
       "  0.7183122038841248,\n",
       "  0.7262930870056152,\n",
       "  0.702754557132721,\n",
       "  0.7045393586158752,\n",
       "  0.7160560488700867,\n",
       "  0.7261583805084229,\n",
       "  0.7085465788841248,\n",
       "  0.7248451113700867,\n",
       "  0.7322198152542114,\n",
       "  0.7198275923728943,\n",
       "  0.7157192826271057,\n",
       "  0.7126885652542114,\n",
       "  0.716460108757019,\n",
       "  0.7202316522598267,\n",
       "  0.7058863043785095,\n",
       "  0.7136314511299133,\n",
       "  0.707401692867279,\n",
       "  0.7228583097457886,\n",
       "  0.7100282907485962,\n",
       "  0.7220838069915771,\n",
       "  0.7003973722457886,\n",
       "  0.7112405896186829,\n",
       "  0.713496744632721,\n",
       "  0.7263604402542114,\n",
       "  0.7232286930084229,\n",
       "  0.7124865055084229,\n",
       "  0.7194234728813171,\n",
       "  0.719389796257019,\n",
       "  0.7255185842514038,\n",
       "  0.7202990055084229,\n",
       "  0.7201979756355286,\n",
       "  0.7303003668785095,\n",
       "  0.7283809185028076,\n",
       "  0.722050130367279,\n",
       "  0.7175377011299133,\n",
       "  0.7088496685028076,\n",
       "  0.7211072444915771,\n",
       "  0.7114425897598267,\n",
       "  0.7244073152542114,\n",
       "  0.7158539891242981,\n",
       "  0.7081761956214905,\n",
       "  0.7028219103813171,\n",
       "  0.708344578742981,\n",
       "  0.700835108757019,\n",
       "  0.7013065814971924,\n",
       "  0.7078731060028076,\n",
       "  0.7286166548728943,\n",
       "  0.6913725733757019,\n",
       "  0.7197265625,\n",
       "  0.7182112336158752],\n",
       " 'fn': [274.0,\n",
       "  198.0,\n",
       "  175.0,\n",
       "  161.0,\n",
       "  140.0,\n",
       "  123.0,\n",
       "  133.0,\n",
       "  113.0,\n",
       "  110.0,\n",
       "  127.0,\n",
       "  108.0,\n",
       "  101.0,\n",
       "  100.0,\n",
       "  85.0,\n",
       "  98.0,\n",
       "  100.0,\n",
       "  94.0,\n",
       "  90.0,\n",
       "  108.0,\n",
       "  83.0,\n",
       "  88.0,\n",
       "  98.0,\n",
       "  95.0,\n",
       "  86.0,\n",
       "  87.0,\n",
       "  79.0,\n",
       "  75.0,\n",
       "  70.0,\n",
       "  75.0,\n",
       "  68.0,\n",
       "  95.0,\n",
       "  92.0,\n",
       "  90.0,\n",
       "  88.0,\n",
       "  86.0,\n",
       "  85.0,\n",
       "  86.0,\n",
       "  76.0,\n",
       "  83.0,\n",
       "  70.0,\n",
       "  63.0,\n",
       "  85.0,\n",
       "  79.0,\n",
       "  79.0,\n",
       "  83.0,\n",
       "  87.0,\n",
       "  87.0,\n",
       "  84.0,\n",
       "  92.0,\n",
       "  69.0,\n",
       "  73.0,\n",
       "  63.0,\n",
       "  77.0,\n",
       "  71.0,\n",
       "  88.0,\n",
       "  81.0,\n",
       "  73.0,\n",
       "  71.0,\n",
       "  79.0,\n",
       "  73.0,\n",
       "  92.0,\n",
       "  77.0,\n",
       "  72.0,\n",
       "  75.0,\n",
       "  67.0,\n",
       "  71.0,\n",
       "  77.0,\n",
       "  82.0,\n",
       "  71.0,\n",
       "  65.0,\n",
       "  64.0,\n",
       "  88.0,\n",
       "  72.0,\n",
       "  84.0,\n",
       "  67.0,\n",
       "  78.0,\n",
       "  66.0,\n",
       "  81.0,\n",
       "  68.0,\n",
       "  74.0,\n",
       "  75.0,\n",
       "  68.0,\n",
       "  76.0,\n",
       "  64.0,\n",
       "  78.0,\n",
       "  85.0,\n",
       "  74.0,\n",
       "  70.0,\n",
       "  80.0,\n",
       "  65.0,\n",
       "  85.0,\n",
       "  68.0,\n",
       "  74.0,\n",
       "  66.0,\n",
       "  76.0,\n",
       "  83.0,\n",
       "  74.0,\n",
       "  78.0,\n",
       "  84.0,\n",
       "  76.0,\n",
       "  72.0,\n",
       "  78.0,\n",
       "  71.0,\n",
       "  91.0,\n",
       "  83.0,\n",
       "  69.0,\n",
       "  69.0,\n",
       "  84.0,\n",
       "  78.0,\n",
       "  76.0,\n",
       "  72.0,\n",
       "  78.0,\n",
       "  87.0,\n",
       "  73.0,\n",
       "  66.0,\n",
       "  70.0,\n",
       "  71.0,\n",
       "  84.0,\n",
       "  75.0,\n",
       "  72.0,\n",
       "  69.0,\n",
       "  72.0,\n",
       "  67.0,\n",
       "  75.0,\n",
       "  74.0,\n",
       "  60.0,\n",
       "  77.0,\n",
       "  71.0,\n",
       "  67.0,\n",
       "  70.0,\n",
       "  79.0,\n",
       "  75.0,\n",
       "  66.0,\n",
       "  71.0,\n",
       "  67.0,\n",
       "  68.0,\n",
       "  63.0,\n",
       "  67.0,\n",
       "  61.0,\n",
       "  74.0,\n",
       "  64.0,\n",
       "  69.0,\n",
       "  64.0,\n",
       "  62.0,\n",
       "  61.0,\n",
       "  68.0,\n",
       "  73.0,\n",
       "  71.0,\n",
       "  65.0,\n",
       "  67.0,\n",
       "  66.0,\n",
       "  70.0,\n",
       "  71.0,\n",
       "  59.0,\n",
       "  70.0,\n",
       "  73.0,\n",
       "  69.0,\n",
       "  72.0,\n",
       "  69.0,\n",
       "  74.0,\n",
       "  68.0,\n",
       "  66.0,\n",
       "  65.0,\n",
       "  72.0,\n",
       "  71.0,\n",
       "  62.0,\n",
       "  80.0,\n",
       "  63.0,\n",
       "  64.0,\n",
       "  57.0,\n",
       "  67.0,\n",
       "  65.0,\n",
       "  74.0,\n",
       "  67.0,\n",
       "  65.0,\n",
       "  62.0,\n",
       "  52.0,\n",
       "  71.0,\n",
       "  66.0,\n",
       "  54.0,\n",
       "  64.0,\n",
       "  58.0,\n",
       "  59.0,\n",
       "  76.0,\n",
       "  58.0,\n",
       "  65.0,\n",
       "  69.0,\n",
       "  77.0,\n",
       "  65.0,\n",
       "  64.0,\n",
       "  50.0,\n",
       "  74.0,\n",
       "  71.0,\n",
       "  67.0,\n",
       "  58.0,\n",
       "  65.0,\n",
       "  57.0,\n",
       "  67.0,\n",
       "  67.0,\n",
       "  62.0,\n",
       "  62.0,\n",
       "  59.0,\n",
       "  57.0,\n",
       "  70.0,\n",
       "  55.0,\n",
       "  55.0,\n",
       "  56.0,\n",
       "  69.0,\n",
       "  61.0,\n",
       "  62.0,\n",
       "  59.0,\n",
       "  54.0,\n",
       "  65.0,\n",
       "  62.0,\n",
       "  64.0,\n",
       "  55.0,\n",
       "  62.0,\n",
       "  57.0,\n",
       "  59.0,\n",
       "  58.0,\n",
       "  62.0,\n",
       "  56.0,\n",
       "  51.0,\n",
       "  61.0,\n",
       "  52.0,\n",
       "  71.0,\n",
       "  52.0,\n",
       "  53.0,\n",
       "  64.0,\n",
       "  60.0,\n",
       "  57.0,\n",
       "  66.0,\n",
       "  62.0,\n",
       "  68.0,\n",
       "  59.0,\n",
       "  60.0,\n",
       "  61.0,\n",
       "  62.0,\n",
       "  60.0,\n",
       "  60.0,\n",
       "  59.0,\n",
       "  54.0,\n",
       "  56.0,\n",
       "  67.0,\n",
       "  58.0,\n",
       "  63.0,\n",
       "  67.0,\n",
       "  59.0,\n",
       "  56.0,\n",
       "  62.0,\n",
       "  69.0,\n",
       "  52.0,\n",
       "  54.0,\n",
       "  63.0,\n",
       "  55.0,\n",
       "  54.0,\n",
       "  62.0],\n",
       " 'tp': [252.0,\n",
       "  329.0,\n",
       "  348.0,\n",
       "  368.0,\n",
       "  388.0,\n",
       "  407.0,\n",
       "  393.0,\n",
       "  419.0,\n",
       "  417.0,\n",
       "  401.0,\n",
       "  427.0,\n",
       "  430.0,\n",
       "  434.0,\n",
       "  437.0,\n",
       "  425.0,\n",
       "  431.0,\n",
       "  429.0,\n",
       "  441.0,\n",
       "  418.0,\n",
       "  443.0,\n",
       "  439.0,\n",
       "  428.0,\n",
       "  438.0,\n",
       "  440.0,\n",
       "  436.0,\n",
       "  449.0,\n",
       "  452.0,\n",
       "  459.0,\n",
       "  456.0,\n",
       "  458.0,\n",
       "  429.0,\n",
       "  438.0,\n",
       "  440.0,\n",
       "  442.0,\n",
       "  441.0,\n",
       "  445.0,\n",
       "  437.0,\n",
       "  452.0,\n",
       "  436.0,\n",
       "  460.0,\n",
       "  465.0,\n",
       "  438.0,\n",
       "  452.0,\n",
       "  449.0,\n",
       "  441.0,\n",
       "  442.0,\n",
       "  443.0,\n",
       "  451.0,\n",
       "  430.0,\n",
       "  459.0,\n",
       "  459.0,\n",
       "  467.0,\n",
       "  459.0,\n",
       "  451.0,\n",
       "  439.0,\n",
       "  445.0,\n",
       "  455.0,\n",
       "  452.0,\n",
       "  451.0,\n",
       "  455.0,\n",
       "  438.0,\n",
       "  448.0,\n",
       "  453.0,\n",
       "  457.0,\n",
       "  455.0,\n",
       "  458.0,\n",
       "  455.0,\n",
       "  445.0,\n",
       "  456.0,\n",
       "  458.0,\n",
       "  466.0,\n",
       "  435.0,\n",
       "  460.0,\n",
       "  448.0,\n",
       "  462.0,\n",
       "  445.0,\n",
       "  464.0,\n",
       "  447.0,\n",
       "  455.0,\n",
       "  449.0,\n",
       "  452.0,\n",
       "  461.0,\n",
       "  454.0,\n",
       "  460.0,\n",
       "  447.0,\n",
       "  445.0,\n",
       "  456.0,\n",
       "  456.0,\n",
       "  452.0,\n",
       "  459.0,\n",
       "  446.0,\n",
       "  461.0,\n",
       "  453.0,\n",
       "  468.0,\n",
       "  456.0,\n",
       "  445.0,\n",
       "  451.0,\n",
       "  444.0,\n",
       "  445.0,\n",
       "  447.0,\n",
       "  457.0,\n",
       "  451.0,\n",
       "  455.0,\n",
       "  439.0,\n",
       "  443.0,\n",
       "  462.0,\n",
       "  451.0,\n",
       "  450.0,\n",
       "  452.0,\n",
       "  450.0,\n",
       "  455.0,\n",
       "  446.0,\n",
       "  438.0,\n",
       "  459.0,\n",
       "  466.0,\n",
       "  459.0,\n",
       "  454.0,\n",
       "  444.0,\n",
       "  449.0,\n",
       "  453.0,\n",
       "  457.0,\n",
       "  460.0,\n",
       "  453.0,\n",
       "  456.0,\n",
       "  453.0,\n",
       "  465.0,\n",
       "  447.0,\n",
       "  457.0,\n",
       "  467.0,\n",
       "  458.0,\n",
       "  452.0,\n",
       "  453.0,\n",
       "  464.0,\n",
       "  460.0,\n",
       "  463.0,\n",
       "  462.0,\n",
       "  462.0,\n",
       "  458.0,\n",
       "  463.0,\n",
       "  453.0,\n",
       "  464.0,\n",
       "  460.0,\n",
       "  462.0,\n",
       "  466.0,\n",
       "  470.0,\n",
       "  459.0,\n",
       "  454.0,\n",
       "  456.0,\n",
       "  459.0,\n",
       "  463.0,\n",
       "  461.0,\n",
       "  456.0,\n",
       "  455.0,\n",
       "  463.0,\n",
       "  469.0,\n",
       "  459.0,\n",
       "  457.0,\n",
       "  453.0,\n",
       "  457.0,\n",
       "  455.0,\n",
       "  455.0,\n",
       "  461.0,\n",
       "  459.0,\n",
       "  458.0,\n",
       "  458.0,\n",
       "  459.0,\n",
       "  451.0,\n",
       "  466.0,\n",
       "  461.0,\n",
       "  473.0,\n",
       "  464.0,\n",
       "  462.0,\n",
       "  456.0,\n",
       "  461.0,\n",
       "  471.0,\n",
       "  468.0,\n",
       "  472.0,\n",
       "  453.0,\n",
       "  462.0,\n",
       "  470.0,\n",
       "  468.0,\n",
       "  471.0,\n",
       "  464.0,\n",
       "  448.0,\n",
       "  474.0,\n",
       "  462.0,\n",
       "  462.0,\n",
       "  449.0,\n",
       "  463.0,\n",
       "  459.0,\n",
       "  479.0,\n",
       "  453.0,\n",
       "  457.0,\n",
       "  457.0,\n",
       "  473.0,\n",
       "  469.0,\n",
       "  469.0,\n",
       "  459.0,\n",
       "  464.0,\n",
       "  465.0,\n",
       "  462.0,\n",
       "  465.0,\n",
       "  470.0,\n",
       "  460.0,\n",
       "  466.0,\n",
       "  471.0,\n",
       "  472.0,\n",
       "  460.0,\n",
       "  465.0,\n",
       "  468.0,\n",
       "  474.0,\n",
       "  472.0,\n",
       "  463.0,\n",
       "  471.0,\n",
       "  465.0,\n",
       "  477.0,\n",
       "  464.0,\n",
       "  474.0,\n",
       "  465.0,\n",
       "  465.0,\n",
       "  464.0,\n",
       "  475.0,\n",
       "  479.0,\n",
       "  457.0,\n",
       "  477.0,\n",
       "  458.0,\n",
       "  479.0,\n",
       "  476.0,\n",
       "  460.0,\n",
       "  471.0,\n",
       "  473.0,\n",
       "  457.0,\n",
       "  463.0,\n",
       "  456.0,\n",
       "  473.0,\n",
       "  471.0,\n",
       "  470.0,\n",
       "  462.0,\n",
       "  467.0,\n",
       "  472.0,\n",
       "  466.0,\n",
       "  470.0,\n",
       "  468.0,\n",
       "  458.0,\n",
       "  470.0,\n",
       "  462.0,\n",
       "  466.0,\n",
       "  464.0,\n",
       "  473.0,\n",
       "  466.0,\n",
       "  465.0,\n",
       "  470.0,\n",
       "  478.0,\n",
       "  463.0,\n",
       "  473.0,\n",
       "  483.0,\n",
       "  470.0],\n",
       " 'loss': [1.0095701217651367,\n",
       "  0.7592267394065857,\n",
       "  0.6744370460510254,\n",
       "  0.6538952589035034,\n",
       "  0.6153839826583862,\n",
       "  0.5945771932601929,\n",
       "  0.6053894758224487,\n",
       "  0.5825170278549194,\n",
       "  0.5884842276573181,\n",
       "  0.5904704928398132,\n",
       "  0.5715133547782898,\n",
       "  0.561547577381134,\n",
       "  0.5529745817184448,\n",
       "  0.5490919351577759,\n",
       "  0.5550735592842102,\n",
       "  0.5571662783622742,\n",
       "  0.5569911599159241,\n",
       "  0.5462775826454163,\n",
       "  0.5665377974510193,\n",
       "  0.5441654920578003,\n",
       "  0.5424695014953613,\n",
       "  0.5436382293701172,\n",
       "  0.5440546870231628,\n",
       "  0.5419728755950928,\n",
       "  0.5445610284805298,\n",
       "  0.5238462090492249,\n",
       "  0.5124298334121704,\n",
       "  0.5196945667266846,\n",
       "  0.518503725528717,\n",
       "  0.5057123303413391,\n",
       "  0.5289191603660583,\n",
       "  0.5277801752090454,\n",
       "  0.5285478234291077,\n",
       "  0.5280136466026306,\n",
       "  0.5210492610931396,\n",
       "  0.5308279991149902,\n",
       "  0.5005843639373779,\n",
       "  0.5201773047447205,\n",
       "  0.5058276653289795,\n",
       "  0.5004215836524963,\n",
       "  0.5165345668792725,\n",
       "  0.5052345991134644,\n",
       "  0.518779456615448,\n",
       "  0.49871402978897095,\n",
       "  0.508188009262085,\n",
       "  0.5025991797447205,\n",
       "  0.5156787037849426,\n",
       "  0.5164351463317871,\n",
       "  0.5087894797325134,\n",
       "  0.491887629032135,\n",
       "  0.5149461627006531,\n",
       "  0.4816116988658905,\n",
       "  0.5084086060523987,\n",
       "  0.5005394220352173,\n",
       "  0.5081210136413574,\n",
       "  0.48965901136398315,\n",
       "  0.5036934614181519,\n",
       "  0.502472460269928,\n",
       "  0.5054982900619507,\n",
       "  0.49016255140304565,\n",
       "  0.49091583490371704,\n",
       "  0.4931863248348236,\n",
       "  0.49157243967056274,\n",
       "  0.4878932237625122,\n",
       "  0.47773677110671997,\n",
       "  0.47607260942459106,\n",
       "  0.49628931283950806,\n",
       "  0.48880791664123535,\n",
       "  0.4791826903820038,\n",
       "  0.48032352328300476,\n",
       "  0.47306764125823975,\n",
       "  0.482478529214859,\n",
       "  0.49281489849090576,\n",
       "  0.4848792254924774,\n",
       "  0.47525155544281006,\n",
       "  0.48184874653816223,\n",
       "  0.4857589304447174,\n",
       "  0.48786279559135437,\n",
       "  0.4780832827091217,\n",
       "  0.4752282500267029,\n",
       "  0.4827004373073578,\n",
       "  0.4912748634815216,\n",
       "  0.4766441285610199,\n",
       "  0.467115193605423,\n",
       "  0.48035696148872375,\n",
       "  0.48693010210990906,\n",
       "  0.49311643838882446,\n",
       "  0.47473064064979553,\n",
       "  0.4742993414402008,\n",
       "  0.4737491011619568,\n",
       "  0.4727354645729065,\n",
       "  0.4764583110809326,\n",
       "  0.46627840399742126,\n",
       "  0.4629930257797241,\n",
       "  0.46488845348358154,\n",
       "  0.48045799136161804,\n",
       "  0.4660447835922241,\n",
       "  0.45431432127952576,\n",
       "  0.4672449827194214,\n",
       "  0.4616401493549347,\n",
       "  0.47105643153190613,\n",
       "  0.4718194007873535,\n",
       "  0.45772626996040344,\n",
       "  0.47487136721611023,\n",
       "  0.47998178005218506,\n",
       "  0.46402403712272644,\n",
       "  0.45652246475219727,\n",
       "  0.4728841185569763,\n",
       "  0.4926675856113434,\n",
       "  0.47082582116127014,\n",
       "  0.47573336958885193,\n",
       "  0.4756796956062317,\n",
       "  0.4672852158546448,\n",
       "  0.46642565727233887,\n",
       "  0.4649357497692108,\n",
       "  0.46278560161590576,\n",
       "  0.461935430765152,\n",
       "  0.47025877237319946,\n",
       "  0.4779113531112671,\n",
       "  0.4951072335243225,\n",
       "  0.47527334094047546,\n",
       "  0.47420263290405273,\n",
       "  0.46128401160240173,\n",
       "  0.4685826003551483,\n",
       "  0.4658469259738922,\n",
       "  0.44804635643959045,\n",
       "  0.45273494720458984,\n",
       "  0.46815839409828186,\n",
       "  0.44045358896255493,\n",
       "  0.45181915163993835,\n",
       "  0.4747319221496582,\n",
       "  0.4772339463233948,\n",
       "  0.454898476600647,\n",
       "  0.46023911237716675,\n",
       "  0.4638430178165436,\n",
       "  0.4595511555671692,\n",
       "  0.4523865580558777,\n",
       "  0.44871199131011963,\n",
       "  0.44574952125549316,\n",
       "  0.45283883810043335,\n",
       "  0.45325928926467896,\n",
       "  0.4614242911338806,\n",
       "  0.44784286618232727,\n",
       "  0.4443170726299286,\n",
       "  0.4382447302341461,\n",
       "  0.44695448875427246,\n",
       "  0.4516778886318207,\n",
       "  0.4483761191368103,\n",
       "  0.4587137699127197,\n",
       "  0.46380335092544556,\n",
       "  0.4434983432292938,\n",
       "  0.4410649538040161,\n",
       "  0.4435856342315674,\n",
       "  0.4359584450721741,\n",
       "  0.4499002695083618,\n",
       "  0.45635098218917847,\n",
       "  0.44856730103492737,\n",
       "  0.44134587049484253,\n",
       "  0.44168034195899963,\n",
       "  0.4549407958984375,\n",
       "  0.44874855875968933,\n",
       "  0.4328800439834595,\n",
       "  0.44446006417274475,\n",
       "  0.45083561539649963,\n",
       "  0.44912633299827576,\n",
       "  0.4431479573249817,\n",
       "  0.4562261402606964,\n",
       "  0.4515581727027893,\n",
       "  0.43438607454299927,\n",
       "  0.4403000771999359,\n",
       "  0.44884487986564636,\n",
       "  0.42955395579338074,\n",
       "  0.43935492634773254,\n",
       "  0.4361836314201355,\n",
       "  0.43738603591918945,\n",
       "  0.4251457452774048,\n",
       "  0.41659224033355713,\n",
       "  0.4277587831020355,\n",
       "  0.44335150718688965,\n",
       "  0.42841652035713196,\n",
       "  0.42607253789901733,\n",
       "  0.4297325909137726,\n",
       "  0.4330601692199707,\n",
       "  0.4423888921737671,\n",
       "  0.445587158203125,\n",
       "  0.4533555209636688,\n",
       "  0.4783641993999481,\n",
       "  0.4683522880077362,\n",
       "  0.45304909348487854,\n",
       "  0.45220664143562317,\n",
       "  0.4415246546268463,\n",
       "  0.4396008551120758,\n",
       "  0.44589850306510925,\n",
       "  0.448684424161911,\n",
       "  0.4451405107975006,\n",
       "  0.4352930784225464,\n",
       "  0.4374536871910095,\n",
       "  0.4349212646484375,\n",
       "  0.4433600902557373,\n",
       "  0.4492150545120239,\n",
       "  0.44871756434440613,\n",
       "  0.4426738917827606,\n",
       "  0.4426988959312439,\n",
       "  0.44031691551208496,\n",
       "  0.4294600188732147,\n",
       "  0.41668882966041565,\n",
       "  0.42448413372039795,\n",
       "  0.43864676356315613,\n",
       "  0.4267071485519409,\n",
       "  0.4541791081428528,\n",
       "  0.4394858181476593,\n",
       "  0.42642539739608765,\n",
       "  0.42760154604911804,\n",
       "  0.43984708189964294,\n",
       "  0.43506842851638794,\n",
       "  0.4186069965362549,\n",
       "  0.4357774257659912,\n",
       "  0.43110010027885437,\n",
       "  0.43488696217536926,\n",
       "  0.4312514066696167,\n",
       "  0.4350394606590271,\n",
       "  0.43927064538002014,\n",
       "  0.4344971477985382,\n",
       "  0.43831732869148254,\n",
       "  0.42538201808929443,\n",
       "  0.4467809498310089,\n",
       "  0.4289116859436035,\n",
       "  0.4354386329650879,\n",
       "  0.4388226866722107,\n",
       "  0.43418559432029724,\n",
       "  0.4183684289455414,\n",
       "  0.43075793981552124,\n",
       "  0.4336990714073181,\n",
       "  0.43550819158554077,\n",
       "  0.42578262090682983,\n",
       "  0.43209949135780334,\n",
       "  0.43345746397972107,\n",
       "  0.42963993549346924,\n",
       "  0.4254710078239441,\n",
       "  0.41827431321144104,\n",
       "  0.4184868633747101,\n",
       "  0.42723849415779114,\n",
       "  0.4348703920841217,\n",
       "  0.4350162446498871,\n",
       "  0.4310692548751831,\n",
       "  0.43312832713127136,\n",
       "  0.44211846590042114,\n",
       "  0.43689054250717163,\n",
       "  0.44136789441108704,\n",
       "  0.43827134370803833,\n",
       "  0.4523366689682007,\n",
       "  0.4294557273387909,\n",
       "  0.43444836139678955,\n",
       "  0.4302506148815155,\n",
       "  0.4496047794818878,\n",
       "  0.42784029245376587,\n",
       "  0.42729175090789795],\n",
       " 'auc': [0.4870123863220215,\n",
       "  0.6529822945594788,\n",
       "  0.705540657043457,\n",
       "  0.7089580297470093,\n",
       "  0.7261047959327698,\n",
       "  0.7413557171821594,\n",
       "  0.7334460020065308,\n",
       "  0.7463670969009399,\n",
       "  0.7422470450401306,\n",
       "  0.7574529647827148,\n",
       "  0.7677225470542908,\n",
       "  0.7681453824043274,\n",
       "  0.7754090428352356,\n",
       "  0.7732055187225342,\n",
       "  0.7696386575698853,\n",
       "  0.7682850956916809,\n",
       "  0.7662941813468933,\n",
       "  0.7740285992622375,\n",
       "  0.7600753307342529,\n",
       "  0.7729281783103943,\n",
       "  0.7792282104492188,\n",
       "  0.7889527678489685,\n",
       "  0.7768651247024536,\n",
       "  0.7793583273887634,\n",
       "  0.7817212343215942,\n",
       "  0.7939960360527039,\n",
       "  0.8001704812049866,\n",
       "  0.7959901690483093,\n",
       "  0.795926034450531,\n",
       "  0.8059633374214172,\n",
       "  0.794894278049469,\n",
       "  0.7987762689590454,\n",
       "  0.7927507758140564,\n",
       "  0.7965238094329834,\n",
       "  0.8026611804962158,\n",
       "  0.7978350520133972,\n",
       "  0.8173495531082153,\n",
       "  0.8021993637084961,\n",
       "  0.8129127621650696,\n",
       "  0.8126406669616699,\n",
       "  0.8053737282752991,\n",
       "  0.8138666152954102,\n",
       "  0.8037914037704468,\n",
       "  0.8136379718780518,\n",
       "  0.8095458745956421,\n",
       "  0.8219250440597534,\n",
       "  0.8091661930084229,\n",
       "  0.8074885606765747,\n",
       "  0.8115651607513428,\n",
       "  0.8231685757637024,\n",
       "  0.8041173219680786,\n",
       "  0.8266141414642334,\n",
       "  0.8134188055992126,\n",
       "  0.81463623046875,\n",
       "  0.813283383846283,\n",
       "  0.8242411613464355,\n",
       "  0.8087379932403564,\n",
       "  0.8115652799606323,\n",
       "  0.8193525075912476,\n",
       "  0.8252886533737183,\n",
       "  0.8263885378837585,\n",
       "  0.8217359185218811,\n",
       "  0.8244389891624451,\n",
       "  0.8319528102874756,\n",
       "  0.8264443874359131,\n",
       "  0.8314165472984314,\n",
       "  0.8245766162872314,\n",
       "  0.828781008720398,\n",
       "  0.8369696736335754,\n",
       "  0.8354726433753967,\n",
       "  0.8340924978256226,\n",
       "  0.8353070616722107,\n",
       "  0.8261954188346863,\n",
       "  0.8324894309043884,\n",
       "  0.8378700613975525,\n",
       "  0.8350918889045715,\n",
       "  0.8293405175209045,\n",
       "  0.8296074867248535,\n",
       "  0.8390885591506958,\n",
       "  0.8376345634460449,\n",
       "  0.8377941250801086,\n",
       "  0.8273297548294067,\n",
       "  0.8416305780410767,\n",
       "  0.8446722626686096,\n",
       "  0.8336368799209595,\n",
       "  0.8330870270729065,\n",
       "  0.8314352631568909,\n",
       "  0.8340847492218018,\n",
       "  0.8410555124282837,\n",
       "  0.8403603434562683,\n",
       "  0.8440313339233398,\n",
       "  0.8420881628990173,\n",
       "  0.8453732132911682,\n",
       "  0.8469318747520447,\n",
       "  0.8517743349075317,\n",
       "  0.8407859802246094,\n",
       "  0.8458250164985657,\n",
       "  0.8541733622550964,\n",
       "  0.8475255966186523,\n",
       "  0.8522592186927795,\n",
       "  0.8462749719619751,\n",
       "  0.8455199003219604,\n",
       "  0.8521708250045776,\n",
       "  0.8407859802246094,\n",
       "  0.8328261375427246,\n",
       "  0.8489025235176086,\n",
       "  0.8513442277908325,\n",
       "  0.8439557552337646,\n",
       "  0.822013258934021,\n",
       "  0.8440033197402954,\n",
       "  0.8410000801086426,\n",
       "  0.8399713635444641,\n",
       "  0.8497760891914368,\n",
       "  0.8497997522354126,\n",
       "  0.847176730632782,\n",
       "  0.8476082682609558,\n",
       "  0.8496701717376709,\n",
       "  0.844745397567749,\n",
       "  0.8371172547340393,\n",
       "  0.8244067430496216,\n",
       "  0.8388687372207642,\n",
       "  0.8427702188491821,\n",
       "  0.8489152193069458,\n",
       "  0.8423582911491394,\n",
       "  0.8475614786148071,\n",
       "  0.8555765151977539,\n",
       "  0.8539149165153503,\n",
       "  0.8460608720779419,\n",
       "  0.8656727075576782,\n",
       "  0.8564647436141968,\n",
       "  0.846243679523468,\n",
       "  0.8398879170417786,\n",
       "  0.8553440570831299,\n",
       "  0.8524986505508423,\n",
       "  0.8483512997627258,\n",
       "  0.8512811064720154,\n",
       "  0.8555084466934204,\n",
       "  0.860891580581665,\n",
       "  0.8581079244613647,\n",
       "  0.8546624779701233,\n",
       "  0.8549098968505859,\n",
       "  0.8502210378646851,\n",
       "  0.8599266409873962,\n",
       "  0.860102653503418,\n",
       "  0.8620203733444214,\n",
       "  0.8604407906532288,\n",
       "  0.8548244833946228,\n",
       "  0.8587548732757568,\n",
       "  0.8515668511390686,\n",
       "  0.8517880439758301,\n",
       "  0.8601319789886475,\n",
       "  0.8625748753547668,\n",
       "  0.865357518196106,\n",
       "  0.8677862286567688,\n",
       "  0.8595976233482361,\n",
       "  0.8565322756767273,\n",
       "  0.8570455312728882,\n",
       "  0.8651312589645386,\n",
       "  0.8655086159706116,\n",
       "  0.8576974272727966,\n",
       "  0.8590188026428223,\n",
       "  0.8690382242202759,\n",
       "  0.86114901304245,\n",
       "  0.8582721948623657,\n",
       "  0.8637719750404358,\n",
       "  0.8615037202835083,\n",
       "  0.8591713905334473,\n",
       "  0.8594080805778503,\n",
       "  0.8702802658081055,\n",
       "  0.8632078170776367,\n",
       "  0.8620396852493286,\n",
       "  0.8727713227272034,\n",
       "  0.8661368489265442,\n",
       "  0.868098258972168,\n",
       "  0.8705350160598755,\n",
       "  0.8755160570144653,\n",
       "  0.8805969953536987,\n",
       "  0.874229371547699,\n",
       "  0.8641875982284546,\n",
       "  0.8688068389892578,\n",
       "  0.8750949501991272,\n",
       "  0.8715552091598511,\n",
       "  0.867759644985199,\n",
       "  0.8657203316688538,\n",
       "  0.8605564832687378,\n",
       "  0.8542454838752747,\n",
       "  0.8409963846206665,\n",
       "  0.846758246421814,\n",
       "  0.8563997745513916,\n",
       "  0.857246994972229,\n",
       "  0.8606936931610107,\n",
       "  0.8651474118232727,\n",
       "  0.8627442121505737,\n",
       "  0.8567788600921631,\n",
       "  0.8602712750434875,\n",
       "  0.866066038608551,\n",
       "  0.8655793070793152,\n",
       "  0.8659255504608154,\n",
       "  0.8658316731452942,\n",
       "  0.8560126423835754,\n",
       "  0.8559963703155518,\n",
       "  0.861127495765686,\n",
       "  0.8579317331314087,\n",
       "  0.8664633631706238,\n",
       "  0.8665743470191956,\n",
       "  0.8775137066841125,\n",
       "  0.8743945956230164,\n",
       "  0.8673877120018005,\n",
       "  0.8729237914085388,\n",
       "  0.8559440970420837,\n",
       "  0.8676823377609253,\n",
       "  0.8722025156021118,\n",
       "  0.8721466064453125,\n",
       "  0.8654081225395203,\n",
       "  0.8672333359718323,\n",
       "  0.8795657157897949,\n",
       "  0.865207850933075,\n",
       "  0.868970513343811,\n",
       "  0.8653832077980042,\n",
       "  0.8662291765213013,\n",
       "  0.8682059049606323,\n",
       "  0.8656639456748962,\n",
       "  0.8677603006362915,\n",
       "  0.862524688243866,\n",
       "  0.871421754360199,\n",
       "  0.8575447201728821,\n",
       "  0.8735276460647583,\n",
       "  0.8591960668563843,\n",
       "  0.8629605770111084,\n",
       "  0.8679155707359314,\n",
       "  0.8797382116317749,\n",
       "  0.8700081706047058,\n",
       "  0.8692027926445007,\n",
       "  0.8666480779647827,\n",
       "  0.8725978136062622,\n",
       "  0.8724818229675293,\n",
       "  0.8704763054847717,\n",
       "  0.8685511350631714,\n",
       "  0.8733451962471008,\n",
       "  0.8787690997123718,\n",
       "  0.8754718899726868,\n",
       "  0.8721963763237,\n",
       "  0.8638426065444946,\n",
       "  0.866635799407959,\n",
       "  0.8707228302955627,\n",
       "  0.868426501750946,\n",
       "  0.8653008341789246,\n",
       "  0.8636978268623352,\n",
       "  0.8625415563583374,\n",
       "  0.8669005036354065,\n",
       "  0.8573524951934814,\n",
       "  0.8646674752235413,\n",
       "  0.8660802245140076,\n",
       "  0.8698147535324097,\n",
       "  0.8509232401847839,\n",
       "  0.8711792826652527,\n",
       "  0.8715195059776306],\n",
       " 'val_accuracy': [0.9833984375,\n",
       "  0.9828125238418579,\n",
       "  0.9833984375,\n",
       "  0.983203113079071,\n",
       "  0.9837890863418579,\n",
       "  0.983203113079071,\n",
       "  0.9839844107627869,\n",
       "  0.9828125238418579,\n",
       "  0.9839844107627869,\n",
       "  0.982617199420929,\n",
       "  0.983203113079071,\n",
       "  0.983593761920929,\n",
       "  0.983593761920929,\n",
       "  0.9833984375,\n",
       "  0.9830078482627869,\n",
       "  0.9833984375,\n",
       "  0.983593761920929,\n",
       "  0.9839844107627869,\n",
       "  0.9830078482627869,\n",
       "  0.9830078482627869,\n",
       "  0.9830078482627869,\n",
       "  0.983203113079071,\n",
       "  0.9828125238418579,\n",
       "  0.900585949420929,\n",
       "  0.918749988079071,\n",
       "  0.930859386920929,\n",
       "  0.9185547232627869,\n",
       "  0.9140625,\n",
       "  0.9228515625,\n",
       "  0.9267578125,\n",
       "  0.903515636920929,\n",
       "  0.9369140863418579,\n",
       "  0.8900390863418579,\n",
       "  0.929492175579071,\n",
       "  0.8335937857627869,\n",
       "  0.869140625,\n",
       "  0.870312511920929,\n",
       "  0.8677734732627869,\n",
       "  0.902539074420929,\n",
       "  0.904492199420929,\n",
       "  0.8900390863418579,\n",
       "  0.8792968988418579,\n",
       "  0.8779296875,\n",
       "  0.901562511920929,\n",
       "  0.902148425579071,\n",
       "  0.884765625,\n",
       "  0.892773449420929,\n",
       "  0.8558593988418579,\n",
       "  0.8783203363418579,\n",
       "  0.889843761920929,\n",
       "  0.8763672113418579,\n",
       "  0.876757800579071,\n",
       "  0.900585949420929,\n",
       "  0.913281261920929,\n",
       "  0.8935546875,\n",
       "  0.8648437857627869,\n",
       "  0.9253906607627869,\n",
       "  0.8984375,\n",
       "  0.9087890982627869,\n",
       "  0.92578125,\n",
       "  0.8951172232627869,\n",
       "  0.8935546875,\n",
       "  0.8896484375,\n",
       "  0.814453125,\n",
       "  0.8882812857627869,\n",
       "  0.826367199420929,\n",
       "  0.8062500357627869,\n",
       "  0.8330078125,\n",
       "  0.87890625,\n",
       "  0.968945324420929,\n",
       "  0.900585949420929,\n",
       "  0.857421875,\n",
       "  0.8814453482627869,\n",
       "  0.89453125,\n",
       "  0.9359375238418579,\n",
       "  0.892773449420929,\n",
       "  0.946093738079071,\n",
       "  0.903515636920929,\n",
       "  0.8675781488418579,\n",
       "  0.8802734613418579,\n",
       "  0.8902344107627869,\n",
       "  0.8960937857627869,\n",
       "  0.9380859732627869,\n",
       "  0.878125011920929,\n",
       "  0.8363281488418579,\n",
       "  0.880859375,\n",
       "  0.882031261920929,\n",
       "  0.8277344107627869,\n",
       "  0.9154297113418579,\n",
       "  0.872851550579071,\n",
       "  0.860546886920929,\n",
       "  0.783007800579071,\n",
       "  0.84375,\n",
       "  0.8408203125,\n",
       "  0.8041015863418579,\n",
       "  0.8359375,\n",
       "  0.84765625,\n",
       "  0.911914050579071,\n",
       "  0.8154296875,\n",
       "  0.864453136920929,\n",
       "  0.890429675579071,\n",
       "  0.908398449420929,\n",
       "  0.849609375,\n",
       "  0.842578113079071,\n",
       "  0.8539062738418579,\n",
       "  0.8447265625,\n",
       "  0.861132800579071,\n",
       "  0.728515625,\n",
       "  0.8296875357627869,\n",
       "  0.826171875,\n",
       "  0.8359375,\n",
       "  0.7515625357627869,\n",
       "  0.795117199420929,\n",
       "  0.829296886920929,\n",
       "  0.7666015625,\n",
       "  0.736328125,\n",
       "  0.76171875,\n",
       "  0.78515625,\n",
       "  0.644726574420929,\n",
       "  0.7802734375,\n",
       "  0.7392578125,\n",
       "  0.751757800579071,\n",
       "  0.7613281607627869,\n",
       "  0.8013672232627869,\n",
       "  0.864453136920929,\n",
       "  0.776171863079071,\n",
       "  0.843554675579071,\n",
       "  0.8587890863418579,\n",
       "  0.878125011920929,\n",
       "  0.8130859732627869,\n",
       "  0.887499988079071,\n",
       "  0.8564453125,\n",
       "  0.8671875,\n",
       "  0.7955078482627869,\n",
       "  0.7835937738418579,\n",
       "  0.8017578125,\n",
       "  0.750781238079071,\n",
       "  0.7896484732627869,\n",
       "  0.795117199420929,\n",
       "  0.837890625,\n",
       "  0.7568359375,\n",
       "  0.80078125,\n",
       "  0.753710925579071,\n",
       "  0.7666015625,\n",
       "  0.8912109732627869,\n",
       "  0.8076171875,\n",
       "  0.8193359375,\n",
       "  0.8130859732627869,\n",
       "  0.821093738079071,\n",
       "  0.8013672232627869,\n",
       "  0.794921875,\n",
       "  0.7525390982627869,\n",
       "  0.783203125,\n",
       "  0.7828125357627869,\n",
       "  0.7740234732627869,\n",
       "  0.7826172113418579,\n",
       "  0.827929675579071,\n",
       "  0.833203136920929,\n",
       "  0.8056640625,\n",
       "  0.773632824420929,\n",
       "  0.815234363079071,\n",
       "  0.8226562738418579,\n",
       "  0.7935547232627869,\n",
       "  0.740039050579071,\n",
       "  0.85546875,\n",
       "  0.90625,\n",
       "  0.755078136920929,\n",
       "  0.7017578482627869,\n",
       "  0.835742175579071,\n",
       "  0.8212890625,\n",
       "  0.7789062857627869,\n",
       "  0.8158203363418579,\n",
       "  0.7880859375,\n",
       "  0.8121094107627869,\n",
       "  0.8121094107627869,\n",
       "  0.8037109375,\n",
       "  0.7630859613418579,\n",
       "  0.7533203363418579,\n",
       "  0.801562488079071,\n",
       "  0.8246093988418579,\n",
       "  0.7914062738418579,\n",
       "  0.753125011920929,\n",
       "  0.848437488079071,\n",
       "  0.834179699420929,\n",
       "  0.7298828363418579,\n",
       "  0.814648449420929,\n",
       "  0.790820300579071,\n",
       "  0.7943359613418579,\n",
       "  0.8296875357627869,\n",
       "  0.8482422232627869,\n",
       "  0.863476574420929,\n",
       "  0.858203113079071,\n",
       "  0.815234363079071,\n",
       "  0.759765625,\n",
       "  0.8599609732627869,\n",
       "  0.7705078125,\n",
       "  0.7972656488418579,\n",
       "  0.767578125,\n",
       "  0.8050781488418579,\n",
       "  0.775195300579071,\n",
       "  0.7835937738418579,\n",
       "  0.7392578125,\n",
       "  0.752148449420929,\n",
       "  0.7496094107627869,\n",
       "  0.833984375,\n",
       "  0.786328136920929,\n",
       "  0.833789050579071,\n",
       "  0.8900390863418579,\n",
       "  0.881054699420929,\n",
       "  0.837890625,\n",
       "  0.807812511920929,\n",
       "  0.812695324420929,\n",
       "  0.824999988079071,\n",
       "  0.775390625,\n",
       "  0.802929699420929,\n",
       "  0.8333984613418579,\n",
       "  0.838671863079071,\n",
       "  0.7925781607627869,\n",
       "  0.8070312738418579,\n",
       "  0.774218738079071,\n",
       "  0.7210937738418579,\n",
       "  0.701953113079071,\n",
       "  0.809374988079071,\n",
       "  0.7953125238418579,\n",
       "  0.7808594107627869,\n",
       "  0.8013672232627869,\n",
       "  0.7671875357627869,\n",
       "  0.8447265625,\n",
       "  0.8167968988418579,\n",
       "  0.853710949420929,\n",
       "  0.8248047232627869,\n",
       "  0.8500000238418579,\n",
       "  0.842578113079071,\n",
       "  0.857226550579071,\n",
       "  0.8333984613418579,\n",
       "  0.799609363079071,\n",
       "  0.8316406607627869,\n",
       "  0.7837890982627869,\n",
       "  0.8519531488418579,\n",
       "  0.7779297232627869,\n",
       "  0.7806640863418579,\n",
       "  0.730273425579071,\n",
       "  0.740429699420929,\n",
       "  0.763671875,\n",
       "  0.7816406488418579,\n",
       "  0.867968738079071,\n",
       "  0.8304687738418579,\n",
       "  0.8128906488418579,\n",
       "  0.779101550579071,\n",
       "  0.8744140863418579,\n",
       "  0.844921886920929,\n",
       "  0.8587890863418579,\n",
       "  0.867382824420929,\n",
       "  0.8187500238418579,\n",
       "  0.7613281607627869,\n",
       "  0.7662109732627869,\n",
       "  0.791210949420929],\n",
       " 'val_fn': [85.0,\n",
       "  88.0,\n",
       "  85.0,\n",
       "  86.0,\n",
       "  83.0,\n",
       "  86.0,\n",
       "  82.0,\n",
       "  88.0,\n",
       "  82.0,\n",
       "  89.0,\n",
       "  86.0,\n",
       "  84.0,\n",
       "  84.0,\n",
       "  85.0,\n",
       "  87.0,\n",
       "  85.0,\n",
       "  84.0,\n",
       "  82.0,\n",
       "  87.0,\n",
       "  87.0,\n",
       "  87.0,\n",
       "  86.0,\n",
       "  88.0,\n",
       "  61.0,\n",
       "  68.0,\n",
       "  71.0,\n",
       "  60.0,\n",
       "  65.0,\n",
       "  68.0,\n",
       "  67.0,\n",
       "  60.0,\n",
       "  72.0,\n",
       "  58.0,\n",
       "  71.0,\n",
       "  51.0,\n",
       "  57.0,\n",
       "  56.0,\n",
       "  59.0,\n",
       "  59.0,\n",
       "  60.0,\n",
       "  53.0,\n",
       "  61.0,\n",
       "  58.0,\n",
       "  69.0,\n",
       "  66.0,\n",
       "  57.0,\n",
       "  65.0,\n",
       "  55.0,\n",
       "  55.0,\n",
       "  61.0,\n",
       "  55.0,\n",
       "  59.0,\n",
       "  62.0,\n",
       "  66.0,\n",
       "  64.0,\n",
       "  57.0,\n",
       "  66.0,\n",
       "  61.0,\n",
       "  63.0,\n",
       "  64.0,\n",
       "  62.0,\n",
       "  60.0,\n",
       "  56.0,\n",
       "  42.0,\n",
       "  58.0,\n",
       "  48.0,\n",
       "  43.0,\n",
       "  41.0,\n",
       "  61.0,\n",
       "  85.0,\n",
       "  64.0,\n",
       "  50.0,\n",
       "  51.0,\n",
       "  56.0,\n",
       "  70.0,\n",
       "  57.0,\n",
       "  77.0,\n",
       "  55.0,\n",
       "  53.0,\n",
       "  53.0,\n",
       "  57.0,\n",
       "  60.0,\n",
       "  69.0,\n",
       "  54.0,\n",
       "  43.0,\n",
       "  57.0,\n",
       "  55.0,\n",
       "  42.0,\n",
       "  62.0,\n",
       "  54.0,\n",
       "  52.0,\n",
       "  31.0,\n",
       "  43.0,\n",
       "  46.0,\n",
       "  34.0,\n",
       "  36.0,\n",
       "  46.0,\n",
       "  63.0,\n",
       "  28.0,\n",
       "  48.0,\n",
       "  50.0,\n",
       "  60.0,\n",
       "  51.0,\n",
       "  47.0,\n",
       "  50.0,\n",
       "  35.0,\n",
       "  38.0,\n",
       "  26.0,\n",
       "  41.0,\n",
       "  41.0,\n",
       "  37.0,\n",
       "  21.0,\n",
       "  31.0,\n",
       "  36.0,\n",
       "  22.0,\n",
       "  18.0,\n",
       "  20.0,\n",
       "  26.0,\n",
       "  14.0,\n",
       "  27.0,\n",
       "  19.0,\n",
       "  26.0,\n",
       "  27.0,\n",
       "  35.0,\n",
       "  41.0,\n",
       "  28.0,\n",
       "  34.0,\n",
       "  51.0,\n",
       "  53.0,\n",
       "  35.0,\n",
       "  52.0,\n",
       "  49.0,\n",
       "  52.0,\n",
       "  34.0,\n",
       "  22.0,\n",
       "  31.0,\n",
       "  24.0,\n",
       "  27.0,\n",
       "  31.0,\n",
       "  42.0,\n",
       "  25.0,\n",
       "  29.0,\n",
       "  24.0,\n",
       "  26.0,\n",
       "  54.0,\n",
       "  37.0,\n",
       "  33.0,\n",
       "  29.0,\n",
       "  31.0,\n",
       "  34.0,\n",
       "  28.0,\n",
       "  18.0,\n",
       "  20.0,\n",
       "  18.0,\n",
       "  35.0,\n",
       "  31.0,\n",
       "  36.0,\n",
       "  36.0,\n",
       "  25.0,\n",
       "  23.0,\n",
       "  34.0,\n",
       "  30.0,\n",
       "  33.0,\n",
       "  24.0,\n",
       "  42.0,\n",
       "  54.0,\n",
       "  22.0,\n",
       "  15.0,\n",
       "  34.0,\n",
       "  31.0,\n",
       "  30.0,\n",
       "  34.0,\n",
       "  28.0,\n",
       "  33.0,\n",
       "  36.0,\n",
       "  31.0,\n",
       "  19.0,\n",
       "  21.0,\n",
       "  33.0,\n",
       "  35.0,\n",
       "  28.0,\n",
       "  20.0,\n",
       "  42.0,\n",
       "  37.0,\n",
       "  18.0,\n",
       "  33.0,\n",
       "  19.0,\n",
       "  29.0,\n",
       "  34.0,\n",
       "  36.0,\n",
       "  48.0,\n",
       "  41.0,\n",
       "  36.0,\n",
       "  25.0,\n",
       "  41.0,\n",
       "  24.0,\n",
       "  22.0,\n",
       "  21.0,\n",
       "  32.0,\n",
       "  32.0,\n",
       "  27.0,\n",
       "  23.0,\n",
       "  20.0,\n",
       "  14.0,\n",
       "  28.0,\n",
       "  19.0,\n",
       "  36.0,\n",
       "  45.0,\n",
       "  47.0,\n",
       "  37.0,\n",
       "  32.0,\n",
       "  30.0,\n",
       "  32.0,\n",
       "  27.0,\n",
       "  31.0,\n",
       "  32.0,\n",
       "  32.0,\n",
       "  24.0,\n",
       "  27.0,\n",
       "  24.0,\n",
       "  16.0,\n",
       "  10.0,\n",
       "  39.0,\n",
       "  27.0,\n",
       "  29.0,\n",
       "  23.0,\n",
       "  22.0,\n",
       "  34.0,\n",
       "  25.0,\n",
       "  40.0,\n",
       "  35.0,\n",
       "  39.0,\n",
       "  45.0,\n",
       "  45.0,\n",
       "  35.0,\n",
       "  29.0,\n",
       "  33.0,\n",
       "  29.0,\n",
       "  41.0,\n",
       "  31.0,\n",
       "  27.0,\n",
       "  16.0,\n",
       "  16.0,\n",
       "  26.0,\n",
       "  27.0,\n",
       "  40.0,\n",
       "  32.0,\n",
       "  26.0,\n",
       "  25.0,\n",
       "  47.0,\n",
       "  45.0,\n",
       "  45.0,\n",
       "  50.0,\n",
       "  34.0,\n",
       "  20.0,\n",
       "  22.0,\n",
       "  26.0],\n",
       " 'val_tp': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  24.0,\n",
       "  18.0,\n",
       "  14.0,\n",
       "  21.0,\n",
       "  18.0,\n",
       "  17.0,\n",
       "  20.0,\n",
       "  24.0,\n",
       "  10.0,\n",
       "  25.0,\n",
       "  12.0,\n",
       "  36.0,\n",
       "  30.0,\n",
       "  28.0,\n",
       "  26.0,\n",
       "  26.0,\n",
       "  22.0,\n",
       "  27.0,\n",
       "  26.0,\n",
       "  27.0,\n",
       "  16.0,\n",
       "  21.0,\n",
       "  28.0,\n",
       "  22.0,\n",
       "  31.0,\n",
       "  29.0,\n",
       "  25.0,\n",
       "  31.0,\n",
       "  31.0,\n",
       "  25.0,\n",
       "  20.0,\n",
       "  24.0,\n",
       "  31.0,\n",
       "  21.0,\n",
       "  22.0,\n",
       "  24.0,\n",
       "  21.0,\n",
       "  25.0,\n",
       "  27.0,\n",
       "  30.0,\n",
       "  44.0,\n",
       "  27.0,\n",
       "  41.0,\n",
       "  45.0,\n",
       "  45.0,\n",
       "  28.0,\n",
       "  3.0,\n",
       "  22.0,\n",
       "  35.0,\n",
       "  36.0,\n",
       "  30.0,\n",
       "  18.0,\n",
       "  30.0,\n",
       "  12.0,\n",
       "  29.0,\n",
       "  35.0,\n",
       "  33.0,\n",
       "  32.0,\n",
       "  28.0,\n",
       "  17.0,\n",
       "  33.0,\n",
       "  42.0,\n",
       "  32.0,\n",
       "  32.0,\n",
       "  42.0,\n",
       "  24.0,\n",
       "  33.0,\n",
       "  36.0,\n",
       "  54.0,\n",
       "  43.0,\n",
       "  41.0,\n",
       "  53.0,\n",
       "  50.0,\n",
       "  39.0,\n",
       "  23.0,\n",
       "  57.0,\n",
       "  38.0,\n",
       "  35.0,\n",
       "  25.0,\n",
       "  33.0,\n",
       "  37.0,\n",
       "  37.0,\n",
       "  50.0,\n",
       "  48.0,\n",
       "  62.0,\n",
       "  44.0,\n",
       "  48.0,\n",
       "  52.0,\n",
       "  61.0,\n",
       "  57.0,\n",
       "  46.0,\n",
       "  62.0,\n",
       "  67.0,\n",
       "  66.0,\n",
       "  59.0,\n",
       "  74.0,\n",
       "  61.0,\n",
       "  66.0,\n",
       "  60.0,\n",
       "  61.0,\n",
       "  51.0,\n",
       "  45.0,\n",
       "  59.0,\n",
       "  52.0,\n",
       "  36.0,\n",
       "  35.0,\n",
       "  55.0,\n",
       "  34.0,\n",
       "  40.0,\n",
       "  33.0,\n",
       "  51.0,\n",
       "  64.0,\n",
       "  56.0,\n",
       "  62.0,\n",
       "  58.0,\n",
       "  53.0,\n",
       "  44.0,\n",
       "  62.0,\n",
       "  58.0,\n",
       "  64.0,\n",
       "  55.0,\n",
       "  33.0,\n",
       "  50.0,\n",
       "  54.0,\n",
       "  56.0,\n",
       "  55.0,\n",
       "  53.0,\n",
       "  58.0,\n",
       "  69.0,\n",
       "  69.0,\n",
       "  66.0,\n",
       "  51.0,\n",
       "  53.0,\n",
       "  52.0,\n",
       "  47.0,\n",
       "  57.0,\n",
       "  61.0,\n",
       "  54.0,\n",
       "  53.0,\n",
       "  56.0,\n",
       "  62.0,\n",
       "  43.0,\n",
       "  31.0,\n",
       "  62.0,\n",
       "  69.0,\n",
       "  57.0,\n",
       "  55.0,\n",
       "  56.0,\n",
       "  50.0,\n",
       "  55.0,\n",
       "  54.0,\n",
       "  52.0,\n",
       "  54.0,\n",
       "  67.0,\n",
       "  68.0,\n",
       "  49.0,\n",
       "  53.0,\n",
       "  58.0,\n",
       "  69.0,\n",
       "  44.0,\n",
       "  50.0,\n",
       "  62.0,\n",
       "  53.0,\n",
       "  61.0,\n",
       "  59.0,\n",
       "  53.0,\n",
       "  53.0,\n",
       "  39.0,\n",
       "  47.0,\n",
       "  50.0,\n",
       "  61.0,\n",
       "  39.0,\n",
       "  63.0,\n",
       "  67.0,\n",
       "  64.0,\n",
       "  57.0,\n",
       "  52.0,\n",
       "  57.0,\n",
       "  65.0,\n",
       "  64.0,\n",
       "  74.0,\n",
       "  60.0,\n",
       "  66.0,\n",
       "  53.0,\n",
       "  41.0,\n",
       "  39.0,\n",
       "  48.0,\n",
       "  56.0,\n",
       "  53.0,\n",
       "  52.0,\n",
       "  57.0,\n",
       "  58.0,\n",
       "  57.0,\n",
       "  53.0,\n",
       "  62.0,\n",
       "  61.0,\n",
       "  64.0,\n",
       "  69.0,\n",
       "  73.0,\n",
       "  46.0,\n",
       "  59.0,\n",
       "  59.0,\n",
       "  62.0,\n",
       "  62.0,\n",
       "  52.0,\n",
       "  63.0,\n",
       "  47.0,\n",
       "  53.0,\n",
       "  45.0,\n",
       "  41.0,\n",
       "  42.0,\n",
       "  50.0,\n",
       "  58.0,\n",
       "  55.0,\n",
       "  59.0,\n",
       "  40.0,\n",
       "  57.0,\n",
       "  62.0,\n",
       "  72.0,\n",
       "  68.0,\n",
       "  57.0,\n",
       "  55.0,\n",
       "  47.0,\n",
       "  56.0,\n",
       "  60.0,\n",
       "  63.0,\n",
       "  40.0,\n",
       "  44.0,\n",
       "  40.0,\n",
       "  36.0,\n",
       "  54.0,\n",
       "  64.0,\n",
       "  64.0,\n",
       "  58.0],\n",
       " 'val_loss': [0.10388150066137314,\n",
       "  0.106190025806427,\n",
       "  0.10386548191308975,\n",
       "  0.10463198274374008,\n",
       "  0.10231689363718033,\n",
       "  0.10463573038578033,\n",
       "  0.10155647248029709,\n",
       "  0.10623849928379059,\n",
       "  0.10164827108383179,\n",
       "  0.10717203468084335,\n",
       "  0.10480041801929474,\n",
       "  0.10322438925504684,\n",
       "  0.10322275012731552,\n",
       "  0.10398705303668976,\n",
       "  0.10559972375631332,\n",
       "  0.10411164909601212,\n",
       "  0.10102538019418716,\n",
       "  0.09851720929145813,\n",
       "  0.10713968425989151,\n",
       "  0.13051623106002808,\n",
       "  0.1272057145833969,\n",
       "  0.13126689195632935,\n",
       "  0.12519003450870514,\n",
       "  0.1829054206609726,\n",
       "  0.17416876554489136,\n",
       "  0.15757830440998077,\n",
       "  0.16476546227931976,\n",
       "  0.1677233725786209,\n",
       "  0.16857650876045227,\n",
       "  0.1596868634223938,\n",
       "  0.1745588779449463,\n",
       "  0.14399532973766327,\n",
       "  0.19907864928245544,\n",
       "  0.16349287331104279,\n",
       "  0.3461475968360901,\n",
       "  0.2675631046295166,\n",
       "  0.2914705276489258,\n",
       "  0.2616289556026459,\n",
       "  0.20505057275295258,\n",
       "  0.20637953281402588,\n",
       "  0.1945563405752182,\n",
       "  0.22383235394954681,\n",
       "  0.20459353923797607,\n",
       "  0.20462973415851593,\n",
       "  0.21748995780944824,\n",
       "  0.2230585813522339,\n",
       "  0.20130042731761932,\n",
       "  0.28319960832595825,\n",
       "  0.2734088599681854,\n",
       "  0.2297237366437912,\n",
       "  0.255241334438324,\n",
       "  0.2568265497684479,\n",
       "  0.22183012962341309,\n",
       "  0.20554141700267792,\n",
       "  0.2165520042181015,\n",
       "  0.23887191712856293,\n",
       "  0.16196419298648834,\n",
       "  0.17812800407409668,\n",
       "  0.17019112408161163,\n",
       "  0.16322742402553558,\n",
       "  0.20447973906993866,\n",
       "  0.21410183608531952,\n",
       "  0.22261743247509003,\n",
       "  0.3318914473056793,\n",
       "  0.24208132922649384,\n",
       "  0.3542688488960266,\n",
       "  0.3680698573589325,\n",
       "  0.2689673602581024,\n",
       "  0.20865784585475922,\n",
       "  0.16291724145412445,\n",
       "  0.17768974602222443,\n",
       "  0.25312894582748413,\n",
       "  0.25490742921829224,\n",
       "  0.1959804743528366,\n",
       "  0.16349199414253235,\n",
       "  0.18483968079090118,\n",
       "  0.17327408492565155,\n",
       "  0.18573182821273804,\n",
       "  0.27185454964637756,\n",
       "  0.2410961389541626,\n",
       "  0.24211852252483368,\n",
       "  0.20688393712043762,\n",
       "  0.19634181261062622,\n",
       "  0.19965365529060364,\n",
       "  0.24403250217437744,\n",
       "  0.22280429303646088,\n",
       "  0.22070948779582977,\n",
       "  0.2806776463985443,\n",
       "  0.17157642543315887,\n",
       "  0.21531803905963898,\n",
       "  0.2338789701461792,\n",
       "  0.36216700077056885,\n",
       "  0.30695340037345886,\n",
       "  0.28046324849128723,\n",
       "  0.3411249816417694,\n",
       "  0.3048396408557892,\n",
       "  0.27255770564079285,\n",
       "  0.2161487191915512,\n",
       "  0.31539058685302734,\n",
       "  0.2309493124485016,\n",
       "  0.2071578949689865,\n",
       "  0.19062793254852295,\n",
       "  0.24039721488952637,\n",
       "  0.26826348900794983,\n",
       "  0.2530910074710846,\n",
       "  0.2788582742214203,\n",
       "  0.24906499683856964,\n",
       "  0.4191812574863434,\n",
       "  0.30490466952323914,\n",
       "  0.29889121651649475,\n",
       "  0.2853699326515198,\n",
       "  0.43654361367225647,\n",
       "  0.33643460273742676,\n",
       "  0.3367187976837158,\n",
       "  0.4061347544193268,\n",
       "  0.46657681465148926,\n",
       "  0.4578606188297272,\n",
       "  0.411348819732666,\n",
       "  0.6777030229568481,\n",
       "  0.4145532250404358,\n",
       "  0.4766537845134735,\n",
       "  0.4075702130794525,\n",
       "  0.40969735383987427,\n",
       "  0.3188484311103821,\n",
       "  0.24470730125904083,\n",
       "  0.33574244379997253,\n",
       "  0.2702181339263916,\n",
       "  0.25323382019996643,\n",
       "  0.23499229550361633,\n",
       "  0.30925434827804565,\n",
       "  0.2246004194021225,\n",
       "  0.24609480798244476,\n",
       "  0.23251429200172424,\n",
       "  0.33145982027053833,\n",
       "  0.40620484948158264,\n",
       "  0.33739763498306274,\n",
       "  0.4055802822113037,\n",
       "  0.3511417508125305,\n",
       "  0.3332745134830475,\n",
       "  0.2901673913002014,\n",
       "  0.38875943422317505,\n",
       "  0.36102986335754395,\n",
       "  0.37693271040916443,\n",
       "  0.402508407831192,\n",
       "  0.24254170060157776,\n",
       "  0.310722291469574,\n",
       "  0.29607805609703064,\n",
       "  0.3201495110988617,\n",
       "  0.3115329444408417,\n",
       "  0.33146369457244873,\n",
       "  0.32756486535072327,\n",
       "  0.4262276589870453,\n",
       "  0.35351550579071045,\n",
       "  0.3392984867095947,\n",
       "  0.38301917910575867,\n",
       "  0.3961385190486908,\n",
       "  0.31622663140296936,\n",
       "  0.30807891488075256,\n",
       "  0.36723634600639343,\n",
       "  0.38782429695129395,\n",
       "  0.3110087215900421,\n",
       "  0.31126585602760315,\n",
       "  0.3643505573272705,\n",
       "  0.4449656903743744,\n",
       "  0.29326626658439636,\n",
       "  0.21157164871692657,\n",
       "  0.3921561539173126,\n",
       "  0.4636133313179016,\n",
       "  0.2838149964809418,\n",
       "  0.302920401096344,\n",
       "  0.38676711916923523,\n",
       "  0.3250509202480316,\n",
       "  0.37397462129592896,\n",
       "  0.3413448929786682,\n",
       "  0.34416040778160095,\n",
       "  0.35341134667396545,\n",
       "  0.413065642118454,\n",
       "  0.436967670917511,\n",
       "  0.3568854331970215,\n",
       "  0.321287602186203,\n",
       "  0.3860146105289459,\n",
       "  0.4120974540710449,\n",
       "  0.31493955850601196,\n",
       "  0.31247153878211975,\n",
       "  0.44935330748558044,\n",
       "  0.309174120426178,\n",
       "  0.3881169259548187,\n",
       "  0.3430008888244629,\n",
       "  0.29317885637283325,\n",
       "  0.2648036479949951,\n",
       "  0.2506319582462311,\n",
       "  0.2737068831920624,\n",
       "  0.33827024698257446,\n",
       "  0.37547802925109863,\n",
       "  0.27999168634414673,\n",
       "  0.3942720293998718,\n",
       "  0.3391655683517456,\n",
       "  0.3951771855354309,\n",
       "  0.34713777899742126,\n",
       "  0.4045267105102539,\n",
       "  0.3861413598060608,\n",
       "  0.4619092047214508,\n",
       "  0.42937514185905457,\n",
       "  0.4425029754638672,\n",
       "  0.3118916451931,\n",
       "  0.4060364365577698,\n",
       "  0.31838104128837585,\n",
       "  0.24168053269386292,\n",
       "  0.2456149309873581,\n",
       "  0.2809576988220215,\n",
       "  0.3435905873775482,\n",
       "  0.3274199962615967,\n",
       "  0.33457276225090027,\n",
       "  0.3974129855632782,\n",
       "  0.3444373309612274,\n",
       "  0.3205944299697876,\n",
       "  0.31141072511672974,\n",
       "  0.37713369727134705,\n",
       "  0.36815688014030457,\n",
       "  0.4039726257324219,\n",
       "  0.502787172794342,\n",
       "  0.4884830415248871,\n",
       "  0.3142114281654358,\n",
       "  0.34323278069496155,\n",
       "  0.36012735962867737,\n",
       "  0.3483630120754242,\n",
       "  0.36766573786735535,\n",
       "  0.2825094759464264,\n",
       "  0.33962538838386536,\n",
       "  0.27131161093711853,\n",
       "  0.30851975083351135,\n",
       "  0.2644076943397522,\n",
       "  0.28457948565483093,\n",
       "  0.2709447741508484,\n",
       "  0.30744704604148865,\n",
       "  0.34138724207878113,\n",
       "  0.3106178343296051,\n",
       "  0.36704906821250916,\n",
       "  0.3086042106151581,\n",
       "  0.37640711665153503,\n",
       "  0.38659796118736267,\n",
       "  0.45104748010635376,\n",
       "  0.45972156524658203,\n",
       "  0.40683871507644653,\n",
       "  0.3733786940574646,\n",
       "  0.2769906222820282,\n",
       "  0.31221750378608704,\n",
       "  0.32519635558128357,\n",
       "  0.37045198678970337,\n",
       "  0.24135804176330566,\n",
       "  0.2894272208213806,\n",
       "  0.23438625037670135,\n",
       "  0.2628917396068573,\n",
       "  0.32006746530532837,\n",
       "  0.39152082800865173,\n",
       "  0.4004031717777252,\n",
       "  0.375581830739975],\n",
       " 'val_auc': [0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.4999999701976776,\n",
       "  0.5,\n",
       "  0.4999999701976776,\n",
       "  0.5,\n",
       "  0.4999999701976776,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.6163846850395203,\n",
       "  0.683110773563385,\n",
       "  0.7497138977050781,\n",
       "  0.6568464040756226,\n",
       "  0.7073531150817871,\n",
       "  0.7081933617591858,\n",
       "  0.7490479946136475,\n",
       "  0.7599126100540161,\n",
       "  0.7363093495368958,\n",
       "  0.7373735904693604,\n",
       "  0.7483039498329163,\n",
       "  0.7293917536735535,\n",
       "  0.7083850502967834,\n",
       "  0.7559669017791748,\n",
       "  0.7678120732307434,\n",
       "  0.7437631487846375,\n",
       "  0.7530922889709473,\n",
       "  0.7388555407524109,\n",
       "  0.767431378364563,\n",
       "  0.746537446975708,\n",
       "  0.7480236291885376,\n",
       "  0.7632560133934021,\n",
       "  0.7611566185951233,\n",
       "  0.7447106242179871,\n",
       "  0.7934225797653198,\n",
       "  0.7393730282783508,\n",
       "  0.7621657848358154,\n",
       "  0.6801016926765442,\n",
       "  0.7504300475120544,\n",
       "  0.7874720692634583,\n",
       "  0.7435498833656311,\n",
       "  0.7773557305335999,\n",
       "  0.7400321364402771,\n",
       "  0.7394325733184814,\n",
       "  0.789295494556427,\n",
       "  0.782981276512146,\n",
       "  0.7514064311981201,\n",
       "  0.7606382369995117,\n",
       "  0.7925742268562317,\n",
       "  0.8077859282493591,\n",
       "  0.775908887386322,\n",
       "  0.761898934841156,\n",
       "  0.7791781425476074,\n",
       "  0.7473053336143494,\n",
       "  0.7660463452339172,\n",
       "  0.7695245146751404,\n",
       "  0.7586632966995239,\n",
       "  0.7944859862327576,\n",
       "  0.7474533915519714,\n",
       "  0.7942989468574524,\n",
       "  0.7882776856422424,\n",
       "  0.7865442633628845,\n",
       "  0.7727404832839966,\n",
       "  0.7626192569732666,\n",
       "  0.785189688205719,\n",
       "  0.7732170820236206,\n",
       "  0.7985498905181885,\n",
       "  0.8002418875694275,\n",
       "  0.7782535552978516,\n",
       "  0.8035598397254944,\n",
       "  0.8115283250808716,\n",
       "  0.8015279173851013,\n",
       "  0.7668866515159607,\n",
       "  0.7750471830368042,\n",
       "  0.73757004737854,\n",
       "  0.7973902225494385,\n",
       "  0.7814454436302185,\n",
       "  0.8013445138931274,\n",
       "  0.8030468821525574,\n",
       "  0.7979536652565002,\n",
       "  0.7770100235939026,\n",
       "  0.8159334659576416,\n",
       "  0.7921262383460999,\n",
       "  0.7958290576934814,\n",
       "  0.7783775329589844,\n",
       "  0.8077269792556763,\n",
       "  0.7872974872589111,\n",
       "  0.7934115529060364,\n",
       "  0.8143644332885742,\n",
       "  0.8077952265739441,\n",
       "  0.7863907814025879,\n",
       "  0.805808961391449,\n",
       "  0.835502028465271,\n",
       "  0.8116631507873535,\n",
       "  0.8054779767990112,\n",
       "  0.7947438955307007,\n",
       "  0.8074069023132324,\n",
       "  0.7828420400619507,\n",
       "  0.7923340201377869,\n",
       "  0.8163573741912842,\n",
       "  0.8165289163589478,\n",
       "  0.7863909006118774,\n",
       "  0.8088465332984924,\n",
       "  0.8183121681213379,\n",
       "  0.8202102184295654,\n",
       "  0.814102828502655,\n",
       "  0.8196982741355896,\n",
       "  0.8213371634483337,\n",
       "  0.824287474155426,\n",
       "  0.8255981802940369,\n",
       "  0.8246724605560303,\n",
       "  0.8248099088668823,\n",
       "  0.7836340069770813,\n",
       "  0.8152256011962891,\n",
       "  0.8198994994163513,\n",
       "  0.8280238509178162,\n",
       "  0.8115887641906738,\n",
       "  0.8118121027946472,\n",
       "  0.8280666470527649,\n",
       "  0.8154342770576477,\n",
       "  0.8399556875228882,\n",
       "  0.8169245719909668,\n",
       "  0.8104764819145203,\n",
       "  0.8149160146713257,\n",
       "  0.8220402598381042,\n",
       "  0.7977170944213867,\n",
       "  0.8093241453170776,\n",
       "  0.8095812201499939,\n",
       "  0.827036440372467,\n",
       "  0.8258342146873474,\n",
       "  0.8133944272994995,\n",
       "  0.8231040239334106,\n",
       "  0.821189820766449,\n",
       "  0.8149965405464172,\n",
       "  0.8315953016281128,\n",
       "  0.816845715045929,\n",
       "  0.8353683948516846,\n",
       "  0.8108567595481873,\n",
       "  0.8218139410018921,\n",
       "  0.8100982904434204,\n",
       "  0.8384329676628113,\n",
       "  0.8433601260185242,\n",
       "  0.8408727645874023,\n",
       "  0.813194990158081,\n",
       "  0.839206337928772,\n",
       "  0.8358924388885498,\n",
       "  0.8549677729606628,\n",
       "  0.847059428691864,\n",
       "  0.8040984272956848,\n",
       "  0.7923060655593872,\n",
       "  0.8138572573661804,\n",
       "  0.8102344870567322,\n",
       "  0.8366812467575073,\n",
       "  0.8310178518295288,\n",
       "  0.8371275067329407,\n",
       "  0.8398358821868896,\n",
       "  0.8243566155433655,\n",
       "  0.8203669190406799,\n",
       "  0.8181071877479553,\n",
       "  0.7744397521018982,\n",
       "  0.8368839025497437,\n",
       "  0.8281148076057434,\n",
       "  0.8325961232185364,\n",
       "  0.8510246872901917,\n",
       "  0.8335598707199097,\n",
       "  0.8393871784210205,\n",
       "  0.8385307788848877,\n",
       "  0.8190926909446716,\n",
       "  0.8302972912788391,\n",
       "  0.8282237648963928,\n",
       "  0.8450203537940979,\n",
       "  0.8372316956520081,\n",
       "  0.8196959495544434,\n",
       "  0.8331665992736816,\n",
       "  0.8315721154212952,\n",
       "  0.8289480209350586,\n",
       "  0.8330698609352112,\n",
       "  0.8249624371528625,\n",
       "  0.8077577352523804,\n",
       "  0.8217447996139526,\n",
       "  0.849708616733551,\n",
       "  0.8301630020141602,\n",
       "  0.8385335206985474,\n",
       "  0.8338012099266052,\n",
       "  0.8326902985572815,\n",
       "  0.8367213010787964,\n",
       "  0.8140159845352173,\n",
       "  0.8265356421470642,\n",
       "  0.8278471827507019,\n",
       "  0.8369452953338623,\n",
       "  0.8643401265144348,\n",
       "  0.8436299562454224,\n",
       "  0.8344791531562805,\n",
       "  0.8053715229034424,\n",
       "  0.8225858211517334,\n",
       "  0.8177526593208313,\n",
       "  0.8358200788497925,\n",
       "  0.8424018025398254,\n",
       "  0.8440322875976562,\n",
       "  0.8473206162452698,\n",
       "  0.8247985243797302,\n",
       "  0.8299678564071655,\n",
       "  0.7981353998184204,\n",
       "  0.8302564024925232,\n",
       "  0.8292765617370605,\n",
       "  0.832892119884491,\n",
       "  0.8316914439201355,\n",
       "  0.8070288896560669,\n",
       "  0.8249193429946899,\n",
       "  0.8473674654960632,\n",
       "  0.8431193232536316,\n",
       "  0.8429644703865051,\n",
       "  0.8364080786705017,\n",
       "  0.8346683979034424,\n",
       "  0.834857165813446,\n",
       "  0.8218231201171875,\n",
       "  0.8095508217811584,\n",
       "  0.8328713774681091,\n",
       "  0.8384021520614624,\n",
       "  0.8509432077407837,\n",
       "  0.8412051200866699,\n",
       "  0.840581476688385,\n",
       "  0.8358989953994751,\n",
       "  0.8384432792663574,\n",
       "  0.8319279551506042,\n",
       "  0.8269633054733276,\n",
       "  0.788905143737793,\n",
       "  0.8132122159004211,\n",
       "  0.8185873627662659,\n",
       "  0.8400716185569763,\n",
       "  0.8337267637252808,\n",
       "  0.8295590877532959,\n",
       "  0.8025032877922058,\n",
       "  0.8251609206199646,\n",
       "  0.8248388171195984,\n",
       "  0.8298345804214478,\n",
       "  0.8308925628662109,\n",
       "  0.8211859464645386,\n",
       "  0.835900604724884,\n",
       "  0.84329754114151,\n",
       "  0.8423089981079102,\n",
       "  0.8434666991233826,\n",
       "  0.8424222469329834,\n",
       "  0.7851787209510803,\n",
       "  0.8126335144042969,\n",
       "  0.8295321464538574,\n",
       "  0.8188686370849609,\n",
       "  0.8305333852767944,\n",
       "  0.8371381163597107,\n",
       "  0.8482334613800049,\n",
       "  0.8248962759971619]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-10T07:27:21.261282Z",
     "iopub.status.busy": "2020-08-10T07:27:21.257010Z",
     "iopub.status.idle": "2020-08-10T07:27:22.506785Z",
     "shell.execute_reply": "2020-08-10T07:27:22.505913Z"
    },
    "papermill": {
     "duration": 1.91359,
     "end_time": "2020-08-10T07:27:22.506968",
     "exception": false,
     "start_time": "2020-08-10T07:27:20.593378",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.558212,
     "end_time": "2020-08-10T07:27:29.270852",
     "exception": false,
     "start_time": "2020-08-10T07:27:28.712640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "duration": 7110.3586,
   "end_time": "2020-08-10T07:27:30.001979",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-10T05:28:59.643379",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
