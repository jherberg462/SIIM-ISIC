{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "try:\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "    dataset_gcs = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n",
    "except ModuleNotFoundError:\n",
    "    #hardcode path while testing locally\n",
    "    dataset_gcs = 'gs://kds-599205fd0d8963558ce1308147ba090f776d31b1662a67f2ddccfa38'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size' : 128,\n",
    "    'img_size' : [256, 256],\n",
    "    'epochs': 1\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_0052060</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  target\n",
       "0  ISIC_0052060       0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.read_csv(dataset_gcs + '/sample_submission.csv')\n",
    "sub.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32542</td>\n",
       "      <td>32542</td>\n",
       "      <td>32477</td>\n",
       "      <td>32474</td>\n",
       "      <td>32024</td>\n",
       "      <td>32542</td>\n",
       "      <td>32542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>575</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name  patient_id    sex  age_approx  \\\n",
       "target                                              \n",
       "0            32542       32542  32477       32474   \n",
       "1              584         584    584         584   \n",
       "\n",
       "        anatom_site_general_challenge  diagnosis  benign_malignant  \n",
       "target                                                              \n",
       "0                               32024      32542             32542  \n",
       "1                                 575        584               584  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(dataset_gcs + '/train.csv')\n",
    "train_df.groupby('target').count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image_label(tfrec):\n",
    "    '''\n",
    "    function to decode an image and target label from tfrecord\n",
    "    \n",
    "    args:\n",
    "        tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "    returns:\n",
    "        decoded_image: tensor, converted image from tfrecord\n",
    "        label: tensor, integer, either 1 or 0\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "    decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "    decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "    label = features['target']\n",
    "    \n",
    "    return decoded_image, label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(tfrec):\n",
    "    '''\n",
    "    function to decode an image from tfrecord\n",
    "    \n",
    "    args:\n",
    "        tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "    returns:\n",
    "        decoded_image: tensor, converted image from tfrecord\n",
    "        img_name: tensor, string, Id of the decoded image\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "    features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "    decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "    decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "    img_name = features['image_name']\n",
    "    \n",
    "    return decoded_image, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image_label(decoded_image, label):\n",
    "    '''\n",
    "    function to convert an image tensor values from 0 to 255 \n",
    "    -> -1 to 1\n",
    "    to be used when dealing with tfrecords containing labels\n",
    "    \n",
    "    args:\n",
    "        decoded_image: tensor that is an image with values from 0 to 255\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image_tensor: tensor that is an image with values from -1 to 1\n",
    "        label, same as input\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "    image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "    #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "    image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "    #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "    image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "    return image_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(decoded_image):\n",
    "    '''\n",
    "    function to convert an image tensor values from 0 to 255 \n",
    "    -> -1 to 1\n",
    "    \n",
    "    args:\n",
    "        decoded_image: tensor that is an image with values from 0 to 255\n",
    "    \n",
    "    returns: \n",
    "        image_tensor: tensor that is an image with values from -1 to 1\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "    image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "    #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "    image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "    #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "    image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_flip(image, label):\n",
    "    '''\n",
    "    function to randomly flip images on the x and/or y axis\n",
    "    \n",
    "    args:\n",
    "        image: tensor, an image\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image: tensor, same as input, but possibly flipped on x and/or y axis\n",
    "        label, tensor, same as input\n",
    "    '''\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image, label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_ds(tfrecords, batch_size):\n",
    "    '''\n",
    "    function to create a ds pipeline from tfrecord files\n",
    "    \n",
    "    args:\n",
    "        tfrecords: list, tfrecord file paths\n",
    "        batch_size: int, batch size for number of records to pass into\n",
    "            model at a time\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images and labels\n",
    "    '''\n",
    "    ds = (tf.data.TFRecordDataset(filenames=[tfrecords]).\n",
    "          cache().\n",
    "          map(decode_image_label).\n",
    "          map(normalize_image_label).\n",
    "          map(random_flip).\n",
    "          repeat().\n",
    "          shuffle(256).\n",
    "          batch(batch_size,\n",
    "               drop_remainder=True).\n",
    "          prefetch(tf.data.experimental.AUTOTUNE)\n",
    "         )\n",
    "    \n",
    "\n",
    "    \n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_ds(tfrecords, batch_size):\n",
    "    '''\n",
    "    function to create a dataset for test data\n",
    "    args:\n",
    "        tfrecords: list, tfrecord file paths\n",
    "        batch_size: int, batch size for number of records to pass into\n",
    "            model at a time\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images and labels\n",
    "    \n",
    "    '''\n",
    "\n",
    "    ds = (tf.data.TFRecordDataset(filenames=[tfrecords]).\n",
    "          cache().\n",
    "          map(decode_image).\n",
    "          map(normalize_image_label).\n",
    "#           map(random_flip).\n",
    "          batch(batch_size).\n",
    "#                 drop_remainder=True).\n",
    "          prefetch(tf.data.experimental.AUTOTUNE)\n",
    "         )\n",
    "    \n",
    "    return ds\n",
    "    ###come back to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_of_layers(model_, filters_, kernal, strides_, dropout=0):\n",
    "    '''\n",
    "    function to add the following layers to a model:\n",
    "    Conv2D, MaxPooling2D, BatchNormalization, LeadyReLU, Dropout\n",
    "\n",
    "    args:\n",
    "      model_ : tf.keras.Sequential model\n",
    "      filters_: int, number of filters in Conv2D layer\n",
    "      kernal: int, kernal size in Conv2D layer\n",
    "      strides_: int, stride size in MaxPooling2D layer\n",
    "      dropout: float, dropout percentage in Dropout layer, default is 0.0\n",
    "        must be less than 1.0\n",
    "\n",
    "    returns:\n",
    "      model_: tf.keras.Sequential model that is the same as the model_ input plus above \n",
    "        layers added\n",
    "    '''\n",
    "    model_.add(layers.Conv2D(filters_, (kernal, kernal), padding='same'))\n",
    "    model_.add(layers.MaxPooling2D(strides_, strides_))\n",
    "    model_.add(layers.BatchNormalization())\n",
    "    model_.add(layers.LeakyReLU())\n",
    "#     model_.add(layers.Dropout(dropout)) #hold off on this for now\n",
    "\n",
    "    return model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 256, 256, 32)      2432      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128, 128, 32)      128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 128, 128, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 128, 128, 64)      51264     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 64, 64, 64)        256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 64, 64, 128)       204928    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 128)       512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 256)       819456    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 256)       1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 512)       3277312   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 8, 8, 512)         2048      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               16777728  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 21,137,601\n",
      "Trainable params: 21,135,617\n",
      "Non-trainable params: 1,984\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_model(input_shape=[*params['img_size'], 3], bias_output=None):\n",
    "    '''\n",
    "    function to create a model that will be trained on train DS\n",
    "    \n",
    "    args:\n",
    "        input_shape: array, default: [1024, 1024, 3], shape\n",
    "            of input tensor that will be fed into model\n",
    "    \n",
    "    returns:\n",
    "        model: tf.sequential() model\n",
    "    '''\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(layers.Conv2D(32, (5, 5), padding='same',\n",
    "                                     input_shape=input_shape)) \n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    \n",
    "    set_of_layers(model, 64, 5, 2)\n",
    "    set_of_layers(model, 128, 5, 2)\n",
    "    set_of_layers(model, 256, 5, 2)\n",
    "    set_of_layers(model, 512, 5, 2)\n",
    "\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512))\n",
    "    \n",
    "    if bias_output is not None:\n",
    "        bias_output = tf.keras.initializers.Constant(bias_output)\n",
    "    model.add(layers.Dense(1, activation='sigmoid', bias_initializer=bias_output))\n",
    "    \n",
    "\n",
    "    metrics = [\n",
    "          keras.metrics.TruePositives(name='tp'),\n",
    "          keras.metrics.FalsePositives(name='fp'),\n",
    "          keras.metrics.TrueNegatives(name='tn'),\n",
    "          keras.metrics.FalseNegatives(name='fn'), \n",
    "          keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "          keras.metrics.Precision(name='precision'),\n",
    "          keras.metrics.Recall(name='recall'),\n",
    "          keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "    \n",
    "    model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.01),\n",
    "    metrics=metrics\n",
    ")\n",
    "    \n",
    "\n",
    "    \n",
    "    return model\n",
    "\n",
    "create_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_size(files):\n",
    "    '''\n",
    "    function to get size of tfrecord Dataset, based on file name\n",
    "    \n",
    "    the file name has the number of records in the file, for example:\n",
    "    train09-2071.tfrec has 2017 records\n",
    "    \n",
    "    args:\n",
    "        files: list of str file names, each item should be the path to a tfrecord file\n",
    "    \n",
    "    returns:\n",
    "        size: int, size of dataset\n",
    "    '''\n",
    "    size = 0\n",
    "    for file in files:\n",
    "        file_size = int(file.split('.tfrec')[0].split('tfrecords/')[1].split('-')[1])\n",
    "        size += file_size\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get test file paths\n",
    "test_files = tf.io.gfile.glob(dataset_gcs + '/tfrecords/test*.tfrec')\n",
    "\n",
    "#get train and validation file paths\n",
    "train_files, valid_files = train_test_split(tf.io.gfile.glob(dataset_gcs + '/tfrecords/train*.tfrec'),\n",
    "                              test_size=.1, random_state=1)\n",
    "\n",
    "#create datasets\n",
    "train_ds = get_train_ds(train_files, params['batch_size'])\n",
    "valid_ds = get_train_ds(valid_files, params['batch_size'])\n",
    "test_ds = get_test_ds(test_files, params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset consists of: 28984 training images, 4142 validation images, and 10982 test images\n"
     ]
    }
   ],
   "source": [
    "train_size, valid_size = get_ds_size(train_files), get_ds_size(valid_files)\n",
    "test_size = get_ds_size(test_files)\n",
    "print('the dataset consists of: {} training images, {} validation images, and {} test images'.\n",
    "     format(train_size, valid_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_steps = train_size / params['batch_size'] \n",
    "valid_steps = valid_size / params['batch_size']\n",
    "test_steps = 1.0 * test_size / params['batch_size'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate class weights\n",
    "\n",
    "targets = train_df.groupby('target').count()['diagnosis'].to_list()\n",
    "target_0 = targets[0]\n",
    "target_1 = targets[1]\n",
    "total = target_0 + target_1\n",
    "\n",
    "class_weight_0 = (1 / target_0) * (total) / 2.0\n",
    "class_weight_1 = (1 / target_1) * (total) / 2.0\n",
    "\n",
    "class_weights = {0: class_weight_0, 1: class_weight_1}\n",
    "\n",
    "initial_bias = np.log([target_1 / target_0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model(bias_output=initial_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227/226 [==============================] - 391s 2s/step - precision: 0.0295 - fp: 10292.0000 - tp: 313.0000 - recall: 0.6089 - loss: 11.4086 - fn: 201.0000 - tn: 18250.0000 - auc: 0.6390 - accuracy: 0.6389 - val_precision: 0.0392 - val_fp: 908.0000 - val_tp: 37.0000 - val_recall: 0.5211 - val_loss: 0.4514 - val_fn: 34.0000 - val_tn: 3245.0000 - val_auc: 0.6519 - val_accuracy: 0.7770\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "#     batch_size=params['batch_size'],\n",
    "    epochs= params['epochs'], \n",
    "    steps_per_epoch=epoch_steps,\n",
    "    validation_data=valid_ds,\n",
    "    validation_steps=valid_steps,\n",
    "    class_weight=class_weights\n",
    ")\n",
    "\n",
    "#512 by 512\n",
    "#epoch 1 - 0.6188, val: 0.6841\n",
    "#epoch 2 - 0.7050, val: 0.7479\n",
    "\n",
    "#256 by 256\n",
    "#epoch 1 - 0.6140, val: 0.6548\n",
    "#epoch 2 - 0.7331, val: 0.6452"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_ds.map(lambda img, igs: img), steps=test_steps)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7f14511ca320> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "                          map(lambda img, ids:ids).\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction_ids = next(iter(test_ds.\n",
    "                          map(lambda img, ids:ids).\n",
    "                          unbatch().\n",
    "                          batch(test_size))).numpy().astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dict = {\n",
    "    'image_name': prediction_ids,\n",
    "    'target': np.concatenate(predictions)\n",
    "}\n",
    "submission_ds = pd.DataFrame(prediction_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6381819</td>\n",
       "      <td>0.749437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_5714684</td>\n",
       "      <td>0.495146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_7198276</td>\n",
       "      <td>0.002747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_4160979</td>\n",
       "      <td>0.330793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_9652852</td>\n",
       "      <td>0.339744</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name    target\n",
       "0  ISIC_6381819  0.749437\n",
       "1  ISIC_5714684  0.495146\n",
       "2  ISIC_7198276  0.002747\n",
       "3  ISIC_4160979  0.330793\n",
       "4  ISIC_9652852  0.339744"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ds.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(metric1, metric2, ylabel):\n",
    "    plt.plot(history.history[metric1], label=metric1)\n",
    "    plt.plot(history.history[metric2], label=metric2)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('auc', 'val_auc', 'auc')\n",
    "plot_metric('loss', 'val_loss', 'loss')\n",
    "plot_metric('accuracy', 'val_accuracy', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': [0.029514379799365997],\n",
       " 'fp': [10292.0],\n",
       " 'tp': [313.0],\n",
       " 'recall': [0.6089494228363037],\n",
       " 'loss': [11.408554077148438],\n",
       " 'fn': [201.0],\n",
       " 'tn': [18250.0],\n",
       " 'auc': [0.6389554738998413],\n",
       " 'accuracy': [0.6388697624206543],\n",
       " 'val_precision': [0.039153438061475754],\n",
       " 'val_fp': [908.0],\n",
       " 'val_tp': [37.0],\n",
       " 'val_recall': [0.5211268067359924],\n",
       " 'val_loss': [0.45137396454811096],\n",
       " 'val_fn': [34.0],\n",
       " 'val_tn': [3245.0],\n",
       " 'val_auc': [0.6518738865852356],\n",
       " 'val_accuracy': [0.7769886255264282]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
