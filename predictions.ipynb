{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:04.555668Z",
     "iopub.status.busy": "2020-08-08T18:09:04.554798Z",
     "iopub.status.idle": "2020-08-08T18:09:12.904884Z",
     "shell.execute_reply": "2020-08-08T18:09:12.904171Z"
    },
    "papermill": {
     "duration": 8.378519,
     "end_time": "2020-08-08T18:09:12.905068",
     "exception": false,
     "start_time": "2020-08-08T18:09:04.526549",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got GCS path via KaggleDatasets .get_gcs_path method\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "try:\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "    dataset_gcs = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n",
    "    print('got GCS path via KaggleDatasets .get_gcs_path method')\n",
    "except ModuleNotFoundError:\n",
    "    #hardcode path while testing locally\n",
    "    dataset_gcs = 'gs://'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:12.952384Z",
     "iopub.status.busy": "2020-08-08T18:09:12.951310Z",
     "iopub.status.idle": "2020-08-08T18:09:12.956220Z",
     "shell.execute_reply": "2020-08-08T18:09:12.955524Z"
    },
    "papermill": {
     "duration": 0.03032,
     "end_time": "2020-08-08T18:09:12.956350",
     "exception": false,
     "start_time": "2020-08-08T18:09:12.926030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:13.001476Z",
     "iopub.status.busy": "2020-08-08T18:09:13.000659Z",
     "iopub.status.idle": "2020-08-08T18:09:13.004574Z",
     "shell.execute_reply": "2020-08-08T18:09:13.003844Z"
    },
    "papermill": {
     "duration": 0.028472,
     "end_time": "2020-08-08T18:09:13.004705",
     "exception": false,
     "start_time": "2020-08-08T18:09:12.976233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size' : 128,\n",
    "    'img_size' : [256, 256],\n",
    "    'epochs': 350\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:13.140051Z",
     "iopub.status.busy": "2020-08-08T18:09:13.061541Z",
     "iopub.status.idle": "2020-08-08T18:09:17.441579Z",
     "shell.execute_reply": "2020-08-08T18:09:17.442251Z"
    },
    "papermill": {
     "duration": 4.418045,
     "end_time": "2020-08-08T18:09:17.442417",
     "exception": false,
     "start_time": "2020-08-08T18:09:13.024372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on TPU  grpc://10.0.0.2:8470\n",
      "REPLICAS:  8\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:17.488832Z",
     "iopub.status.busy": "2020-08-08T18:09:17.488082Z",
     "iopub.status.idle": "2020-08-08T18:09:17.491465Z",
     "shell.execute_reply": "2020-08-08T18:09:17.490740Z"
    },
    "papermill": {
     "duration": 0.028728,
     "end_time": "2020-08-08T18:09:17.491586",
     "exception": false,
     "start_time": "2020-08-08T18:09:17.462858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "params['batch_size'] = params['batch_size'] * strategy.num_replicas_in_sync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:17.538106Z",
     "iopub.status.busy": "2020-08-08T18:09:17.537079Z",
     "iopub.status.idle": "2020-08-08T18:09:17.540368Z",
     "shell.execute_reply": "2020-08-08T18:09:17.539595Z"
    },
    "papermill": {
     "duration": 0.028162,
     "end_time": "2020-08-08T18:09:17.540500",
     "exception": false,
     "start_time": "2020-08-08T18:09:17.512338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sub = pd.read_csv(dataset_gcs + '/sample_submission.csv')\n",
    "# sub.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:17.588811Z",
     "iopub.status.busy": "2020-08-08T18:09:17.587658Z",
     "iopub.status.idle": "2020-08-08T18:09:27.174295Z",
     "shell.execute_reply": "2020-08-08T18:09:27.174892Z"
    },
    "papermill": {
     "duration": 9.613744,
     "end_time": "2020-08-08T18:09:27.175085",
     "exception": false,
     "start_time": "2020-08-08T18:09:17.561341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32542</td>\n",
       "      <td>32542</td>\n",
       "      <td>32477</td>\n",
       "      <td>32474</td>\n",
       "      <td>32024</td>\n",
       "      <td>32542</td>\n",
       "      <td>32542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "      <td>575</td>\n",
       "      <td>584</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        image_name  patient_id    sex  age_approx  \\\n",
       "target                                              \n",
       "0            32542       32542  32477       32474   \n",
       "1              584         584    584         584   \n",
       "\n",
       "        anatom_site_general_challenge  diagnosis  benign_malignant  \n",
       "target                                                              \n",
       "0                               32024      32542             32542  \n",
       "1                                 575        584               584  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(dataset_gcs + '/train.csv')\n",
    "train_df.groupby('target').count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:27.227815Z",
     "iopub.status.busy": "2020-08-08T18:09:27.226826Z",
     "iopub.status.idle": "2020-08-08T18:09:27.231186Z",
     "shell.execute_reply": "2020-08-08T18:09:27.230564Z"
    },
    "papermill": {
     "duration": 0.034552,
     "end_time": "2020-08-08T18:09:27.231322",
     "exception": false,
     "start_time": "2020-08-08T18:09:27.196770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image_label(tfrec):\n",
    "    '''\n",
    "    function to decode an image and target label from tfrecord\n",
    "    \n",
    "    args:\n",
    "        tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "    returns:\n",
    "        decoded_image: tensor, converted image from tfrecord\n",
    "        label: tensor, integer, either 1 or 0\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "        }\n",
    "    features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "    decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "    decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "    label = features['target']\n",
    "    \n",
    "    return decoded_image, label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:27.284776Z",
     "iopub.status.busy": "2020-08-08T18:09:27.283673Z",
     "iopub.status.idle": "2020-08-08T18:09:27.286195Z",
     "shell.execute_reply": "2020-08-08T18:09:27.286755Z"
    },
    "papermill": {
     "duration": 0.033562,
     "end_time": "2020-08-08T18:09:27.286925",
     "exception": false,
     "start_time": "2020-08-08T18:09:27.253363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def decode_image(tfrec):\n",
    "    '''\n",
    "    function to decode an image from tfrecord\n",
    "    \n",
    "    args:\n",
    "        tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "    returns:\n",
    "        decoded_image: tensor, converted image from tfrecord\n",
    "        img_name: tensor, string, Id of the decoded image\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    features_dictionary = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "        }\n",
    "    features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "    decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "    decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "    img_name = features['image_name']\n",
    "    \n",
    "    return decoded_image, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:27.338840Z",
     "iopub.status.busy": "2020-08-08T18:09:27.337788Z",
     "iopub.status.idle": "2020-08-08T18:09:27.341548Z",
     "shell.execute_reply": "2020-08-08T18:09:27.340787Z"
    },
    "papermill": {
     "duration": 0.033006,
     "end_time": "2020-08-08T18:09:27.341677",
     "exception": false,
     "start_time": "2020-08-08T18:09:27.308671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image_label(decoded_image, label):\n",
    "    '''\n",
    "    function to convert an image tensor values from 0 to 255 \n",
    "    -> -1 to 1\n",
    "    to be used when dealing with tfrecords containing labels\n",
    "    \n",
    "    args:\n",
    "        decoded_image: tensor that is an image with values from 0 to 255\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image_tensor: tensor that is an image with values from -1 to 1\n",
    "        label, same as input\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "    image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "    #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "    image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "    #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "    image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "    return image_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:27.393317Z",
     "iopub.status.busy": "2020-08-08T18:09:27.392354Z",
     "iopub.status.idle": "2020-08-08T18:09:27.395680Z",
     "shell.execute_reply": "2020-08-08T18:09:27.394950Z"
    },
    "papermill": {
     "duration": 0.032281,
     "end_time": "2020-08-08T18:09:27.395800",
     "exception": false,
     "start_time": "2020-08-08T18:09:27.363519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normalize_image(decoded_image):\n",
    "    '''\n",
    "    function to convert an image tensor values from 0 to 255 \n",
    "    -> -1 to 1\n",
    "    \n",
    "    args:\n",
    "        decoded_image: tensor that is an image with values from 0 to 255\n",
    "    \n",
    "    returns: \n",
    "        image_tensor: tensor that is an image with values from -1 to 1\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "    image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "    #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "    image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "    #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "    image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "    return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:27.447627Z",
     "iopub.status.busy": "2020-08-08T18:09:27.446669Z",
     "iopub.status.idle": "2020-08-08T18:09:27.450179Z",
     "shell.execute_reply": "2020-08-08T18:09:27.449515Z"
    },
    "papermill": {
     "duration": 0.032067,
     "end_time": "2020-08-08T18:09:27.450313",
     "exception": false,
     "start_time": "2020-08-08T18:09:27.418246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_flip(image, label):\n",
    "    '''\n",
    "    function to randomly flip images on the x and/or y axis\n",
    "    \n",
    "    args:\n",
    "        image: tensor, an image\n",
    "        label: tensor, target label\n",
    "    \n",
    "    returns: \n",
    "        image: tensor, same as input, but possibly flipped on x and/or y axis\n",
    "        label, tensor, same as input\n",
    "    '''\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return image, label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:27.506133Z",
     "iopub.status.busy": "2020-08-08T18:09:27.505014Z",
     "iopub.status.idle": "2020-08-08T18:09:27.508533Z",
     "shell.execute_reply": "2020-08-08T18:09:27.507763Z"
    },
    "papermill": {
     "duration": 0.035788,
     "end_time": "2020-08-08T18:09:27.508659",
     "exception": false,
     "start_time": "2020-08-08T18:09:27.472871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_train_ds(tfrecords, batch_size):\n",
    "    '''\n",
    "    function to create a ds pipeline from tfrecord files\n",
    "    \n",
    "    args:\n",
    "        tfrecords: list, tfrecord file paths\n",
    "        batch_size: int, batch size for number of records to pass into\n",
    "            model at a time\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images and labels\n",
    "    '''\n",
    "    ds = (tf.data.TFRecordDataset(filenames=[tfrecords],\n",
    "                                 num_parallel_reads=tf.data.experimental.AUTOTUNE).\n",
    "          cache(). #need to remove cache while not usnig TPUs\n",
    "          map(decode_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(normalize_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(random_flip, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          repeat().\n",
    "          shuffle(512).\n",
    "          batch(batch_size,\n",
    "               drop_remainder=True).\n",
    "          prefetch(tf.data.experimental.AUTOTUNE)\n",
    "         )\n",
    "    \n",
    "\n",
    "    \n",
    "    return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:27.563364Z",
     "iopub.status.busy": "2020-08-08T18:09:27.562398Z",
     "iopub.status.idle": "2020-08-08T18:09:27.564761Z",
     "shell.execute_reply": "2020-08-08T18:09:27.565308Z"
    },
    "papermill": {
     "duration": 0.033925,
     "end_time": "2020-08-08T18:09:27.565483",
     "exception": false,
     "start_time": "2020-08-08T18:09:27.531558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_test_ds(tfrecords, batch_size):\n",
    "    '''\n",
    "    function to create a dataset for test data\n",
    "    args:\n",
    "        tfrecords: list, tfrecord file paths\n",
    "        batch_size: int, batch size for number of records to pass into\n",
    "            model at a time\n",
    "    returns:\n",
    "        ds: tensorflow input pipeline with images and labels\n",
    "    \n",
    "    '''\n",
    "\n",
    "    ds = (tf.data.TFRecordDataset(filenames=[tfrecords],\n",
    "                                 num_parallel_reads=tf.data.experimental.AUTOTUNE).\n",
    "#           cache(). #there is no reason to cache this ds -- it is only being read 1x\n",
    "          map(decode_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "          map(normalize_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "#           map(random_flip).\n",
    "          batch(batch_size).\n",
    "#                 drop_remainder=True).\n",
    "          prefetch(tf.data.experimental.AUTOTUNE)\n",
    "         )\n",
    "    \n",
    "    return ds\n",
    "    ###come back to this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.022315,
     "end_time": "2020-08-08T18:09:27.610464",
     "exception": false,
     "start_time": "2020-08-08T18:09:27.588149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:27.669593Z",
     "iopub.status.busy": "2020-08-08T18:09:27.668531Z",
     "iopub.status.idle": "2020-08-08T18:09:27.672491Z",
     "shell.execute_reply": "2020-08-08T18:09:27.671597Z"
    },
    "papermill": {
     "duration": 0.038549,
     "end_time": "2020-08-08T18:09:27.672643",
     "exception": false,
     "start_time": "2020-08-08T18:09:27.634094",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_of_layers(input_layer, \n",
    "                  filters_, \n",
    "                  kernal, \n",
    "                  strides_, \n",
    "                  dense=None, \n",
    "                  dense_activation=None,\n",
    "                  dropout=None,\n",
    "                  cnn_activation=None):\n",
    "    '''\n",
    "    function to add the following layers to a model:\n",
    "    Conv2D, MaxPooling2D, BatchNormalization, LeadyReLU, Dense,\n",
    "        Dropout\n",
    "\n",
    "    args:\n",
    "      input_layer : input layer to be fed into above layers\n",
    "      filters_: int, number of filters in Conv2D layer\n",
    "      kernal: int, kernal size in Conv2D layer\n",
    "      strides_: int, stride size in MaxPooling2D layer\n",
    "      dense: int, number of units in dense layer, default is None\n",
    "          Will only add layer if value is passed\n",
    "      dense_activation: str, activation function to pass into Dense layer\n",
    "          default is None\n",
    "      dropout: float, dropout percentage in Dropout layer, default is None\n",
    "        must be less than 1.0. Will only add layer if value is passed \n",
    "      cnn_activation: tensorflow activation layer, default is None\n",
    "          will only add layer is value is passed. Activation layer will be\n",
    "          added after the BatchNormalization layer\n",
    "\n",
    "    returns:\n",
    "      x: model that is the same as the input_layer input plus above \n",
    "        layers added\n",
    "    '''\n",
    "    x = layers.Conv2D(filters_, (kernal, kernal), padding='same')(input_layer)\n",
    "    x = layers.MaxPooling2D(strides_, strides_)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    if cnn_activation:\n",
    "        x = cnn_activation(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    if dense:\n",
    "        x = layers.Dense(dense, activation=dense_activation)(x)\n",
    "    if dropout:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:27.736037Z",
     "iopub.status.busy": "2020-08-08T18:09:27.735142Z",
     "iopub.status.idle": "2020-08-08T18:09:27.738417Z",
     "shell.execute_reply": "2020-08-08T18:09:27.737674Z"
    },
    "papermill": {
     "duration": 0.040291,
     "end_time": "2020-08-08T18:09:27.738544",
     "exception": false,
     "start_time": "2020-08-08T18:09:27.698253",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deconv_set_of_layers(input_layer, \n",
    "                         filters_, \n",
    "                         kernal_, \n",
    "                         stride, \n",
    "                         dense=None, \n",
    "                         dense_activation=None, \n",
    "                         dropout=None,\n",
    "                         cnn_activation=None):\n",
    "    '''\n",
    "    function to add the following layers to a model:\n",
    "    Conv2DTranspose, BatchNormalization, LeadyReLU, Dense\n",
    "\n",
    "    args:\n",
    "      input_layer : input layer to be fed into above layers\n",
    "      filters_: int, number of filters in Conv2DTranspose layer\n",
    "      kernal_: int, kernal size in Conv2DTranspose layer\n",
    "      strides_: int, stride size in Conv2DTranspose layer\n",
    "      dense: int, number of units in dense layer, default is None\n",
    "          Will only add layer if value is passed\n",
    "      dense_activation: str, activation function to pass into Dense layer\n",
    "          default is None\n",
    "      dropout: float, dropout percentage in Dropout layer, default is None\n",
    "        must be less than 1.0. Will only add layer if value is passed \n",
    "      cnn_activation: tensorflow activation layer, default is None\n",
    "          will only add layer is value is passed. Activation layer will be\n",
    "          added after the BatchNormalization layer\n",
    "\n",
    "\n",
    "    returns:\n",
    "      x: model that is the same as the input_layer input plus above \n",
    "        layers added\n",
    "    '''\n",
    "    \n",
    "    x = layers.Conv2DTranspose(filters_,\n",
    "                              kernal_,\n",
    "                              (stride, stride),\n",
    "                              padding='same')(input_layer)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    if cnn_activation:\n",
    "        x = cnn_activation(x)\n",
    "   \n",
    "    if dense:\n",
    "        x = layers.Dense(dense, activation=dense_activation)(x)\n",
    "    \n",
    "    if dropout:\n",
    "        x = layers.Dropout(dropout)(x)\n",
    "    \n",
    "\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:27.808833Z",
     "iopub.status.busy": "2020-08-08T18:09:27.803333Z",
     "iopub.status.idle": "2020-08-08T18:09:27.812687Z",
     "shell.execute_reply": "2020-08-08T18:09:27.811975Z"
    },
    "papermill": {
     "duration": 0.051492,
     "end_time": "2020-08-08T18:09:27.812813",
     "exception": false,
     "start_time": "2020-08-08T18:09:27.761321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_model(input_shape=[*params['img_size'], 3], bias_output=None):\n",
    "    '''\n",
    "    function to create a model that will be trained on train DS\n",
    "    \n",
    "    args:\n",
    "        input_shape: array, default: [1024, 1024, 3], shape\n",
    "            of input tensor that will be fed into model\n",
    "    \n",
    "    returns:\n",
    "        model: tf.sequential() model\n",
    "    '''\n",
    "\n",
    "    relu = layers.ReLU()\n",
    "    leakyrelu = layers.LeakyReLU()\n",
    "    input_tensor = layers.Input(shape=input_shape, name='images_input')\n",
    "    x = input_tensor\n",
    "    filters_list = [64, 128, 256, 512, 1024]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x1 = set_of_layers(x, filter_, 5, 2, 16,  dropout=0.35, cnn_activation=relu)\n",
    "        x2 = set_of_layers(x, filter_, 5, 2, 16,  dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "        x = layers.Concatenate()([x1, x2])\n",
    "#         x = layers.Dense(filter_, activation='elu')(x) #consider adding dropout\n",
    "#         x = layers.Dropout(0.35)(x)\n",
    "    \n",
    "    \n",
    "    filters_list = [256, 128, 64]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x1 = deconv_set_of_layers(x, filter_, 4, 2, 16,  dropout=0.35, cnn_activation=relu)\n",
    "        x2= deconv_set_of_layers(x, filter_, 4, 2, 16,  dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = deconv_set_of_layers(x, filter_, 4, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = deconv_set_of_layers(x, filter_, 4, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "        x = layers.Concatenate()([x1, x2])\n",
    "#         x = layers.Dense(filter_, activation='elu')(x)\n",
    "#         x = layers.Dropout(0.35)(x)        \n",
    "    \n",
    "    filters_list = [64, 128, 256]\n",
    "    \n",
    "    for filter_ in filters_list:\n",
    "        x1 = set_of_layers(x, filter_, 5, 2, 16,  dropout=0.35, cnn_activation=relu)\n",
    "        x2 = set_of_layers(x, filter_, 5, 2, 16,  dropout=0.35, cnn_activation=leakyrelu)\n",
    "#         x3 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=relu)\n",
    "#         x4 = set_of_layers(x, filter_, 5, 2, 16, 'sigmoid', dropout=0.35, cnn_activation=leakyrelu)\n",
    "        \n",
    "        x = layers.Concatenate()([x1, x2])\n",
    "#         x = layers.Dense(filter_, activation='elu')(x)\n",
    "#         x = layers.Dropout(0.35)(x)\n",
    "    \n",
    "\n",
    "    #layers.Concatenate\n",
    "\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128)(x)\n",
    "#     model.add(layers.Dense(64))\n",
    "    \n",
    "    if bias_output is not None:\n",
    "        bias_output = tf.keras.initializers.Constant(bias_output)\n",
    "    output_layer = layers.Dense(1, activation='sigmoid', bias_initializer=bias_output)(x)\n",
    "    \n",
    "    model=keras.Model(inputs=[input_tensor],\n",
    "                     outputs=[output_layer])\n",
    "\n",
    " \n",
    "           \n",
    "    metrics = [\n",
    "          keras.metrics.TruePositives(name='tp'),\n",
    "#           keras.metrics.FalsePositives(name='fp'),\n",
    "#           keras.metrics.TrueNegatives(name='tn'),\n",
    "          keras.metrics.FalseNegatives(name='fn'), \n",
    "          keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#           keras.metrics.Precision(name='precision'),\n",
    "#           keras.metrics.Recall(name='recall'),\n",
    "          keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "    schedule = None\n",
    "    \n",
    "    model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.0003),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.01),\n",
    "    metrics=metrics\n",
    ")\n",
    "    \n",
    "\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:27.866486Z",
     "iopub.status.busy": "2020-08-08T18:09:27.865625Z",
     "iopub.status.idle": "2020-08-08T18:09:27.868465Z",
     "shell.execute_reply": "2020-08-08T18:09:27.869090Z"
    },
    "papermill": {
     "duration": 0.033342,
     "end_time": "2020-08-08T18:09:27.869255",
     "exception": false,
     "start_time": "2020-08-08T18:09:27.835913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ds_size(files):\n",
    "    '''\n",
    "    function to get size of tfrecord Dataset, based on file name\n",
    "    \n",
    "    the file name has the number of records in the file, for example:\n",
    "    train09-2071.tfrec has 2017 records\n",
    "    \n",
    "    args:\n",
    "        files: list of str file names, each item should be the path to a tfrecord file\n",
    "    \n",
    "    returns:\n",
    "        size: int, size of dataset\n",
    "    '''\n",
    "    size = 0\n",
    "    for file in files:\n",
    "        file_size = int(file.split('.tfrec')[0].split('tfrecords/')[1].split('-')[1])\n",
    "        size += file_size\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:28.204369Z",
     "iopub.status.busy": "2020-08-08T18:09:28.200233Z",
     "iopub.status.idle": "2020-08-08T18:09:28.946451Z",
     "shell.execute_reply": "2020-08-08T18:09:28.945610Z"
    },
    "papermill": {
     "duration": 1.053816,
     "end_time": "2020-08-08T18:09:28.946584",
     "exception": false,
     "start_time": "2020-08-08T18:09:27.892768",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#get test file paths\n",
    "test_files = tf.io.gfile.glob(dataset_gcs + '/tfrecords/test*.tfrec')\n",
    "\n",
    "#get train and validation file paths\n",
    "train_files, valid_files = train_test_split(tf.io.gfile.glob(dataset_gcs + '/tfrecords/train*.tfrec'),\n",
    "                              test_size=.1, random_state=1)\n",
    "\n",
    "#create datasets\n",
    "train_ds = get_train_ds(train_files, params['batch_size'])\n",
    "valid_ds = get_train_ds(valid_files, params['batch_size'])\n",
    "test_ds = get_test_ds(test_files, params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:29.000178Z",
     "iopub.status.busy": "2020-08-08T18:09:28.999304Z",
     "iopub.status.idle": "2020-08-08T18:09:29.003892Z",
     "shell.execute_reply": "2020-08-08T18:09:29.003023Z"
    },
    "papermill": {
     "duration": 0.03435,
     "end_time": "2020-08-08T18:09:29.004082",
     "exception": false,
     "start_time": "2020-08-08T18:09:28.969732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dataset consists of: 28984 training images, 4142 validation images, and 10982 test images\n"
     ]
    }
   ],
   "source": [
    "train_size, valid_size = get_ds_size(train_files), get_ds_size(valid_files)\n",
    "test_size = get_ds_size(test_files)\n",
    "print('the dataset consists of: {} training images, {} validation images, and {} test images'.\n",
    "     format(train_size, valid_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.024254,
     "end_time": "2020-08-08T18:09:29.052885",
     "exception": false,
     "start_time": "2020-08-08T18:09:29.028631",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:29.106280Z",
     "iopub.status.busy": "2020-08-08T18:09:29.105479Z",
     "iopub.status.idle": "2020-08-08T18:09:29.109334Z",
     "shell.execute_reply": "2020-08-08T18:09:29.108569Z"
    },
    "papermill": {
     "duration": 0.033356,
     "end_time": "2020-08-08T18:09:29.109476",
     "exception": false,
     "start_time": "2020-08-08T18:09:29.076120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch_steps = train_size / params['batch_size'] \n",
    "valid_steps = valid_size / params['batch_size']\n",
    "test_steps = 1.0 * test_size / params['batch_size'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:29.166072Z",
     "iopub.status.busy": "2020-08-08T18:09:29.165253Z",
     "iopub.status.idle": "2020-08-08T18:09:29.197328Z",
     "shell.execute_reply": "2020-08-08T18:09:29.196566Z"
    },
    "papermill": {
     "duration": 0.064626,
     "end_time": "2020-08-08T18:09:29.197462",
     "exception": false,
     "start_time": "2020-08-08T18:09:29.132836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculate class weights\n",
    "\n",
    "targets = train_df.groupby('target').count()['diagnosis'].to_list()\n",
    "target_0 = targets[0]\n",
    "target_1 = targets[1]\n",
    "total = target_0 + target_1\n",
    "\n",
    "class_weight_0 = (1 / target_0) * (total) / 2.0\n",
    "class_weight_1 = (1 / target_1) * (total) / 2.0\n",
    "\n",
    "class_weights = {0: class_weight_0, 1: class_weight_1}\n",
    "\n",
    "initial_bias = np.log([target_1 / target_0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.023577,
     "end_time": "2020-08-08T18:09:29.244844",
     "exception": false,
     "start_time": "2020-08-08T18:09:29.221267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:29.298587Z",
     "iopub.status.busy": "2020-08-08T18:09:29.297735Z",
     "iopub.status.idle": "2020-08-08T18:09:37.604428Z",
     "shell.execute_reply": "2020-08-08T18:09:37.605321Z"
    },
    "papermill": {
     "duration": 8.337039,
     "end_time": "2020-08-08T18:09:37.605564",
     "exception": false,
     "start_time": "2020-08-08T18:09:29.268525",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "images_input (InputLayer)       [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 64) 4864        images_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 64) 4864        images_input[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 64) 0           conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 128, 128, 64) 256         max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 128, 128, 64) 256         max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu (ReLU)                    multiple             0           batch_normalization[0][0]        \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "                                                                 batch_normalization_4[0][0]      \n",
      "                                                                 batch_normalization_6[0][0]      \n",
      "                                                                 batch_normalization_8[0][0]      \n",
      "                                                                 batch_normalization_10[0][0]     \n",
      "                                                                 batch_normalization_12[0][0]     \n",
      "                                                                 batch_normalization_14[0][0]     \n",
      "                                                                 batch_normalization_16[0][0]     \n",
      "                                                                 batch_normalization_18[0][0]     \n",
      "                                                                 batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         multiple             0           batch_normalization_1[0][0]      \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "                                                                 batch_normalization_5[0][0]      \n",
      "                                                                 batch_normalization_7[0][0]      \n",
      "                                                                 batch_normalization_9[0][0]      \n",
      "                                                                 batch_normalization_11[0][0]     \n",
      "                                                                 batch_normalization_13[0][0]     \n",
      "                                                                 batch_normalization_15[0][0]     \n",
      "                                                                 batch_normalization_17[0][0]     \n",
      "                                                                 batch_normalization_19[0][0]     \n",
      "                                                                 batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 128, 128, 64) 0           re_lu[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 128, 128, 64) 0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128, 128, 16) 1040        re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128, 128, 16) 1040        re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 128, 128, 16) 0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 128, 128, 16) 0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 128, 128, 32) 0           dropout[0][0]                    \n",
      "                                                                 dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 128 102528      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 128 102528      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 128)  0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 128)  512         max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 64, 64, 128)  0           re_lu[1][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 64, 64, 128)  0           leaky_re_lu[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64, 64, 16)   2064        re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64, 64, 16)   2064        re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64, 64, 16)   0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64, 64, 16)   0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 32)   0           dropout_2[0][0]                  \n",
      "                                                                 dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 256)  205056      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 256)  205056      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 32, 32, 256)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 256)  1024        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 32, 32, 256)  1024        max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 32, 32, 256)  0           re_lu[2][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 32, 32, 256)  0           leaky_re_lu[2][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 32, 32, 16)   4112        re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 32, 32, 16)   4112        re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 32, 32, 16)   0           dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 16)   0           dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 32, 32, 32)   0           dropout_4[0][0]                  \n",
      "                                                                 dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 512)  410112      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 512)  410112      concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 16, 16, 512)  0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 16, 16, 512)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 512)  2048        max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 16, 16, 512)  2048        max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 16, 16, 512)  0           re_lu[3][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 16, 16, 512)  0           leaky_re_lu[3][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 16, 16, 16)   8208        re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 16, 16, 16)   8208        re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 16, 16)   0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 16, 16, 16)   0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 16, 16, 32)   0           dropout_6[0][0]                  \n",
      "                                                                 dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 16, 16, 1024) 820224      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 16, 16, 1024) 820224      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 8, 8, 1024)   0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 1024)   4096        max_pooling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 8, 8, 1024)   4096        max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 8, 8, 1024)   0           re_lu[4][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_10 (ReLU)                 (None, 8, 8, 1024)   0           leaky_re_lu[4][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 8, 8, 16)     16400       re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 8, 8, 16)     16400       re_lu_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 8, 8, 16)     0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 8, 8, 16)     0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 8, 8, 32)     0           dropout_8[0][0]                  \n",
      "                                                                 dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 16, 16, 256)  131328      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 16, 16, 256)  131328      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 16, 16, 256)  1024        conv2d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 16, 16, 256)  1024        conv2d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 16, 16, 16)   4112        re_lu[5][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 16, 16, 16)   4112        leaky_re_lu[5][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_10 (Dropout)            (None, 16, 16, 16)   0           dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 16, 16, 16)   0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 16, 16, 32)   0           dropout_10[0][0]                 \n",
      "                                                                 dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 32, 32, 128)  65664       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 32, 32, 128)  65664       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 128)  512         conv2d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 128)  512         conv2d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 32, 32, 16)   2064        re_lu[6][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 32, 32, 16)   2064        leaky_re_lu[6][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 32, 32, 16)   0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 32, 32, 16)   0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 32, 32, 32)   0           dropout_12[0][0]                 \n",
      "                                                                 dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 64, 64, 64)   32832       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTrans (None, 64, 64, 64)   32832       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 64, 64, 64)   256         conv2d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 64, 64, 64)   256         conv2d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 64, 64, 16)   1040        re_lu[7][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 64, 64, 16)   1040        leaky_re_lu[7][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 64, 64, 16)   0           dense_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 64, 64, 16)   0           dense_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 64, 64, 32)   0           dropout_14[0][0]                 \n",
      "                                                                 dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 64, 64, 64)   51264       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 64)   51264       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 32, 32, 64)   0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 64)   256         max_pooling2d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 64)   256         max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_11 (ReLU)                 (None, 32, 32, 64)   0           re_lu[8][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_12 (ReLU)                 (None, 32, 32, 64)   0           leaky_re_lu[8][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_16 (Dense)                (None, 32, 32, 16)   1040        re_lu_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_17 (Dense)                (None, 32, 32, 16)   1040        re_lu_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 32, 32, 16)   0           dense_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 32, 32, 16)   0           dense_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_8 (Concatenate)     (None, 32, 32, 32)   0           dropout_16[0][0]                 \n",
      "                                                                 dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 32, 32, 128)  102528      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 128)  102528      concatenate_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 16, 16, 128)  0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 16, 16, 128)  0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 16, 16, 128)  512         max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 16, 16, 128)  512         max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_13 (ReLU)                 (None, 16, 16, 128)  0           re_lu[9][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_14 (ReLU)                 (None, 16, 16, 128)  0           leaky_re_lu[9][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 16, 16, 16)   2064        re_lu_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 16, 16, 16)   2064        re_lu_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 16, 16, 16)   0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 16, 16, 16)   0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 16, 16, 32)   0           dropout_18[0][0]                 \n",
      "                                                                 dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 256)  205056      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 16, 16, 256)  205056      concatenate_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 8, 8, 256)    0           conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 8, 8, 256)    0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 8, 8, 256)    1024        max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 8, 8, 256)    1024        max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_15 (ReLU)                 (None, 8, 8, 256)    0           re_lu[10][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_16 (ReLU)                 (None, 8, 8, 256)    0           leaky_re_lu[10][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 8, 8, 16)     4112        re_lu_15[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 8, 8, 16)     4112        re_lu_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 8, 8, 16)     0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 8, 8, 16)     0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, 8, 8, 32)     0           dropout_20[0][0]                 \n",
      "                                                                 dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           concatenate_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 128)          262272      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1)            129         dense_22[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 4,640,865\n",
      "Trainable params: 4,629,345\n",
      "Non-trainable params: 11,520\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model(bias_output=initial_bias)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.023662,
     "end_time": "2020-08-08T18:09:37.654295",
     "exception": false,
     "start_time": "2020-08-08T18:09:37.630633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T18:09:37.714848Z",
     "iopub.status.busy": "2020-08-08T18:09:37.713909Z",
     "iopub.status.idle": "2020-08-08T19:48:18.961896Z",
     "shell.execute_reply": "2020-08-08T19:48:18.962662Z"
    },
    "papermill": {
     "duration": 5921.284452,
     "end_time": "2020-08-08T19:48:18.962877",
     "exception": false,
     "start_time": "2020-08-08T18:09:37.678425",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/350\n",
      "29/28 [==============================] - 35s 1s/step - loss: 1.3709 - accuracy: 0.6876 - tp: 214.0000 - auc: 0.5441 - fn: 310.0000 - val_loss: 0.1093 - val_accuracy: 0.9830 - val_tp: 0.0000e+00 - val_auc: 0.5000 - val_fn: 87.0000\n",
      "Epoch 2/350\n",
      "29/28 [==============================] - 23s 780ms/step - loss: 0.9182 - accuracy: 0.6615 - tp: 225.0000 - auc: 0.5514 - fn: 299.0000 - val_loss: 0.1188 - val_accuracy: 0.9834 - val_tp: 0.0000e+00 - val_auc: 0.5000 - val_fn: 85.0000\n",
      "Epoch 3/350\n",
      "29/28 [==============================] - 22s 769ms/step - loss: 0.8452 - accuracy: 0.7140 - tp: 237.0000 - auc: 0.5921 - fn: 295.0000 - val_loss: 0.1377 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_auc: 0.5000 - val_fn: 84.0000\n",
      "Epoch 4/350\n",
      "29/28 [==============================] - 23s 784ms/step - loss: 0.9484 - accuracy: 0.6926 - tp: 263.0000 - auc: 0.6199 - fn: 265.0000 - val_loss: 0.1433 - val_accuracy: 0.9834 - val_tp: 0.0000e+00 - val_auc: 0.4985 - val_fn: 85.0000\n",
      "Epoch 5/350\n",
      "29/28 [==============================] - 22s 774ms/step - loss: 0.7620 - accuracy: 0.6825 - tp: 317.0000 - auc: 0.6884 - fn: 207.0000 - val_loss: 0.1427 - val_accuracy: 0.9828 - val_tp: 0.0000e+00 - val_auc: 0.5000 - val_fn: 88.0000\n",
      "Epoch 6/350\n",
      "29/28 [==============================] - 22s 768ms/step - loss: 0.7112 - accuracy: 0.6871 - tp: 326.0000 - auc: 0.7168 - fn: 206.0000 - val_loss: 0.1428 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_auc: 0.4909 - val_fn: 84.0000\n",
      "Epoch 7/350\n",
      "29/28 [==============================] - 25s 852ms/step - loss: 0.7176 - accuracy: 0.7077 - tp: 324.0000 - auc: 0.7456 - fn: 204.0000 - val_loss: 0.1360 - val_accuracy: 0.9838 - val_tp: 0.0000e+00 - val_auc: 0.5000 - val_fn: 83.0000\n",
      "Epoch 8/350\n",
      "29/28 [==============================] - 24s 818ms/step - loss: 0.6714 - accuracy: 0.6873 - tp: 354.0000 - auc: 0.7488 - fn: 173.0000 - val_loss: 0.1318 - val_accuracy: 0.9830 - val_tp: 0.0000e+00 - val_auc: 0.5934 - val_fn: 87.0000\n",
      "Epoch 9/350\n",
      "29/28 [==============================] - 23s 787ms/step - loss: 0.6953 - accuracy: 0.6802 - tp: 354.0000 - auc: 0.7439 - fn: 176.0000 - val_loss: 0.1255 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_auc: 0.4958 - val_fn: 86.0000\n",
      "Epoch 10/350\n",
      "29/28 [==============================] - 22s 774ms/step - loss: 0.6168 - accuracy: 0.6924 - tp: 370.0000 - auc: 0.7677 - fn: 162.0000 - val_loss: 0.1249 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_auc: 0.6930 - val_fn: 86.0000\n",
      "Epoch 11/350\n",
      "29/28 [==============================] - 22s 772ms/step - loss: 0.6162 - accuracy: 0.6831 - tp: 396.0000 - auc: 0.7781 - fn: 132.0000 - val_loss: 0.1265 - val_accuracy: 0.9822 - val_tp: 0.0000e+00 - val_auc: 0.6928 - val_fn: 91.0000\n",
      "Epoch 12/350\n",
      "29/28 [==============================] - 23s 779ms/step - loss: 0.6033 - accuracy: 0.6881 - tp: 394.0000 - auc: 0.7783 - fn: 141.0000 - val_loss: 0.1224 - val_accuracy: 0.9838 - val_tp: 0.0000e+00 - val_auc: 0.6896 - val_fn: 83.0000\n",
      "Epoch 13/350\n",
      "29/28 [==============================] - 22s 775ms/step - loss: 0.5828 - accuracy: 0.6822 - tp: 416.0000 - auc: 0.7867 - fn: 114.0000 - val_loss: 0.1186 - val_accuracy: 0.9830 - val_tp: 0.0000e+00 - val_auc: 0.6976 - val_fn: 87.0000\n",
      "Epoch 14/350\n",
      "29/28 [==============================] - 22s 776ms/step - loss: 0.5790 - accuracy: 0.6817 - tp: 415.0000 - auc: 0.7912 - fn: 111.0000 - val_loss: 0.1166 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_auc: 0.7137 - val_fn: 86.0000\n",
      "Epoch 15/350\n",
      "29/28 [==============================] - 22s 772ms/step - loss: 0.5757 - accuracy: 0.7001 - tp: 385.0000 - auc: 0.7932 - fn: 142.0000 - val_loss: 0.1195 - val_accuracy: 0.9826 - val_tp: 0.0000e+00 - val_auc: 0.7070 - val_fn: 89.0000\n",
      "Epoch 16/350\n",
      "29/28 [==============================] - 22s 770ms/step - loss: 0.5867 - accuracy: 0.6861 - tp: 408.0000 - auc: 0.7909 - fn: 115.0000 - val_loss: 0.1081 - val_accuracy: 0.9838 - val_tp: 0.0000e+00 - val_auc: 0.6127 - val_fn: 83.0000\n",
      "Epoch 17/350\n",
      "29/28 [==============================] - 23s 784ms/step - loss: 0.5715 - accuracy: 0.6914 - tp: 396.0000 - auc: 0.7954 - fn: 132.0000 - val_loss: 0.1094 - val_accuracy: 0.9834 - val_tp: 0.0000e+00 - val_auc: 0.6814 - val_fn: 85.0000\n",
      "Epoch 18/350\n",
      "29/28 [==============================] - 22s 761ms/step - loss: 0.5479 - accuracy: 0.6861 - tp: 405.0000 - auc: 0.7978 - fn: 115.0000 - val_loss: 0.1062 - val_accuracy: 0.9834 - val_tp: 0.0000e+00 - val_auc: 0.6917 - val_fn: 85.0000\n",
      "Epoch 19/350\n",
      "29/28 [==============================] - 22s 771ms/step - loss: 0.5474 - accuracy: 0.6840 - tp: 425.0000 - auc: 0.8062 - fn: 111.0000 - val_loss: 0.1041 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_auc: 0.6542 - val_fn: 84.0000\n",
      "Epoch 20/350\n",
      "29/28 [==============================] - 22s 757ms/step - loss: 0.5422 - accuracy: 0.6877 - tp: 409.0000 - auc: 0.8019 - fn: 116.0000 - val_loss: 0.1042 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_auc: 0.6939 - val_fn: 84.0000\n",
      "Epoch 21/350\n",
      "29/28 [==============================] - 24s 823ms/step - loss: 0.5345 - accuracy: 0.6874 - tp: 422.0000 - auc: 0.8077 - fn: 101.0000 - val_loss: 0.1049 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_auc: 0.7539 - val_fn: 84.0000\n",
      "Epoch 22/350\n",
      "29/28 [==============================] - 22s 773ms/step - loss: 0.5477 - accuracy: 0.6908 - tp: 426.0000 - auc: 0.8085 - fn: 107.0000 - val_loss: 0.1039 - val_accuracy: 0.9834 - val_tp: 0.0000e+00 - val_auc: 0.7108 - val_fn: 85.0000\n",
      "Epoch 23/350\n",
      "29/28 [==============================] - 24s 839ms/step - loss: 0.5470 - accuracy: 0.6862 - tp: 411.0000 - auc: 0.8043 - fn: 112.0000 - val_loss: 0.1054 - val_accuracy: 0.9828 - val_tp: 0.0000e+00 - val_auc: 0.7781 - val_fn: 88.0000\n",
      "Epoch 24/350\n",
      "29/28 [==============================] - 22s 767ms/step - loss: 0.5283 - accuracy: 0.6993 - tp: 417.0000 - auc: 0.8156 - fn: 116.0000 - val_loss: 0.1015 - val_accuracy: 0.9834 - val_tp: 0.0000e+00 - val_auc: 0.7907 - val_fn: 85.0000\n",
      "Epoch 25/350\n",
      "29/28 [==============================] - 22s 757ms/step - loss: 0.5142 - accuracy: 0.7024 - tp: 433.0000 - auc: 0.8258 - fn: 96.0000 - val_loss: 0.1135 - val_accuracy: 0.9822 - val_tp: 0.0000e+00 - val_auc: 0.7776 - val_fn: 91.0000\n",
      "Epoch 26/350\n",
      "29/28 [==============================] - 23s 798ms/step - loss: 0.5193 - accuracy: 0.6897 - tp: 432.0000 - auc: 0.8192 - fn: 92.0000 - val_loss: 0.1016 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_auc: 0.7669 - val_fn: 84.0000\n",
      "Epoch 27/350\n",
      "29/28 [==============================] - 22s 776ms/step - loss: 0.5235 - accuracy: 0.7146 - tp: 424.0000 - auc: 0.8238 - fn: 105.0000 - val_loss: 0.1065 - val_accuracy: 0.9834 - val_tp: 0.0000e+00 - val_auc: 0.7613 - val_fn: 85.0000\n",
      "Epoch 28/350\n",
      "29/28 [==============================] - 22s 772ms/step - loss: 0.5115 - accuracy: 0.7047 - tp: 434.0000 - auc: 0.8271 - fn: 93.0000 - val_loss: 0.1044 - val_accuracy: 0.9830 - val_tp: 0.0000e+00 - val_auc: 0.7726 - val_fn: 87.0000\n",
      "Epoch 29/350\n",
      "29/28 [==============================] - 23s 785ms/step - loss: 0.4988 - accuracy: 0.7083 - tp: 431.0000 - auc: 0.8340 - fn: 92.0000 - val_loss: 0.1079 - val_accuracy: 0.9807 - val_tp: 1.0000 - val_auc: 0.7707 - val_fn: 88.0000\n",
      "Epoch 30/350\n",
      "29/28 [==============================] - 24s 811ms/step - loss: 0.4980 - accuracy: 0.7066 - tp: 438.0000 - auc: 0.8345 - fn: 91.0000 - val_loss: 0.1087 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_auc: 0.7219 - val_fn: 86.0000\n",
      "Epoch 31/350\n",
      "29/28 [==============================] - 21s 740ms/step - loss: 0.5020 - accuracy: 0.7174 - tp: 428.0000 - auc: 0.8324 - fn: 99.0000 - val_loss: 0.1060 - val_accuracy: 0.9789 - val_tp: 1.0000 - val_auc: 0.7621 - val_fn: 82.0000\n",
      "Epoch 32/350\n",
      "29/28 [==============================] - 21s 734ms/step - loss: 0.4732 - accuracy: 0.7319 - tp: 444.0000 - auc: 0.8531 - fn: 83.0000 - val_loss: 0.1105 - val_accuracy: 0.9820 - val_tp: 0.0000e+00 - val_auc: 0.7754 - val_fn: 88.0000\n",
      "Epoch 33/350\n",
      "29/28 [==============================] - 24s 826ms/step - loss: 0.4962 - accuracy: 0.7037 - tp: 436.0000 - auc: 0.8339 - fn: 96.0000 - val_loss: 0.1079 - val_accuracy: 0.9809 - val_tp: 2.0000 - val_auc: 0.8159 - val_fn: 83.0000\n",
      "Epoch 34/350\n",
      "29/28 [==============================] - 21s 727ms/step - loss: 0.4978 - accuracy: 0.7140 - tp: 413.0000 - auc: 0.8343 - fn: 117.0000 - val_loss: 0.1006 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_auc: 0.8050 - val_fn: 85.0000\n",
      "Epoch 35/350\n",
      "29/28 [==============================] - 23s 785ms/step - loss: 0.4785 - accuracy: 0.7166 - tp: 445.0000 - auc: 0.8477 - fn: 83.0000 - val_loss: 0.1032 - val_accuracy: 0.9826 - val_tp: 0.0000e+00 - val_auc: 0.7891 - val_fn: 87.0000\n",
      "Epoch 36/350\n",
      "29/28 [==============================] - 23s 799ms/step - loss: 0.4869 - accuracy: 0.7259 - tp: 442.0000 - auc: 0.8470 - fn: 89.0000 - val_loss: 0.1241 - val_accuracy: 0.9799 - val_tp: 8.0000 - val_auc: 0.7166 - val_fn: 78.0000\n",
      "Epoch 37/350\n",
      "29/28 [==============================] - 23s 805ms/step - loss: 0.4844 - accuracy: 0.7211 - tp: 437.0000 - auc: 0.8450 - fn: 90.0000 - val_loss: 0.1030 - val_accuracy: 0.9814 - val_tp: 0.0000e+00 - val_auc: 0.7772 - val_fn: 87.0000\n",
      "Epoch 38/350\n",
      "29/28 [==============================] - 23s 791ms/step - loss: 0.4643 - accuracy: 0.7283 - tp: 436.0000 - auc: 0.8536 - fn: 84.0000 - val_loss: 0.0979 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_auc: 0.8084 - val_fn: 82.0000\n",
      "Epoch 39/350\n",
      "29/28 [==============================] - 24s 821ms/step - loss: 0.4683 - accuracy: 0.7336 - tp: 439.0000 - auc: 0.8578 - fn: 83.0000 - val_loss: 0.1160 - val_accuracy: 0.9779 - val_tp: 7.0000 - val_auc: 0.7856 - val_fn: 81.0000\n",
      "Epoch 40/350\n",
      "29/28 [==============================] - 23s 793ms/step - loss: 0.4756 - accuracy: 0.7341 - tp: 432.0000 - auc: 0.8505 - fn: 95.0000 - val_loss: 0.1124 - val_accuracy: 0.9814 - val_tp: 1.0000 - val_auc: 0.7981 - val_fn: 86.0000\n",
      "Epoch 41/350\n",
      "29/28 [==============================] - 23s 783ms/step - loss: 0.4698 - accuracy: 0.7258 - tp: 446.0000 - auc: 0.8536 - fn: 87.0000 - val_loss: 0.1081 - val_accuracy: 0.9811 - val_tp: 1.0000 - val_auc: 0.8029 - val_fn: 85.0000\n",
      "Epoch 42/350\n",
      "29/28 [==============================] - 23s 782ms/step - loss: 0.4667 - accuracy: 0.7287 - tp: 436.0000 - auc: 0.8542 - fn: 85.0000 - val_loss: 0.1080 - val_accuracy: 0.9799 - val_tp: 2.0000 - val_auc: 0.8103 - val_fn: 86.0000\n",
      "Epoch 43/350\n",
      "29/28 [==============================] - 23s 799ms/step - loss: 0.4627 - accuracy: 0.7277 - tp: 450.0000 - auc: 0.8575 - fn: 78.0000 - val_loss: 0.1016 - val_accuracy: 0.9826 - val_tp: 3.0000 - val_auc: 0.8066 - val_fn: 78.0000\n",
      "Epoch 44/350\n",
      "29/28 [==============================] - 24s 818ms/step - loss: 0.4662 - accuracy: 0.7310 - tp: 437.0000 - auc: 0.8564 - fn: 89.0000 - val_loss: 0.1096 - val_accuracy: 0.9805 - val_tp: 5.0000 - val_auc: 0.8299 - val_fn: 78.0000\n",
      "Epoch 45/350\n",
      "29/28 [==============================] - 24s 812ms/step - loss: 0.4753 - accuracy: 0.7262 - tp: 443.0000 - auc: 0.8492 - fn: 86.0000 - val_loss: 0.0994 - val_accuracy: 0.9805 - val_tp: 2.0000 - val_auc: 0.8454 - val_fn: 82.0000\n",
      "Epoch 46/350\n",
      "29/28 [==============================] - 22s 773ms/step - loss: 0.4569 - accuracy: 0.7405 - tp: 443.0000 - auc: 0.8627 - fn: 82.0000 - val_loss: 0.1049 - val_accuracy: 0.9816 - val_tp: 2.0000 - val_auc: 0.8177 - val_fn: 83.0000\n",
      "Epoch 47/350\n",
      "29/28 [==============================] - 22s 774ms/step - loss: 0.4663 - accuracy: 0.7258 - tp: 445.0000 - auc: 0.8565 - fn: 87.0000 - val_loss: 0.1037 - val_accuracy: 0.9830 - val_tp: 3.0000 - val_auc: 0.8198 - val_fn: 82.0000\n",
      "Epoch 48/350\n",
      "29/28 [==============================] - 24s 839ms/step - loss: 0.4514 - accuracy: 0.7416 - tp: 459.0000 - auc: 0.8659 - fn: 76.0000 - val_loss: 0.1048 - val_accuracy: 0.9807 - val_tp: 4.0000 - val_auc: 0.8203 - val_fn: 83.0000\n",
      "Epoch 49/350\n",
      "29/28 [==============================] - 22s 768ms/step - loss: 0.4562 - accuracy: 0.7397 - tp: 435.0000 - auc: 0.8610 - fn: 87.0000 - val_loss: 0.1074 - val_accuracy: 0.9775 - val_tp: 8.0000 - val_auc: 0.8197 - val_fn: 79.0000\n",
      "Epoch 50/350\n",
      "29/28 [==============================] - 22s 751ms/step - loss: 0.4531 - accuracy: 0.7394 - tp: 444.0000 - auc: 0.8661 - fn: 87.0000 - val_loss: 0.1138 - val_accuracy: 0.9766 - val_tp: 7.0000 - val_auc: 0.8282 - val_fn: 80.0000\n",
      "Epoch 51/350\n",
      "29/28 [==============================] - 23s 784ms/step - loss: 0.4508 - accuracy: 0.7404 - tp: 451.0000 - auc: 0.8656 - fn: 81.0000 - val_loss: 0.1207 - val_accuracy: 0.9752 - val_tp: 5.0000 - val_auc: 0.7933 - val_fn: 81.0000\n",
      "Epoch 52/350\n",
      "29/28 [==============================] - 22s 749ms/step - loss: 0.4486 - accuracy: 0.7414 - tp: 450.0000 - auc: 0.8675 - fn: 76.0000 - val_loss: 0.1077 - val_accuracy: 0.9752 - val_tp: 5.0000 - val_auc: 0.8034 - val_fn: 80.0000\n",
      "Epoch 53/350\n",
      "29/28 [==============================] - 22s 753ms/step - loss: 0.4447 - accuracy: 0.7352 - tp: 459.0000 - auc: 0.8711 - fn: 76.0000 - val_loss: 0.1075 - val_accuracy: 0.9803 - val_tp: 4.0000 - val_auc: 0.8314 - val_fn: 85.0000\n",
      "Epoch 54/350\n",
      "29/28 [==============================] - 23s 786ms/step - loss: 0.4400 - accuracy: 0.7536 - tp: 447.0000 - auc: 0.8718 - fn: 77.0000 - val_loss: 0.1126 - val_accuracy: 0.9750 - val_tp: 6.0000 - val_auc: 0.8397 - val_fn: 81.0000\n",
      "Epoch 55/350\n",
      "29/28 [==============================] - 22s 769ms/step - loss: 0.4517 - accuracy: 0.7418 - tp: 454.0000 - auc: 0.8656 - fn: 77.0000 - val_loss: 0.0952 - val_accuracy: 0.9836 - val_tp: 0.0000e+00 - val_auc: 0.8249 - val_fn: 84.0000\n",
      "Epoch 56/350\n",
      "29/28 [==============================] - 23s 779ms/step - loss: 0.4570 - accuracy: 0.7434 - tp: 434.0000 - auc: 0.8614 - fn: 92.0000 - val_loss: 0.0984 - val_accuracy: 0.9820 - val_tp: 2.0000 - val_auc: 0.7960 - val_fn: 82.0000\n",
      "Epoch 57/350\n",
      "29/28 [==============================] - 23s 780ms/step - loss: 0.4393 - accuracy: 0.7405 - tp: 452.0000 - auc: 0.8703 - fn: 74.0000 - val_loss: 0.1063 - val_accuracy: 0.9785 - val_tp: 3.0000 - val_auc: 0.8185 - val_fn: 84.0000\n",
      "Epoch 58/350\n",
      "29/28 [==============================] - 24s 814ms/step - loss: 0.4485 - accuracy: 0.7428 - tp: 443.0000 - auc: 0.8641 - fn: 80.0000 - val_loss: 0.0999 - val_accuracy: 0.9816 - val_tp: 0.0000e+00 - val_auc: 0.8093 - val_fn: 87.0000\n",
      "Epoch 59/350\n",
      "29/28 [==============================] - 23s 785ms/step - loss: 0.4418 - accuracy: 0.7419 - tp: 460.0000 - auc: 0.8711 - fn: 66.0000 - val_loss: 0.0956 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_auc: 0.8400 - val_fn: 85.0000\n",
      "Epoch 60/350\n",
      "29/28 [==============================] - 23s 796ms/step - loss: 0.4398 - accuracy: 0.7535 - tp: 445.0000 - auc: 0.8726 - fn: 82.0000 - val_loss: 0.1039 - val_accuracy: 0.9797 - val_tp: 4.0000 - val_auc: 0.8292 - val_fn: 80.0000\n",
      "Epoch 61/350\n",
      "29/28 [==============================] - 22s 774ms/step - loss: 0.4350 - accuracy: 0.7513 - tp: 458.0000 - auc: 0.8766 - fn: 73.0000 - val_loss: 0.0949 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_auc: 0.8220 - val_fn: 86.0000\n",
      "Epoch 62/350\n",
      "29/28 [==============================] - 23s 785ms/step - loss: 0.4426 - accuracy: 0.7474 - tp: 433.0000 - auc: 0.8690 - fn: 87.0000 - val_loss: 0.0955 - val_accuracy: 0.9832 - val_tp: 0.0000e+00 - val_auc: 0.8066 - val_fn: 84.0000\n",
      "Epoch 63/350\n",
      "29/28 [==============================] - 22s 758ms/step - loss: 0.4432 - accuracy: 0.7438 - tp: 453.0000 - auc: 0.8712 - fn: 83.0000 - val_loss: 0.1362 - val_accuracy: 0.9633 - val_tp: 15.0000 - val_auc: 0.8322 - val_fn: 71.0000\n",
      "Epoch 64/350\n",
      "29/28 [==============================] - 22s 762ms/step - loss: 0.4248 - accuracy: 0.7560 - tp: 446.0000 - auc: 0.8801 - fn: 80.0000 - val_loss: 0.1038 - val_accuracy: 0.9797 - val_tp: 2.0000 - val_auc: 0.8239 - val_fn: 85.0000\n",
      "Epoch 65/350\n",
      "29/28 [==============================] - 21s 730ms/step - loss: 0.4301 - accuracy: 0.7581 - tp: 452.0000 - auc: 0.8810 - fn: 78.0000 - val_loss: 0.1051 - val_accuracy: 0.9793 - val_tp: 11.0000 - val_auc: 0.8391 - val_fn: 77.0000\n",
      "Epoch 66/350\n",
      "29/28 [==============================] - 22s 750ms/step - loss: 0.4251 - accuracy: 0.7620 - tp: 446.0000 - auc: 0.8835 - fn: 84.0000 - val_loss: 0.1207 - val_accuracy: 0.9697 - val_tp: 6.0000 - val_auc: 0.8055 - val_fn: 81.0000\n",
      "Epoch 67/350\n",
      "29/28 [==============================] - 24s 833ms/step - loss: 0.4390 - accuracy: 0.7586 - tp: 438.0000 - auc: 0.8740 - fn: 87.0000 - val_loss: 0.1068 - val_accuracy: 0.9795 - val_tp: 4.0000 - val_auc: 0.7963 - val_fn: 81.0000\n",
      "Epoch 68/350\n",
      "29/28 [==============================] - 22s 742ms/step - loss: 0.4224 - accuracy: 0.7571 - tp: 458.0000 - auc: 0.8837 - fn: 69.0000 - val_loss: 0.1339 - val_accuracy: 0.9627 - val_tp: 12.0000 - val_auc: 0.7922 - val_fn: 75.0000\n",
      "Epoch 69/350\n",
      "29/28 [==============================] - 21s 728ms/step - loss: 0.4239 - accuracy: 0.7565 - tp: 454.0000 - auc: 0.8809 - fn: 72.0000 - val_loss: 0.1204 - val_accuracy: 0.9715 - val_tp: 4.0000 - val_auc: 0.8185 - val_fn: 79.0000\n",
      "Epoch 70/350\n",
      "29/28 [==============================] - 21s 729ms/step - loss: 0.4111 - accuracy: 0.7635 - tp: 457.0000 - auc: 0.8906 - fn: 72.0000 - val_loss: 0.1880 - val_accuracy: 0.9414 - val_tp: 25.0000 - val_auc: 0.7867 - val_fn: 62.0000\n",
      "Epoch 71/350\n",
      "29/28 [==============================] - 23s 784ms/step - loss: 0.4142 - accuracy: 0.7637 - tp: 451.0000 - auc: 0.8865 - fn: 70.0000 - val_loss: 0.1226 - val_accuracy: 0.9705 - val_tp: 9.0000 - val_auc: 0.8023 - val_fn: 79.0000\n",
      "Epoch 72/350\n",
      "29/28 [==============================] - 22s 764ms/step - loss: 0.4178 - accuracy: 0.7562 - tp: 454.0000 - auc: 0.8852 - fn: 75.0000 - val_loss: 0.1044 - val_accuracy: 0.9785 - val_tp: 0.0000e+00 - val_auc: 0.8238 - val_fn: 88.0000\n",
      "Epoch 73/350\n",
      "29/28 [==============================] - 22s 771ms/step - loss: 0.4235 - accuracy: 0.7584 - tp: 456.0000 - auc: 0.8843 - fn: 72.0000 - val_loss: 0.1424 - val_accuracy: 0.9592 - val_tp: 16.0000 - val_auc: 0.7942 - val_fn: 71.0000\n",
      "Epoch 74/350\n",
      "29/28 [==============================] - 22s 769ms/step - loss: 0.4211 - accuracy: 0.7629 - tp: 455.0000 - auc: 0.8842 - fn: 77.0000 - val_loss: 0.1612 - val_accuracy: 0.9434 - val_tp: 24.0000 - val_auc: 0.8349 - val_fn: 61.0000\n",
      "Epoch 75/350\n",
      "29/28 [==============================] - 23s 796ms/step - loss: 0.4158 - accuracy: 0.7636 - tp: 461.0000 - auc: 0.8890 - fn: 74.0000 - val_loss: 0.1330 - val_accuracy: 0.9656 - val_tp: 18.0000 - val_auc: 0.8186 - val_fn: 69.0000\n",
      "Epoch 76/350\n",
      "29/28 [==============================] - 23s 791ms/step - loss: 0.4101 - accuracy: 0.7711 - tp: 443.0000 - auc: 0.8904 - fn: 83.0000 - val_loss: 0.1615 - val_accuracy: 0.9453 - val_tp: 23.0000 - val_auc: 0.8501 - val_fn: 58.0000\n",
      "Epoch 77/350\n",
      "29/28 [==============================] - 22s 762ms/step - loss: 0.4140 - accuracy: 0.7653 - tp: 453.0000 - auc: 0.8877 - fn: 71.0000 - val_loss: 0.1163 - val_accuracy: 0.9768 - val_tp: 10.0000 - val_auc: 0.7872 - val_fn: 77.0000\n",
      "Epoch 78/350\n",
      "29/28 [==============================] - 24s 834ms/step - loss: 0.4124 - accuracy: 0.7598 - tp: 453.0000 - auc: 0.8849 - fn: 71.0000 - val_loss: 0.1299 - val_accuracy: 0.9691 - val_tp: 12.0000 - val_auc: 0.8579 - val_fn: 74.0000\n",
      "Epoch 79/350\n",
      "29/28 [==============================] - 23s 785ms/step - loss: 0.4094 - accuracy: 0.7696 - tp: 460.0000 - auc: 0.8921 - fn: 67.0000 - val_loss: 0.1122 - val_accuracy: 0.9771 - val_tp: 9.0000 - val_auc: 0.8222 - val_fn: 78.0000\n",
      "Epoch 80/350\n",
      "29/28 [==============================] - 23s 783ms/step - loss: 0.4161 - accuracy: 0.7600 - tp: 447.0000 - auc: 0.8864 - fn: 76.0000 - val_loss: 0.1234 - val_accuracy: 0.9668 - val_tp: 13.0000 - val_auc: 0.8283 - val_fn: 74.0000\n",
      "Epoch 81/350\n",
      "29/28 [==============================] - 23s 779ms/step - loss: 0.4167 - accuracy: 0.7686 - tp: 455.0000 - auc: 0.8870 - fn: 75.0000 - val_loss: 0.1174 - val_accuracy: 0.9727 - val_tp: 10.0000 - val_auc: 0.8430 - val_fn: 75.0000\n",
      "Epoch 82/350\n",
      "29/28 [==============================] - 22s 768ms/step - loss: 0.4205 - accuracy: 0.7549 - tp: 450.0000 - auc: 0.8834 - fn: 74.0000 - val_loss: 0.1707 - val_accuracy: 0.9420 - val_tp: 25.0000 - val_auc: 0.8382 - val_fn: 59.0000\n",
      "Epoch 83/350\n",
      "29/28 [==============================] - 23s 809ms/step - loss: 0.4197 - accuracy: 0.7551 - tp: 452.0000 - auc: 0.8862 - fn: 76.0000 - val_loss: 0.1500 - val_accuracy: 0.9486 - val_tp: 15.0000 - val_auc: 0.8171 - val_fn: 71.0000\n",
      "Epoch 84/350\n",
      "29/28 [==============================] - 23s 805ms/step - loss: 0.4212 - accuracy: 0.7671 - tp: 441.0000 - auc: 0.8837 - fn: 84.0000 - val_loss: 0.1188 - val_accuracy: 0.9732 - val_tp: 15.0000 - val_auc: 0.8435 - val_fn: 72.0000\n",
      "Epoch 85/350\n",
      "29/28 [==============================] - 23s 796ms/step - loss: 0.4006 - accuracy: 0.7740 - tp: 464.0000 - auc: 0.8973 - fn: 71.0000 - val_loss: 0.1100 - val_accuracy: 0.9738 - val_tp: 5.0000 - val_auc: 0.8428 - val_fn: 75.0000\n",
      "Epoch 86/350\n",
      "29/28 [==============================] - 22s 770ms/step - loss: 0.4222 - accuracy: 0.7610 - tp: 452.0000 - auc: 0.8832 - fn: 70.0000 - val_loss: 0.1254 - val_accuracy: 0.9658 - val_tp: 14.0000 - val_auc: 0.8548 - val_fn: 72.0000\n",
      "Epoch 87/350\n",
      "29/28 [==============================] - 23s 800ms/step - loss: 0.4050 - accuracy: 0.7666 - tp: 460.0000 - auc: 0.8925 - fn: 67.0000 - val_loss: 0.1478 - val_accuracy: 0.9494 - val_tp: 22.0000 - val_auc: 0.8557 - val_fn: 66.0000\n",
      "Epoch 88/350\n",
      "29/28 [==============================] - 22s 769ms/step - loss: 0.3967 - accuracy: 0.7664 - tp: 471.0000 - auc: 0.8937 - fn: 58.0000 - val_loss: 0.1789 - val_accuracy: 0.9252 - val_tp: 25.0000 - val_auc: 0.8252 - val_fn: 61.0000\n",
      "Epoch 89/350\n",
      "29/28 [==============================] - 22s 756ms/step - loss: 0.3982 - accuracy: 0.7754 - tp: 462.0000 - auc: 0.8982 - fn: 68.0000 - val_loss: 0.1582 - val_accuracy: 0.9432 - val_tp: 30.0000 - val_auc: 0.8567 - val_fn: 59.0000\n",
      "Epoch 90/350\n",
      "29/28 [==============================] - 23s 806ms/step - loss: 0.4011 - accuracy: 0.7701 - tp: 459.0000 - auc: 0.8948 - fn: 68.0000 - val_loss: 0.1523 - val_accuracy: 0.9490 - val_tp: 23.0000 - val_auc: 0.8563 - val_fn: 62.0000\n",
      "Epoch 91/350\n",
      "29/28 [==============================] - 22s 744ms/step - loss: 0.4050 - accuracy: 0.7787 - tp: 463.0000 - auc: 0.8947 - fn: 70.0000 - val_loss: 0.1221 - val_accuracy: 0.9689 - val_tp: 10.0000 - val_auc: 0.8526 - val_fn: 76.0000\n",
      "Epoch 92/350\n",
      "29/28 [==============================] - 23s 777ms/step - loss: 0.3894 - accuracy: 0.7864 - tp: 452.0000 - auc: 0.9040 - fn: 75.0000 - val_loss: 0.1330 - val_accuracy: 0.9611 - val_tp: 20.0000 - val_auc: 0.8468 - val_fn: 65.0000\n",
      "Epoch 93/350\n",
      "29/28 [==============================] - 22s 770ms/step - loss: 0.3854 - accuracy: 0.7825 - tp: 474.0000 - auc: 0.9056 - fn: 61.0000 - val_loss: 0.1167 - val_accuracy: 0.9730 - val_tp: 4.0000 - val_auc: 0.7887 - val_fn: 81.0000\n",
      "Epoch 94/350\n",
      "29/28 [==============================] - 22s 772ms/step - loss: 0.4003 - accuracy: 0.7732 - tp: 456.0000 - auc: 0.8956 - fn: 74.0000 - val_loss: 0.1467 - val_accuracy: 0.9492 - val_tp: 25.0000 - val_auc: 0.8479 - val_fn: 63.0000\n",
      "Epoch 95/350\n",
      "29/28 [==============================] - 23s 799ms/step - loss: 0.4028 - accuracy: 0.7775 - tp: 453.0000 - auc: 0.8957 - fn: 76.0000 - val_loss: 0.1868 - val_accuracy: 0.9322 - val_tp: 26.0000 - val_auc: 0.8218 - val_fn: 60.0000\n",
      "Epoch 96/350\n",
      "29/28 [==============================] - 22s 750ms/step - loss: 0.3989 - accuracy: 0.7732 - tp: 458.0000 - auc: 0.8961 - fn: 67.0000 - val_loss: 0.1889 - val_accuracy: 0.9246 - val_tp: 35.0000 - val_auc: 0.8584 - val_fn: 50.0000\n",
      "Epoch 97/350\n",
      "29/28 [==============================] - 23s 785ms/step - loss: 0.3957 - accuracy: 0.7760 - tp: 453.0000 - auc: 0.8967 - fn: 71.0000 - val_loss: 0.1648 - val_accuracy: 0.9477 - val_tp: 26.0000 - val_auc: 0.8497 - val_fn: 61.0000\n",
      "Epoch 98/350\n",
      "29/28 [==============================] - 23s 803ms/step - loss: 0.4097 - accuracy: 0.7697 - tp: 455.0000 - auc: 0.8923 - fn: 72.0000 - val_loss: 0.1659 - val_accuracy: 0.9410 - val_tp: 16.0000 - val_auc: 0.8205 - val_fn: 68.0000\n",
      "Epoch 99/350\n",
      "29/28 [==============================] - 21s 733ms/step - loss: 0.3972 - accuracy: 0.7796 - tp: 454.0000 - auc: 0.8975 - fn: 71.0000 - val_loss: 0.1294 - val_accuracy: 0.9666 - val_tp: 18.0000 - val_auc: 0.8414 - val_fn: 66.0000\n",
      "Epoch 100/350\n",
      "29/28 [==============================] - 23s 806ms/step - loss: 0.4138 - accuracy: 0.7557 - tp: 463.0000 - auc: 0.8895 - fn: 66.0000 - val_loss: 0.1876 - val_accuracy: 0.9268 - val_tp: 24.0000 - val_auc: 0.8288 - val_fn: 62.0000\n",
      "Epoch 101/350\n",
      "29/28 [==============================] - 23s 794ms/step - loss: 0.3975 - accuracy: 0.7841 - tp: 460.0000 - auc: 0.8986 - fn: 70.0000 - val_loss: 0.1254 - val_accuracy: 0.9643 - val_tp: 21.0000 - val_auc: 0.8618 - val_fn: 60.0000\n",
      "Epoch 102/350\n",
      "29/28 [==============================] - 23s 782ms/step - loss: 0.3749 - accuracy: 0.7825 - tp: 472.0000 - auc: 0.9083 - fn: 54.0000 - val_loss: 0.1210 - val_accuracy: 0.9734 - val_tp: 13.0000 - val_auc: 0.8450 - val_fn: 75.0000\n",
      "Epoch 103/350\n",
      "29/28 [==============================] - 22s 766ms/step - loss: 0.3900 - accuracy: 0.7904 - tp: 451.0000 - auc: 0.9027 - fn: 70.0000 - val_loss: 0.1124 - val_accuracy: 0.9740 - val_tp: 8.0000 - val_auc: 0.8370 - val_fn: 79.0000\n",
      "Epoch 104/350\n",
      "29/28 [==============================] - 22s 753ms/step - loss: 0.3740 - accuracy: 0.7947 - tp: 479.0000 - auc: 0.9093 - fn: 54.0000 - val_loss: 0.1264 - val_accuracy: 0.9660 - val_tp: 13.0000 - val_auc: 0.8490 - val_fn: 76.0000\n",
      "Epoch 105/350\n",
      "29/28 [==============================] - 23s 778ms/step - loss: 0.3864 - accuracy: 0.7907 - tp: 457.0000 - auc: 0.9057 - fn: 69.0000 - val_loss: 0.1476 - val_accuracy: 0.9539 - val_tp: 21.0000 - val_auc: 0.8325 - val_fn: 65.0000\n",
      "Epoch 106/350\n",
      "29/28 [==============================] - 22s 770ms/step - loss: 0.3769 - accuracy: 0.7885 - tp: 469.0000 - auc: 0.9075 - fn: 62.0000 - val_loss: 0.1564 - val_accuracy: 0.9467 - val_tp: 28.0000 - val_auc: 0.8444 - val_fn: 59.0000\n",
      "Epoch 107/350\n",
      "29/28 [==============================] - 22s 771ms/step - loss: 0.3772 - accuracy: 0.7786 - tp: 467.0000 - auc: 0.9075 - fn: 59.0000 - val_loss: 0.2186 - val_accuracy: 0.9189 - val_tp: 29.0000 - val_auc: 0.8297 - val_fn: 58.0000\n",
      "Epoch 108/350\n",
      "29/28 [==============================] - 21s 731ms/step - loss: 0.3860 - accuracy: 0.7924 - tp: 463.0000 - auc: 0.9063 - fn: 66.0000 - val_loss: 0.2996 - val_accuracy: 0.8771 - val_tp: 47.0000 - val_auc: 0.8557 - val_fn: 40.0000\n",
      "Epoch 109/350\n",
      "29/28 [==============================] - 22s 767ms/step - loss: 0.3911 - accuracy: 0.7920 - tp: 464.0000 - auc: 0.9023 - fn: 64.0000 - val_loss: 0.2782 - val_accuracy: 0.8789 - val_tp: 37.0000 - val_auc: 0.8418 - val_fn: 50.0000\n",
      "Epoch 110/350\n",
      "29/28 [==============================] - 22s 765ms/step - loss: 0.3906 - accuracy: 0.7824 - tp: 459.0000 - auc: 0.9017 - fn: 68.0000 - val_loss: 0.1934 - val_accuracy: 0.9293 - val_tp: 20.0000 - val_auc: 0.8087 - val_fn: 65.0000\n",
      "Epoch 111/350\n",
      "29/28 [==============================] - 22s 754ms/step - loss: 0.3575 - accuracy: 0.8033 - tp: 470.0000 - auc: 0.9188 - fn: 54.0000 - val_loss: 0.1728 - val_accuracy: 0.9355 - val_tp: 28.0000 - val_auc: 0.8467 - val_fn: 58.0000\n",
      "Epoch 112/350\n",
      "29/28 [==============================] - 23s 777ms/step - loss: 0.3700 - accuracy: 0.8034 - tp: 471.0000 - auc: 0.9132 - fn: 56.0000 - val_loss: 0.2949 - val_accuracy: 0.8871 - val_tp: 36.0000 - val_auc: 0.8313 - val_fn: 50.0000\n",
      "Epoch 113/350\n",
      "29/28 [==============================] - 22s 765ms/step - loss: 0.3711 - accuracy: 0.7981 - tp: 458.0000 - auc: 0.9113 - fn: 63.0000 - val_loss: 0.2676 - val_accuracy: 0.9014 - val_tp: 28.0000 - val_auc: 0.8237 - val_fn: 56.0000\n",
      "Epoch 114/350\n",
      "29/28 [==============================] - 24s 835ms/step - loss: 0.3788 - accuracy: 0.7957 - tp: 479.0000 - auc: 0.9096 - fn: 60.0000 - val_loss: 0.3123 - val_accuracy: 0.8783 - val_tp: 51.0000 - val_auc: 0.8379 - val_fn: 37.0000\n",
      "Epoch 115/350\n",
      "29/28 [==============================] - 23s 799ms/step - loss: 0.3794 - accuracy: 0.7929 - tp: 468.0000 - auc: 0.9076 - fn: 64.0000 - val_loss: 0.1737 - val_accuracy: 0.9379 - val_tp: 27.0000 - val_auc: 0.8357 - val_fn: 61.0000\n",
      "Epoch 116/350\n",
      "29/28 [==============================] - 22s 767ms/step - loss: 0.3716 - accuracy: 0.7862 - tp: 461.0000 - auc: 0.9091 - fn: 59.0000 - val_loss: 0.1813 - val_accuracy: 0.9322 - val_tp: 32.0000 - val_auc: 0.8435 - val_fn: 52.0000\n",
      "Epoch 117/350\n",
      "29/28 [==============================] - 22s 772ms/step - loss: 0.3862 - accuracy: 0.7848 - tp: 474.0000 - auc: 0.9020 - fn: 56.0000 - val_loss: 0.5933 - val_accuracy: 0.7996 - val_tp: 64.0000 - val_auc: 0.8447 - val_fn: 23.0000\n",
      "Epoch 118/350\n",
      "29/28 [==============================] - 22s 750ms/step - loss: 0.3586 - accuracy: 0.7953 - tp: 475.0000 - auc: 0.9158 - fn: 53.0000 - val_loss: 0.1876 - val_accuracy: 0.9367 - val_tp: 26.0000 - val_auc: 0.8460 - val_fn: 61.0000\n",
      "Epoch 119/350\n",
      "29/28 [==============================] - 25s 846ms/step - loss: 0.3763 - accuracy: 0.7968 - tp: 476.0000 - auc: 0.9087 - fn: 54.0000 - val_loss: 0.2129 - val_accuracy: 0.9232 - val_tp: 26.0000 - val_auc: 0.8118 - val_fn: 54.0000\n",
      "Epoch 120/350\n",
      "29/28 [==============================] - 22s 768ms/step - loss: 0.3769 - accuracy: 0.7916 - tp: 461.0000 - auc: 0.9094 - fn: 63.0000 - val_loss: 0.1970 - val_accuracy: 0.9256 - val_tp: 26.0000 - val_auc: 0.8397 - val_fn: 60.0000\n",
      "Epoch 121/350\n",
      "29/28 [==============================] - 23s 782ms/step - loss: 0.3629 - accuracy: 0.8070 - tp: 459.0000 - auc: 0.9148 - fn: 60.0000 - val_loss: 0.2481 - val_accuracy: 0.8994 - val_tp: 39.0000 - val_auc: 0.8461 - val_fn: 46.0000\n",
      "Epoch 122/350\n",
      "29/28 [==============================] - 23s 800ms/step - loss: 0.3732 - accuracy: 0.7923 - tp: 472.0000 - auc: 0.9109 - fn: 62.0000 - val_loss: 0.2010 - val_accuracy: 0.9211 - val_tp: 31.0000 - val_auc: 0.8485 - val_fn: 52.0000\n",
      "Epoch 123/350\n",
      "29/28 [==============================] - 24s 832ms/step - loss: 0.3594 - accuracy: 0.8104 - tp: 464.0000 - auc: 0.9175 - fn: 59.0000 - val_loss: 0.2019 - val_accuracy: 0.9219 - val_tp: 24.0000 - val_auc: 0.8300 - val_fn: 58.0000\n",
      "Epoch 124/350\n",
      "29/28 [==============================] - 21s 741ms/step - loss: 0.3749 - accuracy: 0.7977 - tp: 458.0000 - auc: 0.9093 - fn: 65.0000 - val_loss: 0.1830 - val_accuracy: 0.9340 - val_tp: 31.0000 - val_auc: 0.8527 - val_fn: 57.0000\n",
      "Epoch 125/350\n",
      "29/28 [==============================] - 23s 797ms/step - loss: 0.3661 - accuracy: 0.8021 - tp: 468.0000 - auc: 0.9153 - fn: 63.0000 - val_loss: 0.1375 - val_accuracy: 0.9619 - val_tp: 16.0000 - val_auc: 0.8328 - val_fn: 70.0000\n",
      "Epoch 126/350\n",
      "29/28 [==============================] - 23s 787ms/step - loss: 0.3553 - accuracy: 0.8008 - tp: 472.0000 - auc: 0.9190 - fn: 55.0000 - val_loss: 0.1629 - val_accuracy: 0.9471 - val_tp: 14.0000 - val_auc: 0.8420 - val_fn: 76.0000\n",
      "Epoch 127/350\n",
      "29/28 [==============================] - 23s 783ms/step - loss: 0.3724 - accuracy: 0.8025 - tp: 464.0000 - auc: 0.9132 - fn: 62.0000 - val_loss: 0.1900 - val_accuracy: 0.9268 - val_tp: 35.0000 - val_auc: 0.8588 - val_fn: 53.0000\n",
      "Epoch 128/350\n",
      "29/28 [==============================] - 22s 747ms/step - loss: 0.3518 - accuracy: 0.8047 - tp: 481.0000 - auc: 0.9210 - fn: 50.0000 - val_loss: 0.1680 - val_accuracy: 0.9396 - val_tp: 30.0000 - val_auc: 0.8382 - val_fn: 54.0000\n",
      "Epoch 129/350\n",
      "29/28 [==============================] - 23s 784ms/step - loss: 0.3547 - accuracy: 0.8016 - tp: 472.0000 - auc: 0.9179 - fn: 53.0000 - val_loss: 0.1319 - val_accuracy: 0.9650 - val_tp: 18.0000 - val_auc: 0.8018 - val_fn: 65.0000\n",
      "Epoch 130/350\n",
      "29/28 [==============================] - 22s 771ms/step - loss: 0.3616 - accuracy: 0.8086 - tp: 470.0000 - auc: 0.9173 - fn: 65.0000 - val_loss: 0.1463 - val_accuracy: 0.9557 - val_tp: 13.0000 - val_auc: 0.8162 - val_fn: 74.0000\n",
      "Epoch 131/350\n",
      "29/28 [==============================] - 24s 835ms/step - loss: 0.3364 - accuracy: 0.8139 - tp: 485.0000 - auc: 0.9279 - fn: 45.0000 - val_loss: 0.1816 - val_accuracy: 0.9391 - val_tp: 28.0000 - val_auc: 0.8633 - val_fn: 58.0000\n",
      "Epoch 132/350\n",
      "29/28 [==============================] - 21s 738ms/step - loss: 0.3443 - accuracy: 0.8116 - tp: 474.0000 - auc: 0.9250 - fn: 53.0000 - val_loss: 0.3392 - val_accuracy: 0.8586 - val_tp: 50.0000 - val_auc: 0.8449 - val_fn: 35.0000\n",
      "Epoch 133/350\n",
      "29/28 [==============================] - 22s 752ms/step - loss: 0.3304 - accuracy: 0.8151 - tp: 478.0000 - auc: 0.9298 - fn: 51.0000 - val_loss: 0.1744 - val_accuracy: 0.9432 - val_tp: 22.0000 - val_auc: 0.8117 - val_fn: 66.0000\n",
      "Epoch 134/350\n",
      "29/28 [==============================] - 23s 802ms/step - loss: 0.3510 - accuracy: 0.8124 - tp: 475.0000 - auc: 0.9230 - fn: 57.0000 - val_loss: 0.2133 - val_accuracy: 0.9258 - val_tp: 31.0000 - val_auc: 0.8403 - val_fn: 53.0000\n",
      "Epoch 135/350\n",
      "29/28 [==============================] - 23s 800ms/step - loss: 0.3558 - accuracy: 0.8055 - tp: 471.0000 - auc: 0.9209 - fn: 60.0000 - val_loss: 0.1960 - val_accuracy: 0.9326 - val_tp: 25.0000 - val_auc: 0.8429 - val_fn: 58.0000\n",
      "Epoch 136/350\n",
      "29/28 [==============================] - 22s 764ms/step - loss: 0.3529 - accuracy: 0.8108 - tp: 467.0000 - auc: 0.9218 - fn: 60.0000 - val_loss: 0.2513 - val_accuracy: 0.9008 - val_tp: 45.0000 - val_auc: 0.8499 - val_fn: 48.0000\n",
      "Epoch 137/350\n",
      "29/28 [==============================] - 22s 768ms/step - loss: 0.3410 - accuracy: 0.8065 - tp: 479.0000 - auc: 0.9256 - fn: 46.0000 - val_loss: 0.4325 - val_accuracy: 0.8289 - val_tp: 49.0000 - val_auc: 0.8452 - val_fn: 34.0000\n",
      "Epoch 138/350\n",
      "29/28 [==============================] - 22s 772ms/step - loss: 0.3440 - accuracy: 0.8212 - tp: 472.0000 - auc: 0.9263 - fn: 55.0000 - val_loss: 0.1912 - val_accuracy: 0.9342 - val_tp: 34.0000 - val_auc: 0.8576 - val_fn: 53.0000\n",
      "Epoch 139/350\n",
      "29/28 [==============================] - 23s 797ms/step - loss: 0.3545 - accuracy: 0.8147 - tp: 464.0000 - auc: 0.9203 - fn: 57.0000 - val_loss: 0.3406 - val_accuracy: 0.8721 - val_tp: 51.0000 - val_auc: 0.8425 - val_fn: 33.0000\n",
      "Epoch 140/350\n",
      "29/28 [==============================] - 22s 768ms/step - loss: 0.3342 - accuracy: 0.8185 - tp: 480.0000 - auc: 0.9286 - fn: 47.0000 - val_loss: 0.1915 - val_accuracy: 0.9314 - val_tp: 29.0000 - val_auc: 0.8368 - val_fn: 53.0000\n",
      "Epoch 141/350\n",
      "29/28 [==============================] - 22s 764ms/step - loss: 0.3314 - accuracy: 0.8210 - tp: 490.0000 - auc: 0.9310 - fn: 43.0000 - val_loss: 0.2130 - val_accuracy: 0.9221 - val_tp: 31.0000 - val_auc: 0.8332 - val_fn: 52.0000\n",
      "Epoch 142/350\n",
      "29/28 [==============================] - 24s 819ms/step - loss: 0.3361 - accuracy: 0.8195 - tp: 479.0000 - auc: 0.9272 - fn: 47.0000 - val_loss: 0.2917 - val_accuracy: 0.8859 - val_tp: 51.0000 - val_auc: 0.8548 - val_fn: 38.0000\n",
      "Epoch 143/350\n",
      "29/28 [==============================] - 21s 725ms/step - loss: 0.3254 - accuracy: 0.8261 - tp: 481.0000 - auc: 0.9331 - fn: 45.0000 - val_loss: 0.2189 - val_accuracy: 0.9137 - val_tp: 32.0000 - val_auc: 0.8527 - val_fn: 54.0000\n",
      "Epoch 144/350\n",
      "29/28 [==============================] - 22s 768ms/step - loss: 0.3296 - accuracy: 0.8224 - tp: 475.0000 - auc: 0.9309 - fn: 52.0000 - val_loss: 0.1761 - val_accuracy: 0.9430 - val_tp: 23.0000 - val_auc: 0.7884 - val_fn: 61.0000\n",
      "Epoch 145/350\n",
      "29/28 [==============================] - 23s 785ms/step - loss: 0.3306 - accuracy: 0.8132 - tp: 485.0000 - auc: 0.9286 - fn: 45.0000 - val_loss: 0.5406 - val_accuracy: 0.8080 - val_tp: 57.0000 - val_auc: 0.8206 - val_fn: 30.0000\n",
      "Epoch 146/350\n",
      "29/28 [==============================] - 22s 754ms/step - loss: 0.3261 - accuracy: 0.8314 - tp: 482.0000 - auc: 0.9347 - fn: 47.0000 - val_loss: 0.3674 - val_accuracy: 0.8549 - val_tp: 45.0000 - val_auc: 0.8310 - val_fn: 40.0000\n",
      "Epoch 147/350\n",
      "29/28 [==============================] - 22s 746ms/step - loss: 0.3355 - accuracy: 0.8212 - tp: 473.0000 - auc: 0.9286 - fn: 49.0000 - val_loss: 0.2079 - val_accuracy: 0.9268 - val_tp: 29.0000 - val_auc: 0.8181 - val_fn: 56.0000\n",
      "Epoch 148/350\n",
      "29/28 [==============================] - 23s 793ms/step - loss: 0.3495 - accuracy: 0.8248 - tp: 465.0000 - auc: 0.9238 - fn: 66.0000 - val_loss: 0.1903 - val_accuracy: 0.9311 - val_tp: 30.0000 - val_auc: 0.8399 - val_fn: 57.0000\n",
      "Epoch 149/350\n",
      "29/28 [==============================] - 22s 750ms/step - loss: 0.3316 - accuracy: 0.8215 - tp: 480.0000 - auc: 0.9307 - fn: 49.0000 - val_loss: 0.3058 - val_accuracy: 0.8742 - val_tp: 36.0000 - val_auc: 0.8317 - val_fn: 48.0000\n",
      "Epoch 150/350\n",
      "29/28 [==============================] - 23s 806ms/step - loss: 0.3208 - accuracy: 0.8300 - tp: 477.0000 - auc: 0.9342 - fn: 51.0000 - val_loss: 0.3289 - val_accuracy: 0.8771 - val_tp: 48.0000 - val_auc: 0.8479 - val_fn: 37.0000\n",
      "Epoch 151/350\n",
      "29/28 [==============================] - 22s 770ms/step - loss: 0.3316 - accuracy: 0.8249 - tp: 481.0000 - auc: 0.9308 - fn: 47.0000 - val_loss: 0.3794 - val_accuracy: 0.8508 - val_tp: 48.0000 - val_auc: 0.8129 - val_fn: 40.0000\n",
      "Epoch 152/350\n",
      "29/28 [==============================] - 22s 768ms/step - loss: 0.3258 - accuracy: 0.8277 - tp: 480.0000 - auc: 0.9335 - fn: 45.0000 - val_loss: 0.6942 - val_accuracy: 0.7613 - val_tp: 67.0000 - val_auc: 0.8168 - val_fn: 19.0000\n",
      "Epoch 153/350\n",
      "29/28 [==============================] - 23s 788ms/step - loss: 0.3393 - accuracy: 0.8215 - tp: 464.0000 - auc: 0.9282 - fn: 62.0000 - val_loss: 0.4512 - val_accuracy: 0.8219 - val_tp: 49.0000 - val_auc: 0.8152 - val_fn: 41.0000\n",
      "Epoch 154/350\n",
      "29/28 [==============================] - 22s 752ms/step - loss: 0.3180 - accuracy: 0.8316 - tp: 484.0000 - auc: 0.9368 - fn: 44.0000 - val_loss: 0.3301 - val_accuracy: 0.8621 - val_tp: 58.0000 - val_auc: 0.8614 - val_fn: 28.0000\n",
      "Epoch 155/350\n",
      "29/28 [==============================] - 21s 727ms/step - loss: 0.3084 - accuracy: 0.8305 - tp: 477.0000 - auc: 0.9391 - fn: 50.0000 - val_loss: 0.5552 - val_accuracy: 0.7896 - val_tp: 56.0000 - val_auc: 0.8033 - val_fn: 30.0000\n",
      "Epoch 156/350\n",
      "29/28 [==============================] - 22s 767ms/step - loss: 0.3047 - accuracy: 0.8401 - tp: 489.0000 - auc: 0.9414 - fn: 45.0000 - val_loss: 0.2308 - val_accuracy: 0.9156 - val_tp: 41.0000 - val_auc: 0.8409 - val_fn: 43.0000\n",
      "Epoch 157/350\n",
      "29/28 [==============================] - 22s 760ms/step - loss: 0.3210 - accuracy: 0.8366 - tp: 473.0000 - auc: 0.9365 - fn: 52.0000 - val_loss: 0.4150 - val_accuracy: 0.8383 - val_tp: 48.0000 - val_auc: 0.8122 - val_fn: 40.0000\n",
      "Epoch 158/350\n",
      "29/28 [==============================] - 23s 776ms/step - loss: 0.3307 - accuracy: 0.8214 - tp: 485.0000 - auc: 0.9322 - fn: 48.0000 - val_loss: 0.1426 - val_accuracy: 0.9605 - val_tp: 21.0000 - val_auc: 0.8347 - val_fn: 63.0000\n",
      "Epoch 159/350\n",
      "29/28 [==============================] - 21s 741ms/step - loss: 0.3021 - accuracy: 0.8395 - tp: 480.0000 - auc: 0.9427 - fn: 39.0000 - val_loss: 0.2139 - val_accuracy: 0.9293 - val_tp: 33.0000 - val_auc: 0.8362 - val_fn: 55.0000\n",
      "Epoch 160/350\n",
      "29/28 [==============================] - 23s 783ms/step - loss: 0.3001 - accuracy: 0.8505 - tp: 489.0000 - auc: 0.9448 - fn: 42.0000 - val_loss: 0.2277 - val_accuracy: 0.9146 - val_tp: 41.0000 - val_auc: 0.8390 - val_fn: 47.0000\n",
      "Epoch 161/350\n",
      "29/28 [==============================] - 24s 813ms/step - loss: 0.2936 - accuracy: 0.8503 - tp: 483.0000 - auc: 0.9465 - fn: 40.0000 - val_loss: 0.1673 - val_accuracy: 0.9439 - val_tp: 38.0000 - val_auc: 0.8619 - val_fn: 49.0000\n",
      "Epoch 162/350\n",
      "29/28 [==============================] - 23s 784ms/step - loss: 0.3000 - accuracy: 0.8461 - tp: 484.0000 - auc: 0.9441 - fn: 42.0000 - val_loss: 0.2062 - val_accuracy: 0.9197 - val_tp: 36.0000 - val_auc: 0.8409 - val_fn: 47.0000\n",
      "Epoch 163/350\n",
      "29/28 [==============================] - 22s 750ms/step - loss: 0.2938 - accuracy: 0.8516 - tp: 493.0000 - auc: 0.9467 - fn: 38.0000 - val_loss: 0.1792 - val_accuracy: 0.9469 - val_tp: 33.0000 - val_auc: 0.8060 - val_fn: 52.0000\n",
      "Epoch 164/350\n",
      "29/28 [==============================] - 23s 795ms/step - loss: 0.3155 - accuracy: 0.8312 - tp: 483.0000 - auc: 0.9356 - fn: 40.0000 - val_loss: 0.2645 - val_accuracy: 0.8990 - val_tp: 38.0000 - val_auc: 0.8612 - val_fn: 45.0000\n",
      "Epoch 165/350\n",
      "29/28 [==============================] - 22s 755ms/step - loss: 0.2975 - accuracy: 0.8427 - tp: 489.0000 - auc: 0.9443 - fn: 35.0000 - val_loss: 0.1895 - val_accuracy: 0.9535 - val_tp: 19.0000 - val_auc: 0.6883 - val_fn: 65.0000\n",
      "Epoch 166/350\n",
      "29/28 [==============================] - 23s 798ms/step - loss: 0.3136 - accuracy: 0.8422 - tp: 476.0000 - auc: 0.9392 - fn: 49.0000 - val_loss: 0.2243 - val_accuracy: 0.9127 - val_tp: 37.0000 - val_auc: 0.8422 - val_fn: 46.0000\n",
      "Epoch 167/350\n",
      "29/28 [==============================] - 22s 755ms/step - loss: 0.3069 - accuracy: 0.8412 - tp: 494.0000 - auc: 0.9424 - fn: 37.0000 - val_loss: 0.2253 - val_accuracy: 0.9127 - val_tp: 23.0000 - val_auc: 0.7947 - val_fn: 60.0000\n",
      "Epoch 168/350\n",
      "29/28 [==============================] - 24s 812ms/step - loss: 0.3197 - accuracy: 0.8385 - tp: 477.0000 - auc: 0.9387 - fn: 50.0000 - val_loss: 0.1947 - val_accuracy: 0.9295 - val_tp: 31.0000 - val_auc: 0.8546 - val_fn: 53.0000\n",
      "Epoch 169/350\n",
      "29/28 [==============================] - 22s 764ms/step - loss: 0.3096 - accuracy: 0.8382 - tp: 483.0000 - auc: 0.9412 - fn: 48.0000 - val_loss: 0.2376 - val_accuracy: 0.9117 - val_tp: 42.0000 - val_auc: 0.8412 - val_fn: 44.0000\n",
      "Epoch 170/350\n",
      "29/28 [==============================] - 23s 798ms/step - loss: 0.3048 - accuracy: 0.8513 - tp: 481.0000 - auc: 0.9434 - fn: 49.0000 - val_loss: 0.2670 - val_accuracy: 0.9068 - val_tp: 45.0000 - val_auc: 0.8622 - val_fn: 42.0000\n",
      "Epoch 171/350\n",
      "29/28 [==============================] - 21s 740ms/step - loss: 0.2869 - accuracy: 0.8549 - tp: 489.0000 - auc: 0.9502 - fn: 37.0000 - val_loss: 0.2748 - val_accuracy: 0.9020 - val_tp: 40.0000 - val_auc: 0.8517 - val_fn: 46.0000\n",
      "Epoch 172/350\n",
      "29/28 [==============================] - 22s 776ms/step - loss: 0.2963 - accuracy: 0.8463 - tp: 492.0000 - auc: 0.9453 - fn: 35.0000 - val_loss: 0.2480 - val_accuracy: 0.9150 - val_tp: 40.0000 - val_auc: 0.8555 - val_fn: 50.0000\n",
      "Epoch 173/350\n",
      "29/28 [==============================] - 23s 808ms/step - loss: 0.2983 - accuracy: 0.8546 - tp: 491.0000 - auc: 0.9460 - fn: 40.0000 - val_loss: 0.4447 - val_accuracy: 0.8342 - val_tp: 58.0000 - val_auc: 0.8546 - val_fn: 29.0000\n",
      "Epoch 174/350\n",
      "29/28 [==============================] - 22s 771ms/step - loss: 0.2928 - accuracy: 0.8507 - tp: 492.0000 - auc: 0.9469 - fn: 41.0000 - val_loss: 0.2420 - val_accuracy: 0.9053 - val_tp: 42.0000 - val_auc: 0.8520 - val_fn: 44.0000\n",
      "Epoch 175/350\n",
      "29/28 [==============================] - 21s 731ms/step - loss: 0.2852 - accuracy: 0.8596 - tp: 493.0000 - auc: 0.9504 - fn: 39.0000 - val_loss: 0.2800 - val_accuracy: 0.8975 - val_tp: 51.0000 - val_auc: 0.8416 - val_fn: 38.0000\n",
      "Epoch 176/350\n",
      "29/28 [==============================] - 22s 743ms/step - loss: 0.3094 - accuracy: 0.8419 - tp: 489.0000 - auc: 0.9410 - fn: 42.0000 - val_loss: 0.4645 - val_accuracy: 0.8316 - val_tp: 54.0000 - val_auc: 0.8348 - val_fn: 33.0000\n",
      "Epoch 177/350\n",
      "29/28 [==============================] - 22s 773ms/step - loss: 0.2969 - accuracy: 0.8530 - tp: 476.0000 - auc: 0.9466 - fn: 51.0000 - val_loss: 0.2771 - val_accuracy: 0.8990 - val_tp: 41.0000 - val_auc: 0.8527 - val_fn: 41.0000\n",
      "Epoch 178/350\n",
      "29/28 [==============================] - 24s 837ms/step - loss: 0.2885 - accuracy: 0.8517 - tp: 486.0000 - auc: 0.9474 - fn: 35.0000 - val_loss: 0.2972 - val_accuracy: 0.8883 - val_tp: 51.0000 - val_auc: 0.8686 - val_fn: 36.0000\n",
      "Epoch 179/350\n",
      "29/28 [==============================] - 22s 769ms/step - loss: 0.2837 - accuracy: 0.8556 - tp: 493.0000 - auc: 0.9504 - fn: 35.0000 - val_loss: 0.3349 - val_accuracy: 0.8797 - val_tp: 50.0000 - val_auc: 0.8507 - val_fn: 37.0000\n",
      "Epoch 180/350\n",
      "29/28 [==============================] - 22s 775ms/step - loss: 0.2815 - accuracy: 0.8530 - tp: 485.0000 - auc: 0.9510 - fn: 40.0000 - val_loss: 0.4312 - val_accuracy: 0.8477 - val_tp: 54.0000 - val_auc: 0.8522 - val_fn: 33.0000\n",
      "Epoch 181/350\n",
      "29/28 [==============================] - 23s 796ms/step - loss: 0.2808 - accuracy: 0.8615 - tp: 482.0000 - auc: 0.9524 - fn: 44.0000 - val_loss: 0.2257 - val_accuracy: 0.9168 - val_tp: 41.0000 - val_auc: 0.8373 - val_fn: 44.0000\n",
      "Epoch 182/350\n",
      "29/28 [==============================] - 22s 772ms/step - loss: 0.2781 - accuracy: 0.8615 - tp: 497.0000 - auc: 0.9534 - fn: 41.0000 - val_loss: 0.2652 - val_accuracy: 0.8971 - val_tp: 40.0000 - val_auc: 0.8461 - val_fn: 45.0000\n",
      "Epoch 183/350\n",
      "29/28 [==============================] - 22s 766ms/step - loss: 0.2671 - accuracy: 0.8611 - tp: 480.0000 - auc: 0.9555 - fn: 38.0000 - val_loss: 0.2612 - val_accuracy: 0.8971 - val_tp: 52.0000 - val_auc: 0.8517 - val_fn: 35.0000\n",
      "Epoch 184/350\n",
      "29/28 [==============================] - 22s 752ms/step - loss: 0.2607 - accuracy: 0.8702 - tp: 497.0000 - auc: 0.9584 - fn: 31.0000 - val_loss: 0.2590 - val_accuracy: 0.9041 - val_tp: 37.0000 - val_auc: 0.8446 - val_fn: 49.0000\n",
      "Epoch 185/350\n",
      "29/28 [==============================] - 23s 787ms/step - loss: 0.2726 - accuracy: 0.8599 - tp: 487.0000 - auc: 0.9545 - fn: 40.0000 - val_loss: 0.2351 - val_accuracy: 0.9047 - val_tp: 37.0000 - val_auc: 0.8527 - val_fn: 48.0000\n",
      "Epoch 186/350\n",
      "29/28 [==============================] - 21s 734ms/step - loss: 0.2727 - accuracy: 0.8655 - tp: 486.0000 - auc: 0.9555 - fn: 43.0000 - val_loss: 0.2245 - val_accuracy: 0.9187 - val_tp: 35.0000 - val_auc: 0.8307 - val_fn: 50.0000\n",
      "Epoch 187/350\n",
      "29/28 [==============================] - 22s 766ms/step - loss: 0.2674 - accuracy: 0.8686 - tp: 487.0000 - auc: 0.9553 - fn: 40.0000 - val_loss: 0.6535 - val_accuracy: 0.7619 - val_tp: 70.0000 - val_auc: 0.8548 - val_fn: 18.0000\n",
      "Epoch 188/350\n",
      "29/28 [==============================] - 22s 754ms/step - loss: 0.2870 - accuracy: 0.8534 - tp: 488.0000 - auc: 0.9499 - fn: 37.0000 - val_loss: 0.2288 - val_accuracy: 0.9262 - val_tp: 27.0000 - val_auc: 0.8163 - val_fn: 61.0000\n",
      "Epoch 189/350\n",
      "29/28 [==============================] - 23s 798ms/step - loss: 0.2875 - accuracy: 0.8565 - tp: 493.0000 - auc: 0.9498 - fn: 43.0000 - val_loss: 0.2943 - val_accuracy: 0.8961 - val_tp: 38.0000 - val_auc: 0.8327 - val_fn: 51.0000\n",
      "Epoch 190/350\n",
      "29/28 [==============================] - 22s 767ms/step - loss: 0.2696 - accuracy: 0.8664 - tp: 486.0000 - auc: 0.9566 - fn: 37.0000 - val_loss: 0.6129 - val_accuracy: 0.8086 - val_tp: 51.0000 - val_auc: 0.8376 - val_fn: 35.0000\n",
      "Epoch 191/350\n",
      "29/28 [==============================] - 22s 773ms/step - loss: 0.2700 - accuracy: 0.8692 - tp: 493.0000 - auc: 0.9561 - fn: 34.0000 - val_loss: 0.3014 - val_accuracy: 0.8951 - val_tp: 44.0000 - val_auc: 0.8590 - val_fn: 45.0000\n",
      "Epoch 192/350\n",
      "29/28 [==============================] - 22s 769ms/step - loss: 0.2716 - accuracy: 0.8691 - tp: 492.0000 - auc: 0.9563 - fn: 38.0000 - val_loss: 0.3109 - val_accuracy: 0.8936 - val_tp: 49.0000 - val_auc: 0.8437 - val_fn: 38.0000\n",
      "Epoch 193/350\n",
      "29/28 [==============================] - 23s 787ms/step - loss: 0.2472 - accuracy: 0.8738 - tp: 501.0000 - auc: 0.9621 - fn: 23.0000 - val_loss: 0.2288 - val_accuracy: 0.9168 - val_tp: 38.0000 - val_auc: 0.8702 - val_fn: 47.0000\n",
      "Epoch 194/350\n",
      "29/28 [==============================] - 22s 770ms/step - loss: 0.2827 - accuracy: 0.8712 - tp: 481.0000 - auc: 0.9523 - fn: 44.0000 - val_loss: 0.2858 - val_accuracy: 0.8871 - val_tp: 42.0000 - val_auc: 0.8450 - val_fn: 42.0000\n",
      "Epoch 195/350\n",
      "29/28 [==============================] - 23s 797ms/step - loss: 0.2672 - accuracy: 0.8713 - tp: 492.0000 - auc: 0.9562 - fn: 42.0000 - val_loss: 0.2344 - val_accuracy: 0.9279 - val_tp: 41.0000 - val_auc: 0.8280 - val_fn: 45.0000\n",
      "Epoch 196/350\n",
      "29/28 [==============================] - 21s 736ms/step - loss: 0.2676 - accuracy: 0.8723 - tp: 485.0000 - auc: 0.9574 - fn: 42.0000 - val_loss: 0.2550 - val_accuracy: 0.9021 - val_tp: 42.0000 - val_auc: 0.8551 - val_fn: 41.0000\n",
      "Epoch 197/350\n",
      "29/28 [==============================] - 23s 799ms/step - loss: 0.2745 - accuracy: 0.8626 - tp: 491.0000 - auc: 0.9537 - fn: 35.0000 - val_loss: 0.1678 - val_accuracy: 0.9490 - val_tp: 28.0000 - val_auc: 0.8436 - val_fn: 59.0000\n",
      "Epoch 198/350\n",
      "29/28 [==============================] - 21s 725ms/step - loss: 0.2397 - accuracy: 0.8857 - tp: 502.0000 - auc: 0.9646 - fn: 26.0000 - val_loss: 0.3256 - val_accuracy: 0.8922 - val_tp: 41.0000 - val_auc: 0.8356 - val_fn: 40.0000\n",
      "Epoch 199/350\n",
      "29/28 [==============================] - 23s 792ms/step - loss: 0.2670 - accuracy: 0.8647 - tp: 495.0000 - auc: 0.9561 - fn: 32.0000 - val_loss: 0.3162 - val_accuracy: 0.8822 - val_tp: 43.0000 - val_auc: 0.8177 - val_fn: 43.0000\n",
      "Epoch 200/350\n",
      "29/28 [==============================] - 23s 803ms/step - loss: 0.2718 - accuracy: 0.8710 - tp: 496.0000 - auc: 0.9561 - fn: 35.0000 - val_loss: 0.2563 - val_accuracy: 0.9018 - val_tp: 46.0000 - val_auc: 0.8511 - val_fn: 40.0000\n",
      "Epoch 201/350\n",
      "29/28 [==============================] - 22s 752ms/step - loss: 0.2623 - accuracy: 0.8775 - tp: 484.0000 - auc: 0.9591 - fn: 40.0000 - val_loss: 0.5429 - val_accuracy: 0.8258 - val_tp: 59.0000 - val_auc: 0.8515 - val_fn: 29.0000\n",
      "Epoch 202/350\n",
      "29/28 [==============================] - 22s 754ms/step - loss: 0.2585 - accuracy: 0.8690 - tp: 491.0000 - auc: 0.9586 - fn: 31.0000 - val_loss: 0.4278 - val_accuracy: 0.8332 - val_tp: 65.0000 - val_auc: 0.8755 - val_fn: 21.0000\n",
      "Epoch 203/350\n",
      "29/28 [==============================] - 22s 766ms/step - loss: 0.2336 - accuracy: 0.8833 - tp: 496.0000 - auc: 0.9667 - fn: 31.0000 - val_loss: 0.3665 - val_accuracy: 0.8686 - val_tp: 56.0000 - val_auc: 0.8588 - val_fn: 30.0000\n",
      "Epoch 204/350\n",
      "29/28 [==============================] - 23s 782ms/step - loss: 0.2291 - accuracy: 0.8877 - tp: 507.0000 - auc: 0.9686 - fn: 24.0000 - val_loss: 0.2609 - val_accuracy: 0.9078 - val_tp: 45.0000 - val_auc: 0.8500 - val_fn: 41.0000\n",
      "Epoch 205/350\n",
      "29/28 [==============================] - 24s 830ms/step - loss: 0.2442 - accuracy: 0.8842 - tp: 488.0000 - auc: 0.9645 - fn: 33.0000 - val_loss: 0.1996 - val_accuracy: 0.9303 - val_tp: 35.0000 - val_auc: 0.8340 - val_fn: 51.0000\n",
      "Epoch 206/350\n",
      "29/28 [==============================] - 22s 773ms/step - loss: 0.2357 - accuracy: 0.8825 - tp: 502.0000 - auc: 0.9655 - fn: 26.0000 - val_loss: 0.1895 - val_accuracy: 0.9416 - val_tp: 33.0000 - val_auc: 0.8247 - val_fn: 51.0000\n",
      "Epoch 207/350\n",
      "29/28 [==============================] - 23s 804ms/step - loss: 0.2347 - accuracy: 0.8918 - tp: 505.0000 - auc: 0.9667 - fn: 26.0000 - val_loss: 0.5301 - val_accuracy: 0.8213 - val_tp: 57.0000 - val_auc: 0.8467 - val_fn: 28.0000\n",
      "Epoch 208/350\n",
      "29/28 [==============================] - 23s 777ms/step - loss: 0.2464 - accuracy: 0.8827 - tp: 491.0000 - auc: 0.9629 - fn: 35.0000 - val_loss: 0.3235 - val_accuracy: 0.8922 - val_tp: 52.0000 - val_auc: 0.8701 - val_fn: 35.0000\n",
      "Epoch 209/350\n",
      "29/28 [==============================] - 23s 794ms/step - loss: 0.2324 - accuracy: 0.8861 - tp: 501.0000 - auc: 0.9673 - fn: 28.0000 - val_loss: 0.2225 - val_accuracy: 0.9242 - val_tp: 34.0000 - val_auc: 0.8202 - val_fn: 53.0000\n",
      "Epoch 210/350\n",
      "29/28 [==============================] - 21s 730ms/step - loss: 0.2347 - accuracy: 0.8906 - tp: 496.0000 - auc: 0.9672 - fn: 33.0000 - val_loss: 0.1536 - val_accuracy: 0.9527 - val_tp: 25.0000 - val_auc: 0.8103 - val_fn: 61.0000\n",
      "Epoch 211/350\n",
      "29/28 [==============================] - 22s 771ms/step - loss: 0.2372 - accuracy: 0.8797 - tp: 502.0000 - auc: 0.9669 - fn: 26.0000 - val_loss: 0.1925 - val_accuracy: 0.9365 - val_tp: 25.0000 - val_auc: 0.8343 - val_fn: 60.0000\n",
      "Epoch 212/350\n",
      "29/28 [==============================] - 23s 786ms/step - loss: 0.2353 - accuracy: 0.8942 - tp: 497.0000 - auc: 0.9673 - fn: 31.0000 - val_loss: 0.4388 - val_accuracy: 0.8652 - val_tp: 56.0000 - val_auc: 0.8570 - val_fn: 34.0000\n",
      "Epoch 213/350\n",
      "29/28 [==============================] - 22s 770ms/step - loss: 0.2495 - accuracy: 0.8786 - tp: 501.0000 - auc: 0.9634 - fn: 28.0000 - val_loss: 0.3533 - val_accuracy: 0.8873 - val_tp: 48.0000 - val_auc: 0.8536 - val_fn: 38.0000\n",
      "Epoch 214/350\n",
      "29/28 [==============================] - 21s 731ms/step - loss: 0.2530 - accuracy: 0.8812 - tp: 495.0000 - auc: 0.9623 - fn: 37.0000 - val_loss: 0.2688 - val_accuracy: 0.9266 - val_tp: 31.0000 - val_auc: 0.8058 - val_fn: 54.0000\n",
      "Epoch 215/350\n",
      "29/28 [==============================] - 23s 788ms/step - loss: 0.2516 - accuracy: 0.8854 - tp: 499.0000 - auc: 0.9633 - fn: 32.0000 - val_loss: 0.2194 - val_accuracy: 0.9285 - val_tp: 42.0000 - val_auc: 0.8451 - val_fn: 43.0000\n",
      "Epoch 216/350\n",
      "29/28 [==============================] - 22s 772ms/step - loss: 0.2394 - accuracy: 0.8908 - tp: 491.0000 - auc: 0.9667 - fn: 39.0000 - val_loss: 0.2396 - val_accuracy: 0.9193 - val_tp: 40.0000 - val_auc: 0.8371 - val_fn: 47.0000\n",
      "Epoch 217/350\n",
      "29/28 [==============================] - 24s 824ms/step - loss: 0.2286 - accuracy: 0.8906 - tp: 501.0000 - auc: 0.9691 - fn: 26.0000 - val_loss: 0.2546 - val_accuracy: 0.9107 - val_tp: 49.0000 - val_auc: 0.8439 - val_fn: 37.0000\n",
      "Epoch 218/350\n",
      "29/28 [==============================] - 22s 769ms/step - loss: 0.2179 - accuracy: 0.8957 - tp: 501.0000 - auc: 0.9723 - fn: 26.0000 - val_loss: 0.2228 - val_accuracy: 0.9309 - val_tp: 29.0000 - val_auc: 0.7889 - val_fn: 59.0000\n",
      "Epoch 219/350\n",
      "29/28 [==============================] - 22s 757ms/step - loss: 0.2508 - accuracy: 0.8825 - tp: 495.0000 - auc: 0.9633 - fn: 36.0000 - val_loss: 0.2449 - val_accuracy: 0.9121 - val_tp: 45.0000 - val_auc: 0.8660 - val_fn: 37.0000\n",
      "Epoch 220/350\n",
      "29/28 [==============================] - 23s 802ms/step - loss: 0.2220 - accuracy: 0.8992 - tp: 482.0000 - auc: 0.9711 - fn: 36.0000 - val_loss: 0.2850 - val_accuracy: 0.9016 - val_tp: 51.0000 - val_auc: 0.8421 - val_fn: 38.0000\n",
      "Epoch 221/350\n",
      "29/28 [==============================] - 22s 769ms/step - loss: 0.2134 - accuracy: 0.9006 - tp: 502.0000 - auc: 0.9732 - fn: 26.0000 - val_loss: 0.2311 - val_accuracy: 0.9303 - val_tp: 35.0000 - val_auc: 0.8257 - val_fn: 53.0000\n",
      "Epoch 222/350\n",
      "29/28 [==============================] - 22s 746ms/step - loss: 0.2293 - accuracy: 0.8910 - tp: 502.0000 - auc: 0.9681 - fn: 25.0000 - val_loss: 0.3231 - val_accuracy: 0.8854 - val_tp: 53.0000 - val_auc: 0.8417 - val_fn: 36.0000\n",
      "Epoch 223/350\n",
      "29/28 [==============================] - 22s 754ms/step - loss: 0.2165 - accuracy: 0.9012 - tp: 510.0000 - auc: 0.9723 - fn: 24.0000 - val_loss: 0.3251 - val_accuracy: 0.8951 - val_tp: 43.0000 - val_auc: 0.8527 - val_fn: 40.0000\n",
      "Epoch 224/350\n",
      "29/28 [==============================] - 22s 769ms/step - loss: 0.2204 - accuracy: 0.8985 - tp: 498.0000 - auc: 0.9710 - fn: 21.0000 - val_loss: 0.1969 - val_accuracy: 0.9494 - val_tp: 28.0000 - val_auc: 0.7628 - val_fn: 56.0000\n",
      "Epoch 225/350\n",
      "29/28 [==============================] - 22s 759ms/step - loss: 0.2253 - accuracy: 0.8972 - tp: 496.0000 - auc: 0.9697 - fn: 34.0000 - val_loss: 0.1824 - val_accuracy: 0.9480 - val_tp: 26.0000 - val_auc: 0.8096 - val_fn: 60.0000\n",
      "Epoch 226/350\n",
      "29/28 [==============================] - 23s 796ms/step - loss: 0.2259 - accuracy: 0.8944 - tp: 492.0000 - auc: 0.9707 - fn: 29.0000 - val_loss: 0.1964 - val_accuracy: 0.9400 - val_tp: 29.0000 - val_auc: 0.8344 - val_fn: 57.0000\n",
      "Epoch 227/350\n",
      "29/28 [==============================] - 22s 755ms/step - loss: 0.2295 - accuracy: 0.8936 - tp: 513.0000 - auc: 0.9691 - fn: 28.0000 - val_loss: 0.2098 - val_accuracy: 0.9326 - val_tp: 35.0000 - val_auc: 0.8422 - val_fn: 53.0000\n",
      "Epoch 228/350\n",
      "29/28 [==============================] - 23s 785ms/step - loss: 0.2279 - accuracy: 0.8977 - tp: 489.0000 - auc: 0.9695 - fn: 36.0000 - val_loss: 0.3343 - val_accuracy: 0.8910 - val_tp: 40.0000 - val_auc: 0.8354 - val_fn: 45.0000\n",
      "Epoch 229/350\n",
      "29/28 [==============================] - 23s 792ms/step - loss: 0.2201 - accuracy: 0.8975 - tp: 501.0000 - auc: 0.9718 - fn: 21.0000 - val_loss: 0.1506 - val_accuracy: 0.9625 - val_tp: 20.0000 - val_auc: 0.7516 - val_fn: 66.0000\n",
      "Epoch 230/350\n",
      "29/28 [==============================] - 21s 735ms/step - loss: 0.2102 - accuracy: 0.9010 - tp: 515.0000 - auc: 0.9734 - fn: 18.0000 - val_loss: 0.2451 - val_accuracy: 0.9285 - val_tp: 39.0000 - val_auc: 0.8343 - val_fn: 45.0000\n",
      "Epoch 231/350\n",
      "29/28 [==============================] - 22s 773ms/step - loss: 0.2088 - accuracy: 0.9031 - tp: 508.0000 - auc: 0.9740 - fn: 21.0000 - val_loss: 0.2527 - val_accuracy: 0.9143 - val_tp: 42.0000 - val_auc: 0.8417 - val_fn: 45.0000\n",
      "Epoch 232/350\n",
      "29/28 [==============================] - 21s 729ms/step - loss: 0.2264 - accuracy: 0.9013 - tp: 488.0000 - auc: 0.9702 - fn: 32.0000 - val_loss: 0.1588 - val_accuracy: 0.9578 - val_tp: 18.0000 - val_auc: 0.8217 - val_fn: 71.0000\n",
      "Epoch 233/350\n",
      "29/28 [==============================] - 22s 766ms/step - loss: 0.2155 - accuracy: 0.8992 - tp: 505.0000 - auc: 0.9729 - fn: 25.0000 - val_loss: 0.2356 - val_accuracy: 0.9297 - val_tp: 34.0000 - val_auc: 0.8131 - val_fn: 52.0000\n",
      "Epoch 234/350\n",
      "29/28 [==============================] - 22s 769ms/step - loss: 0.2260 - accuracy: 0.8956 - tp: 500.0000 - auc: 0.9698 - fn: 26.0000 - val_loss: 0.1841 - val_accuracy: 0.9400 - val_tp: 30.0000 - val_auc: 0.8376 - val_fn: 54.0000\n",
      "Epoch 235/350\n",
      "29/28 [==============================] - 22s 762ms/step - loss: 0.1981 - accuracy: 0.9071 - tp: 509.0000 - auc: 0.9772 - fn: 20.0000 - val_loss: 0.2580 - val_accuracy: 0.9143 - val_tp: 41.0000 - val_auc: 0.8576 - val_fn: 42.0000\n",
      "Epoch 236/350\n",
      "29/28 [==============================] - 23s 778ms/step - loss: 0.1928 - accuracy: 0.9125 - tp: 509.0000 - auc: 0.9785 - fn: 21.0000 - val_loss: 0.1683 - val_accuracy: 0.9520 - val_tp: 27.0000 - val_auc: 0.8296 - val_fn: 56.0000\n",
      "Epoch 237/350\n",
      "29/28 [==============================] - 23s 800ms/step - loss: 0.2048 - accuracy: 0.9027 - tp: 508.0000 - auc: 0.9763 - fn: 25.0000 - val_loss: 0.3140 - val_accuracy: 0.8941 - val_tp: 42.0000 - val_auc: 0.8358 - val_fn: 43.0000\n",
      "Epoch 238/350\n",
      "29/28 [==============================] - 23s 793ms/step - loss: 0.2109 - accuracy: 0.9047 - tp: 505.0000 - auc: 0.9744 - fn: 25.0000 - val_loss: 0.3545 - val_accuracy: 0.8793 - val_tp: 52.0000 - val_auc: 0.8458 - val_fn: 33.0000\n",
      "Epoch 239/350\n",
      "29/28 [==============================] - 24s 816ms/step - loss: 0.2097 - accuracy: 0.9039 - tp: 491.0000 - auc: 0.9741 - fn: 30.0000 - val_loss: 0.3745 - val_accuracy: 0.8791 - val_tp: 51.0000 - val_auc: 0.8305 - val_fn: 36.0000\n",
      "Epoch 240/350\n",
      "29/28 [==============================] - 22s 757ms/step - loss: 0.2215 - accuracy: 0.8987 - tp: 497.0000 - auc: 0.9713 - fn: 31.0000 - val_loss: 0.2996 - val_accuracy: 0.8924 - val_tp: 39.0000 - val_auc: 0.8193 - val_fn: 48.0000\n",
      "Epoch 241/350\n",
      "29/28 [==============================] - 22s 751ms/step - loss: 0.1888 - accuracy: 0.9158 - tp: 506.0000 - auc: 0.9791 - fn: 18.0000 - val_loss: 0.2844 - val_accuracy: 0.9068 - val_tp: 35.0000 - val_auc: 0.8318 - val_fn: 49.0000\n",
      "Epoch 242/350\n",
      "29/28 [==============================] - 23s 781ms/step - loss: 0.1939 - accuracy: 0.9125 - tp: 502.0000 - auc: 0.9788 - fn: 24.0000 - val_loss: 0.2027 - val_accuracy: 0.9318 - val_tp: 31.0000 - val_auc: 0.8251 - val_fn: 53.0000\n",
      "Epoch 243/350\n",
      "29/28 [==============================] - 23s 801ms/step - loss: 0.1987 - accuracy: 0.9094 - tp: 506.0000 - auc: 0.9770 - fn: 23.0000 - val_loss: 0.2554 - val_accuracy: 0.9270 - val_tp: 29.0000 - val_auc: 0.8265 - val_fn: 55.0000\n",
      "Epoch 244/350\n",
      "29/28 [==============================] - 23s 786ms/step - loss: 0.1803 - accuracy: 0.9199 - tp: 498.0000 - auc: 0.9814 - fn: 22.0000 - val_loss: 0.2509 - val_accuracy: 0.9184 - val_tp: 32.0000 - val_auc: 0.7925 - val_fn: 54.0000\n",
      "Epoch 245/350\n",
      "29/28 [==============================] - 23s 782ms/step - loss: 0.1928 - accuracy: 0.9119 - tp: 508.0000 - auc: 0.9788 - fn: 21.0000 - val_loss: 0.2220 - val_accuracy: 0.9398 - val_tp: 40.0000 - val_auc: 0.8349 - val_fn: 47.0000\n",
      "Epoch 246/350\n",
      "29/28 [==============================] - 22s 768ms/step - loss: 0.1843 - accuracy: 0.9177 - tp: 513.0000 - auc: 0.9804 - fn: 16.0000 - val_loss: 0.2072 - val_accuracy: 0.9434 - val_tp: 23.0000 - val_auc: 0.7861 - val_fn: 63.0000\n",
      "Epoch 247/350\n",
      "29/28 [==============================] - 23s 787ms/step - loss: 0.1900 - accuracy: 0.9214 - tp: 503.0000 - auc: 0.9796 - fn: 21.0000 - val_loss: 0.2582 - val_accuracy: 0.9174 - val_tp: 38.0000 - val_auc: 0.8524 - val_fn: 48.0000\n",
      "Epoch 248/350\n",
      "29/28 [==============================] - 23s 796ms/step - loss: 0.2141 - accuracy: 0.9147 - tp: 503.0000 - auc: 0.9745 - fn: 30.0000 - val_loss: 0.1846 - val_accuracy: 0.9553 - val_tp: 17.0000 - val_auc: 0.7623 - val_fn: 65.0000\n",
      "Epoch 249/350\n",
      "29/28 [==============================] - 22s 770ms/step - loss: 0.2102 - accuracy: 0.9062 - tp: 500.0000 - auc: 0.9746 - fn: 24.0000 - val_loss: 0.2508 - val_accuracy: 0.9232 - val_tp: 35.0000 - val_auc: 0.8056 - val_fn: 53.0000\n",
      "Epoch 250/350\n",
      "29/28 [==============================] - 22s 772ms/step - loss: 0.1917 - accuracy: 0.9130 - tp: 508.0000 - auc: 0.9792 - fn: 20.0000 - val_loss: 0.3778 - val_accuracy: 0.8822 - val_tp: 44.0000 - val_auc: 0.8093 - val_fn: 41.0000\n",
      "Epoch 251/350\n",
      "29/28 [==============================] - 23s 793ms/step - loss: 0.1996 - accuracy: 0.9175 - tp: 504.0000 - auc: 0.9772 - fn: 22.0000 - val_loss: 0.2037 - val_accuracy: 0.9396 - val_tp: 32.0000 - val_auc: 0.8169 - val_fn: 54.0000\n",
      "Epoch 252/350\n",
      "29/28 [==============================] - 24s 812ms/step - loss: 0.1830 - accuracy: 0.9177 - tp: 513.0000 - auc: 0.9808 - fn: 20.0000 - val_loss: 0.2421 - val_accuracy: 0.9279 - val_tp: 38.0000 - val_auc: 0.8207 - val_fn: 48.0000\n"
     ]
    }
   ],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', #val_auc\n",
    "                                patience=50,\n",
    "                                mode='max',\n",
    "                                restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "#     batch_size=params['batch_size'],\n",
    "    epochs= params['epochs'], \n",
    "    steps_per_epoch=epoch_steps,\n",
    "    validation_data=valid_ds,\n",
    "    validation_steps=valid_steps,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T19:48:20.127333Z",
     "iopub.status.busy": "2020-08-08T19:48:20.126344Z",
     "iopub.status.idle": "2020-08-08T19:49:14.274976Z",
     "shell.execute_reply": "2020-08-08T19:49:14.274268Z"
    },
    "papermill": {
     "duration": 54.692906,
     "end_time": "2020-08-08T19:49:14.275126",
     "exception": false,
     "start_time": "2020-08-08T19:48:19.582220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(test_ds.map(lambda img, igs: img), steps=test_steps)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T19:49:15.459367Z",
     "iopub.status.busy": "2020-08-08T19:49:15.458250Z",
     "iopub.status.idle": "2020-08-08T19:49:19.869002Z",
     "shell.execute_reply": "2020-08-08T19:49:19.868192Z"
    },
    "papermill": {
     "duration": 5.025168,
     "end_time": "2020-08-08T19:49:19.869130",
     "exception": false,
     "start_time": "2020-08-08T19:49:14.843962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function <lambda> at 0x7f91e189c950> and will run it as-is.\n",
      "Cause: could not parse the source code:\n",
      "\n",
      "                          map(lambda img, ids:ids).\n",
      "\n",
      "This error may be avoided by creating the lambda in a standalone statement.\n",
      "\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "prediction_ids = next(iter(test_ds.\n",
    "                          map(lambda img, ids:ids).\n",
    "                          unbatch().\n",
    "                          batch(test_size))).numpy().astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T19:49:20.962901Z",
     "iopub.status.busy": "2020-08-08T19:49:20.961848Z",
     "iopub.status.idle": "2020-08-08T19:49:20.979484Z",
     "shell.execute_reply": "2020-08-08T19:49:20.978661Z"
    },
    "papermill": {
     "duration": 0.570831,
     "end_time": "2020-08-08T19:49:20.979618",
     "exception": false,
     "start_time": "2020-08-08T19:49:20.408787",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_dict = {\n",
    "    'image_name': prediction_ids,\n",
    "    'target': np.concatenate(predictions)\n",
    "}\n",
    "submission_ds = pd.DataFrame(prediction_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T19:49:22.146239Z",
     "iopub.status.busy": "2020-08-08T19:49:22.145208Z",
     "iopub.status.idle": "2020-08-08T19:49:22.150176Z",
     "shell.execute_reply": "2020-08-08T19:49:22.149423Z"
    },
    "papermill": {
     "duration": 0.572472,
     "end_time": "2020-08-08T19:49:22.150309",
     "exception": false,
     "start_time": "2020-08-08T19:49:21.577837",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_6381819</td>\n",
       "      <td>0.050337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_5583376</td>\n",
       "      <td>0.434673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_6408546</td>\n",
       "      <td>0.000071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_6932354</td>\n",
       "      <td>0.945061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_8191278</td>\n",
       "      <td>0.003169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name    target\n",
       "0  ISIC_6381819  0.050337\n",
       "1  ISIC_5583376  0.434673\n",
       "2  ISIC_6408546  0.000071\n",
       "3  ISIC_6932354  0.945061\n",
       "4  ISIC_8191278  0.003169"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T19:49:23.239089Z",
     "iopub.status.busy": "2020-08-08T19:49:23.238336Z",
     "iopub.status.idle": "2020-08-08T19:49:23.312919Z",
     "shell.execute_reply": "2020-08-08T19:49:23.312281Z"
    },
    "papermill": {
     "duration": 0.625802,
     "end_time": "2020-08-08T19:49:23.313089",
     "exception": false,
     "start_time": "2020-08-08T19:49:22.687287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission_ds.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.537837,
     "end_time": "2020-08-08T19:49:24.443676",
     "exception": false,
     "start_time": "2020-08-08T19:49:23.905839",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T19:49:25.596055Z",
     "iopub.status.busy": "2020-08-08T19:49:25.594894Z",
     "iopub.status.idle": "2020-08-08T19:49:25.600919Z",
     "shell.execute_reply": "2020-08-08T19:49:25.601674Z"
    },
    "papermill": {
     "duration": 0.619683,
     "end_time": "2020-08-08T19:49:25.601904",
     "exception": false,
     "start_time": "2020-08-08T19:49:24.982221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_metric(metric1, metric2, ylabel):\n",
    "    plt.plot(history.history[metric1], label=metric1)\n",
    "    plt.plot(history.history[metric2], label=metric2)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T19:49:26.695276Z",
     "iopub.status.busy": "2020-08-08T19:49:26.694511Z",
     "iopub.status.idle": "2020-08-08T19:49:27.411185Z",
     "shell.execute_reply": "2020-08-08T19:49:27.410495Z"
    },
    "papermill": {
     "duration": 1.262899,
     "end_time": "2020-08-08T19:49:27.411316",
     "exception": false,
     "start_time": "2020-08-08T19:49:26.148417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydd3gcxf3/X3PSqffeLPfeewHTDTbNmG4IhFBM/RL4BRIghJAKCYRQQy/BoXcCBINNMeDee7dlFav3ctKV/f0xt9q9052KrZMsaV7Po+d0t3t7s3u3n/d8yswITdNQKBQKRd/F0t0NUCgUCkX3ooRAoVAo+jhKCBQKhaKPo4RAoVAo+jhKCBQKhaKPo4RAoVAo+jgBEwIhxCtCiGIhxDY/24UQ4kkhxD4hxBYhxKRAtUWhUCgU/gkO4LFfA54GXvezfR4w1P03HXjW/dgqSUlJ2oABAzqnhQqFQtFHWL9+fammacm+tgVMCDRNWy6EGNDKLvOB1zU5om2VECJOCJGuadqR1o47YMAA1q1b14ktVSgUit6PECLH37buzBFkArmm53nu1xQKhULRhXSnEAgfr/mc70IIsUgIsU4Isa6kpCTAzVIoFIq+RXcKQR7Qz/Q8CyjwtaOmaS9omjZF07Qpyck+Q1wKhUKhOEoCmSxui0+B24QQbyOTxFVt5Qf8YbfbycvLw2azdWoDexNhYWFkZWVhtVq7uykKheI4I2BCIIR4CzgFSBJC5AG/B6wAmqY9B3wBnA3sA+qBXxztZ+Xl5REdHc2AAQMQwlfEqW+jaRplZWXk5eUxcODA7m6OQqE4zghk1dDCNrZrwK2d8Vk2m02JQCsIIUhMTETlVxQKhS96zchiJQKto66PQqHwR68RAoVCoeiJbM2rYumOIgDqmxz4Wyzsm11FVNXbA9KG7kwWKxQKRa+loq6JfSW1TM6Ox2IRHq8/8+0+4iNDmDk4keteW0tFvZ1xWbFsyasiMy6cRy4ex6whSRwqrePNNYcZmxnLne9s4rKp/fjLgrGd3lYlBAqFQtHJfLIpn998sAWb3cWswYk8csl4MuPCAXhtxSFe+vFg876hwRYumpTFt7uLue7EgSzdWcTd72/hqztP4pfvbGJzbiUAg5Mj+c28EQFprxKCTuSCCy4gNzcXm83GL3/5SxYtWkRUVBS1tbUAvP/++3z22We89tprFBUVcdNNN3HgwAEAnn32WWbNmtWdzVcoFIDN7qS6wU5KTFib+xZV2/h+dwkNdidXzeiPU9OwCMEjS3YzKCmKCydl8s+v9zD3n8uZMyqVk4cn8/76PGYPTeJvF43jX9/tY/rARM4bn4GmaQghOGNkKgtfXMVZjy8nr6KBu88azpGqBm6YPYiYsMCUf/c6IfjDf7ezo6C6U485KiOG3583us39XnnlFRISEmhoaGDq1KlcdNFFfve9/fbbOfnkk/noo49wOp3NYqFQKLqWnUeq+cvnO/nTBWOosdm57c2NVNQ18cYN0/nDf3cwsV8c15wwgITIEGpsDlJjwrA7XTz29R5e/vEgTQ4XAJtyK1m2s4ghKVHkVTTw9BUjOHdcBmeOSuOPn23nx32lfLgxH4B7zx5BRlw4f77ACPPoBR0zBydy91nD+X5PCQsmZnLLKYMDXuzR64SgO3nyySf56KOPAMjNzWXv3r1+9/3mm294/XU5MWtQUBCxsbFd0kaFojfhcLpYfbCcqQMSCAnueO3L3qIarnp5DaW1jbyxKoclOwpxODUaHS4ufnYlCGngX11xiJAgCzaHkzNGppJf0cCOI9VcNCmLG08exHPf7efDjfkkRYWw4XAlSVGhnDkqDYDsxAhe+vlU7E4Xv/t4G+tzKpgzKrXVdt166hBuPXXIUV2To6HXCUF7eu6B4LvvvmPp0qWsXLmSiIgITjnlFGw2m4eSq5HPCkXnkV/ZwHWvrWVXYQ0/m5HNr+eO4MuthdQ2OrhgYiZ3vLOJwqoGXJocVNkvIYInLp9IbLgMr3y3u5hb39hAeEgw47JieX1VDk0OF09cPoGdR2p47vv9PHThWE4elszrK3Ooa3QQGmzh400FpESH8tTCiZw3PgOAv144lskD4jl3bAZfbj9CcnRoC2GyBll4+KJxzSGg44leJwTdRVVVFfHx8URERLBr1y5WrVoFQGpqKjt37mT48OF89NFHREdHA3D66afz7LPPcscdd+B0OqmrqyMmJqY7T0GhOC7ZmlfFm2ty+NP8MQQHGcb1he/3c6C0jrNGp/KfVYd5d11ec5jm1RUHKayycfqIVCzut3y1vYi73tvM01dMZHNuFTcuXs/g5ChevmYKP+0r4673NhMTFsxZo9M4Z2w6c0alMik7DiEE95iStPefO6pFG8OsQVw5vT8Al03NbvV8jjcRADWOoNOYO3cuDoeDcePG8bvf/Y4ZM2YA8PDDD3Puuedy2mmnkZ6e3rz/E088wbfffsvYsWOZPHky27dv766mKxTHBSv3l/Hgp9tb1NG/vvIQb63JZeWBsubXmhwuPt1cwJmjUnn6iklcPDmLK6Zl89Ets5g3Jo3c8gZ+deZwnrtqMv+6Uv7dd/ZIvt5RxKQ/fs2lz68kPTaM16+bRnpsOHNGpRJmtXDhpCzCrEEEB1mY3D/+uDTagUD4G7xwvDJlyhTNe2GanTt3MnLkyG5qUc9BXSdFV2N3uiisstEvIaLV/RxOF3P+uZyDpXV8ecdsRqRJ71jTNGY8tIyi6kYunpzFo5eMZ+mOIpbtKuKtNbm8+oupnDo8xeNYDU1OVuwv5ZThKQRZPA35D3tL+GzzEQYmR3LJ5CwSo0Kbt+WU1ZEaE0aYNaiTzv74QgixXtO0Kb62qdCQQqEICPVNDha9vp6f9pfy6jVTmT4wESFoNrROl8a/VxwiPCSI/cW1HCytA2DpjiL2FtXy5urD9EsIp6i6kbgIK19uKyQrPpzHl8oijMy4cGYPSWrxueEhQZw+0ncydvbQZGYP9T2Vff/EyM447R6JEgKFQtHp7Cio5q73NrOrsJr0mDBu/s8G7E4XDpfGwmn9eOjCcXyx9Qh//GxH83tmDU6krtHB88sPUGNzEBMW3BwOeuDcUfy/dzfz+NK9nDEyhb9dNI6QYItHzkBx9CghUCgUHcZX5UtJTSPf7S7m5R8PsquwhoTIEF76+RQGJkVx74dbGJsZS1F1I2+tyeWCCZm8/ONBBiRGsPi66QCkx4bx/PIDPLJkN7MGJ/Lyz6fys5dXY7M7uXBSFhP6xWF3agxNifKYskFx7CghUCgUfsmrqOcXr67loQvHMmVAAgBvrznMk8v28t7Ns8iMC8fl0vjT5zt49adDAIxIi+b3543i/PEZzTH4txfNBGT8fs3Bcm78z3oq6+384fzRHvmDiydnkVNWx6/njiA8JIg3b5iOwynzmIOSo7rwzPsWSggUij5EcY2cEuG88Rl8vaOIEWnRDE2N9rv/yz8eZG9xLb/+YAuPXDye5XtKePrbfThdGl9sOUJmfDj/XnGI1QfLWTgtm4snZzIp23+1TXhIEE9dMZEXlx8g1BrEJVOyPLanxoTx94vHNz8PDQ4iVFmpgKMusULRB3C5NF5dcYh/fLWb+iYnf1+ym5KaRk4elswf549m6c5irj3Bc3Gnapudd9fmMjw1mt1FNVz07AoAThySRHGNjddXHSK/ooGs+Ah+e/ZIrp89sF3lllMHJDDV7V0ojg+UECgUvZCqBjubcis5aWgSQgju/2Qbb64+zKnDk5kzKo1/fLWb7IQIVh8s4x9f7eHTzQVYgwQr95dxyZQsxmfFccc7m6hrcvLoJePZV1JDkMXCrMGJJEWF8tSyvfzj6z1Ehwbzya0nEB8Z0t2nrDgGlBB0A+YZSRWKzmZLXiW3vLGBvIoGnlw4kbmj0/hkYz4XTszkH5eORwjBwmn9WLazmOtfX8enmwsAeOATOajxu90lxIZbKa9v4m8XjWVsVixjszznwpo3Np1/Lt3DzacOViLQC1BCoFD0Ij5Yn8e9H24lKSqEYalR/OmzHYQEWahrcjJvbHpz6EYIwYzBiQRbBA6Xxp1nDOPddbncdtoQnly2F2uQhQ9vnsWYTN+TIQ5JiWLZr06hfxsDxRQ9g94nBP+7Bwq3du4x08bCvIf9bv7Nb35D//79ueWWWwB48MEHEUKwfPlyKioqsNvt/PnPf2b+/PltflRtbS3z589v8b5Dhw5x7rnnsm3bNgAeffRRamtrefDBB9m3bx833XQTJSUlBAUF8d577zF48ODOOXdFt+Fyac1lkusOlbNkeyH3nT2y2Zhvy6+ipKaRU4YnU1htIyEyhAf/u51xWbG8ePUU8ioamP/Mj/zq3U1YgwQzByd6HD8qNJhJ2fHsL6nl1lMH88szhgJw7rh0rEGWNkfYDkzquwOwehu9Twi6gcsvv5w77rijWQjeffddvvzyS+68805iYmIoLS1lxowZnH/++W0m08LCwvjoo49avK81rrzySu655x4WLFiAzWbD5XJ12rkpupZGh5O6RicV9U0seOYn5k/I5LfnjOR3n2xn55Fqpg9M5IxRqewpqmHhC6uobXJw2vAUlu0q5pxx6dTYHPzf6UOJjwwhPjKE204dwpPf7GPW4ESifJTfPHTRWGptDo+BWdEBWvxEcfzS+4SglZ57oJg4cSLFxcUUFBRQUlJCfHw86enp3HnnnSxfvhyLxUJ+fj5FRUWkpaW1eixN07jvvvtavM8fNTU15Ofns2DBAkAKieL4o6CygUeX7Oa354z0mN/GzMHSOm5cvI6CShtjMmNosDtZvCqHb3cXk1fRQEiQhSe/2cupI1K45Y0NhIUEMSglimW7iokJC+bzLUdIjAzhBFPP//9OH0peZQPzxqT7/MzBqjZfQW8Ugm7i4osv5v3336ewsJDLL7+cN954g5KSEtavX4/VamXAgAHtWo/A3/uCg4M9evr6sXrapIF9jce+2s3W/CocLo0f9paSGR/Or84c3ry9uMZGTlk9k7Pjufk/6ymuaSQk2MKqA+XcfMpgJvaL41fvbaZ/YgSLThrEbz/axm8+2MK+4lqeXDiRU4Ynsy2vilBrEBc9u4JzxqV79O6tQRYeu3RCd5y6ogehhKCTuPzyy7nhhhsoLS3l+++/59133yUlJQWr1cq3335LTk5Ou45TVVXl832pqakUFxdTVlZGVFQUn332GXPnziUmJoasrCw+/vhjLrjgAhobG3E6nUREqCRed+N0aSxelUNFvR2AuAgr/1mVwy2nDCE8JIiXfjjAnz/fCcCV07PZVVjDny8Yw4i0aF784QCLZg8iPjKE7/rH49IgPsLKW2sO8/76PNJjw5g3Jg1rkIVZ7onX3rxhOqPS1ZoWio6jhKCTGD16NDU1NWRmZpKens6VV17Jeeedx5QpU5gwYQIjRoxo+yDg931Wq5UHHniA6dOnM3DgQI/jLV68mBtvvJEHHngAq9XKe++9x6BBgwJynoq2qaq3ExthZUteJRX1dhZOyybcGsQZI1O44qXV/PbjrUzKjuevX+zkjJGplNTYeGP1YaxBgnPGphMfGdI8nQPgEUp6aME4FvzrJ649YSBWrwnXZg1uOROnQtEe1HoEfQh1nVqSW15PUlQo4SHHNgd9bnk9Fotg0+FKbn1zA39ZMIbi6kae/GYv6++fQ0JkCJqm8ehXu/nXd/vRNBibGcvbi2aw4XAFV728hjmjUnnxap/TxXtQXGMjKTJUTbym6BBqPQKFwgcul8Z5T//ICUOSeOaKSa3u5210dxVW88LyA/x1wViOVNm44JmfiAoNJj1WJuvv/3gbkSHBjM+KI8E94EoIwd1njeD88ZnY7E7GZsZisQhOHJLEfWeP4KRhvufJ9yYlWhUEKDoXJQTdxNatW7nqqqs8XgsNDWX16tXd1KK+x+Hyeirr7Xy+5Qg3zK5kQr+4Fvt8uCGPv36xk6X/72TiIkJYvPIQcREhfLwxn2W7ipk9NIlnvt1Pk8NFfkMD+ZUN3H7aEOwujc25lVwxveX6tcPTPCd5E0Kw6CQ17kPRffQaIfA1P/rxzNixY9m0aVOXfV5PCwF2BbsKawCwBgnueHsjf7toHNMHeQ66+mZXMaW1Tby7LpcThyTzwKfbsQiB0yWv5+8/2U61zcELV03mxR8OsD6ngoXTs0mPDe/y81EojpZesbxPWFgYZWVlytj5QdM0ysrK+swYA03T0DSNapudr3cU+f1d7C6sQQh44aop2J0al72wirve20xZbSOrDpRRWGVj4+FKAP69Iofff7qN2HArWfHhhFuDWDgtm2qbg3FZscwZlcpjl07gxaunKBFQ9Dh6hUeQlZVFXl4eJSUl3d2U45awsDCysrLa3rEXcNGzKxieFo2mwdtrc1l00iCKqm0UVzcyNDWKq2f2Z0hKNLsKq8lOiODUESks/X8n8+Q3e3lx+QE+3piPw6UxIi2a/MoGpg1IYM2hcvIrG3j4wrGcNjKFstomwq1BfLH1CHefNRwhBP0SItpcpF2hOB4JaNWQEGIu8AQQBLykadrDXtvjgVeAwYANuFbTtG2tHdNX1ZCid7PqQBl//3IXk7Ljuf/cUa3uu6+4hjMeW44QEGwRhAUHUdPoICo0mBFp0WzJryJICP77fyey6PV1DE2N4vmrjEKKvUU1vPLTQcpqm/hqhxzR/cHNMwHBgMQIv6OCFYrjnW6pGhJCBAHPAHOAPGCtEOJTTdN2mHa7D9ikadoCIcQI9/6nB6pNip5HVb2dq19Zg8PpYndhDXfPHU5osP9SzyXbpfGOCgmmtsnBezfPZN2hCs4clUpKTBgFlQ2c+9SPLFq8jkNldZw7PsPj/UNTo3nownGU1zXx3Z5laJrG6IzYNidgUyh6MoHMEUwD9mmadkDTtCbgbcB7+s1RwDIATdN2AQOEEKkBbJOih/H1ziKaHC5uO20odU1OVh8ob3X/L7cVMjE7jkcuGcd980YyIi2Gn83oT0qMzI9kxIXz5OUTqWt04NJg6oB4n8dJiAzh2hMGMm9MuhIBRa8nkDmCTCDX9DwPmO61z2bgQuBHIcQ0oD+QBXjMsiaEWAQsAsjOblmOp+i5HCytY9nOIq470Vjm8KH/7WTdoQpe+flUvtx2hIzYMG4+eTAvLN/Psp1FzBiUyMHSOvYV1zK5fzwFVQ18tb2IK6dnszW/invnjWCun0nWAE4cmsTq+86gvslBRIj/W+Ceee0bDa5Q9HQCKQS+ajm9ExIPA08IITYBW4GNgKPFmzTtBeAFkDmCTm6noht59aeDvL4yh7lj0siKj+CHvSU8//0BABa+uIp9JbVcOT2b8JAgThySxOJVOSxelYO7epNR6THY7E4OlNaRW1EPwFmjW5/hVac1EVAo+hKBvBPygH6m51lAgXkHTdOqgV8ACNkdPOj+U/Qi1hwsR9O0FjX6ABsOV7gfK3nm2/28vz6XwcmR3HbaEB77eg/xEVYuniyrne6cM4zshEiiQoMYnBJFjc3B/R/L2oIgi+DzLUcYkRbNALVgikLRIQIpBGuBoUKIgUA+cDlwhXkHIUQcUO/OIVwPLHeLg+I45+lv9rIpt4rnfjbJY9rjqgY7Ly4/wNpD5fxlwViyEyK45Y0NNDmc/PDr04iNMBY9qW9ysPOIHNT12k8H2XC4kgsnZnLXWcPJiAtnwUTPctfRGbGMzvBcOjG3op5am4MGu5MPN+Qzd0z7vAGFQmEQMCHQNM0hhLgNWIIsH31F07TtQoib3NufA0YCrwshnMAO4LpAtUfRebhcGv9emUNJTSOPfb2nuY5e0zRuXLyO1QfLiQwJ5tLnV3LJlCxKaxsB+P2n2zhpWDLnjc+gyeFic24lTpeGNUiw4XAlIUEWHpw/mpgOrJB17zw5id7m3EqW7ynhfK8qIIVC0Ta9YvZRReDRp/BoaHKys7CaC/+1ggGJERwqq2dEWjRzx6TR0OTk+eUH+MuCMZwwOImrXllNbnkDAxIjGN8vjk82ycjgWaNTWX2wHJvdic3uYsHETD7amM9pI1J45Zqp3XymCkXvRM0+qjhqGpqc3PPhFrbmVfH6ddOY+/gPhIcEEWwRfHDzLL7eUcRba3N5YtleNA1mDkpk4dRsLBbBBzfN4u73t3DJlCxOG5HC9ScO4tPN+bz4w0Ey48JxOjX6pURwyvBkPtqowjoKRXehPAKFXx5Zsos3Vx9uXmHrzFGpzaNtTxiSyBvXz2jet9pmp7y2iaz4cI+cgTdOl8Ynm/KZPTQZp0vD7nSRHB3K4pU5XDWzv6rZVygCRGsegRICRTM2u5PyuiYy4sLJKavj5Ee+Y/bQJK49cSC3vrGB+iYn/RMjePD80QxIjGSgqs5RKHoMrQlBr5h9VHHs2J0uFr64irmPL6eu0cHnW48A8PBF4zh1eAqnDk8BYM7IVE4dnqJEQNG9bPsAvri7u1vRa1BC0EcorW3km11F1De1GK9HWW0jv3l/CxsPV1Jtc/DfzQV8vuUIE7PjyIyTUyqfM06O1J03VsXxFccB2z6EtS+BvaG7W9IrUELQB/hkUz7T/7qMa19bx9+/3A3AjoJq7v1wCxV1TZz1+A98tCmfW08dzNCUKB79ag/bC6o5Z6wxTcO8MWl8fedJTO6f4O9jFIpjo2AjfP/39u1bmQOaC0p2tdxWXw5LHwSnvVOb15tRQtBLcbo0XC6NpTuKuPu9LUzOjufMUam8teYwJTWNvPjDAd5ak8t1/15LaW0jb1w3nbvPGsGV07MprW3kvPEZXDm9f/PxhBAMTY1u5RMVfZbP/h+8feWxH2fTW/DtX6Cxpu19Kw/Lx0Ifs9bv+gx+/CcUbj32NvURVPloL2J9Tjl3vrOZZ382iVve2EBRtQ2b3cWItGiev2oyFfVNLN1ZxD+X7uFrd/XPhsOVjM+KZdaQJACunjmAmYOTGJYa1aOW/lR0I/u+hoZK0DQ4lt9Mdb58rMqDlJH+92uoBFuV/L9oe8vtFYfkY2MHJyl47kSYfjNM7ARR62Eoj6AX8MmmfD7dXMC7a/M4XF7Ppc+tJKesngsmZHLf2SP45LYTiI8MYVByFJdPy+bN1YepbXRwzawBAPzihIHNx7JYBMPTonuuCBzZAo7G7m6FwU9PwJf3dt3n2RtaP3+XEw7+YDxvrWrQVg07Pm398xoqZe+8sdow5EdLVZ7no9/9TJMaF/nwCHQh0MWiPTjt0oPIWdH+9/QilBD0Av7+5W7u+WALX+0oJDEyhLomJwsmZvLwReNYdNJgj4VcfnfOKIakRJEUFcr954xkyR0nMX9CL5mWob4cXjgF1r3aPZ+vaeD0SsbvWwqb32rd4HYmb18Bn//K//bdX8C/z5WCCVKk3rjU976b3oB3rzL29YU5/FLsI17fHhoqwNFkCIke9vGHvj1tnPQIvK9tsxB0wCPQk86VOe1/Ty9CCcFxzpGqBh74ZBvldU3Nrx0qreORJbvYeLiCwiob+ZUN1Dc5qai38+D5o3ly4UQePH+0z+OFhwTx1g0zeOfGGQQHWQLf+1/6Bzj0U8feY6uGvPX+b2RbNTx7Ihxe7fl6zRHQnDLp2B2seBKenuxpmBoqpaGrK/X9HrsNvvlLx3qvrVG23zCEvijdIx9Ldrsfd0GFnwl/S/fKx71f+T+eWQhKdra7mc1omvwul/0B6txrjrflEehCMPxsaChvabx9hYYaKuHQj/6P2dlCULAJNr3ZOcfqApQQHMc4XRp3vL2J11fm8O8Vh3C6NHYUVHPlS6t55tv9LPjXCv6+RPbCBiVFEma1cNqIFM4fn0FsuP+J25KjQxmcHBX4E9A0+Olx2P5h6/s57bDsj/DSHCkaXz8AL50Gj42UguBN+X4o2gprXvB8vbZYPhb7iBvrbP8I/ntHx86jvRz8QRoh3aCBYeB9VbeANLLL/+4Zgmmqk15NY23H22CrbD3ZWuE2dOX75WNjDbi8vJjCbfI89H12fwEfLpLX7chmr323QFQqRKa0zyPIW+fpYdSXQ3WeHBego4d+tr4PuWt9n4M1Esa5PRnztWusgfoy+b9ZXNe+CK+dA+tf890ue737s/NbenVHw4qnZBK9hwzYVULQzbz600Fe+uGAz21vrz3M6oPlJEeH8taaw5z71I+c/eQPVDXYeXvRDDLjwvlwQz4hwRbeuXEmH996ApGhx1H+39EoS/zMhtEX2z+GH/4BeWtg/zfSCCUMhogEGeqoKfLcv859o+/+QhrN5tfdn1Oy23/p4I5PYP2rspd+rDjt8M2fjWPpicuy/cY+bQmBHpM2ezFb34PP7oDnZ0NNYfvb43JJb6mpFQHRe8vl7t+cLyF47gR4YjyUuffJXw9b3pF/L50BW94z9i3cCmljIWUEFGyQ11c3frYqqC6Qgvb1A7JX/unt8n8dvR01cgAjFqvhEXxxt/QUzDgdUqDisiFxMKRP8OxoVJh69GaPUj+Xz/6f5/ejo3sEmhNq3MumOO3SW/P+/bWHsr3gaDi639nW9zv2vXcCSgi6mTdWH+Y/q3y7o++ty2Nkegx/uWAMxTWNHCip5U8XjOGrO09ixqBErpwhl+0cmxlLcnQoI9JiurLp/qkrg5X/MnpZuuH2x6EfIDQWIpOhtlD27FNGwuVvQX2p7DGbqXeHWez1sPt/xuu17hvW2QRl+6RB8g656EYm34en0VFy18DyR2DnZ7JnqxuQsn3y0eUyCcFuz/eW7oP930KOO2x2ZJOxTTdU5Qdg37L2t6exGtBa9yT00EeZySPw1wOuyoUhc+T/J9wBd26HzMnwya3yM5x2eV6pYyB5JBTvgHevhgPfymv/zs/ghVNhw+syab73a/n55jBZuVcnKGMCVOZKw9xQDrmrocn9O3I6pEDt/UqKAMDoBVJEy93hLXNYzPzdVxyCoFBp6FsTAjBCT1velb+9nx73fX38oWnGZ+gC116a6uCD67o8rKSEoBtxujQOl9VzuLyeRocTp0vjsa/38Pz3+1m5v4xNuZXMn5DBaSNS+PnM/rz886lcNaM/Ge7RvpdN6UeY1cL0gcfZIK9tH8CSe6HYHTNuyyM49CP0nwUxmbL3VVsIUSmQNgYmXQ3r/y17eod+kgOOdEMSHAYHlxvH0UNDIHvnGxfDY+lpxAAAACAASURBVKM8DUKVOyGZ556vqq6sY1VGTXXw0c3S4OlGp2yvNII6ekilqYbm1VnNHoGmwfvXwH8ukj3q4DAZjtG9mPIDEJFkfJ4/9iyBtS8bz22V8tFfaMjpkEbW3EZfHoHRUBh7Cdy8Ak7/vfTQTrkXnI1SvMv2g8sOKaNgyrUw8zb5tvwN0rM7uFx+l8v+KF8v2CC9lXpTx8BbCPpNl4KqG2NnE+Sukv/Xl8ow0sSr4OxH5GsjzpWPB7+Xj/p3EpPpmSOozJGeC/jOx+idFjA+W/9tRftf/9onNYWGV1Zd0Pq+3ugibm5PF6CEoBspqGygyenCpUFOWT3b8qt4ctleHvrfLha+KH/8543PIDjIwh/mj+HEoUke70+MCmX1zLXcPuI4W9St1u3W1rkNc72fRCnIG6V8Pww4EaLTZI+9vkzGnQFOulsaqs1vwbb34buHZc/fEgxJQz1d6NpiiEqT24q2w+4v5Q1ZuFWKUkOl0UPLc8eenz/J92hWTZM99revlOEQp0O+9tZC2Pwm7PyvYdxL9xlhofB4ozfY4DbMQSFGkhakF9CcZNVg3GXSuOrHKz8oRRBaD/P89IQMqenoBs5eJ72RFtc6X/aIk4a7E9hlUqxcpjCad0w7cTCkjgaL21Rkz4SQKNkr15PDKSPk31l/kSG9go3w3UMyfJMwWIZIAA64jXV9mfE55QcgOkP21iMSIWmYDCfmmSaW1N+nC/3QMyHGXemWMAhCoo3rWXFIepdx/Y3r4WiUv7P0ce7rVAm7PofDboFxNPn2CA67w3YdLabQPUKQn6tp8O7PPfMg/tC/7y6eOkMJQTdysNTo7e0vrmV9jownvnvjTE4fkcIFEzKa5/rxSW0JsWv+Qdj2dwPd1I6hx1Rr3Z5Afbk0pFV58PEt8jlII/bCqfL/ASdK468bTF0IYjIgNEa+p7FWGrKi7dJoRGfI3qNetllXDLGZsqxw31Ij7HLoJ2nwv7wX0MAaIQ2N3SZ7mIdXerZf02RvffEFMg+Rt1YeO+cn2fPsf4I0VnrYpmyvrGePSJQ9Wr2Xqxui1DFSvPRwyvJHIDwBLlsMg06BaYvkfgUb5WdXHJS9bGHx7xFomvQi6koMo6oLD/gWEL23PPg0+VjoTtq6nFI4dn3esieaMMjzeXCIbPPepTI5LCzSeOtkTJSGO2+tPK9Z/ycNddIwI4nvbDTOq/wAJA+TwhfbD+IHyNcPucc6RKfDfvd11jsWUSnG51kssqdvFoL4/hAWY1z/qjxAk78LkK+/fQW8chZ89zf4c7JxbJBCUFNoCILDZmxz2mUnwCy0LhdUm0JAZXuN/6sLpMDv+FjG/ttCv/5dPBZGCUE3cqjMJAQltWw4XEFmXDjTBibw8jVTefzyia0foNBdwdHeOOTBH3yHDba+b4QMvGmqbz084Qs9Vq8/osl4745PZG26nizcs0TeZMPPljdzdJo09GAIAUBolDRsunE7skmGTqLT5A27/lX452h5w0emyB524RYjVLL+VRli2PWZfD50jtymV8Ac2eJ5YxdslMbnxDvhwhfd51IMPzwm8xhz/iRf0w1b+UHZu0wbK3vAZfs98wPJw43r8c7P4MB3MsQy4hy4+hNp9KMzYOMb8nzs9e6ebpTva7/tQ3l+jVXyvPQQiM0kBIdXwmvnGvF1MPIDuhDo5++0y1j821fIOL5ORKIMB3kzdA5UHZY93PgBYDV1VjImuENiwOgLYfI1cNceyPJaeU4PD5UfkOd67j/hnMfktQAp5ADTbjA8Ot0jiEz2PFbaWCmKLpdbCAZAWKxx/XUBTBomw3Dm0NB3f3Xv47420Rny+zOXmtpNQrBxsfwOt5oS5iufgicnGEJcth+Cw2U7awqMPJZ3xZUv9O/boTyCPsPB0joiQoJIjw1jf0kdG3IqmJgd1/4D6GV47RnRWbxTDiTyLrm0N8jklHdCVuejRfDeNe1vE7QMDYGM6+uVMRsXyx55VT4MnwcL3wJLkKfx9xCCaClguojVl0FkovQW6kpkj7+2UHoTUckyrm1xl88mDTOEUjeY/dwL6uijUptqpEGqK4XP75KeSnCYTJDG9pP7lB+Q4jD5FzJUIty3jjVChlZK90hBSxwkb+KaI4ZhThoqHwu3wp4vYfavYPoi4/wsFjjpLhkLX/2cfC1+IIREtuzZV+XB+7+A96/1vLbgaeB2/88dx3f3TpvqZPIzKBT6uY2yPk7A5TAMkG40T74HLn0dn4y6QIpU2V6ZJDaT4e68ZM+U3pkQEBIhz8dMfZkMTzWUy23p4yFrsvz+IlPk9xoeD5N+LkN9G/9jCIHZIwApBPY6GZKpzJFCEBpjfN+6AMb3lwJR76N4Qf+tZk2W+Z6CjTKkZ7F6egQbFsvHVc9IT8zlhDUvyn3061m6V4bUYjKlR7BniXy9Ot/wkv3RLATKI+j15JbXs2JfKXuLaumfGMmQlChW7C+loMrG5P7x7T+Q3sNoT0Jq81vyMX+D5+t6jH3fNy3jw5omvQhzfLs1ctd69tzMP/q6EvnZA2bL5/u/kcYyNsvYx5yUizYJQYiXRwCGRwCeoZ3IFCkSoxfIkIxe9YIpzqsbK3MC98gm99TGL0rPYdR8CI+ThgmMa508HKxhhmEbeJJxjJHnGcJRc8QwzIlDPY/h3TsGmRRPGCQHpQEk6ELg5RHo+QdzHFpPxptDQ7rxqz4iwzgvnCJDW+c8CmFxUuj0EJbLYeQJ9KqqtLEyXOeL8DiZsAWZGzCTPkGGvSZf4/l6gi4E7u+hvtxIdHtfj1S3VxCTBZFJMGyuLF2tKZQ97RCvMTB6EnjvV9JDih/gDg1Vu0NtOdKgR6dLIfBOUIPxm82aJgVk9xeyci002hCCou0y4Z0+Xn6Xh1fKz9THPeiiW3FQnm9MBhTtkGXR/U+Q2/x5BfXl0hvTv2+VI+jdfLq5gNl//5YrXlrNj/tKGZQkhaCoWvYApnWkAkiP8dYWy4SXP1xOo/bbWwj08E11nqfB3/+NNDq2yrZ7MTr//aXsUeuGyewRlO+Xf4NOkb39nBUyDBSTaexjNv6Rpl5faJTbIzAJQWSSIRxmj0jvLc5/Gq5dYiRdR5wjH8MTZM8QjKomkDdo/noZDpl0Ncy+y/05XkKgJymT3QZwyBnysd90uU2v9qkrNYQgyUsIfFWhBFnhwpdkL1QEyUSrLyEwGzGLe8yIfr3NoSG9Z1+dJyucXA644j15bkLI82o+lmb0QPVrGdLGwkMzbpKCohs4ndAouHs/jL/c83VdOPV8wpGNMlcy8nzoP9Nz3xT3qHj9Wg8/W55j3hopzN7J25SR0tDryVg9NKQ55fWrzIG4ftLrNAvBRS/DL76U/+v3Qb9p8rH8gMwpBIcZQrDzM0DI94G8l3Z8Kn9TlmCjZLkyVyarY0w5rDnuyqkjm+RzvdxVZ+NieOMSox3KI+i9aJrGM9/sY3hqNI9dOp7+iRGcMCSJm04ezN8uGsv7N81kdEZs+w5mq5I/1rhsQDPCMb7IWyt/kFlT5aO50sb8v578LNkDixfIenGQbnd78gR1JTLWrLnj7WYB0Y+dMVH2fPWKDbNHEOXu4YcnyKSkTkiUFIEWHoHJoOpGUReC4FBplAbMljflyb+WRjY20zDueslnbLa8RvnrpUE//ymZwNQ/OzjcqPNvFgL39sxJMOZimHW7fB6ZaFyLhkpAGAlXbzHxJmsyXLoYTrlHCoM5R7D9I/j3eVJMg0LkOfSfZXwWeIaG9JxP/gb5/c26HYaeYWyPTPL8zeg9UF0IQtuYcjx+APzmEAw5veU2iw+zonsEGRPk4/rXpYHVDaSZVLcQxLo7CbrXUbDRs4OgExwqvZeCDUbbQt1jahqrpUcQ5xb/sDjD2EYmG7+F2mIpJmljafZa0sZJ70/PEVQclN9dnBy/g6NBHj8mQ35m6V7ZAXA0SM9Q/32OXgBZU6QYHtkkQ0VPTvCc/K+uBNCM628OR3UBSgi6kBX7y9hdVMP1swdy4aQsvr/7VK6Ynk1qTBiXTc1myoAOeAP6AKWhZ8nHaq+E8Zf3GkkqPZww+RfyscA0eKn5pkiR7jAYvUm9fhvaHguguRPC5lLEWtOITP3YGRM9SwrNHkFUCiA88wMgb+qmWi+PINFTCIbNdR/DawW1uH5wxxbpzg88ST4GWaXY1JfJz5t4pXTzy/ZKw25G7z3rI0T1zxx8OiQOkT3ci1+Gke56dt0jqHd7BGEx0lCFJ8jXLFZjH18MO1OKFnjmCNa/Juvad38pjdp1X0sPAowcQUOl9CbA+B70kct6NU7z9fNKuOrfhz7Owjv84ouOlFWGx8ucy7RFMr9SdVj+5hIGtty3OTTkFswkd7Jdc7XMD+iMOt/dJos0wmHuDpWtyp030IXA1NGKSDQEr7ZI5ntCIo3BamljPT2Cylx57KAQ+Tl2m0zsB4fJ8F/ZPqPSKC5bClpQqCyBBikGh1dLbxtkGNDllPdOvfv3pYd5lRD0HkprG1n0+jryKuoprW3k/o+3kRwdynnjO2G2T73KYYDbNTeHR0r2wKp/yakbwBjxOmyu/AGbpzOoOSJ709NvlMnFkt2e0/zqtBUe8jUwyel2b0Oi5U2cPVNWoSSaShJjTUIQZJU9Ve+bPTRK9ry8PYKIRCMpfPKv4fynZY/eHwvfgfOekv/rnxEe5w6XuA1opo+1vfU8QUSSNOoAA2fD/61v2XMOiZQeRF2pDNXohkf/vOg03z1mX+ihocZaw6CX7ZUeRsJAGUoLi/MMDXl7G/qEcm0Jge4R6GM+Qjt5LiohYM4fpDEMd3d49LCdNymjYcxFRicnNMrohXu3W2fEuYCQeYXgECnAIA1rfZnJIzALQYLx/TmbjOqnVHe7Ukd7CkHVYdmxEEJ+x/YGKQbWcCkeZfuh8pDcN66fvN9+vd8QtkGnyHDplndkW/d+BQ9ne05ToguBXQlBr+HzLUf4akcRT3+zjxsXr+dIVQPP/WwSYdagtt/cFvoPLtsdXzUnjPXSNt1AVB+RPbLIRNkbN0/KVlMke+CTr5E9nbUvyYShCHK7yu7aa3O830xFDjw+1seUDe7eYnCYUU54kjvurodKQqI9b0yQVUTe4YaQKHfYQ5ODhUAKhsXiThgL2WucdFXrRjYo2NiuG5QId/XRMLfR0RPJZvR9/YV0zAgh21Zf5vYI9Pa6j9GRUaq6EBxcLg2Vfk3NvejIZM/QkDnU1tymICOJ3fw+L6/EOznZHo/gaIlwh89S/QhBcAhc/IoxAAyM6iR/HkFUiixrzRgvn+u/E318gS4k5t9beII04nonQBeCKdfKXnxYjHzNbpM99+oC4zpaw6QX5WiQ+yQNlR2fHHfhQqxbMMwdhUHuMTO2Sph6vfQiXA6ZhNaFQK9w8+URBHACu+NohrLex7Jd0ni+vVb2sB+/bELnrflbcUga8KhU9wCptfDj4zLmv/O/cp9mISgwQjAxGV6jcQvds0cmyUqZLe/KBGhsFlzwL2nIXzrdc/oGM7lrpDusD/rRicmUiUprhDSuR7bIcApIMQJPb0Dn/Kdavma+mTImyEFdusHTK4esYb7b5w/doOhhmrP+Knuh4T7KdzsiBCANXV2p9GDC4jw/LzrN//u80XME+76W/w+YDXv+51mKGZnsGRpKHS0Nmz4eA2TvNMjrVvfnEZg/O1C0JQS+SBkBe5f4zhHoXPaGEa7SDb5eUKF7RPrrIVHGbyY0Whpna4R8Puhk+QfSA7RVSwPtcshrCW6PwCb/gsOMJPieJVKEfP2OYjPlfqV7ZCjxnEfh9QtkJ0sf7+EvNOS0y2TyuEthwhWtXqqjQXkEAaKu0cGq/WWcMTIFi4A5o1I7dwEYPQEmhDRQOz6Gpb+XseTqPGngdANRU2D0RGMypIeQuxbevEweRzdOA06UN0TOCtmjGXCiySMwhYaW/BY2vyP/1yswityJ16hU9wRy7ps9JBKu/hR+fcC4SfUebYwPIfCFWQjGL4QbfzBu7PGXw5RftO84ZvQ8hG6UEgbC2It979tRIYhMkiGWBnNoyDRSur3oOYKi7bIsc6C79NY82jcySX43NYXyuwuPM66X3m7vsJB5m47Z8ASHtRSOziSijdCQL5o9Aj+hIZCeRJA7VBidJgXxwHfyuXdoKNzUIdMTy+aBcc3HDJfXRk++x7o9C90jsNfL92VOkaKvh4/8MWSOvL56yWyUe8xEg3u0vT6y2FuYl9wnJ/PTQ6GdjBKCAPHjvlKanC6uPXEgX95xEk8tnOh/AZj938rSy464fuYE2IhzYdg8+OUW+O0RuGsvTPyZMf1AdYFhgKLTpRew+ws5uKl8v2Gk0t1udU2B0eMODnFXWrg9Ak2Tc+XvdM8BrwuBXoFz1l/h3MeMHqU1Qh7D3GMPjZZeQWvr0pox907DYjxDBlOvlwO0OkpzaKgdHprem2+3R+AW4YYKwyM42tCQ5pRGKDpNDuQaNR+yTXmQyGQ5HuIfw+X3HRpjCIHe426PEJgNTyC9AZDiFRTiOTVFWww4UZbs+grd+SIsRoZN68vkb1APhelCYP7e9evlUwhC3UKgJ4H7GfvabXKbNVz+xkfNd++T7b9dp94Li74zynMjk2X+zXu6anP56OHVciDojFth3CVtnflRoUJDAWL5nhIiQ4KY0j+BkOA29HbX57InP/M2o+a8NZwOWd0x1i0Ec7zmbI9KkX8uuzRIdSWGEYvJkC6uPukaGB5ByiiZOHY5vMo6U4wcga1SliPqFUHe88kPOkXedFvc8x+FRPg+h+uXGq54W5gTl51lpHTj7h0r90WzEe+AR6CHEvQKlI6KCRjnWlMgxTo2s+VoX70HnDJKJuz7TTOmiUgbK3uR3qN6zeekYxaCzk4UezPzNtkzDupA7zauH9y6uu39zAyfBzk/Gp4ztCEEPn6PusGvcgtBcwcpXPbe7Tb5P0iPcsO/W+ZjzIRGe3aAIpN9Tydhfm39qzKfdup9/o97jCiPIED8tK+UGYMS2xYBMNzC9sw9X7QD1jwve4q6R+AL/UYvcifL9J6obvTNszvqHkFwqPEjNQtBZIpRNaSXF+pC4L3Mod4D1ns8Vj8DkyIS2h/XN4eGOstI6bFmPTTUGnoPz1epo89jJxkVVJmT5aN+PVvrLXpjHtTlL0k64lzZ8736E7hzmxzdrF+j7JkylKDX7nu00U/5KEijE0iShhrltoFk+Dz5aL5P9N+n+Xtvl0eQK9/T/Lt2VxPZ643fcf8T5PQmHTk3f9+ryyE7fA0VcgzJ2IsDKtDKI+gkNE3j5R8P8tX2IkZlxHCorJ6fzxrQvjfrs3HuXyZHbOrkrZO9gfOeMqpdPr7ZGNwU15oQuHu6zYOY3PF4vVfraJDvr8zxNE7p42WlhblXE5VsVF/oUxDUFMkkmjl3EBZrxJabb5hWZk9tL2bD1FlGKqoDQpA1Fa5fZhj1tjCPE9CN8ICT4KqPWi9v9cZDCFJ97zNwNgz80ut9boORPg7u3uc7cdl83gLQutYj6CoSB0th1Kt1wLgWPoXAh0eg5wiqCzw7R8Hh8r512Y33WYLgopc61kZ/5bAgP3f5o/LRe8qOTiagHoEQYq4QYrcQYp8Q4h4f22OFEP8VQmwWQmwXQhxF1q97+e/mAi59biUfbsjnz5/v5EBpHa+tOATAiUPaEXYAwyM49KNnbHDX53KyLT3skr9BioDeq2mth9o8NYK7aiIm3fMRZJL1ms89bxQ9BmsWB7NHUO0WAmejabSt+wYJ9+Fu+wsNdQSzYeosI5U2Ds54UE5f0BZCyPr39g6g0kU4aZgRirBY5KyfHRmEZQ6D+es5+kK/9hGJvkUAjNyPXm/flTmCruSy/8DU64znPpPFbXgE9gZ3It70HmuYMbdTcAcr1sx4CIHXb2Pre7DyaZh6g2+vrhMJmBAIIYKAZ4B5wChgoRBilNdutwI7NE0bD5wC/EMIEUIP4qUfDrDmUDl3vb+ZQUmRfHPXyQxMiiQ9NowhKe28oeorZJ2/vd73qF99pO+6l2Xv46YfZKlca2EGf3PkRKYYM2fGD5RJOHPt/YQr5c2TbErkJQ2VUx6X7DFCQ2BME6FPdWCOu7YVGuoI5tBQZxkpi0VOM+3PUB4LukeQMan1/dqiPR6BL0Kj5XVvyxub80djLQQPIeiE7+x4JTwBpt9kzD0FrQuBNVyGYetKPccgWCOMDtyxeL1mIdDvUX26lK3vy5Hycx86+uO3k0B6BNOAfZqmHdA0rQl4G5jvtY8GRAtZThMFlAP+1s077jhYWsfmvCoGJkWiaXDHnGHEhFl5e9EMFl83zX+VkDcN5cYslnrdMxj1/hWHZGhm01uyhjguu+04pO76lu+XYSHdiwgKNuLjvqpJrOHSnTaj3zQ7P/EcwawvHqILQbgPIegMjyAkAMniQKJ7Xfp0z0fL0QrB6AvlgjBtMfnnxqRxjl4YGvKFxQLz/uZZutpcPuorNOTu7dcWeXYagsOMUs/OEgI9qa/fRzVHZE6vI0n1oySQOYJMwDxXQR7gHSB9GvgUKACigcs0TZ+xzEAIsQhYBJCd3YFkW4B5f30uQsAb10+nvK6J0RnyB5UaE0ZqTDvdRUeTrBVPHSsnoTILgV6yWXFQegMRCXDqb9t33CCr9DIaKuSoWbMoxbhLSH0JgS9iMuT0vDs+lb2n8AQpXjkrZRlo4hC5n4dHYCofPVaajxXZ/ukZupPYLDmrZXtzCv7Qz1tY2lfmqjP0DM8J5lpDNzLmKQ0CnSw+3mg1NOS+j+31Xh5BeMt9jgY9RGerlPdjzo/uAYnFUgg6UlxwDATyrvLVHfYulD8L2ARkABOAp4UQMS3epGkvaJo2RdO0KcnJrSRXupBnvt3HM9/u54yRqWTEhTMmM7b9HoAZ3b2MiPdccg+M2SH3fi2ncDj5Nx0zCHpvQ5+QTSc6XYpER8Iio+ZLkcr5yTBwLrtMSOoVSeE+hKAzwgwWixSBntRT7T/TcwbVo8Fca27phGlJfKGHIewNRsiwJ13nzqDV8lGTkQ/z8gia9znGgojIZHk875Jme728T7uAQApBHmAuqM1C9vzN/AL4UJPsAw4CXitdHD+sPVTO/R9v5a01h3lkyW7mT8jgqYXtHODiD71iKDxBGtWiHXI4udNhjAzWk7L6EoPtJTJZVjeYF08Bufzfab/r2LHGLzSEJXGwHBAEsspIH8VpTmg25wg6wSMAebP2hLBQZ6Jfw44kijuKPlLV0SBzGyFR7R/x3Vtoj0cAgfEIQH6/4fG+xzh0kRAEMjS0FhgqhBgI5AOXA96TZBwGTgd+EEKkAsMBH8sHdT+LV+XwwCfbmgf/jkiL5u8XjyM02E9PrXQvbH5bhnJaC2c0ewQJspLF2SjfGx4PaMYAr6jUlguJt8W4S2HwqS1/4INPg8EdOxSRiXJ2z7cuk9UwUalyltK0cbIH+fNPjXnkoXNzBCA/ozcnMX2hi2hH8gMdRfc07A1S0G/8vvWSxt5Iq+WjJiPvnSPQOdbOjj6Qs1kITKWtgShm8EHAhEDTNIcQ4jZgCRAEvKJp2nYhxE3u7c8BfwJeE0JsRYaSfqNpWmmg2nS07C2q4U+f7eCkocncfdZwXv7xIDefMti/CICcxXP1czDmQk8D6Y3ZI9Bv+KJtxgjjtHFywY3+szpWegidX3s8fC7cvlGOMdj0phQCfVoK72UNm2+uTjLeeiVMX8ISJI1MIIWgOUfQIL2Djox87i00D4JsQwj8eQQdnfDQm7kPA5oxWaSHEPR8jwBN074AvvB67TnT/wXAmYFsQ2fw+0+3ExkSxKOXjCc5OpR/XtaOml59/vjc1a0Lgdkj0IeqN1TIAVsA2TOkEGTPOvoT6Ex0ryQmHWqy/E/REJWKnB++A3PrtMbsXxnhqL7EzFuNqqxAoOcI0LqkOuW4JGMCnPWQ79CrR47AZJQ9QkPHmCPQB2H69Ah6gRD0BvIq6lmxv4y7zhxGcnRo+95kq5a9epATRk251v++Zo9A7/E3mebyGb1AJopHtGPgU1dyxh8818j1Jr4//HJz51U9eJe09hVOuz+wx7cE+/6/L2EJgpm3+N5mNvJmj6Azk8U6/abLSRTNOT0lBMcHn2yS+e35EzqQQMtdI1fkikz2XO7RFw3l8kcVEuGefVRIN10XgvTxcN1XR9f4QJLYjiRDa3MhKY4PzMa/r3oErRFs6vyZ4/UeoaFOEoLQKDjnH55rf4R1TY6gBxRldw82u5OHvtjJ4pU5TO4fT7+EDiSEDq+QVTRTb5CDwfQwjy/qK4yySyFkTNheLweThcd7/hAVis7GwyNQQtACazs8gmOtGvLGI0Hd88tHezRLdxbx/PIDBFkEi07qYLVO6V7ZYx7iHtSjj8D1RUO510CsCBkaqisObJJQoQBPLyCQi9H0VPSOmDXS81qZK4U6yyNo/kwlBMcN3+4qIS7CyvJfn8pZozuwvCDIHn1otExChcXB/m/k63VlnnMJgXuFMFNC1epeFLuxxhj6rlAECuURtI6eI/BeW1tPIluCOz+kFmQ1Bvd1UfmoEgIfuFwa3+8pZvbQZIIsRzFauKlO1rxbgmQlwr6lMv6/5F544WT4cJF8bquWK3tlTTHea42UC7801va9EZ6KrkflCFpH9wi8DbIuEMdaMeQLIaRXEBzW+d6GH5QQ+GB7QTWltU2cOvwoB9Y01Rk170POkInfwi1y4ZngcNjyjlzZK38doMlVpXRCIuRC1rqYKBSBRFUNtY61DY/gWMcQ+CM4rMvCQqCEwCerD5YBHVhPwJumOmNwypDT5eN3D8sFzYe5h03YKuUC8gi58LWONUKGhppq+97kX4quxyNHoDyCFliCZZjGu3pH9wQC1WNXQtD95FU0EBUa3P5xA97Y643efHSarIHf7R5Xpy9wbasyBpuFmXIB1gh3aKhGhYYUgUflCFpHCGn0W3gEAQwNgfQ0lBB0L3kVZnQfUQAAFfVJREFU9WTFhx/dbKLgGRoCOO0B2atIGg7J7jn1bNVyoJg5PwCm0FCtCg0pAo8QstQZlEfgj9RRnusXgCEEgQoNRSR16XQfKijog9zyho6NGzCjaS3j+8nD5ECRiCSjZ1FXIsND5nVQQXoEtko50Vxfm21T0T1YgsHpVDkCf1y/tOVrQVYpoJ01u643l7zW+eMTWkF9815omkZeRT0zB7djUXNfOBrl0nbeE1jp00w01shHffnJcK/1BawRxvTToSpHoOgCLMFy1lvlEXQMa3jgjHVs104FrkJDXlTW26lrcnbcI3A64P1rjSkl/M2UGRIlw0TlB+Vz74VmQiJoXr9HhYYUXYE+kEzlCDpGF5Z3BhrlEXiRWyHXIc2K7+AXXFsI2z4wEjz+jLgQcqBYhVsIfHkEOio0pOgK9JCQGlncMawRfUsIhBAzgO2aptW4n0cDozRNWx3IxnUlTpfGw//bSW65XMS7w0LQWCsfq92LsLW2IEtYrBEa8vYIzEKgqoYUXYHuCSiPoGOc+UeIyWp7vx5Ae7sAzwKTTM/rfLzWo7n/4228teZw8/Os+A6Ghprq5GNVnnxsrTcfFguVOfL/Fh6BSYDUOAJFV9DsESgh6BCjF3R3CzqN9uYIhKZpzQvPa5rmoheFlcrrmnhrzWHmT8ggKjSYmLBgYsM7eFM0uZPAuhC0Vk1grklukSOI9P2/QhEoVI6gz9NeY35ACHE70gsAuIXjdG3ho6GgUoaD5o1JY96YdHLL6zt+ED00pK841poR14UgOLxljFGFhhRdjcoR9Hna+83fBDwJ3I8saVkGLApUo7qaomobAKkxYUzMPsrRfE21ns/bIwQRPkpUPZLFKjSk6AJUjqDP0y4h0DStGLg8wG3pNgrdQpAWeww1wfr4AJ32hIYifIiOOcmsQkOKrkDlCPo87a0aepXm4nYDTdNaWYy351BUZcMiIDnqGFYDOxqPwDtRDIaAWILV6mSKrsHinmJCjSzus7T3m//M9H8YsAAo6PzmdA+F1TaSokIJDjqG8XV61ZBOa0KgLzjjnSgGQwhCoozF7BWKQKJ7Asoj6LO0NzT0gfm5EOItwMcEHD2TwurGYwsLgZEsBveqRSH+923NIwgxCYFC0RU0h4Za+c0qejVH2wUeCmR3ZkO6k6IqG6kxxygETaYcgTWy9d58c46gFY9AVQwpugpdCFRoqM/S3hxBDUaOQAOKgF8HqlFdTWG1jWkDfRjljmD2CFobVQztyxEoj0DRVahkcZ+nvaGhaCFEAtIT0LvOLZLHPRGb3UlVg/3YQ0NNtXJaWs3ZdrVPq+Wj7nEFqmJI0VUEqfLRvk57PYLrgV8CWcAmYAawEjgtcE3rGgqrjDEEx0RjrVxIoiq37TnKU8fAnD/B8Hkttwkh36+moFZ0Fcoj6PO0N0fwS2AqkKNp2qnARKAkYK3qQprHEBxzjqAOYvvJ/9sK61gscMLtnktUmrFGqNCQoutQOYI+T3uFwKZpmg1ACBGqadouYHjgmtV1FDUPJmujZj9/Pax+3v/2phr30nKi7RxBW5x0N0y44tiOoVC0F+UR9Hna2wXIE0LEAR8DXwshKugl4wjaHRpa+Yxcb6D/CS3XLwUZGgqLkfH/Y43vz7jp2N6vUHQEi5p0rq/TLo9A07QFmqZVapr2IPA74GXggkA2rKsorLYRGRJEdFgbN0HhVvm48hnf25tqZTgnYyKkjOrcRioUgaR5QJkKDfVVOjyOQNO07zVN+1TTtKa29hVCzBVC7BZC7BNC3ONj+91CiE3uv21CCKe7OqnLKKq2kdpWxVBTHZTuleMDtr4H9eWe250OcNhkgvfqj+GUFqeqUBy/NE8xoTyCvkrA1iwWQgQBzwDzgFHAQiGER1dZ07RHNE2boGnaBOBe4HtN08pbHi1wFFbZ2k4UF+8ENFnl47JDbbHndn0wmUrwKnoiFjXFRF8nkIvXTwP2aZp2wO09vA3Mb2X/hcBbAWyPT4qqG9sWgsIt8jFrqnx0NHhu1+cZUrX/ip6IyhH0eQIpBJlArul5nvu1FgghIoC5wAe+tgcKl0trX2iocCuExkLSEPnc0ei5XR9VrKaFUPREVI6gzxNIIfA12Y6/0cjnAT/5CwsJIRYJIdYJIdaVlHTe8IWyuiYcLq1tjyB3LaSNlSuKgcwHmNGnoFYLySh6IipH0OcJpBDkAf1Mz7PwX3J6Oa2EhTRNe0HTtCmapk1JTk7utAYaK5N5jSFwNMGhn6BwGxTtgKKtMPJcCHYLRguPwJ0jUB6BoieicgR9nkD6gmuBoUKIgUA+0ti3GCUlhIgFTgZ+FsC2+MS8RKUHW9+DT26R/8f1lzHUsZdAbZF8TfcINrwuRSHSLU6hfkYKKxTHM2pkcZ8nYB6BpmkO4DZgCbATeFfTtO1CiJuEEOYRUwuArzRNq/N1nEDid4lKW5V8HHUBVObA0DMhMsnTI9A0+OYvsO4VY8F6X5PIKRTHO2pkcZ8noF0ATdO+AL7weu05r+evAa8Fsh3+KK2RQyFaLFGpOeXjeU/ISqFhc+VzfelIe4OsJKotBM0F9WXydV/rCygUxzsJAyEyxciBKfocfdoXrG9yEBpsablEpcshH4NDYdZtxutmj2DvV+6DlMkBZtZItcawomcy5iL5p5ZG7bP0cSFwEhES1HKDLgTeMVPd0DtssPdr+b/mhPKDKiyk6LkoAejzBLJq6LhHCoEPLXS5Q0PCSyTMHkHRdmOFsdI9EBEfuIYqFApFAOnTQtBgdxDuzyMQFrlugJkgqxQHR4McTRw/QL5ecUh5BAqFosfSp4WgrtFJpD8h8FdKFxwGDZWABnHuYRKa0/f6wwqFQtED6NNC0NDk9O8R+BWCUKNKKC7beF1VDCkUih5KnxaCervDf46gVY/APW4grr/xugoNKRSKHkrfFoJWPQIfr4PbI6iQ/0ckGrXXKjSkUCh6KH1bCI4mR2ANNzyCkEg54hhUaEihUPRY+rYQNLUSGvIuHdUJDjVWKLNGGAKghEChUPRQ+rQQNNj9hYbayBHoC9OERECE2yNQoSGFQtFD6bNC0ORwYXdqRFiPIkegExJlJIlVslihUPRQ+qwQNDTJ0cMRob5CQ22MI9CxRqgcgUKh6PH02bmG6u1yPiG/cw21No5AJyQShpwhF7O3RgSglQqFQhF4+q4Q6B5Bh4XANFWvNQKGnC7/FAqFoofS50ND4T5zBM62cwQiSE07rVAoegV9VggMj+AocwQhkWr6XoVC0Svos0JQ1+TOEYQeZY5A5QQUCkUvoc8KQcNR5wh0j0AJgUKh6B30WSFoDg1ZfRh8zeU/R2A1hYYUCoWiF9BnhaDBHRrq+KRzbiGwKiFQKBS9gz4rBHVujyDyaHMEKjSkUCh6CX1WCPTQUFjwUeYIVLJYoVD0EvqsEDQ0OQi3BmGx+CgBbWvSOVA5AoVC0Wvos0JQ3+T0XTEE7Zt0TgmBQqHoJfRpIfCZKIb2TTGhQkMKhaKX0IeFwNGGR9BWslh5BAqFonfQZ4WgvK6JhMgQ3xvbkyNQHoFCoegl9FkhOFJlIy0mzPdGlSNQKBR9iD4pBC6XRlG1jbTYcD87tOIRWN3vCYkKTOMUCoWii+mTQlBe34TdqZEe25pH4EcIEofAnD/B8HmBa6BCoVB0IQEVAiHEXCHEbiHEPiHEPX72OUUIsUkIsV0I8X0g26NTWGUDIM2vEDjlegO+EAJOuB3C4wLUOoVCoehaArZCmRAiCHgGmAPkAWuFEJ9qmrbDtE8c8C9grqZph4UQKYFqj5kjuhAcTY5AoVAoehmB9AimAfs0TTugaVoT8DYw32ufK4APNU07DKBpWnEA29NMYbUUgqMKDSkUCkUvI5BCkAnkmp7nuV8zMwyIF0J8J4RYL4S4OoDtaaawqoFgiyAxys9Sk0oIFApFHyKQ1s7XOo6aj8+fDJwOhAMrhRCrNE3b43EgIRYBiwCys7OPuWFHqmykRIcS5GueIU0DrZWqIYVCoehlBNIjyAP6mZ5nAQU+9vlS07Q6TdNKgeXAeO8DaZr2gqZpUzRNm5KcnHzMDZOloz7CQk47OJvk/0oIFApFHyGQQrAWGCqEGCiECAEuBz712ucTYLYQIlgIEQFMB3YGsE2A9AjSfY0hWLwAvrxX/q+SxQqFoo8QsG6vpmkOIcRtwBIgCHhF07TtQoib3Nuf0zRtpxDiS2AL4AJe0jRtW6DapFNS08hJQ33kBypyDAFQHoFCoegjBNTaaZr2BfCF12vPeT1/BHgkkO0w43C6qLE5iI/wMc/Q/2/vfmPkquowjn+f/tkWWqSF8i+llAKNsQQpsKkKSjCoQGPSkoBWgRA1Eg0kkkhiCYrEFyaa4DsUMJJUJIAKSIMmokRQXigtTVsopVIqptsSitgW22X/zPbni3umO52dWTbdnbnsnOeTbObeO3e259eze5899849U+mDgd5i2UFgZpnI7s7ife8NAjDn2Okjn6z0wcDBYtlBYGaZyC8IeouLwc2D4ECx7GsEZpaJ7IJgb28xIhhxaujQoeIdQ4M+NWRmeckvCA4WI4IRQTDUXzwePjXkEYGZ5SG7INjX2+QaweB76dEjAjPLS3ZBsDddI5hb/+lklf4j1x0EZpaJDINgkOlTxaz6zyuu9B257lNDZpaJ7IJgX+8Ac47tQqqbZ8gjAjPLVHZBsLd3gLnN3jpay0FgZpnIMAgGmdPsruJaDgIzy0R2QbCvd4A5x4xlROBrBGaWhwyDYLDJPEO+RmBmecoqCCKCfb2DzJnlawRmZlVZBUHvwBADQ4cajwgGHQRmlqesguCNd4rpI+Y1+qzi+hGBfI3AzPKQVRD8et1OuqZO4dMfbvBxlyOuETgIzCwP2QTBwf4Kj23YxfLzTuXEsYwIfGrIzDKRTRA8tXk3B/orXP/xhY13cBCYWaayOdpdfcHpnDhrBhctnNt4BweBmWUqm6Nd17QpfGbJKc138DUCM8tUNqeG3pdHBGaWKQdBVaUPqJmR1EFgZplwEFQN9sHMDw2vOwjMLBMOgqpKH8w8fnjd1wjMLBMOgqpKP8ycM7zuEYGZZcJBUFXpg67Zw1NLOAjMLBMOgqpKH0ybAdNmFus+NWRmmXAQVFX6ihCYlmYm9YjAzDLhIKiq9MP0mcMjAvm/xszy4KNd1eERwYxiNCC9/2vMzDqAg6BqsOYagU8LmVlGHARVlf4jRwRmZploaRBIulLSNknbJa1u8PxlkvZL2pi+7mxle0Z1+NTQTL9jyMyy0rI/fSVNBe4BPgv0AOskrY2IV+p2/VtEfL5V7RiTCBjyiMDM8tTKI94yYHtE7ACQ9AiwAqgPgvbY8yq88uTw+sKLoWsW7N8Ji68otvkagZllqJVHvPnAzpr1HuBjDfb7hKRNwG7gtojYUr+DpJuAmwDOOOOMo2vN21vh2R82fu4LDxaPs0/2iMDMstPKI16j919G3foGYGFEHJC0HPgdsHjEiyLuB+4H6O7urv8eY7NkJdy5t1ge6odND8OBt4tw+P23i/sGFl8BO54dnmbCzCwDrQyCHmBBzfrpFH/1HxYR79Ys/0HSTyXNi4j/THhrpOF7A6YcA91fLZZfexp2rYdFl8Lsk+D8L8GCRgMXM7PO1Mp3Da0DFktaJKkLWAWsrd1B0qlScXSWtCy1550Wtmmkc1cWj0vS4zmXw7Kvt7UJZmZlatmIICIqkm4B/ghMBR6IiC2SvpGevxe4BvimpArwHrAqIo7u1M/RWnod7N8F513b1n/WzOyDQu0+7o5Xd3d3rF+/vuxmmJlNKpJejIjuRs/5zmIzs8w5CMzMMucgMDPLnIPAzCxzDgIzs8w5CMzMMucgMDPLnIPAzCxzk+6GMklvA/8+ypfPAyZ+HqMPNtfc+XKrF1zz0VgYESc1emLSBcF4SFrf7M66TuWaO19u9YJrnmg+NWRmljkHgZlZ5nILgvvLbkAJXHPny61ecM0TKqtrBGZmNlJuIwIzM6uTTRBIulLSNknbJa0uuz2tIOkNSS9J2ihpfdp2gqQ/SXotPc4tu53jIekBSXskvVyzrWmNkm5Pfb5N0hXltHp8mtR8l6Rdqa83ps/8rj43qWuWtEDSXyRtlbRF0rfS9o7t51Fqbk8/R0THf1F8QtrrwFlAF7AJWFJ2u1pQ5xvAvLptPwZWp+XVwI/Kbuc4a7wUuBB4+f1qBJakvp4BLEo/A1PLrmGCar4LuK3BvpO+ZuA04MK0fBzwz1RXx/bzKDW3pZ9zGREsA7ZHxI6IGAAeAVaU3KZ2WQGsSctrgJUltmXcIuKvwH/rNjercQXwSET0R8S/gO0UPwuTSpOam5n0NUfEmxGxIS3/D9gKzKeD+3mUmpuZ0JpzCYL5wM6a9R5G/0+erAJ4WtKLkm5K206JiDeh+GEDTi6tda3TrMZO7/dbJG1Op46qp0k6qmZJZwIXAP8gk36uqxna0M+5BIEabOvEt0tdEhEXAlcBN0u6tOwGlayT+/1nwNnAUuBN4O60vWNqljQbeAy4NSLeHW3XBts6pea29HMuQdADLKhZPx3YXVJbWiYidqfHPcATFEPFtySdBpAe95TXwpZpVmPH9ntEvBURQxFxCPg5w6cFOqJmSdMpDogPRcTjaXNH93OjmtvVz7kEwTpgsaRFkrqAVcDakts0oSTNknRcdRn4HPAyRZ03pt1uBJ4sp4Ut1azGtcAqSTMkLQIWAy+U0L4JVz0gJldT9DV0QM2SBPwC2BoRP6l5qmP7uVnNbevnsq+Wt/Gq/HKKK/GvA3eU3Z4W1HcWxbsINgFbqjUCJwLPAK+lxxPKbus463yYYog8SPFX0ddGqxG4I/X5NuCqsts/gTU/CLwEbE4HhdM6pWbgkxSnOTYDG9PX8k7u51Fqbks/+85iM7PM5XJqyMzMmnAQmJllzkFgZpY5B4GZWeYcBGZmmXMQmLWRpMskPVV2O8xqOQjMzDLnIDBrQNL1kl5Ic8DfJ2mqpAOS7pa0QdIzkk5K+y6V9Pc0MdgT1YnBJJ0j6c+SNqXXnJ2+/WxJv5X0qqSH0l2lZqVxEJjVkfQR4IsUk/gtBYaA64BZwIYoJvZ7Dvh+eskvge9ExEcp7gKtbn8IuCcizgcuprg7GIqZJW+lmFP+LOCSlhdlNoppZTfA7APocuAiYF36Y/0YignODgGPpn1+BTwu6XhgTkQ8l7avAX6T5n2aHxFPAEREH0D6fi9ERE9a3wicCTzf+rLMGnMQmI0kYE1E3H7ERul7dfuNNj/LaKd7+muWh/DvoZXMp4bMRnoGuEbSyXD4s3IXUvy+XJP2+TLwfETsB/ZK+lTafgPwXBRzyfdIWpm+xwxJx7a1CrMx8l8iZnUi4hVJ36X4tLcpFLN+3gwcBM6V9CKwn+I6AhRTIt+bDvQ7gK+k7TcA90n6Qfoe17axDLMx8+yjZmMk6UBEzC67HWYTzaeGzMwy5xGBmVnmPCIwM8ucg8DMLHMOAjOzzDkIzMwy5yAwM8ucg8DMLHP/B7mPvOAye8enAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric('auc', 'val_auc', 'auc')\n",
    "plot_metric('loss', 'val_loss', 'loss')\n",
    "plot_metric('accuracy', 'val_accuracy', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T19:49:28.586267Z",
     "iopub.status.busy": "2020-08-08T19:49:28.570806Z",
     "iopub.status.idle": "2020-08-08T19:49:28.603366Z",
     "shell.execute_reply": "2020-08-08T19:49:28.603961Z"
    },
    "papermill": {
     "duration": 0.589254,
     "end_time": "2020-08-08T19:49:28.604126",
     "exception": false,
     "start_time": "2020-08-08T19:49:28.014872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [1.3709207773208618,\n",
       "  0.9181996583938599,\n",
       "  0.8451749682426453,\n",
       "  0.9483582973480225,\n",
       "  0.7620341777801514,\n",
       "  0.7111567258834839,\n",
       "  0.717616856098175,\n",
       "  0.6714364886283875,\n",
       "  0.6953167915344238,\n",
       "  0.6167508959770203,\n",
       "  0.6161810159683228,\n",
       "  0.6033344864845276,\n",
       "  0.5828312039375305,\n",
       "  0.5789617300033569,\n",
       "  0.5757079720497131,\n",
       "  0.5867489576339722,\n",
       "  0.5714876651763916,\n",
       "  0.5479499101638794,\n",
       "  0.5473689436912537,\n",
       "  0.5422126650810242,\n",
       "  0.5344599485397339,\n",
       "  0.5476610064506531,\n",
       "  0.5470278263092041,\n",
       "  0.528260350227356,\n",
       "  0.5141686201095581,\n",
       "  0.519288182258606,\n",
       "  0.52347332239151,\n",
       "  0.5114681124687195,\n",
       "  0.4987756013870239,\n",
       "  0.4980456531047821,\n",
       "  0.5020077228546143,\n",
       "  0.47320491075515747,\n",
       "  0.4961674213409424,\n",
       "  0.4977782368659973,\n",
       "  0.47850942611694336,\n",
       "  0.48685789108276367,\n",
       "  0.48438286781311035,\n",
       "  0.4643111824989319,\n",
       "  0.46827957034111023,\n",
       "  0.4756180942058563,\n",
       "  0.46976301074028015,\n",
       "  0.4666987955570221,\n",
       "  0.46271008253097534,\n",
       "  0.4662439525127411,\n",
       "  0.4753030240535736,\n",
       "  0.4569293260574341,\n",
       "  0.4663461744785309,\n",
       "  0.45142123103141785,\n",
       "  0.4562159478664398,\n",
       "  0.4531111717224121,\n",
       "  0.45078393816947937,\n",
       "  0.44859760999679565,\n",
       "  0.444705992937088,\n",
       "  0.4400414824485779,\n",
       "  0.451651006937027,\n",
       "  0.45702749490737915,\n",
       "  0.43931347131729126,\n",
       "  0.4484899640083313,\n",
       "  0.44175952672958374,\n",
       "  0.4398100972175598,\n",
       "  0.4349650740623474,\n",
       "  0.4425555467605591,\n",
       "  0.4431568384170532,\n",
       "  0.42477813363075256,\n",
       "  0.4301396608352661,\n",
       "  0.4250987768173218,\n",
       "  0.43902766704559326,\n",
       "  0.4223830997943878,\n",
       "  0.42385008931159973,\n",
       "  0.41106775403022766,\n",
       "  0.41416698694229126,\n",
       "  0.41780662536621094,\n",
       "  0.4235231578350067,\n",
       "  0.42108964920043945,\n",
       "  0.4157932996749878,\n",
       "  0.4100722670555115,\n",
       "  0.41401800513267517,\n",
       "  0.4123806655406952,\n",
       "  0.4093596041202545,\n",
       "  0.4161178767681122,\n",
       "  0.4167250990867615,\n",
       "  0.420503705739975,\n",
       "  0.41968244314193726,\n",
       "  0.4212094843387604,\n",
       "  0.40061914920806885,\n",
       "  0.4221562445163727,\n",
       "  0.4050031304359436,\n",
       "  0.39671793580055237,\n",
       "  0.39817148447036743,\n",
       "  0.40114453434944153,\n",
       "  0.4050443470478058,\n",
       "  0.3893626928329468,\n",
       "  0.38536736369132996,\n",
       "  0.4002840518951416,\n",
       "  0.4027736783027649,\n",
       "  0.39893224835395813,\n",
       "  0.3957144320011139,\n",
       "  0.4097232520580292,\n",
       "  0.397230863571167,\n",
       "  0.41383448243141174,\n",
       "  0.39754992723464966,\n",
       "  0.37492701411247253,\n",
       "  0.3900068402290344,\n",
       "  0.37400153279304504,\n",
       "  0.38639551401138306,\n",
       "  0.3769463896751404,\n",
       "  0.3772319555282593,\n",
       "  0.38598915934562683,\n",
       "  0.3910924196243286,\n",
       "  0.39062604308128357,\n",
       "  0.3574926555156708,\n",
       "  0.37000522017478943,\n",
       "  0.3711177408695221,\n",
       "  0.3787820041179657,\n",
       "  0.3794136941432953,\n",
       "  0.37160661816596985,\n",
       "  0.3862473964691162,\n",
       "  0.3585599362850189,\n",
       "  0.3762798309326172,\n",
       "  0.37693020701408386,\n",
       "  0.36285752058029175,\n",
       "  0.3732168972492218,\n",
       "  0.3594411611557007,\n",
       "  0.3748999536037445,\n",
       "  0.3660529553890228,\n",
       "  0.355311781167984,\n",
       "  0.37244072556495667,\n",
       "  0.3517557680606842,\n",
       "  0.35470104217529297,\n",
       "  0.361633837223053,\n",
       "  0.3364424407482147,\n",
       "  0.34433233737945557,\n",
       "  0.33038684725761414,\n",
       "  0.35104817152023315,\n",
       "  0.35584545135498047,\n",
       "  0.3528716564178467,\n",
       "  0.34102436900138855,\n",
       "  0.3439573049545288,\n",
       "  0.35454586148262024,\n",
       "  0.3341522216796875,\n",
       "  0.3313888609409332,\n",
       "  0.33605074882507324,\n",
       "  0.3254114091396332,\n",
       "  0.32961779832839966,\n",
       "  0.33059319853782654,\n",
       "  0.32611149549484253,\n",
       "  0.33554333448410034,\n",
       "  0.34945836663246155,\n",
       "  0.3315548598766327,\n",
       "  0.3207542598247528,\n",
       "  0.33164769411087036,\n",
       "  0.32584691047668457,\n",
       "  0.33934226632118225,\n",
       "  0.31796807050704956,\n",
       "  0.30837875604629517,\n",
       "  0.3046775162220001,\n",
       "  0.32102084159851074,\n",
       "  0.3306879699230194,\n",
       "  0.30208685994148254,\n",
       "  0.30012640357017517,\n",
       "  0.29362139105796814,\n",
       "  0.29997122287750244,\n",
       "  0.29379284381866455,\n",
       "  0.315547376871109,\n",
       "  0.2975384294986725,\n",
       "  0.31364622712135315,\n",
       "  0.30692431330680847,\n",
       "  0.31972989439964294,\n",
       "  0.30958864092826843,\n",
       "  0.30480438470840454,\n",
       "  0.2868540287017822,\n",
       "  0.2962600290775299,\n",
       "  0.29832902550697327,\n",
       "  0.29281681776046753,\n",
       "  0.2851632535457611,\n",
       "  0.3093835413455963,\n",
       "  0.29686060547828674,\n",
       "  0.2885332703590393,\n",
       "  0.28367915749549866,\n",
       "  0.28146669268608093,\n",
       "  0.28082019090652466,\n",
       "  0.2781189978122711,\n",
       "  0.26710155606269836,\n",
       "  0.26074498891830444,\n",
       "  0.27264097332954407,\n",
       "  0.272661417722702,\n",
       "  0.26735493540763855,\n",
       "  0.28704211115837097,\n",
       "  0.287474125623703,\n",
       "  0.26955103874206543,\n",
       "  0.2699955105781555,\n",
       "  0.27163153886795044,\n",
       "  0.24720065295696259,\n",
       "  0.2826979160308838,\n",
       "  0.2671775221824646,\n",
       "  0.2675550580024719,\n",
       "  0.27445629239082336,\n",
       "  0.23973973095417023,\n",
       "  0.26702943444252014,\n",
       "  0.2717542350292206,\n",
       "  0.2623239755630493,\n",
       "  0.2584723234176636,\n",
       "  0.23355837166309357,\n",
       "  0.22908230125904083,\n",
       "  0.24423755705356598,\n",
       "  0.23574700951576233,\n",
       "  0.23465564846992493,\n",
       "  0.2463953047990799,\n",
       "  0.2323976755142212,\n",
       "  0.23473139107227325,\n",
       "  0.23721082508563995,\n",
       "  0.2352963089942932,\n",
       "  0.24950259923934937,\n",
       "  0.25298741459846497,\n",
       "  0.25164997577667236,\n",
       "  0.23941515386104584,\n",
       "  0.22859276831150055,\n",
       "  0.2178667187690735,\n",
       "  0.25077566504478455,\n",
       "  0.22202442586421967,\n",
       "  0.21338561177253723,\n",
       "  0.22926566004753113,\n",
       "  0.21651656925678253,\n",
       "  0.220442533493042,\n",
       "  0.22529025375843048,\n",
       "  0.22588011622428894,\n",
       "  0.22946806252002716,\n",
       "  0.2278723269701004,\n",
       "  0.2201167494058609,\n",
       "  0.21019507944583893,\n",
       "  0.20882253348827362,\n",
       "  0.22637230157852173,\n",
       "  0.2154989093542099,\n",
       "  0.22603638470172882,\n",
       "  0.19813953340053558,\n",
       "  0.19284123182296753,\n",
       "  0.204800546169281,\n",
       "  0.2109336405992508,\n",
       "  0.2097300887107849,\n",
       "  0.2215077430009842,\n",
       "  0.1888454556465149,\n",
       "  0.19387347996234894,\n",
       "  0.19871364533901215,\n",
       "  0.18026365339756012,\n",
       "  0.1928386688232422,\n",
       "  0.18425606191158295,\n",
       "  0.1900290995836258,\n",
       "  0.21405842900276184,\n",
       "  0.21016466617584229,\n",
       "  0.19174370169639587,\n",
       "  0.19959603250026703,\n",
       "  0.18295778334140778],\n",
       " 'accuracy': [0.6875673532485962,\n",
       "  0.6615369319915771,\n",
       "  0.7139682173728943,\n",
       "  0.6926185488700867,\n",
       "  0.6824824810028076,\n",
       "  0.687129557132721,\n",
       "  0.707671046257019,\n",
       "  0.6872979402542114,\n",
       "  0.6802262663841248,\n",
       "  0.6923828125,\n",
       "  0.6830886006355286,\n",
       "  0.6880724430084229,\n",
       "  0.6821793913841248,\n",
       "  0.6817416548728943,\n",
       "  0.7000606060028076,\n",
       "  0.6860519647598267,\n",
       "  0.69140625,\n",
       "  0.6861193180084229,\n",
       "  0.6839978694915771,\n",
       "  0.6876683831214905,\n",
       "  0.6874326467514038,\n",
       "  0.690800130367279,\n",
       "  0.6862203478813171,\n",
       "  0.6992524266242981,\n",
       "  0.7023841738700867,\n",
       "  0.6897225379943848,\n",
       "  0.7145743370056152,\n",
       "  0.704707682132721,\n",
       "  0.7083109021186829,\n",
       "  0.7065934538841248,\n",
       "  0.7173693180084229,\n",
       "  0.7319167256355286,\n",
       "  0.7036974430084229,\n",
       "  0.7140355706214905,\n",
       "  0.7165611386299133,\n",
       "  0.7258553504943848,\n",
       "  0.721073567867279,\n",
       "  0.7283472418785095,\n",
       "  0.7336341738700867,\n",
       "  0.7340719103813171,\n",
       "  0.7257879972457886,\n",
       "  0.7287176847457886,\n",
       "  0.7276737689971924,\n",
       "  0.7310411930084229,\n",
       "  0.7261583805084229,\n",
       "  0.7405037879943848,\n",
       "  0.7258216738700867,\n",
       "  0.7416150569915771,\n",
       "  0.7396956086158752,\n",
       "  0.7394261956214905,\n",
       "  0.7403690814971924,\n",
       "  0.7414466738700867,\n",
       "  0.7352168560028076,\n",
       "  0.7536368370056152,\n",
       "  0.7417833805084229,\n",
       "  0.7433997988700867,\n",
       "  0.7404701113700867,\n",
       "  0.7427599430084229,\n",
       "  0.7419180870056152,\n",
       "  0.753535807132721,\n",
       "  0.7512796521186829,\n",
       "  0.747407078742981,\n",
       "  0.743803858757019,\n",
       "  0.7559604048728943,\n",
       "  0.7580819129943848,\n",
       "  0.7620218396186829,\n",
       "  0.7585533261299133,\n",
       "  0.7570716738700867,\n",
       "  0.756465494632721,\n",
       "  0.7635371685028076,\n",
       "  0.7637392282485962,\n",
       "  0.756196141242981,\n",
       "  0.7583512663841248,\n",
       "  0.7629310488700867,\n",
       "  0.7636381983757019,\n",
       "  0.7710802555084229,\n",
       "  0.7653219103813171,\n",
       "  0.759765625,\n",
       "  0.7696322798728943,\n",
       "  0.7600013613700867,\n",
       "  0.7685546875,\n",
       "  0.7549164891242981,\n",
       "  0.7550511956214905,\n",
       "  0.7671403288841248,\n",
       "  0.774043619632721,\n",
       "  0.7610116004943848,\n",
       "  0.7665678858757019,\n",
       "  0.7664331793785095,\n",
       "  0.7753569483757019,\n",
       "  0.7701036930084229,\n",
       "  0.7787244319915771,\n",
       "  0.7863685488700867,\n",
       "  0.7824622988700867,\n",
       "  0.7731680870056152,\n",
       "  0.7774784564971924,\n",
       "  0.7732017636299133,\n",
       "  0.7759630680084229,\n",
       "  0.7697333097457886,\n",
       "  0.779633641242981,\n",
       "  0.7557246685028076,\n",
       "  0.7841460108757019,\n",
       "  0.7824622988700867,\n",
       "  0.7904431819915771,\n",
       "  0.7946861386299133,\n",
       "  0.7907125353813171,\n",
       "  0.788456380367279,\n",
       "  0.7785560488700867,\n",
       "  0.7923963069915771,\n",
       "  0.7920258641242981,\n",
       "  0.7823949456214905,\n",
       "  0.8033068180084229,\n",
       "  0.8034078478813171,\n",
       "  0.7980872988700867,\n",
       "  0.7957300543785095,\n",
       "  0.7929350733757019,\n",
       "  0.7862001657485962,\n",
       "  0.784819483757019,\n",
       "  0.7953259944915771,\n",
       "  0.7968413233757019,\n",
       "  0.7915880680084229,\n",
       "  0.8070447444915771,\n",
       "  0.792328953742981,\n",
       "  0.8104458451271057,\n",
       "  0.7977168560028076,\n",
       "  0.8020609021186829,\n",
       "  0.8008486032485962,\n",
       "  0.8025323152542114,\n",
       "  0.8046538233757019,\n",
       "  0.8015557527542114,\n",
       "  0.80859375,\n",
       "  0.8139143586158752,\n",
       "  0.8115571141242981,\n",
       "  0.815059244632721,\n",
       "  0.8123989701271057,\n",
       "  0.8055293560028076,\n",
       "  0.8108499646186829,\n",
       "  0.8064722418785095,\n",
       "  0.8211543560028076,\n",
       "  0.8146551847457886,\n",
       "  0.8185277581214905,\n",
       "  0.8209859728813171,\n",
       "  0.8195379972457886,\n",
       "  0.8260708451271057,\n",
       "  0.8223666548728943,\n",
       "  0.8132408261299133,\n",
       "  0.8313577771186829,\n",
       "  0.8211880326271057,\n",
       "  0.8247911930084229,\n",
       "  0.8214574456214905,\n",
       "  0.8299770951271057,\n",
       "  0.8249258995056152,\n",
       "  0.8276535272598267,\n",
       "  0.8214574456214905,\n",
       "  0.8315597772598267,\n",
       "  0.8304822444915771,\n",
       "  0.8401131629943848,\n",
       "  0.8366446495056152,\n",
       "  0.8214237689971924,\n",
       "  0.839473307132721,\n",
       "  0.8504849076271057,\n",
       "  0.8503165245056152,\n",
       "  0.8461408615112305,\n",
       "  0.8515961766242981,\n",
       "  0.8311557173728943,\n",
       "  0.8427397608757019,\n",
       "  0.8422346115112305,\n",
       "  0.8412244319915771,\n",
       "  0.838496744632721,\n",
       "  0.838227391242981,\n",
       "  0.8513267636299133,\n",
       "  0.8548963069915771,\n",
       "  0.846309244632721,\n",
       "  0.8545932173728943,\n",
       "  0.8507206439971924,\n",
       "  0.8595770597457886,\n",
       "  0.8418979048728943,\n",
       "  0.8530441522598267,\n",
       "  0.8516972064971924,\n",
       "  0.8555697798728943,\n",
       "  0.8530441522598267,\n",
       "  0.8614965081214905,\n",
       "  0.8615301847457886,\n",
       "  0.8610923886299133,\n",
       "  0.8702182173728943,\n",
       "  0.8598800897598267,\n",
       "  0.8655037879943848,\n",
       "  0.8685681819915771,\n",
       "  0.8534482717514038,\n",
       "  0.8565126657485962,\n",
       "  0.8664129972457886,\n",
       "  0.8692416548728943,\n",
       "  0.869140625,\n",
       "  0.8737540245056152,\n",
       "  0.8711611032485962,\n",
       "  0.8713294863700867,\n",
       "  0.8723397254943848,\n",
       "  0.8625741004943848,\n",
       "  0.8857421875,\n",
       "  0.8646619319915771,\n",
       "  0.8710263967514038,\n",
       "  0.8774918913841248,\n",
       "  0.8690059185028076,\n",
       "  0.8833175897598267,\n",
       "  0.8876616358757019,\n",
       "  0.884159505367279,\n",
       "  0.8825094103813171,\n",
       "  0.8918036222457886,\n",
       "  0.8827114701271057,\n",
       "  0.886078953742981,\n",
       "  0.890625,\n",
       "  0.8797144293785095,\n",
       "  0.8942281603813171,\n",
       "  0.8786368370056152,\n",
       "  0.881229817867279,\n",
       "  0.885405421257019,\n",
       "  0.8907933831214905,\n",
       "  0.8905913233757019,\n",
       "  0.8957435488700867,\n",
       "  0.882475733757019,\n",
       "  0.8991783261299133,\n",
       "  0.9006263613700867,\n",
       "  0.8910291194915771,\n",
       "  0.9011988043785095,\n",
       "  0.8985385298728943,\n",
       "  0.8972252011299133,\n",
       "  0.8944302201271057,\n",
       "  0.8936220407485962,\n",
       "  0.8976966738700867,\n",
       "  0.8975282907485962,\n",
       "  0.901030421257019,\n",
       "  0.9030845761299133,\n",
       "  0.9012998342514038,\n",
       "  0.8992120027542114,\n",
       "  0.8955751657485962,\n",
       "  0.9071255326271057,\n",
       "  0.912479817867279,\n",
       "  0.902680516242981,\n",
       "  0.904667317867279,\n",
       "  0.9038927555084229,\n",
       "  0.8987405896186829,\n",
       "  0.9158135652542114,\n",
       "  0.9125134944915771,\n",
       "  0.9094491004943848,\n",
       "  0.9198881983757019,\n",
       "  0.9119073152542114,\n",
       "  0.9177330136299133,\n",
       "  0.9213698506355286,\n",
       "  0.914702296257019,\n",
       "  0.90625,\n",
       "  0.9130185842514038,\n",
       "  0.9174636006355286,\n",
       "  0.9176656603813171],\n",
       " 'tp': [214.0,\n",
       "  225.0,\n",
       "  237.0,\n",
       "  263.0,\n",
       "  317.0,\n",
       "  326.0,\n",
       "  324.0,\n",
       "  354.0,\n",
       "  354.0,\n",
       "  370.0,\n",
       "  396.0,\n",
       "  394.0,\n",
       "  416.0,\n",
       "  415.0,\n",
       "  385.0,\n",
       "  408.0,\n",
       "  396.0,\n",
       "  405.0,\n",
       "  425.0,\n",
       "  409.0,\n",
       "  422.0,\n",
       "  426.0,\n",
       "  411.0,\n",
       "  417.0,\n",
       "  433.0,\n",
       "  432.0,\n",
       "  424.0,\n",
       "  434.0,\n",
       "  431.0,\n",
       "  438.0,\n",
       "  428.0,\n",
       "  444.0,\n",
       "  436.0,\n",
       "  413.0,\n",
       "  445.0,\n",
       "  442.0,\n",
       "  437.0,\n",
       "  436.0,\n",
       "  439.0,\n",
       "  432.0,\n",
       "  446.0,\n",
       "  436.0,\n",
       "  450.0,\n",
       "  437.0,\n",
       "  443.0,\n",
       "  443.0,\n",
       "  445.0,\n",
       "  459.0,\n",
       "  435.0,\n",
       "  444.0,\n",
       "  451.0,\n",
       "  450.0,\n",
       "  459.0,\n",
       "  447.0,\n",
       "  454.0,\n",
       "  434.0,\n",
       "  452.0,\n",
       "  443.0,\n",
       "  460.0,\n",
       "  445.0,\n",
       "  458.0,\n",
       "  433.0,\n",
       "  453.0,\n",
       "  446.0,\n",
       "  452.0,\n",
       "  446.0,\n",
       "  438.0,\n",
       "  458.0,\n",
       "  454.0,\n",
       "  457.0,\n",
       "  451.0,\n",
       "  454.0,\n",
       "  456.0,\n",
       "  455.0,\n",
       "  461.0,\n",
       "  443.0,\n",
       "  453.0,\n",
       "  453.0,\n",
       "  460.0,\n",
       "  447.0,\n",
       "  455.0,\n",
       "  450.0,\n",
       "  452.0,\n",
       "  441.0,\n",
       "  464.0,\n",
       "  452.0,\n",
       "  460.0,\n",
       "  471.0,\n",
       "  462.0,\n",
       "  459.0,\n",
       "  463.0,\n",
       "  452.0,\n",
       "  474.0,\n",
       "  456.0,\n",
       "  453.0,\n",
       "  458.0,\n",
       "  453.0,\n",
       "  455.0,\n",
       "  454.0,\n",
       "  463.0,\n",
       "  460.0,\n",
       "  472.0,\n",
       "  451.0,\n",
       "  479.0,\n",
       "  457.0,\n",
       "  469.0,\n",
       "  467.0,\n",
       "  463.0,\n",
       "  464.0,\n",
       "  459.0,\n",
       "  470.0,\n",
       "  471.0,\n",
       "  458.0,\n",
       "  479.0,\n",
       "  468.0,\n",
       "  461.0,\n",
       "  474.0,\n",
       "  475.0,\n",
       "  476.0,\n",
       "  461.0,\n",
       "  459.0,\n",
       "  472.0,\n",
       "  464.0,\n",
       "  458.0,\n",
       "  468.0,\n",
       "  472.0,\n",
       "  464.0,\n",
       "  481.0,\n",
       "  472.0,\n",
       "  470.0,\n",
       "  485.0,\n",
       "  474.0,\n",
       "  478.0,\n",
       "  475.0,\n",
       "  471.0,\n",
       "  467.0,\n",
       "  479.0,\n",
       "  472.0,\n",
       "  464.0,\n",
       "  480.0,\n",
       "  490.0,\n",
       "  479.0,\n",
       "  481.0,\n",
       "  475.0,\n",
       "  485.0,\n",
       "  482.0,\n",
       "  473.0,\n",
       "  465.0,\n",
       "  480.0,\n",
       "  477.0,\n",
       "  481.0,\n",
       "  480.0,\n",
       "  464.0,\n",
       "  484.0,\n",
       "  477.0,\n",
       "  489.0,\n",
       "  473.0,\n",
       "  485.0,\n",
       "  480.0,\n",
       "  489.0,\n",
       "  483.0,\n",
       "  484.0,\n",
       "  493.0,\n",
       "  483.0,\n",
       "  489.0,\n",
       "  476.0,\n",
       "  494.0,\n",
       "  477.0,\n",
       "  483.0,\n",
       "  481.0,\n",
       "  489.0,\n",
       "  492.0,\n",
       "  491.0,\n",
       "  492.0,\n",
       "  493.0,\n",
       "  489.0,\n",
       "  476.0,\n",
       "  486.0,\n",
       "  493.0,\n",
       "  485.0,\n",
       "  482.0,\n",
       "  497.0,\n",
       "  480.0,\n",
       "  497.0,\n",
       "  487.0,\n",
       "  486.0,\n",
       "  487.0,\n",
       "  488.0,\n",
       "  493.0,\n",
       "  486.0,\n",
       "  493.0,\n",
       "  492.0,\n",
       "  501.0,\n",
       "  481.0,\n",
       "  492.0,\n",
       "  485.0,\n",
       "  491.0,\n",
       "  502.0,\n",
       "  495.0,\n",
       "  496.0,\n",
       "  484.0,\n",
       "  491.0,\n",
       "  496.0,\n",
       "  507.0,\n",
       "  488.0,\n",
       "  502.0,\n",
       "  505.0,\n",
       "  491.0,\n",
       "  501.0,\n",
       "  496.0,\n",
       "  502.0,\n",
       "  497.0,\n",
       "  501.0,\n",
       "  495.0,\n",
       "  499.0,\n",
       "  491.0,\n",
       "  501.0,\n",
       "  501.0,\n",
       "  495.0,\n",
       "  482.0,\n",
       "  502.0,\n",
       "  502.0,\n",
       "  510.0,\n",
       "  498.0,\n",
       "  496.0,\n",
       "  492.0,\n",
       "  513.0,\n",
       "  489.0,\n",
       "  501.0,\n",
       "  515.0,\n",
       "  508.0,\n",
       "  488.0,\n",
       "  505.0,\n",
       "  500.0,\n",
       "  509.0,\n",
       "  509.0,\n",
       "  508.0,\n",
       "  505.0,\n",
       "  491.0,\n",
       "  497.0,\n",
       "  506.0,\n",
       "  502.0,\n",
       "  506.0,\n",
       "  498.0,\n",
       "  508.0,\n",
       "  513.0,\n",
       "  503.0,\n",
       "  503.0,\n",
       "  500.0,\n",
       "  508.0,\n",
       "  504.0,\n",
       "  513.0],\n",
       " 'auc': [0.5440689325332642,\n",
       "  0.5513811111450195,\n",
       "  0.5920990705490112,\n",
       "  0.6199160814285278,\n",
       "  0.6884135603904724,\n",
       "  0.7168204188346863,\n",
       "  0.7455711364746094,\n",
       "  0.7488074898719788,\n",
       "  0.743885338306427,\n",
       "  0.7676719427108765,\n",
       "  0.7781069874763489,\n",
       "  0.7782609462738037,\n",
       "  0.7867196202278137,\n",
       "  0.7911725044250488,\n",
       "  0.7932125926017761,\n",
       "  0.7909489870071411,\n",
       "  0.7953731417655945,\n",
       "  0.7977623343467712,\n",
       "  0.8062092065811157,\n",
       "  0.8018833994865417,\n",
       "  0.8077150583267212,\n",
       "  0.808535099029541,\n",
       "  0.8043323159217834,\n",
       "  0.8155924081802368,\n",
       "  0.8257549405097961,\n",
       "  0.8192358613014221,\n",
       "  0.823805570602417,\n",
       "  0.8271095156669617,\n",
       "  0.8339859247207642,\n",
       "  0.8345040082931519,\n",
       "  0.8324421048164368,\n",
       "  0.8531102538108826,\n",
       "  0.8338707089424133,\n",
       "  0.834298849105835,\n",
       "  0.8476638793945312,\n",
       "  0.847013533115387,\n",
       "  0.8449853658676147,\n",
       "  0.853621244430542,\n",
       "  0.8578406572341919,\n",
       "  0.8504795432090759,\n",
       "  0.8536485433578491,\n",
       "  0.8542261123657227,\n",
       "  0.8575187921524048,\n",
       "  0.8564189672470093,\n",
       "  0.8491647839546204,\n",
       "  0.8626814484596252,\n",
       "  0.8564560413360596,\n",
       "  0.8658997416496277,\n",
       "  0.8610378503799438,\n",
       "  0.8661209344863892,\n",
       "  0.8656250834465027,\n",
       "  0.8675312995910645,\n",
       "  0.8710707426071167,\n",
       "  0.8718202114105225,\n",
       "  0.8655729293823242,\n",
       "  0.8614400625228882,\n",
       "  0.8702788352966309,\n",
       "  0.864060640335083,\n",
       "  0.8711115121841431,\n",
       "  0.8726151585578918,\n",
       "  0.8766193985939026,\n",
       "  0.868998110294342,\n",
       "  0.8711692690849304,\n",
       "  0.8801488280296326,\n",
       "  0.8809726238250732,\n",
       "  0.8834681510925293,\n",
       "  0.8739945888519287,\n",
       "  0.8837141990661621,\n",
       "  0.8808799982070923,\n",
       "  0.8906089067459106,\n",
       "  0.886488676071167,\n",
       "  0.8851794004440308,\n",
       "  0.8843334913253784,\n",
       "  0.8841813802719116,\n",
       "  0.8889712691307068,\n",
       "  0.8904005885124207,\n",
       "  0.8877128958702087,\n",
       "  0.8848919868469238,\n",
       "  0.8920641541481018,\n",
       "  0.8864224553108215,\n",
       "  0.8870028853416443,\n",
       "  0.8833857178688049,\n",
       "  0.8861850500106812,\n",
       "  0.8837496638298035,\n",
       "  0.8972794413566589,\n",
       "  0.8831954002380371,\n",
       "  0.892463743686676,\n",
       "  0.8936834335327148,\n",
       "  0.898191511631012,\n",
       "  0.8948101997375488,\n",
       "  0.8946744799613953,\n",
       "  0.9039599299430847,\n",
       "  0.905571460723877,\n",
       "  0.8955591320991516,\n",
       "  0.8956847190856934,\n",
       "  0.8961451649665833,\n",
       "  0.8967150449752808,\n",
       "  0.8922606110572815,\n",
       "  0.8974631428718567,\n",
       "  0.8895050883293152,\n",
       "  0.8985806703567505,\n",
       "  0.9082909822463989,\n",
       "  0.9026946425437927,\n",
       "  0.9092822670936584,\n",
       "  0.905678927898407,\n",
       "  0.9075108170509338,\n",
       "  0.9075121879577637,\n",
       "  0.9063231945037842,\n",
       "  0.9022758603096008,\n",
       "  0.9016991853713989,\n",
       "  0.9187524318695068,\n",
       "  0.9131603240966797,\n",
       "  0.911261260509491,\n",
       "  0.9095508456230164,\n",
       "  0.9076115489006042,\n",
       "  0.9091217517852783,\n",
       "  0.9020237326622009,\n",
       "  0.9157668948173523,\n",
       "  0.9086649417877197,\n",
       "  0.9093835949897766,\n",
       "  0.9148446917533875,\n",
       "  0.9109067320823669,\n",
       "  0.9174593687057495,\n",
       "  0.9093102812767029,\n",
       "  0.9153498411178589,\n",
       "  0.9189674854278564,\n",
       "  0.9131848216056824,\n",
       "  0.921025812625885,\n",
       "  0.9178788065910339,\n",
       "  0.9173320531845093,\n",
       "  0.9279032349586487,\n",
       "  0.9249778985977173,\n",
       "  0.9298098087310791,\n",
       "  0.9230302572250366,\n",
       "  0.9209270477294922,\n",
       "  0.9218174815177917,\n",
       "  0.925632894039154,\n",
       "  0.9262542724609375,\n",
       "  0.9202705025672913,\n",
       "  0.9286047220230103,\n",
       "  0.9309819340705872,\n",
       "  0.9271930456161499,\n",
       "  0.9331374168395996,\n",
       "  0.9309061169624329,\n",
       "  0.9285559058189392,\n",
       "  0.9347220063209534,\n",
       "  0.9285696148872375,\n",
       "  0.9238075017929077,\n",
       "  0.9306685328483582,\n",
       "  0.9342288970947266,\n",
       "  0.9307798743247986,\n",
       "  0.9335237145423889,\n",
       "  0.9282495975494385,\n",
       "  0.9368475675582886,\n",
       "  0.9391319751739502,\n",
       "  0.941399097442627,\n",
       "  0.9365198016166687,\n",
       "  0.9322100281715393,\n",
       "  0.9427487850189209,\n",
       "  0.944806694984436,\n",
       "  0.946502685546875,\n",
       "  0.9440947771072388,\n",
       "  0.946700930595398,\n",
       "  0.9355974197387695,\n",
       "  0.9443274140357971,\n",
       "  0.9391700029373169,\n",
       "  0.9424153566360474,\n",
       "  0.9387317299842834,\n",
       "  0.9411926865577698,\n",
       "  0.9433530569076538,\n",
       "  0.9501569271087646,\n",
       "  0.9453379511833191,\n",
       "  0.946029007434845,\n",
       "  0.946947455406189,\n",
       "  0.9504228234291077,\n",
       "  0.9410372972488403,\n",
       "  0.9466086626052856,\n",
       "  0.9474442005157471,\n",
       "  0.9503870606422424,\n",
       "  0.9510094523429871,\n",
       "  0.9524422287940979,\n",
       "  0.9533878564834595,\n",
       "  0.9555323123931885,\n",
       "  0.9584057331085205,\n",
       "  0.9544887542724609,\n",
       "  0.9555138349533081,\n",
       "  0.9552799463272095,\n",
       "  0.9499056339263916,\n",
       "  0.9497559070587158,\n",
       "  0.9565778374671936,\n",
       "  0.9561201930046082,\n",
       "  0.956306517124176,\n",
       "  0.9620989561080933,\n",
       "  0.9522979259490967,\n",
       "  0.9562175273895264,\n",
       "  0.9574272036552429,\n",
       "  0.9536677002906799,\n",
       "  0.9645980000495911,\n",
       "  0.9560627341270447,\n",
       "  0.9560859203338623,\n",
       "  0.9591200351715088,\n",
       "  0.9586443901062012,\n",
       "  0.9667447805404663,\n",
       "  0.9685777425765991,\n",
       "  0.9645302891731262,\n",
       "  0.9655333161354065,\n",
       "  0.9666812419891357,\n",
       "  0.9629231095314026,\n",
       "  0.9672585129737854,\n",
       "  0.9671856760978699,\n",
       "  0.9668647050857544,\n",
       "  0.9673140048980713,\n",
       "  0.9634437561035156,\n",
       "  0.9622632265090942,\n",
       "  0.9633083939552307,\n",
       "  0.9666854739189148,\n",
       "  0.9691086411476135,\n",
       "  0.9723154902458191,\n",
       "  0.9633012413978577,\n",
       "  0.9710997939109802,\n",
       "  0.9732363820075989,\n",
       "  0.9680519104003906,\n",
       "  0.9723455309867859,\n",
       "  0.971031665802002,\n",
       "  0.9696580767631531,\n",
       "  0.9707021713256836,\n",
       "  0.9690530896186829,\n",
       "  0.9694932699203491,\n",
       "  0.9718316793441772,\n",
       "  0.9733815789222717,\n",
       "  0.973966658115387,\n",
       "  0.970160961151123,\n",
       "  0.9728742837905884,\n",
       "  0.9698231220245361,\n",
       "  0.9771557450294495,\n",
       "  0.9784990549087524,\n",
       "  0.9762800335884094,\n",
       "  0.9743622541427612,\n",
       "  0.974104642868042,\n",
       "  0.9713473320007324,\n",
       "  0.9791163206100464,\n",
       "  0.9787524938583374,\n",
       "  0.9770475625991821,\n",
       "  0.9813641309738159,\n",
       "  0.9788444638252258,\n",
       "  0.9803692698478699,\n",
       "  0.9795922040939331,\n",
       "  0.9744709134101868,\n",
       "  0.9745767116546631,\n",
       "  0.9792336225509644,\n",
       "  0.9771811366081238,\n",
       "  0.980810821056366],\n",
       " 'fn': [310.0,\n",
       "  299.0,\n",
       "  295.0,\n",
       "  265.0,\n",
       "  207.0,\n",
       "  206.0,\n",
       "  204.0,\n",
       "  173.0,\n",
       "  176.0,\n",
       "  162.0,\n",
       "  132.0,\n",
       "  141.0,\n",
       "  114.0,\n",
       "  111.0,\n",
       "  142.0,\n",
       "  115.0,\n",
       "  132.0,\n",
       "  115.0,\n",
       "  111.0,\n",
       "  116.0,\n",
       "  101.0,\n",
       "  107.0,\n",
       "  112.0,\n",
       "  116.0,\n",
       "  96.0,\n",
       "  92.0,\n",
       "  105.0,\n",
       "  93.0,\n",
       "  92.0,\n",
       "  91.0,\n",
       "  99.0,\n",
       "  83.0,\n",
       "  96.0,\n",
       "  117.0,\n",
       "  83.0,\n",
       "  89.0,\n",
       "  90.0,\n",
       "  84.0,\n",
       "  83.0,\n",
       "  95.0,\n",
       "  87.0,\n",
       "  85.0,\n",
       "  78.0,\n",
       "  89.0,\n",
       "  86.0,\n",
       "  82.0,\n",
       "  87.0,\n",
       "  76.0,\n",
       "  87.0,\n",
       "  87.0,\n",
       "  81.0,\n",
       "  76.0,\n",
       "  76.0,\n",
       "  77.0,\n",
       "  77.0,\n",
       "  92.0,\n",
       "  74.0,\n",
       "  80.0,\n",
       "  66.0,\n",
       "  82.0,\n",
       "  73.0,\n",
       "  87.0,\n",
       "  83.0,\n",
       "  80.0,\n",
       "  78.0,\n",
       "  84.0,\n",
       "  87.0,\n",
       "  69.0,\n",
       "  72.0,\n",
       "  72.0,\n",
       "  70.0,\n",
       "  75.0,\n",
       "  72.0,\n",
       "  77.0,\n",
       "  74.0,\n",
       "  83.0,\n",
       "  71.0,\n",
       "  71.0,\n",
       "  67.0,\n",
       "  76.0,\n",
       "  75.0,\n",
       "  74.0,\n",
       "  76.0,\n",
       "  84.0,\n",
       "  71.0,\n",
       "  70.0,\n",
       "  67.0,\n",
       "  58.0,\n",
       "  68.0,\n",
       "  68.0,\n",
       "  70.0,\n",
       "  75.0,\n",
       "  61.0,\n",
       "  74.0,\n",
       "  76.0,\n",
       "  67.0,\n",
       "  71.0,\n",
       "  72.0,\n",
       "  71.0,\n",
       "  66.0,\n",
       "  70.0,\n",
       "  54.0,\n",
       "  70.0,\n",
       "  54.0,\n",
       "  69.0,\n",
       "  62.0,\n",
       "  59.0,\n",
       "  66.0,\n",
       "  64.0,\n",
       "  68.0,\n",
       "  54.0,\n",
       "  56.0,\n",
       "  63.0,\n",
       "  60.0,\n",
       "  64.0,\n",
       "  59.0,\n",
       "  56.0,\n",
       "  53.0,\n",
       "  54.0,\n",
       "  63.0,\n",
       "  60.0,\n",
       "  62.0,\n",
       "  59.0,\n",
       "  65.0,\n",
       "  63.0,\n",
       "  55.0,\n",
       "  62.0,\n",
       "  50.0,\n",
       "  53.0,\n",
       "  65.0,\n",
       "  45.0,\n",
       "  53.0,\n",
       "  51.0,\n",
       "  57.0,\n",
       "  60.0,\n",
       "  60.0,\n",
       "  46.0,\n",
       "  55.0,\n",
       "  57.0,\n",
       "  47.0,\n",
       "  43.0,\n",
       "  47.0,\n",
       "  45.0,\n",
       "  52.0,\n",
       "  45.0,\n",
       "  47.0,\n",
       "  49.0,\n",
       "  66.0,\n",
       "  49.0,\n",
       "  51.0,\n",
       "  47.0,\n",
       "  45.0,\n",
       "  62.0,\n",
       "  44.0,\n",
       "  50.0,\n",
       "  45.0,\n",
       "  52.0,\n",
       "  48.0,\n",
       "  39.0,\n",
       "  42.0,\n",
       "  40.0,\n",
       "  42.0,\n",
       "  38.0,\n",
       "  40.0,\n",
       "  35.0,\n",
       "  49.0,\n",
       "  37.0,\n",
       "  50.0,\n",
       "  48.0,\n",
       "  49.0,\n",
       "  37.0,\n",
       "  35.0,\n",
       "  40.0,\n",
       "  41.0,\n",
       "  39.0,\n",
       "  42.0,\n",
       "  51.0,\n",
       "  35.0,\n",
       "  35.0,\n",
       "  40.0,\n",
       "  44.0,\n",
       "  41.0,\n",
       "  38.0,\n",
       "  31.0,\n",
       "  40.0,\n",
       "  43.0,\n",
       "  40.0,\n",
       "  37.0,\n",
       "  43.0,\n",
       "  37.0,\n",
       "  34.0,\n",
       "  38.0,\n",
       "  23.0,\n",
       "  44.0,\n",
       "  42.0,\n",
       "  42.0,\n",
       "  35.0,\n",
       "  26.0,\n",
       "  32.0,\n",
       "  35.0,\n",
       "  40.0,\n",
       "  31.0,\n",
       "  31.0,\n",
       "  24.0,\n",
       "  33.0,\n",
       "  26.0,\n",
       "  26.0,\n",
       "  35.0,\n",
       "  28.0,\n",
       "  33.0,\n",
       "  26.0,\n",
       "  31.0,\n",
       "  28.0,\n",
       "  37.0,\n",
       "  32.0,\n",
       "  39.0,\n",
       "  26.0,\n",
       "  26.0,\n",
       "  36.0,\n",
       "  36.0,\n",
       "  26.0,\n",
       "  25.0,\n",
       "  24.0,\n",
       "  21.0,\n",
       "  34.0,\n",
       "  29.0,\n",
       "  28.0,\n",
       "  36.0,\n",
       "  21.0,\n",
       "  18.0,\n",
       "  21.0,\n",
       "  32.0,\n",
       "  25.0,\n",
       "  26.0,\n",
       "  20.0,\n",
       "  21.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  30.0,\n",
       "  31.0,\n",
       "  18.0,\n",
       "  24.0,\n",
       "  23.0,\n",
       "  22.0,\n",
       "  21.0,\n",
       "  16.0,\n",
       "  21.0,\n",
       "  30.0,\n",
       "  24.0,\n",
       "  20.0,\n",
       "  22.0,\n",
       "  20.0],\n",
       " 'val_loss': [0.10932308435440063,\n",
       "  0.11878740787506104,\n",
       "  0.13774335384368896,\n",
       "  0.14325501024723053,\n",
       "  0.1426883488893509,\n",
       "  0.14283548295497894,\n",
       "  0.136036679148674,\n",
       "  0.13180004060268402,\n",
       "  0.12545739114284515,\n",
       "  0.12488073110580444,\n",
       "  0.12647823989391327,\n",
       "  0.12242033332586288,\n",
       "  0.11863084137439728,\n",
       "  0.11656422913074493,\n",
       "  0.11952681839466095,\n",
       "  0.10810809582471848,\n",
       "  0.10942482948303223,\n",
       "  0.10622071474790573,\n",
       "  0.10411747545003891,\n",
       "  0.10417144745588303,\n",
       "  0.10488644987344742,\n",
       "  0.10392474383115768,\n",
       "  0.10535011440515518,\n",
       "  0.10152425616979599,\n",
       "  0.11349742859601974,\n",
       "  0.10157803446054459,\n",
       "  0.10648705065250397,\n",
       "  0.10438515245914459,\n",
       "  0.1079278513789177,\n",
       "  0.1086764708161354,\n",
       "  0.10598017275333405,\n",
       "  0.11045332998037338,\n",
       "  0.10793355852365494,\n",
       "  0.10064106434583664,\n",
       "  0.10316374152898788,\n",
       "  0.12410081923007965,\n",
       "  0.10298037528991699,\n",
       "  0.09794265776872635,\n",
       "  0.11603380739688873,\n",
       "  0.11237742751836777,\n",
       "  0.1080586314201355,\n",
       "  0.10796081274747849,\n",
       "  0.10158481448888779,\n",
       "  0.10957010090351105,\n",
       "  0.09941543638706207,\n",
       "  0.10486092418432236,\n",
       "  0.10371658951044083,\n",
       "  0.10479990392923355,\n",
       "  0.10737891495227814,\n",
       "  0.11377127468585968,\n",
       "  0.12067635357379913,\n",
       "  0.10770834982395172,\n",
       "  0.10748995840549469,\n",
       "  0.11257176846265793,\n",
       "  0.09524037688970566,\n",
       "  0.09836967289447784,\n",
       "  0.10630136728286743,\n",
       "  0.0999084934592247,\n",
       "  0.09560475498437881,\n",
       "  0.1038970947265625,\n",
       "  0.09493225067853928,\n",
       "  0.09553194046020508,\n",
       "  0.13621209561824799,\n",
       "  0.10375650227069855,\n",
       "  0.10505092144012451,\n",
       "  0.12069568783044815,\n",
       "  0.10680849850177765,\n",
       "  0.133867546916008,\n",
       "  0.12040136009454727,\n",
       "  0.1880422830581665,\n",
       "  0.12260271608829498,\n",
       "  0.10435859113931656,\n",
       "  0.14242608845233917,\n",
       "  0.16119854152202606,\n",
       "  0.13295647501945496,\n",
       "  0.16149549186229706,\n",
       "  0.11625801771879196,\n",
       "  0.12985330820083618,\n",
       "  0.11222340166568756,\n",
       "  0.12342647463083267,\n",
       "  0.11743646115064621,\n",
       "  0.17070692777633667,\n",
       "  0.15003295242786407,\n",
       "  0.11876308917999268,\n",
       "  0.10998786985874176,\n",
       "  0.12535224854946136,\n",
       "  0.14779789745807648,\n",
       "  0.1788650006055832,\n",
       "  0.1581955999135971,\n",
       "  0.15233735740184784,\n",
       "  0.12206234037876129,\n",
       "  0.13299092650413513,\n",
       "  0.11666146665811539,\n",
       "  0.14666017889976501,\n",
       "  0.18677610158920288,\n",
       "  0.1889173686504364,\n",
       "  0.1648053675889969,\n",
       "  0.16594640910625458,\n",
       "  0.12939123809337616,\n",
       "  0.18760378658771515,\n",
       "  0.12537464499473572,\n",
       "  0.12103264778852463,\n",
       "  0.11238645762205124,\n",
       "  0.12640677392482758,\n",
       "  0.14761511981487274,\n",
       "  0.15641485154628754,\n",
       "  0.21855762600898743,\n",
       "  0.29955944418907166,\n",
       "  0.2781929075717926,\n",
       "  0.19342294335365295,\n",
       "  0.17282173037528992,\n",
       "  0.29488933086395264,\n",
       "  0.26756173372268677,\n",
       "  0.31232449412345886,\n",
       "  0.1736757606267929,\n",
       "  0.18131886422634125,\n",
       "  0.5932783484458923,\n",
       "  0.18758079409599304,\n",
       "  0.21292667090892792,\n",
       "  0.19701175391674042,\n",
       "  0.24805758893489838,\n",
       "  0.2009599655866623,\n",
       "  0.20191431045532227,\n",
       "  0.1829843968153,\n",
       "  0.1374850571155548,\n",
       "  0.16289865970611572,\n",
       "  0.19001498818397522,\n",
       "  0.16804127395153046,\n",
       "  0.13187697529792786,\n",
       "  0.14628493785858154,\n",
       "  0.18155339360237122,\n",
       "  0.33923229575157166,\n",
       "  0.1743943691253662,\n",
       "  0.21331198513507843,\n",
       "  0.1960362195968628,\n",
       "  0.25126343965530396,\n",
       "  0.43254613876342773,\n",
       "  0.19124983251094818,\n",
       "  0.3405922055244446,\n",
       "  0.19152887165546417,\n",
       "  0.21299703419208527,\n",
       "  0.291693776845932,\n",
       "  0.21885354816913605,\n",
       "  0.17606869339942932,\n",
       "  0.5405518412590027,\n",
       "  0.36744794249534607,\n",
       "  0.20792101323604584,\n",
       "  0.19027285277843475,\n",
       "  0.30584993958473206,\n",
       "  0.32888349890708923,\n",
       "  0.3793691098690033,\n",
       "  0.6941859126091003,\n",
       "  0.4512207508087158,\n",
       "  0.33007290959358215,\n",
       "  0.5551719069480896,\n",
       "  0.23082385957241058,\n",
       "  0.4150247275829315,\n",
       "  0.1425522416830063,\n",
       "  0.21393711864948273,\n",
       "  0.22765038907527924,\n",
       "  0.16727881133556366,\n",
       "  0.2062380313873291,\n",
       "  0.17915570735931396,\n",
       "  0.26447710394859314,\n",
       "  0.18952254951000214,\n",
       "  0.2242744266986847,\n",
       "  0.22530630230903625,\n",
       "  0.19470934569835663,\n",
       "  0.23755721747875214,\n",
       "  0.26702627539634705,\n",
       "  0.27482661604881287,\n",
       "  0.24798475205898285,\n",
       "  0.44467803835868835,\n",
       "  0.2419590950012207,\n",
       "  0.2800223231315613,\n",
       "  0.4644671082496643,\n",
       "  0.2770531475543976,\n",
       "  0.2972242832183838,\n",
       "  0.3348986804485321,\n",
       "  0.43119320273399353,\n",
       "  0.22573347389698029,\n",
       "  0.26523837447166443,\n",
       "  0.26123353838920593,\n",
       "  0.2590395212173462,\n",
       "  0.23508058488368988,\n",
       "  0.2244797945022583,\n",
       "  0.6535376906394958,\n",
       "  0.22875063121318817,\n",
       "  0.2942516505718231,\n",
       "  0.6129225492477417,\n",
       "  0.3014277517795563,\n",
       "  0.310899019241333,\n",
       "  0.22879743576049805,\n",
       "  0.28582653403282166,\n",
       "  0.23436503112316132,\n",
       "  0.2549942135810852,\n",
       "  0.1677546352148056,\n",
       "  0.32559332251548767,\n",
       "  0.3162122666835785,\n",
       "  0.2563278079032898,\n",
       "  0.5429277420043945,\n",
       "  0.4278225600719452,\n",
       "  0.36649593710899353,\n",
       "  0.26089707016944885,\n",
       "  0.19956794381141663,\n",
       "  0.18953382968902588,\n",
       "  0.530078113079071,\n",
       "  0.32347485423088074,\n",
       "  0.22251546382904053,\n",
       "  0.15362749993801117,\n",
       "  0.1924944519996643,\n",
       "  0.43876034021377563,\n",
       "  0.3533490002155304,\n",
       "  0.26876503229141235,\n",
       "  0.2194126695394516,\n",
       "  0.23958399891853333,\n",
       "  0.2546035349369049,\n",
       "  0.22275586426258087,\n",
       "  0.24491265416145325,\n",
       "  0.284962922334671,\n",
       "  0.23111389577388763,\n",
       "  0.3231218159198761,\n",
       "  0.3251231014728546,\n",
       "  0.19694004952907562,\n",
       "  0.1824060082435608,\n",
       "  0.19640865921974182,\n",
       "  0.20978069305419922,\n",
       "  0.3342568874359131,\n",
       "  0.15060807764530182,\n",
       "  0.2451428472995758,\n",
       "  0.2526858448982239,\n",
       "  0.15879105031490326,\n",
       "  0.23555481433868408,\n",
       "  0.1840621680021286,\n",
       "  0.25800806283950806,\n",
       "  0.16834241151809692,\n",
       "  0.31401047110557556,\n",
       "  0.3544979989528656,\n",
       "  0.37449556589126587,\n",
       "  0.29961201548576355,\n",
       "  0.2844245135784149,\n",
       "  0.20269440114498138,\n",
       "  0.25539320707321167,\n",
       "  0.25093433260917664,\n",
       "  0.2220177948474884,\n",
       "  0.20717886090278625,\n",
       "  0.25823652744293213,\n",
       "  0.1845860779285431,\n",
       "  0.2508138120174408,\n",
       "  0.377840131521225,\n",
       "  0.20371559262275696,\n",
       "  0.24209074676036835],\n",
       " 'val_accuracy': [0.9830078482627869,\n",
       "  0.9833984375,\n",
       "  0.983593761920929,\n",
       "  0.9833984375,\n",
       "  0.9828125238418579,\n",
       "  0.983593761920929,\n",
       "  0.9837890863418579,\n",
       "  0.9830078482627869,\n",
       "  0.983203113079071,\n",
       "  0.983203113079071,\n",
       "  0.982226550579071,\n",
       "  0.9837890863418579,\n",
       "  0.9830078482627869,\n",
       "  0.983203113079071,\n",
       "  0.982617199420929,\n",
       "  0.9837890863418579,\n",
       "  0.9833984375,\n",
       "  0.9833984375,\n",
       "  0.983593761920929,\n",
       "  0.983593761920929,\n",
       "  0.983593761920929,\n",
       "  0.9833984375,\n",
       "  0.9828125238418579,\n",
       "  0.9833984375,\n",
       "  0.982226550579071,\n",
       "  0.983593761920929,\n",
       "  0.9833984375,\n",
       "  0.9830078482627869,\n",
       "  0.980664074420929,\n",
       "  0.983203113079071,\n",
       "  0.9789062738418579,\n",
       "  0.9820312857627869,\n",
       "  0.9808593988418579,\n",
       "  0.983203113079071,\n",
       "  0.982617199420929,\n",
       "  0.9798828363418579,\n",
       "  0.9814453125,\n",
       "  0.983593761920929,\n",
       "  0.9779297113418579,\n",
       "  0.9814453125,\n",
       "  0.9810547232627869,\n",
       "  0.9798828363418579,\n",
       "  0.982617199420929,\n",
       "  0.98046875,\n",
       "  0.98046875,\n",
       "  0.981640636920929,\n",
       "  0.9830078482627869,\n",
       "  0.980664074420929,\n",
       "  0.9775390625,\n",
       "  0.9765625,\n",
       "  0.9751953482627869,\n",
       "  0.9751953482627869,\n",
       "  0.980273425579071,\n",
       "  0.9750000238418579,\n",
       "  0.983593761920929,\n",
       "  0.9820312857627869,\n",
       "  0.978515625,\n",
       "  0.981640636920929,\n",
       "  0.983203113079071,\n",
       "  0.979687511920929,\n",
       "  0.983203113079071,\n",
       "  0.983203113079071,\n",
       "  0.9632812738418579,\n",
       "  0.979687511920929,\n",
       "  0.979296863079071,\n",
       "  0.9697265625,\n",
       "  0.9794921875,\n",
       "  0.962695300579071,\n",
       "  0.971484363079071,\n",
       "  0.94140625,\n",
       "  0.970507800579071,\n",
       "  0.978515625,\n",
       "  0.959179699420929,\n",
       "  0.943359375,\n",
       "  0.965624988079071,\n",
       "  0.9453125,\n",
       "  0.976757824420929,\n",
       "  0.9691406488418579,\n",
       "  0.9771484732627869,\n",
       "  0.966796875,\n",
       "  0.97265625,\n",
       "  0.9419922232627869,\n",
       "  0.9486328363418579,\n",
       "  0.9732422232627869,\n",
       "  0.973828136920929,\n",
       "  0.9658203125,\n",
       "  0.949414074420929,\n",
       "  0.9251953363418579,\n",
       "  0.943164050579071,\n",
       "  0.949023425579071,\n",
       "  0.968945324420929,\n",
       "  0.961132824420929,\n",
       "  0.9730468988418579,\n",
       "  0.94921875,\n",
       "  0.9322265982627869,\n",
       "  0.924609363079071,\n",
       "  0.9476562738418579,\n",
       "  0.9410156607627869,\n",
       "  0.966601550579071,\n",
       "  0.9267578125,\n",
       "  0.9642578363418579,\n",
       "  0.973437488079071,\n",
       "  0.9740234613418579,\n",
       "  0.966015636920929,\n",
       "  0.953906238079071,\n",
       "  0.9466797113418579,\n",
       "  0.9189453125,\n",
       "  0.877148449420929,\n",
       "  0.87890625,\n",
       "  0.9292969107627869,\n",
       "  0.935546875,\n",
       "  0.8871093988418579,\n",
       "  0.9013671875,\n",
       "  0.8783203363418579,\n",
       "  0.9378906488418579,\n",
       "  0.9322265982627869,\n",
       "  0.799609363079071,\n",
       "  0.936718761920929,\n",
       "  0.9232422113418579,\n",
       "  0.925585925579071,\n",
       "  0.8994140625,\n",
       "  0.921093761920929,\n",
       "  0.921875,\n",
       "  0.9339843988418579,\n",
       "  0.9619140625,\n",
       "  0.947070300579071,\n",
       "  0.9267578125,\n",
       "  0.939648449420929,\n",
       "  0.965039074420929,\n",
       "  0.9556640982627869,\n",
       "  0.9390625357627869,\n",
       "  0.858593761920929,\n",
       "  0.943164050579071,\n",
       "  0.92578125,\n",
       "  0.9326171875,\n",
       "  0.9007812738418579,\n",
       "  0.828906238079071,\n",
       "  0.9341797232627869,\n",
       "  0.8720703125,\n",
       "  0.931445300579071,\n",
       "  0.922070324420929,\n",
       "  0.885937511920929,\n",
       "  0.9136719107627869,\n",
       "  0.9429687857627869,\n",
       "  0.8080078363418579,\n",
       "  0.8548828363418579,\n",
       "  0.9267578125,\n",
       "  0.9310547113418579,\n",
       "  0.874218761920929,\n",
       "  0.877148449420929,\n",
       "  0.850781261920929,\n",
       "  0.7613281607627869,\n",
       "  0.8218750357627869,\n",
       "  0.862109363079071,\n",
       "  0.7896484732627869,\n",
       "  0.9156250357627869,\n",
       "  0.8382812738418579,\n",
       "  0.9605469107627869,\n",
       "  0.9292969107627869,\n",
       "  0.9146484732627869,\n",
       "  0.9439453482627869,\n",
       "  0.919726550579071,\n",
       "  0.9468750357627869,\n",
       "  0.8990234732627869,\n",
       "  0.9535156488418579,\n",
       "  0.9126953482627869,\n",
       "  0.9126953482627869,\n",
       "  0.929492175579071,\n",
       "  0.9117187857627869,\n",
       "  0.9068359732627869,\n",
       "  0.9019531607627869,\n",
       "  0.9150390625,\n",
       "  0.834179699420929,\n",
       "  0.9052734375,\n",
       "  0.8974609375,\n",
       "  0.8316406607627869,\n",
       "  0.8990234732627869,\n",
       "  0.8882812857627869,\n",
       "  0.879687488079071,\n",
       "  0.84765625,\n",
       "  0.916796863079071,\n",
       "  0.8970703482627869,\n",
       "  0.8970703482627869,\n",
       "  0.904101550579071,\n",
       "  0.9046875238418579,\n",
       "  0.918749988079071,\n",
       "  0.761914074420929,\n",
       "  0.9261718988418579,\n",
       "  0.8960937857627869,\n",
       "  0.80859375,\n",
       "  0.8951172232627869,\n",
       "  0.8935546875,\n",
       "  0.916796863079071,\n",
       "  0.8871093988418579,\n",
       "  0.927929699420929,\n",
       "  0.902148425579071,\n",
       "  0.949023425579071,\n",
       "  0.8921875357627869,\n",
       "  0.8822265863418579,\n",
       "  0.9017578363418579,\n",
       "  0.8257812857627869,\n",
       "  0.833203136920929,\n",
       "  0.8685547113418579,\n",
       "  0.9078125357627869,\n",
       "  0.9302734732627869,\n",
       "  0.941601574420929,\n",
       "  0.8212890625,\n",
       "  0.8921875357627869,\n",
       "  0.9242187738418579,\n",
       "  0.9527344107627869,\n",
       "  0.9365234375,\n",
       "  0.865234375,\n",
       "  0.8873047232627869,\n",
       "  0.926562488079071,\n",
       "  0.928515613079071,\n",
       "  0.9193359613418579,\n",
       "  0.9107422232627869,\n",
       "  0.930859386920929,\n",
       "  0.912109375,\n",
       "  0.901562511920929,\n",
       "  0.9302734732627869,\n",
       "  0.8853515982627869,\n",
       "  0.8951172232627869,\n",
       "  0.949414074420929,\n",
       "  0.948046863079071,\n",
       "  0.9400390982627869,\n",
       "  0.9326171875,\n",
       "  0.8910156488418579,\n",
       "  0.9625000357627869,\n",
       "  0.928515613079071,\n",
       "  0.914257824420929,\n",
       "  0.957812488079071,\n",
       "  0.9296875,\n",
       "  0.9400390982627869,\n",
       "  0.914257824420929,\n",
       "  0.951953113079071,\n",
       "  0.8941406607627869,\n",
       "  0.8792968988418579,\n",
       "  0.879101574420929,\n",
       "  0.892382800579071,\n",
       "  0.9068359732627869,\n",
       "  0.931835949420929,\n",
       "  0.926953136920929,\n",
       "  0.9183593988418579,\n",
       "  0.9398437738418579,\n",
       "  0.943359375,\n",
       "  0.9173828363418579,\n",
       "  0.955273449420929,\n",
       "  0.9232422113418579,\n",
       "  0.8822265863418579,\n",
       "  0.939648449420929,\n",
       "  0.927929699420929],\n",
       " 'val_tp': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  8.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  7.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  2.0,\n",
       "  3.0,\n",
       "  5.0,\n",
       "  2.0,\n",
       "  2.0,\n",
       "  3.0,\n",
       "  4.0,\n",
       "  8.0,\n",
       "  7.0,\n",
       "  5.0,\n",
       "  5.0,\n",
       "  4.0,\n",
       "  6.0,\n",
       "  0.0,\n",
       "  2.0,\n",
       "  3.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  4.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  15.0,\n",
       "  2.0,\n",
       "  11.0,\n",
       "  6.0,\n",
       "  4.0,\n",
       "  12.0,\n",
       "  4.0,\n",
       "  25.0,\n",
       "  9.0,\n",
       "  0.0,\n",
       "  16.0,\n",
       "  24.0,\n",
       "  18.0,\n",
       "  23.0,\n",
       "  10.0,\n",
       "  12.0,\n",
       "  9.0,\n",
       "  13.0,\n",
       "  10.0,\n",
       "  25.0,\n",
       "  15.0,\n",
       "  15.0,\n",
       "  5.0,\n",
       "  14.0,\n",
       "  22.0,\n",
       "  25.0,\n",
       "  30.0,\n",
       "  23.0,\n",
       "  10.0,\n",
       "  20.0,\n",
       "  4.0,\n",
       "  25.0,\n",
       "  26.0,\n",
       "  35.0,\n",
       "  26.0,\n",
       "  16.0,\n",
       "  18.0,\n",
       "  24.0,\n",
       "  21.0,\n",
       "  13.0,\n",
       "  8.0,\n",
       "  13.0,\n",
       "  21.0,\n",
       "  28.0,\n",
       "  29.0,\n",
       "  47.0,\n",
       "  37.0,\n",
       "  20.0,\n",
       "  28.0,\n",
       "  36.0,\n",
       "  28.0,\n",
       "  51.0,\n",
       "  27.0,\n",
       "  32.0,\n",
       "  64.0,\n",
       "  26.0,\n",
       "  26.0,\n",
       "  26.0,\n",
       "  39.0,\n",
       "  31.0,\n",
       "  24.0,\n",
       "  31.0,\n",
       "  16.0,\n",
       "  14.0,\n",
       "  35.0,\n",
       "  30.0,\n",
       "  18.0,\n",
       "  13.0,\n",
       "  28.0,\n",
       "  50.0,\n",
       "  22.0,\n",
       "  31.0,\n",
       "  25.0,\n",
       "  45.0,\n",
       "  49.0,\n",
       "  34.0,\n",
       "  51.0,\n",
       "  29.0,\n",
       "  31.0,\n",
       "  51.0,\n",
       "  32.0,\n",
       "  23.0,\n",
       "  57.0,\n",
       "  45.0,\n",
       "  29.0,\n",
       "  30.0,\n",
       "  36.0,\n",
       "  48.0,\n",
       "  48.0,\n",
       "  67.0,\n",
       "  49.0,\n",
       "  58.0,\n",
       "  56.0,\n",
       "  41.0,\n",
       "  48.0,\n",
       "  21.0,\n",
       "  33.0,\n",
       "  41.0,\n",
       "  38.0,\n",
       "  36.0,\n",
       "  33.0,\n",
       "  38.0,\n",
       "  19.0,\n",
       "  37.0,\n",
       "  23.0,\n",
       "  31.0,\n",
       "  42.0,\n",
       "  45.0,\n",
       "  40.0,\n",
       "  40.0,\n",
       "  58.0,\n",
       "  42.0,\n",
       "  51.0,\n",
       "  54.0,\n",
       "  41.0,\n",
       "  51.0,\n",
       "  50.0,\n",
       "  54.0,\n",
       "  41.0,\n",
       "  40.0,\n",
       "  52.0,\n",
       "  37.0,\n",
       "  37.0,\n",
       "  35.0,\n",
       "  70.0,\n",
       "  27.0,\n",
       "  38.0,\n",
       "  51.0,\n",
       "  44.0,\n",
       "  49.0,\n",
       "  38.0,\n",
       "  42.0,\n",
       "  41.0,\n",
       "  42.0,\n",
       "  28.0,\n",
       "  41.0,\n",
       "  43.0,\n",
       "  46.0,\n",
       "  59.0,\n",
       "  65.0,\n",
       "  56.0,\n",
       "  45.0,\n",
       "  35.0,\n",
       "  33.0,\n",
       "  57.0,\n",
       "  52.0,\n",
       "  34.0,\n",
       "  25.0,\n",
       "  25.0,\n",
       "  56.0,\n",
       "  48.0,\n",
       "  31.0,\n",
       "  42.0,\n",
       "  40.0,\n",
       "  49.0,\n",
       "  29.0,\n",
       "  45.0,\n",
       "  51.0,\n",
       "  35.0,\n",
       "  53.0,\n",
       "  43.0,\n",
       "  28.0,\n",
       "  26.0,\n",
       "  29.0,\n",
       "  35.0,\n",
       "  40.0,\n",
       "  20.0,\n",
       "  39.0,\n",
       "  42.0,\n",
       "  18.0,\n",
       "  34.0,\n",
       "  30.0,\n",
       "  41.0,\n",
       "  27.0,\n",
       "  42.0,\n",
       "  52.0,\n",
       "  51.0,\n",
       "  39.0,\n",
       "  35.0,\n",
       "  31.0,\n",
       "  29.0,\n",
       "  32.0,\n",
       "  40.0,\n",
       "  23.0,\n",
       "  38.0,\n",
       "  17.0,\n",
       "  35.0,\n",
       "  44.0,\n",
       "  32.0,\n",
       "  38.0],\n",
       " 'val_auc': [0.5,\n",
       "  0.5,\n",
       "  0.5,\n",
       "  0.4985046088695526,\n",
       "  0.5,\n",
       "  0.4909224808216095,\n",
       "  0.4999999701976776,\n",
       "  0.5933950543403625,\n",
       "  0.4957544207572937,\n",
       "  0.6929830312728882,\n",
       "  0.6928179860115051,\n",
       "  0.6895502209663391,\n",
       "  0.6976335644721985,\n",
       "  0.713718831539154,\n",
       "  0.707024335861206,\n",
       "  0.6126794219017029,\n",
       "  0.6813645362854004,\n",
       "  0.6917180418968201,\n",
       "  0.6541934013366699,\n",
       "  0.6939428448677063,\n",
       "  0.7538732886314392,\n",
       "  0.7107635140419006,\n",
       "  0.7780953049659729,\n",
       "  0.7907284498214722,\n",
       "  0.7776488661766052,\n",
       "  0.7669352293014526,\n",
       "  0.761322557926178,\n",
       "  0.7725642919540405,\n",
       "  0.7707471251487732,\n",
       "  0.7218599915504456,\n",
       "  0.7620642781257629,\n",
       "  0.7754305005073547,\n",
       "  0.8158689737319946,\n",
       "  0.805006206035614,\n",
       "  0.7890713810920715,\n",
       "  0.7165947556495667,\n",
       "  0.7772164940834045,\n",
       "  0.8084011673927307,\n",
       "  0.785636842250824,\n",
       "  0.7981128692626953,\n",
       "  0.8028606176376343,\n",
       "  0.8102642893791199,\n",
       "  0.806586503982544,\n",
       "  0.8298624753952026,\n",
       "  0.8454048037528992,\n",
       "  0.8177476525306702,\n",
       "  0.8198315501213074,\n",
       "  0.8203297257423401,\n",
       "  0.8197153210639954,\n",
       "  0.8282461166381836,\n",
       "  0.793261706829071,\n",
       "  0.8033812046051025,\n",
       "  0.8314204812049866,\n",
       "  0.8396694660186768,\n",
       "  0.8249485492706299,\n",
       "  0.7960328459739685,\n",
       "  0.8184674382209778,\n",
       "  0.8092634677886963,\n",
       "  0.8400000333786011,\n",
       "  0.8291587829589844,\n",
       "  0.8219838738441467,\n",
       "  0.8065559267997742,\n",
       "  0.8322126865386963,\n",
       "  0.8239482045173645,\n",
       "  0.8391433358192444,\n",
       "  0.8055410385131836,\n",
       "  0.7963442802429199,\n",
       "  0.7921535968780518,\n",
       "  0.8184506893157959,\n",
       "  0.7867145538330078,\n",
       "  0.8023141026496887,\n",
       "  0.8237655162811279,\n",
       "  0.7942203879356384,\n",
       "  0.8349121809005737,\n",
       "  0.8186039924621582,\n",
       "  0.8500584363937378,\n",
       "  0.7872146964073181,\n",
       "  0.857937216758728,\n",
       "  0.8221942186355591,\n",
       "  0.8283215165138245,\n",
       "  0.8429756164550781,\n",
       "  0.8381710648536682,\n",
       "  0.8170623779296875,\n",
       "  0.8434548377990723,\n",
       "  0.8428072929382324,\n",
       "  0.8548499941825867,\n",
       "  0.8556895852088928,\n",
       "  0.8251632452011108,\n",
       "  0.8567197918891907,\n",
       "  0.8562553524971008,\n",
       "  0.8526080250740051,\n",
       "  0.8468083739280701,\n",
       "  0.7886744141578674,\n",
       "  0.8479424715042114,\n",
       "  0.8217803239822388,\n",
       "  0.8583821654319763,\n",
       "  0.8497410416603088,\n",
       "  0.8205103874206543,\n",
       "  0.8414146900177002,\n",
       "  0.8287586569786072,\n",
       "  0.8618333339691162,\n",
       "  0.8449525237083435,\n",
       "  0.8370195031166077,\n",
       "  0.8490024209022522,\n",
       "  0.8325352668762207,\n",
       "  0.8444448709487915,\n",
       "  0.8297261595726013,\n",
       "  0.8556765913963318,\n",
       "  0.8418117165565491,\n",
       "  0.8086720108985901,\n",
       "  0.8466554880142212,\n",
       "  0.8313212394714355,\n",
       "  0.8237289190292358,\n",
       "  0.8379294276237488,\n",
       "  0.8356575965881348,\n",
       "  0.8434902429580688,\n",
       "  0.8447283506393433,\n",
       "  0.8459980487823486,\n",
       "  0.8118042945861816,\n",
       "  0.8397002816200256,\n",
       "  0.8460904955863953,\n",
       "  0.8485156893730164,\n",
       "  0.8300222754478455,\n",
       "  0.8526620268821716,\n",
       "  0.8328375816345215,\n",
       "  0.8419839143753052,\n",
       "  0.8587959408760071,\n",
       "  0.8381803035736084,\n",
       "  0.8018003106117249,\n",
       "  0.8161811232566833,\n",
       "  0.8632832169532776,\n",
       "  0.8448529839515686,\n",
       "  0.8116610646247864,\n",
       "  0.8403236269950867,\n",
       "  0.8429476618766785,\n",
       "  0.8498529195785522,\n",
       "  0.8452367782592773,\n",
       "  0.8575947880744934,\n",
       "  0.8425350189208984,\n",
       "  0.8368302583694458,\n",
       "  0.8332303762435913,\n",
       "  0.8548493385314941,\n",
       "  0.8527177572250366,\n",
       "  0.7883941531181335,\n",
       "  0.8205599784851074,\n",
       "  0.831047534942627,\n",
       "  0.8181399703025818,\n",
       "  0.8398752212524414,\n",
       "  0.8317024111747742,\n",
       "  0.847869873046875,\n",
       "  0.8129088878631592,\n",
       "  0.8168060779571533,\n",
       "  0.8151635527610779,\n",
       "  0.8614420890808105,\n",
       "  0.8032783269882202,\n",
       "  0.8408874273300171,\n",
       "  0.8122269511222839,\n",
       "  0.8347065448760986,\n",
       "  0.8362185955047607,\n",
       "  0.8389704823493958,\n",
       "  0.8619421720504761,\n",
       "  0.8409037590026855,\n",
       "  0.8060329556465149,\n",
       "  0.861249566078186,\n",
       "  0.6883226633071899,\n",
       "  0.8422397375106812,\n",
       "  0.7946723103523254,\n",
       "  0.8545933961868286,\n",
       "  0.8412342071533203,\n",
       "  0.8621581196784973,\n",
       "  0.8516507148742676,\n",
       "  0.8555202484130859,\n",
       "  0.8545633554458618,\n",
       "  0.852038562297821,\n",
       "  0.8415554165840149,\n",
       "  0.8348165154457092,\n",
       "  0.8527035117149353,\n",
       "  0.8685982823371887,\n",
       "  0.850726306438446,\n",
       "  0.8521517515182495,\n",
       "  0.8372602462768555,\n",
       "  0.846061110496521,\n",
       "  0.8517415523529053,\n",
       "  0.8446033000946045,\n",
       "  0.8526995182037354,\n",
       "  0.8306708335876465,\n",
       "  0.8548019528388977,\n",
       "  0.8162601590156555,\n",
       "  0.8326945900917053,\n",
       "  0.837622880935669,\n",
       "  0.8590100407600403,\n",
       "  0.8436744213104248,\n",
       "  0.8701852560043335,\n",
       "  0.8450349569320679,\n",
       "  0.8279972076416016,\n",
       "  0.8550639748573303,\n",
       "  0.8436171412467957,\n",
       "  0.8356460928916931,\n",
       "  0.8177220821380615,\n",
       "  0.8511425852775574,\n",
       "  0.851542055606842,\n",
       "  0.8755073547363281,\n",
       "  0.85884690284729,\n",
       "  0.8499537706375122,\n",
       "  0.8339583873748779,\n",
       "  0.8247072696685791,\n",
       "  0.8466956615447998,\n",
       "  0.870082676410675,\n",
       "  0.8202243447303772,\n",
       "  0.8103190064430237,\n",
       "  0.8343104124069214,\n",
       "  0.8570024371147156,\n",
       "  0.8535782694816589,\n",
       "  0.8058145642280579,\n",
       "  0.8450820446014404,\n",
       "  0.837148129940033,\n",
       "  0.8439124822616577,\n",
       "  0.7889043688774109,\n",
       "  0.8660436868667603,\n",
       "  0.8420816659927368,\n",
       "  0.8256849050521851,\n",
       "  0.8416692018508911,\n",
       "  0.8526963591575623,\n",
       "  0.7628492116928101,\n",
       "  0.8095876574516296,\n",
       "  0.8343666195869446,\n",
       "  0.8422040939331055,\n",
       "  0.8353585600852966,\n",
       "  0.7515614628791809,\n",
       "  0.8343414664268494,\n",
       "  0.8416885137557983,\n",
       "  0.8217290639877319,\n",
       "  0.8130732774734497,\n",
       "  0.8375739455223083,\n",
       "  0.8575755953788757,\n",
       "  0.829645037651062,\n",
       "  0.8357590436935425,\n",
       "  0.8458378314971924,\n",
       "  0.8304534554481506,\n",
       "  0.8192651271820068,\n",
       "  0.8318321108818054,\n",
       "  0.8251186013221741,\n",
       "  0.826525092124939,\n",
       "  0.7924635410308838,\n",
       "  0.8348568081855774,\n",
       "  0.7860766053199768,\n",
       "  0.8524117469787598,\n",
       "  0.7622519135475159,\n",
       "  0.8055943250656128,\n",
       "  0.8093395829200745,\n",
       "  0.8169112205505371,\n",
       "  0.8206786513328552],\n",
       " 'val_fn': [87.0,\n",
       "  85.0,\n",
       "  84.0,\n",
       "  85.0,\n",
       "  88.0,\n",
       "  84.0,\n",
       "  83.0,\n",
       "  87.0,\n",
       "  86.0,\n",
       "  86.0,\n",
       "  91.0,\n",
       "  83.0,\n",
       "  87.0,\n",
       "  86.0,\n",
       "  89.0,\n",
       "  83.0,\n",
       "  85.0,\n",
       "  85.0,\n",
       "  84.0,\n",
       "  84.0,\n",
       "  84.0,\n",
       "  85.0,\n",
       "  88.0,\n",
       "  85.0,\n",
       "  91.0,\n",
       "  84.0,\n",
       "  85.0,\n",
       "  87.0,\n",
       "  88.0,\n",
       "  86.0,\n",
       "  82.0,\n",
       "  88.0,\n",
       "  83.0,\n",
       "  85.0,\n",
       "  87.0,\n",
       "  78.0,\n",
       "  87.0,\n",
       "  82.0,\n",
       "  81.0,\n",
       "  86.0,\n",
       "  85.0,\n",
       "  86.0,\n",
       "  78.0,\n",
       "  78.0,\n",
       "  82.0,\n",
       "  83.0,\n",
       "  82.0,\n",
       "  83.0,\n",
       "  79.0,\n",
       "  80.0,\n",
       "  81.0,\n",
       "  80.0,\n",
       "  85.0,\n",
       "  81.0,\n",
       "  84.0,\n",
       "  82.0,\n",
       "  84.0,\n",
       "  87.0,\n",
       "  85.0,\n",
       "  80.0,\n",
       "  86.0,\n",
       "  84.0,\n",
       "  71.0,\n",
       "  85.0,\n",
       "  77.0,\n",
       "  81.0,\n",
       "  81.0,\n",
       "  75.0,\n",
       "  79.0,\n",
       "  62.0,\n",
       "  79.0,\n",
       "  88.0,\n",
       "  71.0,\n",
       "  61.0,\n",
       "  69.0,\n",
       "  58.0,\n",
       "  77.0,\n",
       "  74.0,\n",
       "  78.0,\n",
       "  74.0,\n",
       "  75.0,\n",
       "  59.0,\n",
       "  71.0,\n",
       "  72.0,\n",
       "  75.0,\n",
       "  72.0,\n",
       "  66.0,\n",
       "  61.0,\n",
       "  59.0,\n",
       "  62.0,\n",
       "  76.0,\n",
       "  65.0,\n",
       "  81.0,\n",
       "  63.0,\n",
       "  60.0,\n",
       "  50.0,\n",
       "  61.0,\n",
       "  68.0,\n",
       "  66.0,\n",
       "  62.0,\n",
       "  60.0,\n",
       "  75.0,\n",
       "  79.0,\n",
       "  76.0,\n",
       "  65.0,\n",
       "  59.0,\n",
       "  58.0,\n",
       "  40.0,\n",
       "  50.0,\n",
       "  65.0,\n",
       "  58.0,\n",
       "  50.0,\n",
       "  56.0,\n",
       "  37.0,\n",
       "  61.0,\n",
       "  52.0,\n",
       "  23.0,\n",
       "  61.0,\n",
       "  54.0,\n",
       "  60.0,\n",
       "  46.0,\n",
       "  52.0,\n",
       "  58.0,\n",
       "  57.0,\n",
       "  70.0,\n",
       "  76.0,\n",
       "  53.0,\n",
       "  54.0,\n",
       "  65.0,\n",
       "  74.0,\n",
       "  58.0,\n",
       "  35.0,\n",
       "  66.0,\n",
       "  53.0,\n",
       "  58.0,\n",
       "  48.0,\n",
       "  34.0,\n",
       "  53.0,\n",
       "  33.0,\n",
       "  53.0,\n",
       "  52.0,\n",
       "  38.0,\n",
       "  54.0,\n",
       "  61.0,\n",
       "  30.0,\n",
       "  40.0,\n",
       "  56.0,\n",
       "  57.0,\n",
       "  48.0,\n",
       "  37.0,\n",
       "  40.0,\n",
       "  19.0,\n",
       "  41.0,\n",
       "  28.0,\n",
       "  30.0,\n",
       "  43.0,\n",
       "  40.0,\n",
       "  63.0,\n",
       "  55.0,\n",
       "  47.0,\n",
       "  49.0,\n",
       "  47.0,\n",
       "  52.0,\n",
       "  45.0,\n",
       "  65.0,\n",
       "  46.0,\n",
       "  60.0,\n",
       "  53.0,\n",
       "  44.0,\n",
       "  42.0,\n",
       "  46.0,\n",
       "  50.0,\n",
       "  29.0,\n",
       "  44.0,\n",
       "  38.0,\n",
       "  33.0,\n",
       "  41.0,\n",
       "  36.0,\n",
       "  37.0,\n",
       "  33.0,\n",
       "  44.0,\n",
       "  45.0,\n",
       "  35.0,\n",
       "  49.0,\n",
       "  48.0,\n",
       "  50.0,\n",
       "  18.0,\n",
       "  61.0,\n",
       "  51.0,\n",
       "  35.0,\n",
       "  45.0,\n",
       "  38.0,\n",
       "  47.0,\n",
       "  42.0,\n",
       "  45.0,\n",
       "  41.0,\n",
       "  59.0,\n",
       "  40.0,\n",
       "  43.0,\n",
       "  40.0,\n",
       "  29.0,\n",
       "  21.0,\n",
       "  30.0,\n",
       "  41.0,\n",
       "  51.0,\n",
       "  51.0,\n",
       "  28.0,\n",
       "  35.0,\n",
       "  53.0,\n",
       "  61.0,\n",
       "  60.0,\n",
       "  34.0,\n",
       "  38.0,\n",
       "  54.0,\n",
       "  43.0,\n",
       "  47.0,\n",
       "  37.0,\n",
       "  59.0,\n",
       "  37.0,\n",
       "  38.0,\n",
       "  53.0,\n",
       "  36.0,\n",
       "  40.0,\n",
       "  56.0,\n",
       "  60.0,\n",
       "  57.0,\n",
       "  53.0,\n",
       "  45.0,\n",
       "  66.0,\n",
       "  45.0,\n",
       "  45.0,\n",
       "  71.0,\n",
       "  52.0,\n",
       "  54.0,\n",
       "  42.0,\n",
       "  56.0,\n",
       "  43.0,\n",
       "  33.0,\n",
       "  36.0,\n",
       "  48.0,\n",
       "  49.0,\n",
       "  53.0,\n",
       "  55.0,\n",
       "  54.0,\n",
       "  47.0,\n",
       "  63.0,\n",
       "  48.0,\n",
       "  65.0,\n",
       "  53.0,\n",
       "  41.0,\n",
       "  54.0,\n",
       "  48.0]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-08T19:49:29.722973Z",
     "iopub.status.busy": "2020-08-08T19:49:29.710030Z",
     "iopub.status.idle": "2020-08-08T19:49:31.392888Z",
     "shell.execute_reply": "2020-08-08T19:49:31.392234Z"
    },
    "papermill": {
     "duration": 2.237265,
     "end_time": "2020-08-08T19:49:31.393061",
     "exception": false,
     "start_time": "2020-08-08T19:49:29.155796",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.548759,
     "end_time": "2020-08-08T19:49:32.544337",
     "exception": false,
     "start_time": "2020-08-08T19:49:31.995578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.599784,
     "end_time": "2020-08-08T19:49:33.716253",
     "exception": false,
     "start_time": "2020-08-08T19:49:33.116469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "papermill": {
   "duration": 6034.99974,
   "end_time": "2020-08-08T19:49:34.408468",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-08T18:08:59.408728",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
