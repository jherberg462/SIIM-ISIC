{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'SIIM-ISIC'...\n",
      "remote: Enumerating objects: 9, done.\u001b[K\n",
      "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
      "remote: Compressing objects: 100% (9/9), done.\u001b[K\n",
      "remote: Total 9 (delta 1), reused 3 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (9/9), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/jherberg462/SIIM-ISIC.git --depth 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('SIIM-ISIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'batch_size' : 128,\n",
    "    'img_size' : 256, #length and width will be equal\n",
    "    'epochs': 400\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from create_params import update_env_variables\n",
    "update_env_variables(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got GCS path via KaggleDatasets .get_gcs_path method\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'params_scratch' from 'params' (/kaggle/working/SIIM-ISIC/params.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-14c780b7becb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m                             \u001b[0mnormalize_image_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_flip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m                             get_train_ds, get_test_ds, get_ds_size)\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mparams\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparams_scratch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'params_scratch' from 'params' (/kaggle/working/SIIM-ISIC/params.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "try:\n",
    "    from kaggle_datasets import KaggleDatasets\n",
    "    dataset_gcs = KaggleDatasets().get_gcs_path('siim-isic-melanoma-classification')\n",
    "    print('got GCS path via KaggleDatasets .get_gcs_path method')\n",
    "except ModuleNotFoundError:\n",
    "    #hardcode path while testing locally\n",
    "    dataset_gcs = 'gs://kds-599205fd0d8963558ce1308147ba090f776d31b1662a67f2ddccfa38'\n",
    "\n",
    "#\n",
    "from input_pipeline import (decode_image_label, decode_image, \n",
    "                            normalize_image_label, random_flip, \n",
    "                            get_train_ds, get_test_ds, get_ds_size)\n",
    "from params import params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = pd.read_csv(dataset_gcs + '/sample_submission.csv')\n",
    "# sub.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(dataset_gcs + '/train.csv')\n",
    "train_df.groupby('target').count() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decode_image_label(tfrec):\n",
    "#     '''\n",
    "#     function to decode an image and target label from tfrecord\n",
    "    \n",
    "#     args:\n",
    "#         tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "#     returns:\n",
    "#         decoded_image: tensor, converted image from tfrecord\n",
    "#         label: tensor, integer, either 1 or 0\n",
    "    \n",
    "#     '''\n",
    "    \n",
    "#     features_dictionary = {\n",
    "#         'image': tf.io.FixedLenFeature([], tf.string),\n",
    "#         \"target\": tf.io.FixedLenFeature([], tf.int64)\n",
    "#         }\n",
    "#     features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "#     decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "#     decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "#     label = features['target']\n",
    "    \n",
    "#     return decoded_image, label\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def decode_image(tfrec):\n",
    "#     '''\n",
    "#     function to decode an image from tfrecord\n",
    "    \n",
    "#     args:\n",
    "#         tfrec: tfrecord, single record of training/validation data\n",
    "    \n",
    "#     returns:\n",
    "#         decoded_image: tensor, converted image from tfrecord\n",
    "#         img_name: tensor, string, Id of the decoded image\n",
    "    \n",
    "#     '''\n",
    "    \n",
    "#     features_dictionary = {\n",
    "#         'image': tf.io.FixedLenFeature([], tf.string),\n",
    "#         \"image_name\": tf.io.FixedLenFeature([], tf.string)\n",
    "#         }\n",
    "#     features = tf.io.parse_single_example(tfrec, features_dictionary)\n",
    "#     decoded_image = tf.io.decode_jpeg(features['image'], 3)\n",
    "#     decoded_image = tf.image.resize(decoded_image, params['img_size'])\n",
    "#     img_name = features['image_name']\n",
    "    \n",
    "#     return decoded_image, img_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def normalize_image_label(decoded_image, label):\n",
    "#     '''\n",
    "#     function to convert an image tensor values from 0 to 255 \n",
    "#     -> -1 to 1\n",
    "#     to be used when dealing with tfrecords containing labels\n",
    "    \n",
    "#     args:\n",
    "#         decoded_image: tensor that is an image with values from 0 to 255\n",
    "#         label: tensor, target label\n",
    "    \n",
    "#     returns: \n",
    "#         image_tensor: tensor that is an image with values from -1 to 1\n",
    "#         label, same as input\n",
    "    \n",
    "#     '''\n",
    "    \n",
    "#     #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "#     image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "#     #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "#     image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "#     #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "#     image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "#     return image_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ***not needed? ***\n",
    "# def normalize_image(decoded_image):\n",
    "#     '''\n",
    "#     function to convert an image tensor values from 0 to 255 \n",
    "#     -> -1 to 1\n",
    "    \n",
    "#     args:\n",
    "#         decoded_image: tensor that is an image with values from 0 to 255\n",
    "    \n",
    "#     returns: \n",
    "#         image_tensor: tensor that is an image with values from -1 to 1\n",
    "    \n",
    "#     '''\n",
    "    \n",
    "#     #add dim at the zero axis Shape will be from (x, y, z) -> (None, x, y, z)\n",
    "#     image_tensor = tf.expand_dims(decoded_image, 0)\n",
    "#     #undo the above line -- this is needed due to TF not allowing a filtered tensor py_function\n",
    "#     image_tensor = tf.gather(image_tensor, 0)\n",
    "\n",
    "#     #convert tensor values to between -1 and 1 (0 to 255 -> -1 to 1)\n",
    "#     image_tensor = (tf.cast(image_tensor, tf.float32) - 127.5) / 127.5\n",
    "\n",
    "#     return image_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def random_flip(image, label):\n",
    "#     '''\n",
    "#     function to randomly flip images on the x and/or y axis\n",
    "    \n",
    "#     args:\n",
    "#         image: tensor, an image\n",
    "#         label: tensor, target label\n",
    "    \n",
    "#     returns: \n",
    "#         image: tensor, same as input, but possibly flipped on x and/or y axis\n",
    "#         label, tensor, same as input\n",
    "#     '''\n",
    "#     image = tf.image.random_flip_left_right(image)\n",
    "#     image = tf.image.random_flip_up_down(image)\n",
    "#     return image, label  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_train_ds(tfrecords, batch_size):\n",
    "#     '''\n",
    "#     function to create a ds pipeline from tfrecord files\n",
    "    \n",
    "#     args:\n",
    "#         tfrecords: list, tfrecord file paths\n",
    "#         batch_size: int, batch size for number of records to pass into\n",
    "#             model at a time\n",
    "#     returns:\n",
    "#         ds: tensorflow input pipeline with images and labels\n",
    "#     '''\n",
    "#     ds = (tf.data.TFRecordDataset(filenames=[tfrecords],\n",
    "#                                  num_parallel_reads=tf.data.experimental.AUTOTUNE).\n",
    "#           cache(). #need to remove cache while not usnig TPUs\n",
    "#           map(decode_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "#           map(normalize_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "#           map(random_flip, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "#           repeat().\n",
    "#           shuffle(512).\n",
    "#           batch(batch_size,\n",
    "#                drop_remainder=True).\n",
    "#           prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#          )\n",
    "    \n",
    "\n",
    "    \n",
    "#     return ds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_test_ds(tfrecords, batch_size):\n",
    "#     '''\n",
    "#     function to create a dataset for test data\n",
    "#     args:\n",
    "#         tfrecords: list, tfrecord file paths\n",
    "#         batch_size: int, batch size for number of records to pass into\n",
    "#             model at a time\n",
    "#     returns:\n",
    "#         ds: tensorflow input pipeline with images and labels\n",
    "    \n",
    "#     '''\n",
    "\n",
    "#     ds = (tf.data.TFRecordDataset(filenames=[tfrecords],\n",
    "#                                  num_parallel_reads=tf.data.experimental.AUTOTUNE).\n",
    "# #           cache(). #there is no reason to cache this ds -- it is only being read 1x\n",
    "#           map(decode_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "#           map(normalize_image_label, num_parallel_calls=tf.data.experimental.AUTOTUNE).\n",
    "# #           map(random_flip).\n",
    "#           batch(batch_size).\n",
    "# #                 drop_remainder=True).\n",
    "#           prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#          )\n",
    "    \n",
    "#     return ds\n",
    "#     ###come back to this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_of_layers(model_, filters_, kernal, strides_, dropout=0):\n",
    "    '''\n",
    "    function to add the following layers to a model:\n",
    "    Conv2D, MaxPooling2D, BatchNormalization, LeadyReLU, Dropout\n",
    "\n",
    "    args:\n",
    "      model_ : tf.keras.Sequential model\n",
    "      filters_: int, number of filters in Conv2D layer\n",
    "      kernal: int, kernal size in Conv2D layer\n",
    "      strides_: int, stride size in MaxPooling2D layer\n",
    "      dropout: float, dropout percentage in Dropout layer, default is 0.0\n",
    "        must be less than 1.0\n",
    "\n",
    "    returns:\n",
    "      model_: tf.keras.Sequential model that is the same as the model_ input plus above \n",
    "        layers added\n",
    "    '''\n",
    "    model_.add(layers.Conv2D(filters_, (kernal, kernal), padding='same'))\n",
    "    model_.add(layers.MaxPooling2D(strides_, strides_))\n",
    "    model_.add(layers.BatchNormalization())\n",
    "    model_.add(layers.ReLU()) #also try ReLU // LeakyReLU\n",
    "    model_.add(layers.Dense(16)) #try activation fn here\n",
    "    model_.add(layers.Dropout(0.5)) #hold off on this for now //hardcode at 0.1\n",
    "\n",
    "    return model_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deconv_set_of_layers(model_, filters_, kernal_, stride):\n",
    "    '''\n",
    "    function to add the following layers to a model:\n",
    "    Conv2DTranspose, BatchNormalization, LeadyReLU, Dense\n",
    "\n",
    "    args:\n",
    "      model_ : tf.keras.Sequential model\n",
    "      filters_: int, number of filters in Conv2DTranspose layer\n",
    "      kernal_: int, kernal size in Conv2DTranspose layer\n",
    "      strides_: int, stride size in Conv2DTranspose layer\n",
    "\n",
    "\n",
    "    returns:\n",
    "      model_: tf.keras.Sequential model that is the same as the model_ input plus above \n",
    "        layers added\n",
    "    '''\n",
    "    model_.add(layers.Conv2DTranspose(filters_,\n",
    "                                     kernal_,\n",
    "                                     (stride, stride),\n",
    "                                     padding='same'))\n",
    "    model_.add(layers.BatchNormalization())\n",
    "    model_.add(layers.Dense(16, activation='tanh')) #keep this hardcoded for now\n",
    "    model_.add(layers.Dropout(0.5))\n",
    "    return model_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape=[*params['img_size'], 3], bias_output=None):\n",
    "    '''\n",
    "    function to create a model that will be trained on train DS\n",
    "    \n",
    "    args:\n",
    "        input_shape: array, default: [1024, 1024, 3], shape\n",
    "            of input tensor that will be fed into model\n",
    "    \n",
    "    returns:\n",
    "        model: tf.sequential() model\n",
    "    '''\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(layers.Conv2D(32, (5, 5), padding='same',\n",
    "                                     input_shape=input_shape)) \n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dense(16))\n",
    "    model.add(layers.Dropout(.5))\n",
    "    \n",
    "    set_of_layers(model, 128, 5, 2)\n",
    "    set_of_layers(model, 256, 5, 2)\n",
    "    set_of_layers(model, 512, 5, 2)\n",
    "    set_of_layers(model, 1024, 5, 2)\n",
    "    deconv_set_of_layers(model, 256, 4, 2)\n",
    "    deconv_set_of_layers(model, 128, 4, 2)\n",
    "    deconv_set_of_layers(model, 64, 4, 2)\n",
    "    \n",
    "    set_of_layers(model, 64, 5, 2)\n",
    "    set_of_layers(model, 128, 5, 2)\n",
    "    set_of_layers(model, 256, 5, 2)\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128))\n",
    "#     model.add(layers.Dense(64))\n",
    "    \n",
    "    if bias_output is not None:\n",
    "        bias_output = tf.keras.initializers.Constant(bias_output)\n",
    "    model.add(layers.Dense(1, activation='sigmoid', bias_initializer=bias_output))\n",
    "    \n",
    "\n",
    "    metrics = [\n",
    "          keras.metrics.TruePositives(name='tp'),\n",
    "#           keras.metrics.FalsePositives(name='fp'),\n",
    "#           keras.metrics.TrueNegatives(name='tn'),\n",
    "          keras.metrics.FalseNegatives(name='fn'), \n",
    "          keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "#           keras.metrics.Precision(name='precision'),\n",
    "#           keras.metrics.Recall(name='recall'),\n",
    "          keras.metrics.AUC(name='auc'),\n",
    "    ]\n",
    "    schedule = None\n",
    "    \n",
    "    model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.0001),\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing = 0.01),\n",
    "    metrics=metrics\n",
    ")\n",
    "    \n",
    "\n",
    "    \n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_size(files):\n",
    "    '''\n",
    "    function to get size of tfrecord Dataset, based on file name\n",
    "    \n",
    "    the file name has the number of records in the file, for example:\n",
    "    train09-2071.tfrec has 2017 records\n",
    "    \n",
    "    args:\n",
    "        files: list of str file names, each item should be the path to a tfrecord file\n",
    "    \n",
    "    returns:\n",
    "        size: int, size of dataset\n",
    "    '''\n",
    "    size = 0\n",
    "    for file in files:\n",
    "        file_size = int(file.split('.tfrec')[0].split('tfrecords/')[1].split('-')[1])\n",
    "        size += file_size\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get test file paths\n",
    "test_files = tf.io.gfile.glob(dataset_gcs + '/tfrecords/test*.tfrec')\n",
    "\n",
    "#get train and validation file paths\n",
    "train_files, valid_files = train_test_split(tf.io.gfile.glob(dataset_gcs + '/tfrecords/train*.tfrec'),\n",
    "                              test_size=.1, random_state=1)\n",
    "\n",
    "#create datasets\n",
    "train_ds = get_train_ds(train_files, params['batch_size'])\n",
    "valid_ds = get_train_ds(valid_files, params['batch_size'])\n",
    "test_ds = get_test_ds(test_files, params['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, valid_size = get_ds_size(train_files), get_ds_size(valid_files)\n",
    "test_size = get_ds_size(test_files)\n",
    "print('the dataset consists of: {} training images, {} validation images, and {} test images'.\n",
    "     format(train_size, valid_size, test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_steps = train_size / params['batch_size'] \n",
    "valid_steps = valid_size / params['batch_size']\n",
    "test_steps = 1.0 * test_size / params['batch_size'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate class weights\n",
    "\n",
    "targets = train_df.groupby('target').count()['diagnosis'].to_list()\n",
    "target_0 = targets[0]\n",
    "target_1 = targets[1]\n",
    "total = target_0 + target_1\n",
    "\n",
    "class_weight_0 = (1 / target_0) * (total) / 2.0\n",
    "class_weight_1 = (1 / target_1) * (total) / 2.0\n",
    "\n",
    "class_weights = {0: class_weight_0, 1: class_weight_1}\n",
    "\n",
    "initial_bias = np.log([target_1 / target_0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model = create_model(bias_output=initial_bias)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc', #val_auc\n",
    "                                patience=40,\n",
    "                                mode='max',\n",
    "                                restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "#     batch_size=params['batch_size'],\n",
    "    epochs= params['epochs'], \n",
    "    steps_per_epoch=epoch_steps,\n",
    "    validation_data=valid_ds,\n",
    "    validation_steps=valid_steps,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_ds.map(lambda img, igs: img), steps=test_steps)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_ids = next(iter(test_ds.\n",
    "                          map(lambda img, ids:ids).\n",
    "                          unbatch().\n",
    "                          batch(test_size))).numpy().astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_dict = {\n",
    "    'image_name': prediction_ids,\n",
    "    'target': np.concatenate(predictions)\n",
    "}\n",
    "submission_ds = pd.DataFrame(prediction_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ds.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(metric1, metric2, ylabel):\n",
    "    plt.plot(history.history[metric1], label=metric1)\n",
    "    plt.plot(history.history[metric2], label=metric2)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_metric('auc', 'val_auc', 'auc')\n",
    "plot_metric('loss', 'val_loss', 'loss')\n",
    "plot_metric('accuracy', 'val_accuracy', 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
